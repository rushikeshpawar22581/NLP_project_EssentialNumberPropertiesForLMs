{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy\n",
    "# %pip install pandas\n",
    "# %pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing the required libraries\n",
    "# %pip install transformers\n",
    "# %pip install torchtext\n",
    "# %pip install sentencepiece\n",
    "# %pip install datasets\n",
    "# %pip install torchmetrics\n",
    "# %pip install matplotlib\n",
    "# %pip install seaborn\n",
    "# %pip install scikit-learn\n",
    "# #huggiface download\n",
    "# %pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biomedialab/anaconda3/envs/viveksdmlenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the model llama 2 13b chat gguf\n",
    "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGUF\"\n",
    "model_basename = \"llama-2-13b-chat.Q5_K_S.gguf\" # the model is in gguf format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/biomedialab/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_S.gguf\n"
     ]
    }
   ],
   "source": [
    "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)\n",
    "\n",
    "#print toal path\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from /home/biomedialab/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_S.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 16\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q5_K:  281 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
      "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Small\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 8.36 GiB (5.51 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors:        CPU buffer size =  8555.93 MiB\n",
      "....................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   400.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  400.00 MiB, K (f16):  200.00 MiB, V (f16):  200.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    85.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1286\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '5120', 'llama.feed_forward_length': '13824', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '40', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '40', 'llama.attention.head_count_kv': '40', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '16'}\n",
      "Using fallback chat format: None\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "lcpp_llm = None\n",
    "lcpp_llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_threads=2, # CPU cores\n",
    "    n_batch=512, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "    n_gpu_layers=32 # Change this value based on your model and your GPU VRAM pool.\n",
    "    )\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt= f\"List the factors of 50?\"\n",
    "\n",
    "prompt_template=f'''You are a math assistant. I will ask you to find factors of given number. Please answer in the correct format. For example, if I ask 'List the factors of 15?' , you should answer 'factors=[1, 3, 5, 15]'. Do not include any other information in your answer.\n",
    "USER: {prompt}\n",
    "\n",
    "ASSISTANT:'''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       6.15 ms /    15 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4636.61 ms /    88 tokens (   52.69 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =    9516.08 ms /    14 runs   (  679.72 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14193.16 ms /   102 tokens\n"
     ]
    }
   ],
   "source": [
    "response=lcpp_llm(prompt=prompt_template, max_tokens=500, temperature=0.00001, top_p=0.95,\n",
    "                  repeat_penalty=1.2, top_k=150,\n",
    "                  echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " factors=[1, 2, 4, 50]\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load file in data folder int_addition.json\n",
    "with open('primality_test.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primes</th>\n",
       "      <th>composites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3187</td>\n",
       "      <td>99160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59509</td>\n",
       "      <td>12005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58787</td>\n",
       "      <td>33309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22861</td>\n",
       "      <td>73881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89519</td>\n",
       "      <td>78681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>38053</td>\n",
       "      <td>83445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>74797</td>\n",
       "      <td>35077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>78823</td>\n",
       "      <td>18386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>61751</td>\n",
       "      <td>19887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>25321</td>\n",
       "      <td>12784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      primes  composites\n",
       "0       3187       99160\n",
       "1      59509       12005\n",
       "2      58787       33309\n",
       "3      22861       73881\n",
       "4      89519       78681\n",
       "...      ...         ...\n",
       "4995   38053       83445\n",
       "4996   74797       35077\n",
       "4997   78823       18386\n",
       "4998   61751       19887\n",
       "4999   25321       12784\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data as pandas dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "#last 5 rows\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primes</th>\n",
       "      <th>composites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>99881</td>\n",
       "      <td>99938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>99901</td>\n",
       "      <td>99941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>99907</td>\n",
       "      <td>99954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>99929</td>\n",
       "      <td>99964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>99991</td>\n",
       "      <td>99979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      primes  composites\n",
       "0          2          33\n",
       "1         23          34\n",
       "2         31          45\n",
       "3         37          82\n",
       "4         41         126\n",
       "...      ...         ...\n",
       "4995   99881       99938\n",
       "4996   99901       99941\n",
       "4997   99907       99954\n",
       "4998   99929       99964\n",
       "4999   99991       99979\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df = pd.DataFrame({'primes': df.sort_values('primes')['primes'].values, 'composites': df.sort_values('composites')['composites'].values})\n",
    "\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       6.52 ms /    16 runs   (    0.41 ms per token,  2455.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1210.72 ms /    22 tokens (   55.03 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =   10179.27 ms /    15 runs   (  678.62 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11433.41 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    17 runs   (    0.47 ms per token,  2125.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     625.80 ms /    11 tokens (   56.89 ms per token,    17.58 tokens per second)\n",
      "llama_print_timings:        eval time =   10792.41 ms /    16 runs   (  674.53 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11468.90 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.28 ms /    20 runs   (    0.41 ms per token,  2416.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     723.82 ms /    12 tokens (   60.32 ms per token,    16.58 tokens per second)\n",
      "llama_print_timings:        eval time =   13428.90 ms /    19 runs   (  706.78 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   14206.20 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    19 runs   (    0.42 ms per token,  2374.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     711.75 ms /    12 tokens (   59.31 ms per token,    16.86 tokens per second)\n",
      "llama_print_timings:        eval time =   12086.27 ms /    18 runs   (  671.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12850.70 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.42 ms /    32 runs   (    0.45 ms per token,  2219.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     735.44 ms /    13 tokens (   56.57 ms per token,    17.68 tokens per second)\n",
      "llama_print_timings:        eval time =   20979.10 ms /    31 runs   (  676.75 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21807.67 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.05 ms /    17 runs   (    0.47 ms per token,  2111.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.46 ms /    12 tokens (   57.29 ms per token,    17.46 tokens per second)\n",
      "llama_print_timings:        eval time =   10994.86 ms /    16 runs   (  687.18 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   11733.02 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.10 ms /    32 runs   (    0.41 ms per token,  2443.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.96 ms /    12 tokens (   55.33 ms per token,    18.07 tokens per second)\n",
      "llama_print_timings:        eval time =   20823.04 ms /    31 runs   (  671.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21573.01 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.90 ms /    22 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     713.77 ms /    13 tokens (   54.91 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =   14073.41 ms /    21 runs   (  670.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14846.77 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.43 ms /    18 runs   (    0.41 ms per token,  2421.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.55 ms /    12 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   11643.71 ms /    17 runs   (  684.92 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12337.26 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.08 ms /    43 runs   (    0.42 ms per token,  2378.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     668.80 ms /    12 tokens (   55.73 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =   29191.77 ms /    42 runs   (  695.04 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   29981.82 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.55 ms /    18 runs   (    0.42 ms per token,  2384.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.54 ms /    12 tokens (   54.30 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   11319.91 ms /    17 runs   (  665.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12020.57 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.80 ms /    26 runs   (    0.42 ms per token,  2407.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.10 ms /    12 tokens (   54.17 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   16723.32 ms /    25 runs   (  668.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17444.17 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.52 ms /    21 runs   (    0.41 ms per token,  2466.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     717.81 ms /    13 tokens (   55.22 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =   13339.20 ms /    20 runs   (  666.96 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14113.41 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.89 ms /    25 runs   (    0.40 ms per token,  2526.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.66 ms /    12 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   16318.71 ms /    24 runs   (  679.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17033.82 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    18 runs   (    0.42 ms per token,  2401.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     674.47 ms /    12 tokens (   56.21 ms per token,    17.79 tokens per second)\n",
      "llama_print_timings:        eval time =   11793.61 ms /    17 runs   (  693.74 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   12518.44 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.49 ms /    18 runs   (    0.42 ms per token,  2404.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.61 ms /    12 tokens (   57.38 ms per token,    17.43 tokens per second)\n",
      "llama_print_timings:        eval time =   11371.51 ms /    17 runs   (  668.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12110.64 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.42 ms /    18 runs   (    0.47 ms per token,  2137.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     673.42 ms /    12 tokens (   56.12 ms per token,    17.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11499.90 ms /    17 runs   (  676.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12228.66 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.71 ms /    21 runs   (    0.41 ms per token,  2410.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     864.27 ms /    13 tokens (   66.48 ms per token,    15.04 tokens per second)\n",
      "llama_print_timings:        eval time =   13444.82 ms /    20 runs   (  672.24 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14366.81 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.22 ms /    31 runs   (    0.43 ms per token,  2344.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.81 ms /    12 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   20090.55 ms /    30 runs   (  669.68 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20819.01 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.90 ms /    21 runs   (    0.42 ms per token,  2360.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     672.40 ms /    12 tokens (   56.03 ms per token,    17.85 tokens per second)\n",
      "llama_print_timings:        eval time =   13949.10 ms /    20 runs   (  697.45 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   14681.31 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.32 ms /    32 runs   (    0.42 ms per token,  2402.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     726.08 ms /    13 tokens (   55.85 ms per token,    17.90 tokens per second)\n",
      "llama_print_timings:        eval time =   21281.10 ms /    31 runs   (  686.49 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   22096.62 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.71 ms /    28 runs   (    0.42 ms per token,  2391.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     665.14 ms /    12 tokens (   55.43 ms per token,    18.04 tokens per second)\n",
      "llama_print_timings:        eval time =   18129.36 ms /    27 runs   (  671.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18874.52 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.96 ms /    21 runs   (    0.43 ms per token,  2344.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.38 ms /    12 tokens (   54.28 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   13286.30 ms /    20 runs   (  664.31 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13996.95 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.69 ms /    21 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     711.11 ms /    13 tokens (   54.70 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =   13242.63 ms /    20 runs   (  662.13 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14012.63 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.84 ms /    44 runs   (    0.41 ms per token,  2466.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     605.44 ms /    11 tokens (   55.04 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =   29494.88 ms /    43 runs   (  685.93 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   30222.19 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.74 ms /    28 runs   (    0.42 ms per token,  2384.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.27 ms /    12 tokens (   56.77 ms per token,    17.61 tokens per second)\n",
      "llama_print_timings:        eval time =   18301.32 ms /    27 runs   (  677.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19061.28 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.09 ms /    24 runs   (    0.42 ms per token,  2377.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.89 ms /    12 tokens (   55.32 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =   15589.09 ms /    23 runs   (  677.79 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16320.40 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.58 ms /    21 runs   (    0.41 ms per token,  2446.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     726.47 ms /    13 tokens (   55.88 ms per token,    17.89 tokens per second)\n",
      "llama_print_timings:        eval time =   13784.21 ms /    20 runs   (  689.21 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   14568.41 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.80 ms /    26 runs   (    0.42 ms per token,  2407.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     618.47 ms /    11 tokens (   56.22 ms per token,    17.79 tokens per second)\n",
      "llama_print_timings:        eval time =   17011.81 ms /    25 runs   (  680.47 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17702.98 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.50 ms /    28 runs   (    0.41 ms per token,  2434.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     661.15 ms /    12 tokens (   55.10 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =   18235.36 ms /    27 runs   (  675.38 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18974.88 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.86 ms /    31 runs   (    0.41 ms per token,  2410.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     673.14 ms /    12 tokens (   56.09 ms per token,    17.83 tokens per second)\n",
      "llama_print_timings:        eval time =   20371.44 ms /    30 runs   (  679.05 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   21131.49 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    18 runs   (    0.42 ms per token,  2353.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.21 ms /    12 tokens (   53.27 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   11197.08 ms /    17 runs   (  658.65 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   11887.59 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    18 runs   (    0.41 ms per token,  2432.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.76 ms /    12 tokens (   57.40 ms per token,    17.42 tokens per second)\n",
      "llama_print_timings:        eval time =   11279.01 ms /    17 runs   (  663.47 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12019.28 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.82 ms /    21 runs   (    0.42 ms per token,  2380.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.00 ms /    12 tokens (   56.92 ms per token,    17.57 tokens per second)\n",
      "llama_print_timings:        eval time =   13615.58 ms /    20 runs   (  680.78 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14357.78 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.62 ms /    18 runs   (    0.48 ms per token,  2089.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     740.46 ms /    13 tokens (   56.96 ms per token,    17.56 tokens per second)\n",
      "llama_print_timings:        eval time =   11528.68 ms /    17 runs   (  678.16 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12325.83 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.39 ms /    40 runs   (    0.41 ms per token,  2440.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.64 ms /    12 tokens (   54.97 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =   26414.43 ms /    39 runs   (  677.29 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27188.59 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.22 ms /    21 runs   (    0.44 ms per token,  2276.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.68 ms /    12 tokens (   54.97 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =   13150.54 ms /    20 runs   (  657.53 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13871.38 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.96 ms /    39 runs   (    0.41 ms per token,  2443.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.75 ms /    11 tokens (   58.80 ms per token,    17.01 tokens per second)\n",
      "llama_print_timings:        eval time =   25613.03 ms /    38 runs   (  674.03 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26372.58 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.93 ms /    39 runs   (    0.41 ms per token,  2447.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     733.59 ms /    14 tokens (   52.40 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   25372.87 ms /    38 runs   (  667.71 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26218.03 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.16 ms /    19 runs   (    0.43 ms per token,  2329.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     664.20 ms /    12 tokens (   55.35 ms per token,    18.07 tokens per second)\n",
      "llama_print_timings:        eval time =   12446.08 ms /    18 runs   (  691.45 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13165.20 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.99 ms /    19 runs   (    0.42 ms per token,  2379.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     732.53 ms /    13 tokens (   56.35 ms per token,    17.75 tokens per second)\n",
      "llama_print_timings:        eval time =   12442.17 ms /    18 runs   (  691.23 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13229.98 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.48 ms /    26 runs   (    0.40 ms per token,  2480.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     662.35 ms /    12 tokens (   55.20 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =   16821.59 ms /    25 runs   (  672.86 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17557.90 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.53 ms /    60 runs   (    0.41 ms per token,  2446.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     661.00 ms /    11 tokens (   60.09 ms per token,    16.64 tokens per second)\n",
      "llama_print_timings:        eval time =   40070.79 ms /    59 runs   (  679.17 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   40903.37 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.52 ms /    23 runs   (    0.41 ms per token,  2416.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.88 ms /    12 tokens (   54.24 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   14835.85 ms /    22 runs   (  674.36 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15551.64 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.62 ms /    29 runs   (    0.40 ms per token,  2495.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     614.45 ms /    11 tokens (   55.86 ms per token,    17.90 tokens per second)\n",
      "llama_print_timings:        eval time =   18685.69 ms /    28 runs   (  667.35 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19379.81 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      28.23 ms /    70 runs   (    0.40 ms per token,  2479.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.42 ms /    12 tokens (   54.95 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =   46285.91 ms /    69 runs   (  670.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   47140.42 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.63 ms /    52 runs   (    0.42 ms per token,  2403.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.95 ms /    11 tokens (   54.45 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   34483.91 ms /    51 runs   (  676.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   35233.19 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    19 runs   (    0.41 ms per token,  2424.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.08 ms /    12 tokens (   54.34 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   11865.49 ms /    18 runs   (  659.19 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12571.20 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.97 ms /    22 runs   (    0.41 ms per token,  2451.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.86 ms /    12 tokens (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   14098.45 ms /    21 runs   (  671.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14805.99 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    18 runs   (    0.41 ms per token,  2416.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     618.19 ms /    11 tokens (   56.20 ms per token,    17.79 tokens per second)\n",
      "llama_print_timings:        eval time =   11375.01 ms /    17 runs   (  669.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12043.25 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.24 ms /    33 runs   (    0.40 ms per token,  2493.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     662.73 ms /    12 tokens (   55.23 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =   21283.73 ms /    32 runs   (  665.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22038.43 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    19 runs   (    0.40 ms per token,  2492.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.49 ms /    12 tokens (   54.29 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   11966.75 ms /    18 runs   (  664.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12671.22 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.93 ms /    32 runs   (    0.40 ms per token,  2474.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     690.18 ms /    13 tokens (   53.09 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   20614.64 ms /    31 runs   (  664.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21394.07 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.97 ms /    26 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.64 ms /    12 tokens (   54.97 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =   16848.05 ms /    25 runs   (  673.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17584.68 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    16 runs   (    0.43 ms per token,  2331.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.01 ms /    12 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   10368.57 ms /    15 runs   (  691.24 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   11054.12 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.89 ms /    26 runs   (    0.42 ms per token,  2387.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.99 ms /    12 tokens (   60.42 ms per token,    16.55 tokens per second)\n",
      "llama_print_timings:        eval time =   17562.72 ms /    25 runs   (  702.51 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   18361.75 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.02 ms /    27 runs   (    0.41 ms per token,  2449.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     747.03 ms /    13 tokens (   57.46 ms per token,    17.40 tokens per second)\n",
      "llama_print_timings:        eval time =   17316.69 ms /    26 runs   (  666.03 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18140.56 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.82 ms /    22 runs   (    0.40 ms per token,  2494.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.44 ms /    12 tokens (   54.45 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =   14010.38 ms /    21 runs   (  667.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14725.65 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.35 ms /    25 runs   (    0.45 ms per token,  2203.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.55 ms /    12 tokens (   64.71 ms per token,    15.45 tokens per second)\n",
      "llama_print_timings:        eval time =   16215.07 ms /    24 runs   (  675.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17071.39 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.59 ms /    26 runs   (    0.41 ms per token,  2455.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     666.77 ms /    12 tokens (   55.56 ms per token,    18.00 tokens per second)\n",
      "llama_print_timings:        eval time =   16698.56 ms /    25 runs   (  667.94 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17440.60 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.77 ms /    34 runs   (    0.40 ms per token,  2469.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.81 ms /    12 tokens (   54.40 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   22578.17 ms /    33 runs   (  684.19 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   23328.40 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.04 ms /    29 runs   (    0.42 ms per token,  2408.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     706.12 ms /    13 tokens (   54.32 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   18712.41 ms /    28 runs   (  668.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19503.29 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.87 ms /    21 runs   (    0.42 ms per token,  2367.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.31 ms /    12 tokens (   56.44 ms per token,    17.72 tokens per second)\n",
      "llama_print_timings:        eval time =   13727.45 ms /    20 runs   (  686.37 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14466.30 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.56 ms /    26 runs   (    0.48 ms per token,  2070.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     738.62 ms /    12 tokens (   61.55 ms per token,    16.25 tokens per second)\n",
      "llama_print_timings:        eval time =   16863.51 ms /    25 runs   (  674.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17686.35 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.80 ms /    26 runs   (    0.42 ms per token,  2408.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.42 ms /    12 tokens (   58.70 ms per token,    17.04 tokens per second)\n",
      "llama_print_timings:        eval time =   17040.05 ms /    25 runs   (  681.60 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17819.94 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.77 ms /    26 runs   (    0.41 ms per token,  2414.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     608.92 ms /    11 tokens (   55.36 ms per token,    18.06 tokens per second)\n",
      "llama_print_timings:        eval time =   16980.65 ms /    25 runs   (  679.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17665.94 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.65 ms /    23 runs   (    0.42 ms per token,  2382.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     605.35 ms /    11 tokens (   55.03 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =   14691.77 ms /    22 runs   (  667.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15364.40 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.58 ms /    65 runs   (    0.41 ms per token,  2445.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     668.51 ms /    12 tokens (   55.71 ms per token,    17.95 tokens per second)\n",
      "llama_print_timings:        eval time =   43544.93 ms /    64 runs   (  680.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   44405.26 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.69 ms /    40 runs   (    0.44 ms per token,  2261.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     729.79 ms /    13 tokens (   56.14 ms per token,    17.81 tokens per second)\n",
      "llama_print_timings:        eval time =   26874.45 ms /    39 runs   (  689.09 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   27726.50 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.58 ms /    41 runs   (    0.40 ms per token,  2472.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.32 ms /    12 tokens (   55.28 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =   26803.66 ms /    40 runs   (  670.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   27587.88 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.24 ms /    40 runs   (    0.43 ms per token,  2319.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     669.11 ms /    12 tokens (   55.76 ms per token,    17.93 tokens per second)\n",
      "llama_print_timings:        eval time =   26444.78 ms /    39 runs   (  678.07 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27236.03 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.51 ms /    38 runs   (    0.43 ms per token,  2301.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     703.21 ms /    13 tokens (   54.09 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   24791.61 ms /    37 runs   (  670.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   25608.25 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.40 ms /    43 runs   (    0.40 ms per token,  2471.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     721.20 ms /    12 tokens (   60.10 ms per token,    16.64 tokens per second)\n",
      "llama_print_timings:        eval time =   28583.12 ms /    42 runs   (  680.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   29430.67 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.15 ms /    24 runs   (    0.42 ms per token,  2364.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.14 ms /    11 tokens (   57.74 ms per token,    17.32 tokens per second)\n",
      "llama_print_timings:        eval time =   15645.57 ms /    23 runs   (  680.24 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16351.74 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.41 ms /    33 runs   (    0.41 ms per token,  2460.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     708.31 ms /    13 tokens (   54.49 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =   21646.59 ms /    32 runs   (  676.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22450.86 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.44 ms /    28 runs   (    0.41 ms per token,  2446.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.89 ms /    12 tokens (   55.32 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =   18311.85 ms /    27 runs   (  678.22 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19057.19 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.67 ms /    31 runs   (    0.41 ms per token,  2446.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     708.93 ms /    12 tokens (   59.08 ms per token,    16.93 tokens per second)\n",
      "llama_print_timings:        eval time =   20607.89 ms /    30 runs   (  686.93 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   21408.42 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.19 ms /    32 runs   (    0.44 ms per token,  2254.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     665.83 ms /    12 tokens (   55.49 ms per token,    18.02 tokens per second)\n",
      "llama_print_timings:        eval time =   20771.37 ms /    31 runs   (  670.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21537.38 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.08 ms /    19 runs   (    0.43 ms per token,  2351.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.22 ms /    11 tokens (   57.84 ms per token,    17.29 tokens per second)\n",
      "llama_print_timings:        eval time =   11983.00 ms /    18 runs   (  665.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12675.06 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.14 ms /    22 runs   (    0.42 ms per token,  2407.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     664.12 ms /    12 tokens (   55.34 ms per token,    18.07 tokens per second)\n",
      "llama_print_timings:        eval time =   14416.05 ms /    21 runs   (  686.48 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   15144.44 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.15 ms /    37 runs   (    0.44 ms per token,  2290.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     716.38 ms /    13 tokens (   55.11 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =   24232.27 ms /    36 runs   (  673.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   25062.56 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.33 ms /    32 runs   (    0.42 ms per token,  2400.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.41 ms /    12 tokens (   56.53 ms per token,    17.69 tokens per second)\n",
      "llama_print_timings:        eval time =   20608.58 ms /    31 runs   (  664.79 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21379.76 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.38 ms /    24 runs   (    0.43 ms per token,  2312.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.80 ms /    12 tokens (   53.65 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   15113.03 ms /    23 runs   (  657.09 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15830.43 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.56 ms /    26 runs   (    0.41 ms per token,  2461.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     657.09 ms /    12 tokens (   54.76 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =   16333.21 ms /    25 runs   (  653.33 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   17066.50 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.13 ms /    37 runs   (    0.41 ms per token,  2445.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     691.08 ms /    13 tokens (   53.16 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   23922.31 ms /    36 runs   (  664.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24722.55 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.27 ms /    30 runs   (    0.41 ms per token,  2444.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.22 ms /    12 tokens (   54.94 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =   19598.14 ms /    29 runs   (  675.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20343.73 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.07 ms /    19 runs   (    0.48 ms per token,  2095.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     621.60 ms /    11 tokens (   56.51 ms per token,    17.70 tokens per second)\n",
      "llama_print_timings:        eval time =   12002.50 ms /    18 runs   (  666.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12684.89 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.63 ms /    34 runs   (    0.40 ms per token,  2495.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     662.75 ms /    12 tokens (   55.23 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =   21890.74 ms /    33 runs   (  663.36 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   22652.89 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.10 ms /    23 runs   (    0.40 ms per token,  2527.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.59 ms /    12 tokens (   54.72 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =   14790.04 ms /    22 runs   (  672.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15512.62 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.46 ms /    43 runs   (    0.41 ms per token,  2462.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     749.12 ms /    14 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   27724.09 ms /    42 runs   (  660.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   28596.71 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.18 ms /    40 runs   (    0.40 ms per token,  2471.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     605.92 ms /    11 tokens (   55.08 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =   25940.41 ms /    39 runs   (  665.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26662.33 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.35 ms /    64 runs   (    0.41 ms per token,  2429.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.30 ms /    12 tokens (   53.69 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   41839.14 ms /    63 runs   (  664.11 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   42671.09 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.59 ms /    49 runs   (    0.42 ms per token,  2380.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.03 ms /    12 tokens (   54.50 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =   32191.57 ms /    48 runs   (  670.66 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   32993.18 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    19 runs   (    0.41 ms per token,  2437.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.30 ms /    12 tokens (   54.11 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   12078.57 ms /    18 runs   (  671.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12783.66 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.80 ms /    37 runs   (    0.43 ms per token,  2341.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.91 ms /    12 tokens (   53.99 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   23944.17 ms /    36 runs   (  665.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24705.80 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      35.65 ms /    87 runs   (    0.41 ms per token,  2440.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.67 ms /    11 tokens (   54.15 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   59089.00 ms /    86 runs   (  687.08 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   59944.77 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.67 ms /    43 runs   (    0.43 ms per token,  2303.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     709.70 ms /    13 tokens (   54.59 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   28606.05 ms /    42 runs   (  681.10 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   29446.45 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.20 ms /    42 runs   (    0.41 ms per token,  2442.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.98 ms /    12 tokens (   53.91 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   27768.75 ms /    41 runs   (  677.29 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   28539.23 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.95 ms /    32 runs   (    0.40 ms per token,  2471.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.19 ms /    11 tokens (   54.56 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   20924.06 ms /    31 runs   (  674.97 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21617.66 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.23 ms /    42 runs   (    0.41 ms per token,  2437.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     674.73 ms /    12 tokens (   56.23 ms per token,    17.78 tokens per second)\n",
      "llama_print_timings:        eval time =   28050.25 ms /    41 runs   (  684.15 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   28846.75 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 100 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.79 ms /    26 runs   (    0.42 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.36 ms /    11 tokens (   58.76 ms per token,    17.02 tokens per second)\n",
      "llama_print_timings:        eval time =   16886.53 ms /    25 runs   (  675.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17609.93 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.14 ms /    22 runs   (    0.42 ms per token,  2408.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     661.07 ms /    12 tokens (   55.09 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =   14137.70 ms /    21 runs   (  673.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14865.24 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    18 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     623.34 ms /    11 tokens (   56.67 ms per token,    17.65 tokens per second)\n",
      "llama_print_timings:        eval time =   11889.07 ms /    17 runs   (  699.36 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   12567.52 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.55 ms /    26 runs   (    0.41 ms per token,  2465.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.33 ms /    12 tokens (   54.11 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   16693.10 ms /    25 runs   (  667.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17419.70 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.67 ms /    35 runs   (    0.42 ms per token,  2385.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.16 ms /    13 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   22985.86 ms /    34 runs   (  676.05 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   23775.36 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.61 ms /    59 runs   (    0.42 ms per token,  2397.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.54 ms /    12 tokens (   56.54 ms per token,    17.69 tokens per second)\n",
      "llama_print_timings:        eval time =   38537.63 ms /    58 runs   (  664.44 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   39387.54 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.16 ms /    36 runs   (    0.45 ms per token,  2227.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     710.26 ms /    13 tokens (   54.64 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =   24367.37 ms /    35 runs   (  696.21 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   25194.16 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.01 ms /    19 runs   (    0.42 ms per token,  2372.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     676.51 ms /    12 tokens (   56.38 ms per token,    17.74 tokens per second)\n",
      "llama_print_timings:        eval time =   12198.75 ms /    18 runs   (  677.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12930.64 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    19 runs   (    0.41 ms per token,  2436.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     658.01 ms /    12 tokens (   54.83 ms per token,    18.24 tokens per second)\n",
      "llama_print_timings:        eval time =   12075.98 ms /    18 runs   (  670.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12789.01 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.55 ms /    36 runs   (    0.43 ms per token,  2315.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.48 ms /    12 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   24618.79 ms /    35 runs   (  703.39 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   25373.07 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.68 ms /    43 runs   (    0.41 ms per token,  2432.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     709.22 ms /    12 tokens (   59.10 ms per token,    16.92 tokens per second)\n",
      "llama_print_timings:        eval time =   28675.93 ms /    42 runs   (  682.76 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   29512.94 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    18 runs   (    0.41 ms per token,  2462.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     741.86 ms /    13 tokens (   57.07 ms per token,    17.52 tokens per second)\n",
      "llama_print_timings:        eval time =   11246.08 ms /    17 runs   (  661.53 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12040.63 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.62 ms /    30 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     708.02 ms /    13 tokens (   54.46 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =   19415.21 ms /    29 runs   (  669.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20215.31 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.37 ms /    30 runs   (    0.41 ms per token,  2425.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.81 ms /    11 tokens (   58.80 ms per token,    17.01 tokens per second)\n",
      "llama_print_timings:        eval time =   19827.73 ms /    29 runs   (  683.71 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20564.40 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.98 ms /    53 runs   (    0.41 ms per token,  2411.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.15 ms /    11 tokens (   58.01 ms per token,    17.24 tokens per second)\n",
      "llama_print_timings:        eval time =   35249.81 ms /    52 runs   (  677.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   36045.13 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.17 ms /    29 runs   (    0.42 ms per token,  2383.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     689.80 ms /    12 tokens (   57.48 ms per token,    17.40 tokens per second)\n",
      "llama_print_timings:        eval time =   18691.94 ms /    28 runs   (  667.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19468.41 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    16 runs   (    0.41 ms per token,  2431.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.70 ms /    12 tokens (   53.56 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =    9799.45 ms /    15 runs   (  653.30 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   10487.56 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.20 ms /    39 runs   (    0.42 ms per token,  2406.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.53 ms /    11 tokens (   59.32 ms per token,    16.86 tokens per second)\n",
      "llama_print_timings:        eval time =   25747.67 ms /    38 runs   (  677.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26515.38 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.64 ms /    26 runs   (    0.41 ms per token,  2442.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.02 ms /    12 tokens (   53.42 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   16714.94 ms /    25 runs   (  668.60 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17432.24 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.52 ms /    33 runs   (    0.41 ms per token,  2441.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     616.05 ms /    11 tokens (   56.00 ms per token,    17.86 tokens per second)\n",
      "llama_print_timings:        eval time =   20965.27 ms /    32 runs   (  655.16 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   21677.82 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.95 ms /    19 runs   (    0.42 ms per token,  2390.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.07 ms /    12 tokens (   56.51 ms per token,    17.70 tokens per second)\n",
      "llama_print_timings:        eval time =   12128.68 ms /    18 runs   (  673.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12863.72 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.20 ms /    32 runs   (    0.41 ms per token,  2423.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     721.46 ms /    13 tokens (   55.50 ms per token,    18.02 tokens per second)\n",
      "llama_print_timings:        eval time =   20497.15 ms /    31 runs   (  661.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21313.82 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.67 ms /    44 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     661.23 ms /    12 tokens (   55.10 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =   28615.23 ms /    43 runs   (  665.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   29404.05 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    19 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.72 ms /    11 tokens (   54.61 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   12050.20 ms /    18 runs   (  669.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12706.57 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    19 runs   (    0.41 ms per token,  2413.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.01 ms /    12 tokens (   54.50 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =   12077.34 ms /    18 runs   (  670.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12785.93 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.90 ms /    30 runs   (    0.40 ms per token,  2521.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.77 ms /    12 tokens (   53.31 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   19442.32 ms /    29 runs   (  670.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20167.52 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.12 ms /    38 runs   (    0.40 ms per token,  2512.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.23 ms /    12 tokens (   57.19 ms per token,    17.49 tokens per second)\n",
      "llama_print_timings:        eval time =   24906.97 ms /    37 runs   (  673.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   25704.02 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.41 ms /    38 runs   (    0.41 ms per token,  2465.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.20 ms /    11 tokens (   53.84 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   24815.97 ms /    37 runs   (  670.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   25520.68 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    19 runs   (    0.41 ms per token,  2443.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.55 ms /    12 tokens (   56.96 ms per token,    17.56 tokens per second)\n",
      "llama_print_timings:        eval time =   12072.30 ms /    18 runs   (  670.68 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12810.80 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.47 ms /    55 runs   (    0.43 ms per token,  2343.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.84 ms /    13 tokens (   52.91 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   36884.66 ms /    54 runs   (  683.05 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   37737.31 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.42 ms /    26 runs   (    0.40 ms per token,  2494.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     668.47 ms /    12 tokens (   55.71 ms per token,    17.95 tokens per second)\n",
      "llama_print_timings:        eval time =   16738.01 ms /    25 runs   (  669.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17481.67 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.60 ms /    31 runs   (    0.41 ms per token,  2460.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     703.51 ms /    13 tokens (   54.12 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   19672.68 ms /    30 runs   (  655.76 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   20465.92 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.74 ms /    34 runs   (    0.40 ms per token,  2473.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     664.13 ms /    12 tokens (   55.34 ms per token,    18.07 tokens per second)\n",
      "llama_print_timings:        eval time =   21476.00 ms /    33 runs   (  650.79 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   22238.68 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.43 ms /    31 runs   (    0.40 ms per token,  2494.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.55 ms /    12 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   19845.86 ms /    30 runs   (  661.53 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20580.59 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.60 ms /    51 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     615.95 ms /    11 tokens (   56.00 ms per token,    17.86 tokens per second)\n",
      "llama_print_timings:        eval time =   33237.06 ms /    50 runs   (  664.74 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   34001.76 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.76 ms /    31 runs   (    0.41 ms per token,  2430.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     703.63 ms /    13 tokens (   54.13 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   19973.51 ms /    30 runs   (  665.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20768.59 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.77 ms /    58 runs   (    0.41 ms per token,  2440.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.54 ms /    12 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   38540.73 ms /    57 runs   (  676.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   39356.36 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    19 runs   (    0.41 ms per token,  2450.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.46 ms /    12 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   11854.90 ms /    18 runs   (  658.61 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12556.08 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.02 ms /    32 runs   (    0.41 ms per token,  2457.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.69 ms /    12 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   20667.79 ms /    31 runs   (  666.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21397.95 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    19 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.48 ms /    12 tokens (   53.46 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   11753.31 ms /    18 runs   (  652.96 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12450.05 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.84 ms /    22 runs   (    0.40 ms per token,  2488.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     735.50 ms /    14 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   13960.28 ms /    21 runs   (  664.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14759.78 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.29 ms /    30 runs   (    0.44 ms per token,  2256.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.50 ms /    12 tokens (   53.79 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   19326.71 ms /    29 runs   (  666.44 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20064.63 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.03 ms /    31 runs   (    0.42 ms per token,  2379.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.11 ms /    12 tokens (   53.34 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   19677.59 ms /    30 runs   (  655.92 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   20412.68 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.20 ms /    25 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.47 ms /    12 tokens (   54.12 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   15936.26 ms /    24 runs   (  664.01 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16659.08 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.14 ms /    25 runs   (    0.41 ms per token,  2465.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.82 ms /    11 tokens (   53.89 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   15779.80 ms /    24 runs   (  657.49 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   16445.06 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.31 ms /    25 runs   (    0.41 ms per token,  2425.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.57 ms /    12 tokens (   54.05 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   15876.33 ms /    24 runs   (  661.51 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16597.61 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.24 ms /    33 runs   (    0.40 ms per token,  2491.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     723.51 ms /    13 tokens (   55.65 ms per token,    17.97 tokens per second)\n",
      "llama_print_timings:        eval time =   21230.27 ms /    32 runs   (  663.45 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   22049.22 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.87 ms /    42 runs   (    0.40 ms per token,  2489.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.10 ms /    11 tokens (   57.28 ms per token,    17.46 tokens per second)\n",
      "llama_print_timings:        eval time =   27346.70 ms /    41 runs   (  666.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28097.93 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.74 ms /    37 runs   (    0.40 ms per token,  2510.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     671.04 ms /    12 tokens (   55.92 ms per token,    17.88 tokens per second)\n",
      "llama_print_timings:        eval time =   23984.81 ms /    36 runs   (  666.24 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24762.68 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.78 ms /    26 runs   (    0.41 ms per token,  2412.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.07 ms /    13 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   16653.61 ms /    25 runs   (  666.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17408.57 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.71 ms /    21 runs   (    0.41 ms per token,  2411.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.65 ms /    12 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   13289.83 ms /    20 runs   (  664.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13998.61 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.38 ms /    50 runs   (    0.41 ms per token,  2453.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     603.64 ms /    11 tokens (   54.88 ms per token,    18.22 tokens per second)\n",
      "llama_print_timings:        eval time =   33775.78 ms /    49 runs   (  689.30 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   34527.82 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.62 ms /    43 runs   (    0.41 ms per token,  2439.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.92 ms /    11 tokens (   59.36 ms per token,    16.85 tokens per second)\n",
      "llama_print_timings:        eval time =   28856.49 ms /    42 runs   (  687.06 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   29637.27 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      29.11 ms /    64 runs   (    0.45 ms per token,  2198.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.12 ms /    12 tokens (   67.51 ms per token,    14.81 tokens per second)\n",
      "llama_print_timings:        eval time =   43889.28 ms /    63 runs   (  696.66 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   44907.29 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.07 ms /    19 runs   (    0.42 ms per token,  2353.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.05 ms /    12 tokens (   57.17 ms per token,    17.49 tokens per second)\n",
      "llama_print_timings:        eval time =   12357.58 ms /    18 runs   (  686.53 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13102.21 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.03 ms /    26 runs   (    0.42 ms per token,  2356.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     622.17 ms /    11 tokens (   56.56 ms per token,    17.68 tokens per second)\n",
      "llama_print_timings:        eval time =   16727.73 ms /    25 runs   (  669.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17429.32 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.16 ms /    29 runs   (    0.45 ms per token,  2203.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     671.18 ms /    12 tokens (   55.93 ms per token,    17.88 tokens per second)\n",
      "llama_print_timings:        eval time =   19090.72 ms /    28 runs   (  681.81 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19855.99 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.39 ms /    43 runs   (    0.40 ms per token,  2472.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     734.84 ms /    13 tokens (   56.53 ms per token,    17.69 tokens per second)\n",
      "llama_print_timings:        eval time =   27657.24 ms /    42 runs   (  658.51 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   28517.88 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.91 ms /    24 runs   (    0.41 ms per token,  2420.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.32 ms /    12 tokens (   53.44 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   15186.63 ms /    23 runs   (  660.29 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15898.44 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.10 ms /    32 runs   (    0.41 ms per token,  2443.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.73 ms /    12 tokens (   54.56 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   20853.67 ms /    31 runs   (  672.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21602.60 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.98 ms /    19 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     691.80 ms /    13 tokens (   53.22 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   12172.98 ms /    18 runs   (  676.28 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12921.37 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.84 ms /    29 runs   (    0.41 ms per token,  2449.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.51 ms /    12 tokens (   54.13 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   18718.83 ms /    28 runs   (  668.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19454.31 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.79 ms /    21 runs   (    0.42 ms per token,  2388.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     669.91 ms /    12 tokens (   55.83 ms per token,    17.91 tokens per second)\n",
      "llama_print_timings:        eval time =   13470.41 ms /    20 runs   (  673.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14202.53 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.46 ms /    28 runs   (    0.41 ms per token,  2443.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.40 ms /    12 tokens (   53.78 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   17851.41 ms /    27 runs   (  661.16 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   18578.11 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    19 runs   (    0.41 ms per token,  2450.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     707.54 ms /    13 tokens (   54.43 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   12153.47 ms /    18 runs   (  675.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12916.32 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    19 runs   (    0.41 ms per token,  2421.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.94 ms /    12 tokens (   54.08 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   12082.89 ms /    18 runs   (  671.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12786.99 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.58 ms /    26 runs   (    0.41 ms per token,  2457.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     612.02 ms /    11 tokens (   55.64 ms per token,    17.97 tokens per second)\n",
      "llama_print_timings:        eval time =   16834.13 ms /    25 runs   (  673.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17521.93 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.42 ms /    30 runs   (    0.41 ms per token,  2415.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.70 ms /    12 tokens (   54.14 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   19189.30 ms /    29 runs   (  661.70 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19927.71 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.08 ms /    32 runs   (    0.41 ms per token,  2447.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.58 ms /    12 tokens (   54.55 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   20827.05 ms /    31 runs   (  671.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21576.97 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.37 ms /    31 runs   (    0.40 ms per token,  2507.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     603.89 ms /    11 tokens (   54.90 ms per token,    18.22 tokens per second)\n",
      "llama_print_timings:        eval time =   20106.19 ms /    30 runs   (  670.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20799.53 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.23 ms /    30 runs   (    0.41 ms per token,  2452.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.06 ms /    13 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   19449.44 ms /    29 runs   (  670.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20219.11 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.91 ms /    32 runs   (    0.40 ms per token,  2478.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.59 ms /    12 tokens (   54.47 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =   20589.89 ms /    31 runs   (  664.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21335.75 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.62 ms /    31 runs   (    0.41 ms per token,  2455.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.27 ms /    12 tokens (   53.52 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   19950.60 ms /    30 runs   (  665.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20683.57 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.44 ms /    52 runs   (    0.41 ms per token,  2425.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.28 ms /    12 tokens (   53.44 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   34394.76 ms /    51 runs   (  674.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   35190.93 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.86 ms /    22 runs   (    0.40 ms per token,  2484.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     697.41 ms /    13 tokens (   53.65 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   14267.89 ms /    21 runs   (  679.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15029.17 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.11 ms /    41 runs   (    0.42 ms per token,  2396.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.53 ms /    12 tokens (   53.54 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   26599.73 ms /    40 runs   (  664.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   27366.19 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.62 ms /    35 runs   (    0.39 ms per token,  2570.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.98 ms /    12 tokens (   54.00 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   22517.90 ms /    34 runs   (  662.29 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   23267.88 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.90 ms /    19 runs   (    0.42 ms per token,  2404.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     695.32 ms /    13 tokens (   53.49 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   12059.59 ms /    18 runs   (  669.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12810.73 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.85 ms /    49 runs   (    0.41 ms per token,  2469.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.07 ms /    12 tokens (   54.42 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   32079.71 ms /    48 runs   (  668.33 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   32876.74 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.31 ms /    30 runs   (    0.41 ms per token,  2437.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.39 ms /    12 tokens (   54.62 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   19273.50 ms /    29 runs   (  664.60 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20019.41 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.36 ms /    30 runs   (    0.41 ms per token,  2427.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.06 ms /    12 tokens (   54.17 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   19581.41 ms /    29 runs   (  675.22 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20318.97 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.77 ms /    41 runs   (    0.41 ms per token,  2445.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.52 ms /    12 tokens (   54.63 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   26694.75 ms /    40 runs   (  667.37 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   27471.36 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.15 ms /    32 runs   (    0.41 ms per token,  2433.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.06 ms /    11 tokens (   58.55 ms per token,    17.08 tokens per second)\n",
      "llama_print_timings:        eval time =   20884.23 ms /    31 runs   (  673.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21622.38 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.17 ms /    28 runs   (    0.40 ms per token,  2506.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     706.26 ms /    13 tokens (   54.33 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   18228.54 ms /    27 runs   (  675.13 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19016.40 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.93 ms /    22 runs   (    0.41 ms per token,  2463.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     664.43 ms /    12 tokens (   55.37 ms per token,    18.06 tokens per second)\n",
      "llama_print_timings:        eval time =   13918.86 ms /    21 runs   (  662.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14648.07 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    19 runs   (    0.41 ms per token,  2418.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.14 ms /    12 tokens (   54.01 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   12077.43 ms /    18 runs   (  670.97 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12781.83 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.81 ms /    29 runs   (    0.41 ms per token,  2456.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.77 ms /    12 tokens (   53.56 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   18794.81 ms /    28 runs   (  671.24 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19521.69 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.52 ms /    23 runs   (    0.41 ms per token,  2416.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     657.98 ms /    12 tokens (   54.83 ms per token,    18.24 tokens per second)\n",
      "llama_print_timings:        eval time =   14969.81 ms /    22 runs   (  680.45 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15694.88 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.71 ms /    26 runs   (    0.41 ms per token,  2428.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     666.22 ms /    12 tokens (   55.52 ms per token,    18.01 tokens per second)\n",
      "llama_print_timings:        eval time =   16582.82 ms /    25 runs   (  663.31 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17324.22 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.23 ms /    32 runs   (    0.41 ms per token,  2418.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     749.33 ms /    14 tokens (   53.52 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   20753.68 ms /    31 runs   (  669.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21597.22 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.02 ms /    19 runs   (    0.42 ms per token,  2368.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     601.22 ms /    11 tokens (   54.66 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =   12081.86 ms /    18 runs   (  671.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12738.66 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.49 ms /    23 runs   (    0.41 ms per token,  2422.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.66 ms /    12 tokens (   54.56 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   14687.02 ms /    22 runs   (  667.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15408.57 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    19 runs   (    0.41 ms per token,  2452.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     691.22 ms /    13 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   12253.88 ms /    18 runs   (  680.77 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13002.02 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.71 ms /    48 runs   (    0.41 ms per token,  2435.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.91 ms /    12 tokens (   54.58 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   31506.33 ms /    47 runs   (  670.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   32304.38 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.62 ms /    23 runs   (    0.42 ms per token,  2390.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     660.52 ms /    12 tokens (   55.04 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =   14174.57 ms /    22 runs   (  644.30 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   14903.32 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.02 ms /    27 runs   (    0.41 ms per token,  2449.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     689.84 ms /    13 tokens (   53.06 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   17333.58 ms /    26 runs   (  666.68 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18103.27 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.40 ms /    23 runs   (    0.41 ms per token,  2446.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.11 ms /    11 tokens (   54.56 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   15014.68 ms /    22 runs   (  682.49 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15682.01 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.87 ms /    24 runs   (    0.41 ms per token,  2432.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     675.71 ms /    12 tokens (   56.31 ms per token,    17.76 tokens per second)\n",
      "llama_print_timings:        eval time =   15597.14 ms /    23 runs   (  678.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16343.93 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.62 ms /    36 runs   (    0.41 ms per token,  2462.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.15 ms /    12 tokens (   54.18 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   23671.84 ms /    35 runs   (  676.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   24429.15 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.15 ms /    22 runs   (    0.42 ms per token,  2405.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.69 ms /    12 tokens (   53.72 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   13898.30 ms /    21 runs   (  661.82 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14608.88 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 200 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.35 ms /    23 runs   (    0.41 ms per token,  2459.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     615.58 ms /    11 tokens (   55.96 ms per token,    17.87 tokens per second)\n",
      "llama_print_timings:        eval time =   14767.32 ms /    22 runs   (  671.24 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15450.17 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.71 ms /    26 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     718.40 ms /    13 tokens (   55.26 ms per token,    18.10 tokens per second)\n",
      "llama_print_timings:        eval time =   16491.53 ms /    25 runs   (  659.66 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   17287.53 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.07 ms /    35 runs   (    0.40 ms per token,  2487.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.08 ms /    12 tokens (   53.42 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   22676.31 ms /    34 runs   (  666.95 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   23421.03 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      38.04 ms /    93 runs   (    0.41 ms per token,  2445.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     699.64 ms /    13 tokens (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   61652.07 ms /    92 runs   (  670.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   62632.89 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.67 ms /    48 runs   (    0.41 ms per token,  2440.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.01 ms /    12 tokens (   53.67 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   32021.09 ms /    47 runs   (  681.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   32806.96 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    19 runs   (    0.41 ms per token,  2425.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.60 ms /    11 tokens (   54.60 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   12386.97 ms /    18 runs   (  688.16 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13043.84 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    19 runs   (    0.41 ms per token,  2434.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.81 ms /    11 tokens (   57.62 ms per token,    17.36 tokens per second)\n",
      "llama_print_timings:        eval time =   12049.11 ms /    18 runs   (  669.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12739.59 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.17 ms /    22 runs   (    0.42 ms per token,  2399.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     706.91 ms /    13 tokens (   54.38 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =   14060.41 ms /    21 runs   (  669.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14832.79 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.52 ms /    43 runs   (    0.41 ms per token,  2453.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.15 ms /    12 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   28252.81 ms /    42 runs   (  672.69 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29025.78 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.83 ms /    26 runs   (    0.42 ms per token,  2401.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.00 ms /    12 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   16812.72 ms /    25 runs   (  672.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17529.34 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.04 ms /    35 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.51 ms /    11 tokens (   53.77 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   22229.97 ms /    34 runs   (  653.82 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   22925.48 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.14 ms /    22 runs   (    0.42 ms per token,  2407.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.95 ms /    12 tokens (   53.50 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   14079.55 ms /    21 runs   (  670.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14786.11 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.27 ms /    22 runs   (    0.42 ms per token,  2372.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     709.48 ms /    13 tokens (   54.58 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   14173.70 ms /    21 runs   (  674.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14948.36 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.12 ms /    52 runs   (    0.41 ms per token,  2462.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.03 ms /    12 tokens (   53.92 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   34248.52 ms /    51 runs   (  671.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   35047.63 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.97 ms /    64 runs   (    0.41 ms per token,  2464.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     607.32 ms /    11 tokens (   55.21 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =   42502.60 ms /    63 runs   (  674.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   43299.74 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.64 ms /    26 runs   (    0.41 ms per token,  2443.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.86 ms /    12 tokens (   54.07 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   16687.42 ms /    25 runs   (  667.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17411.92 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.25 ms /    32 runs   (    0.41 ms per token,  2414.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     691.40 ms /    13 tokens (   53.18 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   21009.08 ms /    31 runs   (  677.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21794.51 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.79 ms /    29 runs   (    0.41 ms per token,  2459.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.52 ms /    12 tokens (   57.79 ms per token,    17.30 tokens per second)\n",
      "llama_print_timings:        eval time =   18810.37 ms /    28 runs   (  671.80 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19589.39 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      64.79 ms /   159 runs   (    0.41 ms per token,  2453.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     602.84 ms /    11 tokens (   54.80 ms per token,    18.25 tokens per second)\n",
      "llama_print_timings:        eval time =  106092.36 ms /   158 runs   (  671.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =  107179.69 ms /   169 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.73 ms /    31 runs   (    0.41 ms per token,  2435.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.24 ms /    12 tokens (   57.77 ms per token,    17.31 tokens per second)\n",
      "llama_print_timings:        eval time =   19803.15 ms /    30 runs   (  660.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20590.00 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.14 ms /    49 runs   (    0.43 ms per token,  2317.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     726.89 ms /    13 tokens (   55.91 ms per token,    17.88 tokens per second)\n",
      "llama_print_timings:        eval time =   31663.16 ms /    48 runs   (  659.65 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   32544.18 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.12 ms /    22 runs   (    0.41 ms per token,  2411.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     606.69 ms /    11 tokens (   55.15 ms per token,    18.13 tokens per second)\n",
      "llama_print_timings:        eval time =   14057.45 ms /    21 runs   (  669.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14729.96 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.47 ms /    52 runs   (    0.41 ms per token,  2422.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.49 ms /    12 tokens (   56.79 ms per token,    17.61 tokens per second)\n",
      "llama_print_timings:        eval time =   34182.07 ms /    51 runs   (  670.24 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   35018.66 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.71 ms /    36 runs   (    0.41 ms per token,  2446.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.69 ms /    12 tokens (   53.81 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   23408.94 ms /    35 runs   (  668.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24162.18 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.22 ms /    59 runs   (    0.41 ms per token,  2435.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.87 ms /    12 tokens (   54.41 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   38409.76 ms /    58 runs   (  662.24 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   39238.11 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      29.18 ms /    71 runs   (    0.41 ms per token,  2433.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.42 ms /    13 tokens (   53.34 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   45807.52 ms /    70 runs   (  654.39 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   46714.14 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.08 ms /    22 runs   (    0.41 ms per token,  2423.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.39 ms /    12 tokens (   53.45 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   14230.40 ms /    21 runs   (  677.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14937.65 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.41 ms /    52 runs   (    0.41 ms per token,  2428.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.46 ms /    11 tokens (   59.59 ms per token,    16.78 tokens per second)\n",
      "llama_print_timings:        eval time =   34049.95 ms /    51 runs   (  667.65 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   34862.06 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.00 ms /    60 runs   (    0.42 ms per token,  2400.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.18 ms /    12 tokens (   54.26 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   38905.10 ms /    59 runs   (  659.41 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   39736.65 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      33.06 ms /    77 runs   (    0.43 ms per token,  2328.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.58 ms /    11 tokens (   58.23 ms per token,    17.17 tokens per second)\n",
      "llama_print_timings:        eval time =   52766.90 ms /    76 runs   (  694.30 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   53652.07 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.03 ms /    44 runs   (    0.41 ms per token,  2439.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     713.87 ms /    12 tokens (   59.49 ms per token,    16.81 tokens per second)\n",
      "llama_print_timings:        eval time =   29513.65 ms /    43 runs   (  686.36 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   30360.19 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.85 ms /    38 runs   (    0.42 ms per token,  2397.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.22 ms /    12 tokens (   57.10 ms per token,    17.51 tokens per second)\n",
      "llama_print_timings:        eval time =   25537.97 ms /    37 runs   (  690.22 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   26338.84 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      30.74 ms /    75 runs   (    0.41 ms per token,  2439.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.93 ms /    12 tokens (   58.24 ms per token,    17.17 tokens per second)\n",
      "llama_print_timings:        eval time =   49411.75 ms /    74 runs   (  667.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   50340.84 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.08 ms /    22 runs   (    0.41 ms per token,  2422.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     737.18 ms /    14 tokens (   52.66 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   14256.78 ms /    21 runs   (  678.89 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15059.38 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.86 ms /    34 runs   (    0.41 ms per token,  2453.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.54 ms /    12 tokens (   56.54 ms per token,    17.69 tokens per second)\n",
      "llama_print_timings:        eval time =   22025.08 ms /    33 runs   (  667.43 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22804.88 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.79 ms /    29 runs   (    0.41 ms per token,  2459.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     715.00 ms /    13 tokens (   55.00 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =   18874.27 ms /    28 runs   (  674.08 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19675.21 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.12 ms /    34 runs   (    0.42 ms per token,  2407.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     623.36 ms /    11 tokens (   56.67 ms per token,    17.65 tokens per second)\n",
      "llama_print_timings:        eval time =   21729.61 ms /    33 runs   (  658.47 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   22455.49 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.07 ms /    49 runs   (    0.41 ms per token,  2442.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     673.42 ms /    12 tokens (   56.12 ms per token,    17.82 tokens per second)\n",
      "llama_print_timings:        eval time =   31644.02 ms /    48 runs   (  659.25 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   32463.15 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.30 ms /    42 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.47 ms /    11 tokens (   59.04 ms per token,    16.94 tokens per second)\n",
      "llama_print_timings:        eval time =   27737.96 ms /    41 runs   (  676.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   28513.47 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    19 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     696.59 ms /    11 tokens (   63.33 ms per token,    15.79 tokens per second)\n",
      "llama_print_timings:        eval time =   11945.39 ms /    18 runs   (  663.63 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12699.63 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.55 ms /    30 runs   (    0.42 ms per token,  2389.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     672.98 ms /    12 tokens (   56.08 ms per token,    17.83 tokens per second)\n",
      "llama_print_timings:        eval time =   19452.41 ms /    29 runs   (  670.77 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20217.00 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.55 ms /    66 runs   (    0.40 ms per token,  2485.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.40 ms /    11 tokens (   59.67 ms per token,    16.76 tokens per second)\n",
      "llama_print_timings:        eval time =   44224.43 ms /    65 runs   (  680.38 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   45078.95 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.73 ms /    32 runs   (    0.40 ms per token,  2514.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.25 ms /    12 tokens (   54.44 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   20831.72 ms /    31 runs   (  671.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21579.02 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.89 ms /    22 runs   (    0.40 ms per token,  2474.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.08 ms /    12 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   14055.05 ms /    21 runs   (  669.29 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14761.49 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.51 ms /    43 runs   (    0.48 ms per token,  2096.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     729.52 ms /    11 tokens (   66.32 ms per token,    15.08 tokens per second)\n",
      "llama_print_timings:        eval time =   30780.75 ms /    42 runs   (  732.88 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =   31654.47 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.27 ms /    42 runs   (    0.41 ms per token,  2432.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     890.60 ms /    13 tokens (   68.51 ms per token,    14.60 tokens per second)\n",
      "llama_print_timings:        eval time =   27958.65 ms /    41 runs   (  681.92 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   28976.54 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.08 ms /    35 runs   (    0.40 ms per token,  2485.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     601.78 ms /    11 tokens (   54.71 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =   22727.94 ms /    34 runs   (  668.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   23435.36 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    19 runs   (    0.41 ms per token,  2438.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.78 ms /    12 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   11935.18 ms /    18 runs   (  663.07 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12636.53 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.95 ms /    22 runs   (    0.41 ms per token,  2459.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.49 ms /    12 tokens (   54.04 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   13934.36 ms /    21 runs   (  663.54 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14648.99 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.87 ms /    22 runs   (    0.40 ms per token,  2480.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     604.83 ms /    11 tokens (   54.98 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =   13844.94 ms /    21 runs   (  659.28 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14514.51 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.81 ms /    37 runs   (    0.40 ms per token,  2498.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.94 ms /    12 tokens (   56.83 ms per token,    17.60 tokens per second)\n",
      "llama_print_timings:        eval time =   23800.20 ms /    36 runs   (  661.12 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   24590.60 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.66 ms /    32 runs   (    0.43 ms per token,  2342.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     752.40 ms /    13 tokens (   57.88 ms per token,    17.28 tokens per second)\n",
      "llama_print_timings:        eval time =   20698.39 ms /    31 runs   (  667.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21549.15 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    19 runs   (    0.41 ms per token,  2442.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     694.40 ms /    12 tokens (   57.87 ms per token,    17.28 tokens per second)\n",
      "llama_print_timings:        eval time =   11979.95 ms /    18 runs   (  665.55 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12730.73 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    19 runs   (    0.41 ms per token,  2438.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.88 ms /    12 tokens (   53.99 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   12025.22 ms /    18 runs   (  668.07 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12729.58 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.51 ms /    43 runs   (    0.41 ms per token,  2455.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     623.35 ms /    11 tokens (   56.67 ms per token,    17.65 tokens per second)\n",
      "llama_print_timings:        eval time =   28265.25 ms /    42 runs   (  672.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29016.58 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.52 ms /    43 runs   (    0.41 ms per token,  2454.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.68 ms /    12 tokens (   54.97 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =   28103.96 ms /    42 runs   (  669.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28892.17 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.49 ms /    58 runs   (    0.41 ms per token,  2468.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.57 ms /    12 tokens (   53.55 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   37430.72 ms /    57 runs   (  656.68 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   38245.00 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.38 ms /    28 runs   (    0.48 ms per token,  2092.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     701.53 ms /    13 tokens (   53.96 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   18001.68 ms /    27 runs   (  666.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18796.93 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.54 ms /    23 runs   (    0.41 ms per token,  2411.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.11 ms /    12 tokens (   53.43 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   14806.52 ms /    22 runs   (  673.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15515.44 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.46 ms /    26 runs   (    0.40 ms per token,  2485.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.22 ms /    12 tokens (   53.93 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   16766.96 ms /    25 runs   (  670.68 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17491.76 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.27 ms /    62 runs   (    0.41 ms per token,  2453.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     699.51 ms /    12 tokens (   58.29 ms per token,    17.15 tokens per second)\n",
      "llama_print_timings:        eval time =   40833.93 ms /    61 runs   (  669.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   41717.31 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.12 ms /    57 runs   (    0.41 ms per token,  2465.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.50 ms /    12 tokens (   53.54 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   37919.02 ms /    56 runs   (  677.13 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   38732.19 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.73 ms /    33 runs   (    0.42 ms per token,  2404.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.33 ms /    13 tokens (   52.95 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   21334.54 ms /    32 runs   (  666.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22120.82 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.97 ms /    19 runs   (    0.42 ms per token,  2384.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.42 ms /    12 tokens (   53.20 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   12082.11 ms /    18 runs   (  671.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12777.37 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.93 ms /    27 runs   (    0.40 ms per token,  2469.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     700.29 ms /    13 tokens (   53.87 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   17008.63 ms /    26 runs   (  654.18 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   17788.53 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    19 runs   (    0.42 ms per token,  2399.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.70 ms /    13 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   11926.84 ms /    18 runs   (  662.60 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12669.80 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.49 ms /    26 runs   (    0.40 ms per token,  2479.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     717.25 ms /    12 tokens (   59.77 ms per token,    16.73 tokens per second)\n",
      "llama_print_timings:        eval time =   16937.07 ms /    25 runs   (  677.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17730.34 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.00 ms /    32 runs   (    0.41 ms per token,  2460.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.22 ms /    12 tokens (   54.18 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   21218.02 ms /    31 runs   (  684.45 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   21963.82 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.43 ms /    31 runs   (    0.40 ms per token,  2494.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.19 ms /    12 tokens (   54.10 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   20166.24 ms /    30 runs   (  672.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20906.31 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.39 ms /    41 runs   (    0.40 ms per token,  2501.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.71 ms /    13 tokens (   53.75 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   26574.94 ms /    40 runs   (  664.37 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   27395.84 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.96 ms /    19 runs   (    0.42 ms per token,  2386.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.45 ms /    12 tokens (   54.70 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =   12045.58 ms /    18 runs   (  669.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12758.44 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.32 ms /    28 runs   (    0.40 ms per token,  2472.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.21 ms /    12 tokens (   54.68 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =   17932.84 ms /    27 runs   (  664.18 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   18671.78 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    19 runs   (    0.41 ms per token,  2415.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.76 ms /    12 tokens (   53.98 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   11879.91 ms /    18 runs   (  659.99 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12583.57 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.02 ms /    32 runs   (    0.41 ms per token,  2458.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     689.34 ms /    13 tokens (   53.03 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   20381.28 ms /    31 runs   (  657.46 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21164.93 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    19 runs   (    0.41 ms per token,  2417.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     617.72 ms /    11 tokens (   56.16 ms per token,    17.81 tokens per second)\n",
      "llama_print_timings:        eval time =   11959.50 ms /    18 runs   (  664.42 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12632.84 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.21 ms /    53 runs   (    0.42 ms per token,  2386.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.80 ms /    12 tokens (   53.98 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   34616.56 ms /    52 runs   (  665.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   35425.38 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    19 runs   (    0.41 ms per token,  2441.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.82 ms /    12 tokens (   54.23 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   11798.81 ms /    18 runs   (  655.49 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12505.77 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.18 ms /    22 runs   (    0.42 ms per token,  2396.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     766.50 ms /    14 tokens (   54.75 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =   13907.32 ms /    21 runs   (  662.25 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14739.55 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.99 ms /    37 runs   (    0.41 ms per token,  2468.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.09 ms /    12 tokens (   54.17 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   23677.18 ms /    36 runs   (  657.70 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   24437.27 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.46 ms /    31 runs   (    0.40 ms per token,  2488.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     670.28 ms /    12 tokens (   55.86 ms per token,    17.90 tokens per second)\n",
      "llama_print_timings:        eval time =   19830.25 ms /    30 runs   (  661.01 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20592.68 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.16 ms /    29 runs   (    0.42 ms per token,  2384.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.51 ms /    12 tokens (   53.38 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   18592.57 ms /    28 runs   (  664.02 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19321.03 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.63 ms /    33 runs   (    0.41 ms per token,  2421.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.89 ms /    12 tokens (   54.16 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   21349.10 ms /    32 runs   (  667.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22097.66 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.91 ms /    19 runs   (    0.42 ms per token,  2401.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.18 ms /    11 tokens (   62.29 ms per token,    16.05 tokens per second)\n",
      "llama_print_timings:        eval time =   11906.27 ms /    18 runs   (  661.46 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12648.79 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.64 ms /    63 runs   (    0.41 ms per token,  2456.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     708.88 ms /    13 tokens (   54.53 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   41073.69 ms /    62 runs   (  662.48 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   41971.82 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.15 ms /    30 runs   (    0.40 ms per token,  2469.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     657.57 ms /    12 tokens (   54.80 ms per token,    18.25 tokens per second)\n",
      "llama_print_timings:        eval time =   19173.55 ms /    29 runs   (  661.16 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19919.51 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.34 ms /    21 runs   (    0.40 ms per token,  2517.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.67 ms /    12 tokens (   54.47 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =   13377.22 ms /    20 runs   (  668.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14092.52 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      34.31 ms /    81 runs   (    0.42 ms per token,  2361.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     605.54 ms /    11 tokens (   55.05 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =   53694.86 ms /    80 runs   (  671.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   54548.42 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.79 ms /    37 runs   (    0.40 ms per token,  2501.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     660.81 ms /    12 tokens (   55.07 ms per token,    18.16 tokens per second)\n",
      "llama_print_timings:        eval time =   23986.53 ms /    36 runs   (  666.29 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24756.43 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.18 ms /    40 runs   (    0.40 ms per token,  2471.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.46 ms /    12 tokens (   54.71 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =   26210.45 ms /    39 runs   (  672.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26985.25 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.63 ms /    60 runs   (    0.41 ms per token,  2435.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.27 ms /    12 tokens (   53.61 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   39171.21 ms /    59 runs   (  663.92 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   39990.31 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.80 ms /    61 runs   (    0.41 ms per token,  2459.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.89 ms /    13 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   40811.98 ms /    60 runs   (  680.20 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   41686.86 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.81 ms /    37 runs   (    0.40 ms per token,  2497.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     625.97 ms /    11 tokens (   56.91 ms per token,    17.57 tokens per second)\n",
      "llama_print_timings:        eval time =   24268.26 ms /    36 runs   (  674.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25004.86 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.60 ms /    37 runs   (    0.42 ms per token,  2371.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.11 ms /    12 tokens (   54.01 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   24337.00 ms /    36 runs   (  676.03 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25099.55 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.53 ms /    62 runs   (    0.41 ms per token,  2428.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     610.98 ms /    11 tokens (   55.54 ms per token,    18.00 tokens per second)\n",
      "llama_print_timings:        eval time =   40844.43 ms /    61 runs   (  669.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   41642.03 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.07 ms /    60 runs   (    0.40 ms per token,  2492.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.17 ms /    13 tokens (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   39495.94 ms /    59 runs   (  669.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   40365.00 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.22 ms /    30 runs   (    0.41 ms per token,  2454.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.60 ms /    12 tokens (   56.47 ms per token,    17.71 tokens per second)\n",
      "llama_print_timings:        eval time =   19417.53 ms /    29 runs   (  669.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20184.51 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.76 ms /    31 runs   (    0.41 ms per token,  2430.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.74 ms /    12 tokens (   54.06 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   19990.24 ms /    30 runs   (  666.34 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20730.31 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.81 ms /    60 runs   (    0.41 ms per token,  2418.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     660.10 ms /    12 tokens (   55.01 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =   40189.64 ms /    59 runs   (  681.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   41031.15 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    19 runs   (    0.41 ms per token,  2417.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     709.11 ms /    11 tokens (   64.46 ms per token,    15.51 tokens per second)\n",
      "llama_print_timings:        eval time =   12386.97 ms /    18 runs   (  688.16 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13154.03 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    19 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.10 ms /    12 tokens (   54.67 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =   11639.05 ms /    18 runs   (  646.61 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   12352.52 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 300 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.51 ms /    28 runs   (    0.41 ms per token,  2433.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.79 ms /    12 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   18036.76 ms /    27 runs   (  668.03 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18763.08 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.82 ms /    60 runs   (    0.41 ms per token,  2417.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     978.81 ms /    13 tokens (   75.29 ms per token,    13.28 tokens per second)\n",
      "llama_print_timings:        eval time =   40083.97 ms /    59 runs   (  679.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   41244.75 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.85 ms /    36 runs   (    0.41 ms per token,  2423.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.10 ms /    12 tokens (   57.17 ms per token,    17.49 tokens per second)\n",
      "llama_print_timings:        eval time =   23658.54 ms /    35 runs   (  675.96 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   24453.33 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.97 ms /    24 runs   (    0.42 ms per token,  2406.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.35 ms /    12 tokens (   56.78 ms per token,    17.61 tokens per second)\n",
      "llama_print_timings:        eval time =   15348.58 ms /    23 runs   (  667.33 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16101.76 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      32.39 ms /    73 runs   (    0.44 ms per token,  2253.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.52 ms /    12 tokens (   58.21 ms per token,    17.18 tokens per second)\n",
      "llama_print_timings:        eval time =   49423.11 ms /    72 runs   (  686.43 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   50356.67 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.52 ms /    48 runs   (    0.41 ms per token,  2458.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.52 ms /    12 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   31485.01 ms /    47 runs   (  669.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   32274.37 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    18 runs   (    0.42 ms per token,  2365.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.46 ms /    11 tokens (   57.95 ms per token,    17.26 tokens per second)\n",
      "llama_print_timings:        eval time =   11549.03 ms /    17 runs   (  679.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12241.29 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.43 ms /    30 runs   (    0.41 ms per token,  2414.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     696.81 ms /    13 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   19625.40 ms /    29 runs   (  676.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20412.64 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.79 ms /    29 runs   (    0.41 ms per token,  2458.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.35 ms /    12 tokens (   53.70 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   18301.64 ms /    28 runs   (  653.63 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   19030.79 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.06 ms /    27 runs   (    0.41 ms per token,  2440.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     676.31 ms /    12 tokens (   56.36 ms per token,    17.74 tokens per second)\n",
      "llama_print_timings:        eval time =   17597.15 ms /    26 runs   (  676.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18353.27 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.32 ms /    32 runs   (    0.42 ms per token,  2402.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     605.30 ms /    11 tokens (   55.03 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =   20446.47 ms /    31 runs   (  659.56 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21148.72 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.66 ms /    31 runs   (    0.41 ms per token,  2449.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.99 ms /    12 tokens (   58.25 ms per token,    17.17 tokens per second)\n",
      "llama_print_timings:        eval time =   20272.88 ms /    30 runs   (  675.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21063.59 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.55 ms /    26 runs   (    0.41 ms per token,  2464.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     691.00 ms /    13 tokens (   53.15 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   16825.75 ms /    25 runs   (  673.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17592.82 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.74 ms /    28 runs   (    0.42 ms per token,  2385.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.32 ms /    12 tokens (   55.28 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =   18296.05 ms /    27 runs   (  677.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19043.19 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.87 ms /    66 runs   (    0.42 ms per token,  2368.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.36 ms /    13 tokens (   55.72 ms per token,    17.95 tokens per second)\n",
      "llama_print_timings:        eval time =   44479.46 ms /    65 runs   (  684.30 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   45405.95 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.12 ms /    29 runs   (    0.42 ms per token,  2393.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.87 ms /    12 tokens (   56.91 ms per token,    17.57 tokens per second)\n",
      "llama_print_timings:        eval time =   18587.53 ms /    28 runs   (  663.84 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19356.88 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.90 ms /    40 runs   (    0.40 ms per token,  2515.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.04 ms /    12 tokens (   56.50 ms per token,    17.70 tokens per second)\n",
      "llama_print_timings:        eval time =   26468.73 ms /    39 runs   (  678.69 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27262.57 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.89 ms /    36 runs   (    0.41 ms per token,  2418.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.41 ms /    12 tokens (   58.70 ms per token,    17.04 tokens per second)\n",
      "llama_print_timings:        eval time =   23706.06 ms /    35 runs   (  677.32 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   24517.84 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.56 ms /    22 runs   (    0.43 ms per token,  2301.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.11 ms /    12 tokens (   53.84 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   14536.99 ms /    21 runs   (  692.24 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   15250.30 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.00 ms /    28 runs   (    0.43 ms per token,  2334.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     873.32 ms /    12 tokens (   72.78 ms per token,    13.74 tokens per second)\n",
      "llama_print_timings:        eval time =   18722.33 ms /    27 runs   (  693.42 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   19679.52 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.92 ms /    37 runs   (    0.40 ms per token,  2480.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     696.48 ms /    13 tokens (   53.58 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   24044.26 ms /    36 runs   (  667.90 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24848.61 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.12 ms /    19 runs   (    0.48 ms per token,  2083.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     674.17 ms /    11 tokens (   61.29 ms per token,    16.32 tokens per second)\n",
      "llama_print_timings:        eval time =   12159.33 ms /    18 runs   (  675.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12894.84 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.52 ms /    28 runs   (    0.41 ms per token,  2430.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     661.09 ms /    12 tokens (   55.09 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =   18330.19 ms /    27 runs   (  678.90 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19072.86 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.07 ms /    52 runs   (    0.41 ms per token,  2467.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.98 ms /    12 tokens (   53.92 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   33877.91 ms /    51 runs   (  664.27 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   34678.76 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.11 ms /    30 runs   (    0.40 ms per token,  2477.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     665.76 ms /    12 tokens (   55.48 ms per token,    18.02 tokens per second)\n",
      "llama_print_timings:        eval time =   18992.85 ms /    29 runs   (  654.93 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   19747.18 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.80 ms /    34 runs   (    0.41 ms per token,  2463.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.14 ms /    12 tokens (   54.93 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =   22077.93 ms /    33 runs   (  669.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22837.63 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.75 ms /    24 runs   (    0.41 ms per token,  2461.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.91 ms /    13 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   15368.18 ms /    23 runs   (  668.18 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16126.46 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.56 ms /    43 runs   (    0.41 ms per token,  2448.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.75 ms /    12 tokens (   54.56 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   27844.90 ms /    42 runs   (  662.97 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   28626.63 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.53 ms /    62 runs   (    0.41 ms per token,  2428.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     700.67 ms /    12 tokens (   58.39 ms per token,    17.13 tokens per second)\n",
      "llama_print_timings:        eval time =   41429.79 ms /    61 runs   (  679.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   42315.29 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    19 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     718.41 ms /    12 tokens (   59.87 ms per token,    16.70 tokens per second)\n",
      "llama_print_timings:        eval time =   12218.85 ms /    18 runs   (  678.83 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12994.00 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.55 ms /    58 runs   (    0.42 ms per token,  2362.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.08 ms /    12 tokens (   56.42 ms per token,    17.72 tokens per second)\n",
      "llama_print_timings:        eval time =   38515.02 ms /    57 runs   (  675.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   39367.57 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.10 ms /    29 runs   (    0.42 ms per token,  2396.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     857.57 ms /    14 tokens (   61.26 ms per token,    16.33 tokens per second)\n",
      "llama_print_timings:        eval time =   19235.58 ms /    28 runs   (  686.98 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20180.27 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.84 ms /    22 runs   (    0.40 ms per token,  2487.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.32 ms /    12 tokens (   56.44 ms per token,    17.72 tokens per second)\n",
      "llama_print_timings:        eval time =   13989.03 ms /    21 runs   (  666.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14731.56 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      35.73 ms /    85 runs   (    0.42 ms per token,  2378.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     668.73 ms /    12 tokens (   55.73 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =   56493.01 ms /    84 runs   (  672.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   57422.41 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.03 ms /    40 runs   (    0.43 ms per token,  2349.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     662.10 ms /    12 tokens (   55.17 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =   25927.33 ms /    39 runs   (  664.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26713.14 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.51 ms /    28 runs   (    0.41 ms per token,  2432.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     666.90 ms /    12 tokens (   55.57 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =   17929.45 ms /    27 runs   (  664.05 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   18678.50 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.65 ms /    28 runs   (    0.42 ms per token,  2403.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.57 ms /    12 tokens (   54.13 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   18014.24 ms /    27 runs   (  667.19 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18748.12 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.16 ms /    24 runs   (    0.42 ms per token,  2362.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.80 ms /    12 tokens (   54.07 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   15441.06 ms /    23 runs   (  671.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16162.45 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.96 ms /    35 runs   (    0.40 ms per token,  2507.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     669.63 ms /    12 tokens (   55.80 ms per token,    17.92 tokens per second)\n",
      "llama_print_timings:        eval time =   22491.82 ms /    34 runs   (  661.52 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   23264.88 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.11 ms /    22 runs   (    0.41 ms per token,  2415.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.79 ms /    12 tokens (   56.82 ms per token,    17.60 tokens per second)\n",
      "llama_print_timings:        eval time =   14296.79 ms /    21 runs   (  680.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15043.71 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.70 ms /    21 runs   (    0.41 ms per token,  2414.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     707.21 ms /    13 tokens (   54.40 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   13611.99 ms /    20 runs   (  680.60 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14381.66 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.57 ms /    31 runs   (    0.41 ms per token,  2465.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.44 ms /    12 tokens (   53.95 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   19962.06 ms /    30 runs   (  665.40 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20699.65 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.66 ms /    48 runs   (    0.41 ms per token,  2440.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     665.19 ms /    11 tokens (   60.47 ms per token,    16.54 tokens per second)\n",
      "llama_print_timings:        eval time =   31441.57 ms /    47 runs   (  668.97 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   32248.05 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.08 ms /    30 runs   (    0.40 ms per token,  2482.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.98 ms /    12 tokens (   54.00 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   19236.66 ms /    29 runs   (  663.33 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19972.00 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.73 ms /    31 runs   (    0.41 ms per token,  2435.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.69 ms /    12 tokens (   53.81 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   20052.32 ms /    30 runs   (  668.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20790.20 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.35 ms /    33 runs   (    0.40 ms per token,  2471.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     658.28 ms /    12 tokens (   54.86 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =   21135.40 ms /    32 runs   (  660.48 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21891.33 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.23 ms /    35 runs   (    0.41 ms per token,  2459.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.87 ms /    12 tokens (   54.74 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =   22485.09 ms /    34 runs   (  661.33 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   23243.64 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.37 ms /    31 runs   (    0.40 ms per token,  2506.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     623.41 ms /    11 tokens (   56.67 ms per token,    17.64 tokens per second)\n",
      "llama_print_timings:        eval time =   20141.96 ms /    30 runs   (  671.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20855.59 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.60 ms /    31 runs   (    0.41 ms per token,  2460.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     708.58 ms /    13 tokens (   54.51 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =   20062.17 ms /    30 runs   (  668.74 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20861.99 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.50 ms /    31 runs   (    0.40 ms per token,  2480.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.36 ms /    12 tokens (   53.61 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   19894.75 ms /    30 runs   (  663.16 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20628.56 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.26 ms /    47 runs   (    0.41 ms per token,  2440.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.14 ms /    12 tokens (   55.26 ms per token,    18.10 tokens per second)\n",
      "llama_print_timings:        eval time =   30990.20 ms /    46 runs   (  673.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   31793.97 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.16 ms /    22 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     669.80 ms /    12 tokens (   55.82 ms per token,    17.92 tokens per second)\n",
      "llama_print_timings:        eval time =   14189.85 ms /    21 runs   (  675.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14924.33 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.13 ms /    22 runs   (    0.42 ms per token,  2409.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.74 ms /    12 tokens (   52.98 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   14105.54 ms /    21 runs   (  671.69 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14805.55 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.13 ms /    29 runs   (    0.42 ms per token,  2391.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     727.41 ms /    13 tokens (   55.95 ms per token,    17.87 tokens per second)\n",
      "llama_print_timings:        eval time =   18576.08 ms /    28 runs   (  663.43 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19389.71 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.41 ms /    28 runs   (    0.41 ms per token,  2454.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.65 ms /    12 tokens (   54.72 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =   18073.57 ms /    27 runs   (  669.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18813.07 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.71 ms /    31 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.32 ms /    13 tokens (   54.18 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   20456.15 ms /    30 runs   (  681.87 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   21253.27 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.31 ms /    30 runs   (    0.44 ms per token,  2254.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.16 ms /    12 tokens (   56.43 ms per token,    17.72 tokens per second)\n",
      "llama_print_timings:        eval time =   19653.09 ms /    29 runs   (  677.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20425.73 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.80 ms /    31 runs   (    0.45 ms per token,  2245.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.05 ms /    12 tokens (   57.00 ms per token,    17.54 tokens per second)\n",
      "llama_print_timings:        eval time =   20284.10 ms /    30 runs   (  676.14 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21065.06 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.43 ms /    32 runs   (    0.45 ms per token,  2217.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.66 ms /    11 tokens (   59.15 ms per token,    16.91 tokens per second)\n",
      "llama_print_timings:        eval time =   21554.06 ms /    31 runs   (  695.29 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   22306.24 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.93 ms /    40 runs   (    0.45 ms per token,  2231.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     880.72 ms /    11 tokens (   80.07 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:        eval time =   27207.73 ms /    39 runs   (  697.63 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   28215.01 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.43 ms /    32 runs   (    0.45 ms per token,  2217.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1009.73 ms /    12 tokens (   84.14 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:        eval time =   21787.63 ms /    31 runs   (  702.83 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   22900.34 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.29 ms /    40 runs   (    0.48 ms per token,  2073.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1087.11 ms /    13 tokens (   83.62 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:        eval time =   26296.38 ms /    39 runs   (  674.27 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27520.00 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.45 ms /    28 runs   (    0.41 ms per token,  2446.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     658.65 ms /    12 tokens (   54.89 ms per token,    18.22 tokens per second)\n",
      "llama_print_timings:        eval time =   18397.11 ms /    27 runs   (  681.37 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19139.94 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.52 ms /    30 runs   (    0.42 ms per token,  2395.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.29 ms /    12 tokens (   54.02 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   19849.06 ms /    29 runs   (  684.45 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20585.68 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.12 ms /    19 runs   (    0.48 ms per token,  2083.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1089.30 ms /    13 tokens (   83.79 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:        eval time =   12311.21 ms /    18 runs   (  683.96 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13462.44 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.12 ms /    26 runs   (    0.43 ms per token,  2338.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1019.56 ms /    12 tokens (   84.96 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:        eval time =   17087.13 ms /    25 runs   (  683.49 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   18184.17 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.27 ms /    22 runs   (    0.47 ms per token,  2142.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     953.30 ms /    11 tokens (   86.66 ms per token,    11.54 tokens per second)\n",
      "llama_print_timings:        eval time =   14156.23 ms /    21 runs   (  674.11 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15180.15 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.77 ms /    52 runs   (    0.46 ms per token,  2187.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1036.73 ms /    12 tokens (   86.39 ms per token,    11.57 tokens per second)\n",
      "llama_print_timings:        eval time =   34390.60 ms /    51 runs   (  674.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   35593.96 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.96 ms /    21 runs   (    0.43 ms per token,  2344.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.97 ms /    11 tokens (   58.00 ms per token,    17.24 tokens per second)\n",
      "llama_print_timings:        eval time =   13551.19 ms /    20 runs   (  677.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14253.03 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.93 ms /    31 runs   (    0.45 ms per token,  2225.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     880.32 ms /    12 tokens (   73.36 ms per token,    13.63 tokens per second)\n",
      "llama_print_timings:        eval time =   21066.42 ms /    30 runs   (  702.21 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   22045.89 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.12 ms /    43 runs   (    0.42 ms per token,  2373.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     667.39 ms /    12 tokens (   55.62 ms per token,    17.98 tokens per second)\n",
      "llama_print_timings:        eval time =   28462.16 ms /    42 runs   (  677.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   29258.93 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.76 ms /    34 runs   (    0.43 ms per token,  2303.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     749.81 ms /    13 tokens (   57.68 ms per token,    17.34 tokens per second)\n",
      "llama_print_timings:        eval time =   22136.80 ms /    33 runs   (  670.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22993.12 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.02 ms /    31 runs   (    0.42 ms per token,  2381.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     689.52 ms /    12 tokens (   57.46 ms per token,    17.40 tokens per second)\n",
      "llama_print_timings:        eval time =   20607.85 ms /    30 runs   (  686.93 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   21391.21 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.21 ms /    32 runs   (    0.41 ms per token,  2422.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.50 ms /    12 tokens (   54.71 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =   20935.24 ms /    31 runs   (  675.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21687.75 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.51 ms /    59 runs   (    0.42 ms per token,  2406.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.17 ms /    12 tokens (   57.01 ms per token,    17.54 tokens per second)\n",
      "llama_print_timings:        eval time =   39693.15 ms /    58 runs   (  684.36 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   40553.19 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.22 ms /    35 runs   (    0.41 ms per token,  2461.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     739.34 ms /    13 tokens (   56.87 ms per token,    17.58 tokens per second)\n",
      "llama_print_timings:        eval time =   22866.06 ms /    34 runs   (  672.53 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   23709.21 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.25 ms /    29 runs   (    0.42 ms per token,  2367.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     706.40 ms /    13 tokens (   54.34 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   18661.12 ms /    28 runs   (  666.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19454.36 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.21 ms /    35 runs   (    0.41 ms per token,  2462.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.67 ms /    12 tokens (   54.14 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   22508.32 ms /    34 runs   (  662.01 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   23261.79 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.16 ms /    28 runs   (    0.43 ms per token,  2302.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.72 ms /    12 tokens (   53.89 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   18258.90 ms /    27 runs   (  676.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18992.58 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.54 ms /    63 runs   (    0.42 ms per token,  2373.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.55 ms /    11 tokens (   54.32 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   42147.75 ms /    62 runs   (  679.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   42932.62 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.38 ms /    46 runs   (    0.42 ms per token,  2373.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     668.33 ms /    12 tokens (   55.69 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:        eval time =   30706.15 ms /    45 runs   (  682.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   31515.13 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.68 ms /    19 runs   (    0.46 ms per token,  2187.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     778.18 ms /    14 tokens (   55.58 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =   12291.02 ms /    18 runs   (  682.83 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13129.88 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.57 ms /    30 runs   (    0.42 ms per token,  2385.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.51 ms /    12 tokens (   64.54 ms per token,    15.49 tokens per second)\n",
      "llama_print_timings:        eval time =   20161.44 ms /    29 runs   (  695.22 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   21025.10 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.55 ms /    37 runs   (    0.42 ms per token,  2380.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1016.92 ms /    12 tokens (   84.74 ms per token,    11.80 tokens per second)\n",
      "llama_print_timings:        eval time =   25014.69 ms /    36 runs   (  694.85 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   26143.50 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    19 runs   (    0.41 ms per token,  2418.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     612.72 ms /    11 tokens (   55.70 ms per token,    17.95 tokens per second)\n",
      "llama_print_timings:        eval time =   12260.35 ms /    18 runs   (  681.13 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12930.08 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.56 ms /    36 runs   (    0.43 ms per token,  2314.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     712.45 ms /    13 tokens (   54.80 ms per token,    18.25 tokens per second)\n",
      "llama_print_timings:        eval time =   25113.35 ms /    35 runs   (  717.52 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =   25940.86 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.94 ms /    33 runs   (    0.42 ms per token,  2366.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1065.89 ms /    12 tokens (   88.82 ms per token,    11.26 tokens per second)\n",
      "llama_print_timings:        eval time =   23374.21 ms /    32 runs   (  730.44 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =   24544.12 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.27 ms /    24 runs   (    0.43 ms per token,  2337.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     967.58 ms /    11 tokens (   87.96 ms per token,    11.37 tokens per second)\n",
      "llama_print_timings:        eval time =   16621.59 ms /    23 runs   (  722.68 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =   17665.50 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.89 ms /    33 runs   (    0.42 ms per token,  2376.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1048.51 ms /    12 tokens (   87.38 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:        eval time =   22979.26 ms /    32 runs   (  718.10 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =   24131.97 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.66 ms /    48 runs   (    0.43 ms per token,  2323.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1045.03 ms /    12 tokens (   87.09 ms per token,    11.48 tokens per second)\n",
      "llama_print_timings:        eval time =   34157.24 ms /    47 runs   (  726.75 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =   35353.51 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.43 ms /    34 runs   (    0.42 ms per token,  2357.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1050.29 ms /    12 tokens (   87.52 ms per token,    11.43 tokens per second)\n",
      "llama_print_timings:        eval time =   23810.77 ms /    33 runs   (  721.54 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =   24966.89 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.65 ms /    37 runs   (    0.42 ms per token,  2364.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1052.04 ms /    12 tokens (   87.67 ms per token,    11.41 tokens per second)\n",
      "llama_print_timings:        eval time =   25968.91 ms /    36 runs   (  721.36 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =   27136.16 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.45 ms /    22 runs   (    0.43 ms per token,  2329.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1127.66 ms /    13 tokens (   86.74 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:        eval time =   14761.00 ms /    21 runs   (  702.90 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   15957.43 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.86 ms /    63 runs   (    0.43 ms per token,  2345.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1047.90 ms /    12 tokens (   87.33 ms per token,    11.45 tokens per second)\n",
      "llama_print_timings:        eval time =   43556.32 ms /    62 runs   (  702.52 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   44802.92 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.31 ms /    22 runs   (    0.42 ms per token,  2363.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1091.64 ms /    12 tokens (   90.97 ms per token,    10.99 tokens per second)\n",
      "llama_print_timings:        eval time =   14717.76 ms /    21 runs   (  700.85 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   15877.36 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.31 ms /    22 runs   (    0.42 ms per token,  2362.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1038.71 ms /    12 tokens (   86.56 ms per token,    11.55 tokens per second)\n",
      "llama_print_timings:        eval time =   14633.83 ms /    21 runs   (  696.85 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   15739.39 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.88 ms /    25 runs   (    0.43 ms per token,  2298.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1114.71 ms /    13 tokens (   85.75 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:        eval time =   16819.23 ms /    24 runs   (  700.80 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   18010.30 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.44 ms /    20 runs   (    0.42 ms per token,  2369.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1031.87 ms /    12 tokens (   85.99 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:        eval time =   13202.92 ms /    19 runs   (  694.89 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   14296.08 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      29.69 ms /    70 runs   (    0.42 ms per token,  2357.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1085.87 ms /    12 tokens (   90.49 ms per token,    11.05 tokens per second)\n",
      "llama_print_timings:        eval time =   48057.04 ms /    69 runs   (  696.48 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   49361.98 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.60 ms /    30 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1032.78 ms /    12 tokens (   86.06 ms per token,    11.62 tokens per second)\n",
      "llama_print_timings:        eval time =   19884.87 ms /    29 runs   (  685.69 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   21009.44 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 400 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.76 ms /    33 runs   (    0.42 ms per token,  2397.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1035.68 ms /    12 tokens (   86.31 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:        eval time =   22150.29 ms /    32 runs   (  692.20 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   23286.22 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.37 ms /    32 runs   (    0.42 ms per token,  2393.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     956.88 ms /    11 tokens (   86.99 ms per token,    11.50 tokens per second)\n",
      "llama_print_timings:        eval time =   21263.58 ms /    31 runs   (  685.92 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   22317.97 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.90 ms /    24 runs   (    0.41 ms per token,  2423.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1106.86 ms /    13 tokens (   85.14 ms per token,    11.74 tokens per second)\n",
      "llama_print_timings:        eval time =   15782.18 ms /    23 runs   (  686.18 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16961.51 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.93 ms /    50 runs   (    0.42 ms per token,  2389.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1027.64 ms /    12 tokens (   85.64 ms per token,    11.68 tokens per second)\n",
      "llama_print_timings:        eval time =   33889.18 ms /    49 runs   (  691.62 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   35069.61 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.97 ms /    23 runs   (    0.43 ms per token,  2306.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     951.90 ms /    11 tokens (   86.54 ms per token,    11.56 tokens per second)\n",
      "llama_print_timings:        eval time =   15086.59 ms /    22 runs   (  685.75 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16109.92 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.47 ms /    27 runs   (    0.42 ms per token,  2354.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1030.97 ms /    12 tokens (   85.91 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:        eval time =   17837.45 ms /    26 runs   (  686.06 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   18950.46 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.65 ms /    23 runs   (    0.42 ms per token,  2383.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1021.22 ms /    12 tokens (   85.10 ms per token,    11.75 tokens per second)\n",
      "llama_print_timings:        eval time =   14950.51 ms /    22 runs   (  679.57 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16040.79 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.34 ms /    34 runs   (    0.42 ms per token,  2370.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1020.67 ms /    12 tokens (   85.06 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:        eval time =   22649.55 ms /    33 runs   (  686.35 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   23773.18 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.63 ms /    18 runs   (    0.42 ms per token,  2359.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1028.99 ms /    12 tokens (   85.75 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:        eval time =   11460.26 ms /    17 runs   (  674.13 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12545.09 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.01 ms /    19 runs   (    0.42 ms per token,  2373.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1110.42 ms /    13 tokens (   85.42 ms per token,    11.71 tokens per second)\n",
      "llama_print_timings:        eval time =   12192.32 ms /    18 runs   (  677.35 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13360.27 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    19 runs   (    0.41 ms per token,  2410.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1106.68 ms /    13 tokens (   85.13 ms per token,    11.75 tokens per second)\n",
      "llama_print_timings:        eval time =   12268.97 ms /    18 runs   (  681.61 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13433.64 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    17 runs   (    0.43 ms per token,  2323.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1043.19 ms /    12 tokens (   86.93 ms per token,    11.50 tokens per second)\n",
      "llama_print_timings:        eval time =   10791.95 ms /    16 runs   (  674.50 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11889.90 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.68 ms /    30 runs   (    0.49 ms per token,  2043.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1033.18 ms /    12 tokens (   86.10 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:        eval time =   19805.15 ms /    29 runs   (  682.94 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20940.70 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.30 ms /    22 runs   (    0.42 ms per token,  2365.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     956.73 ms /    11 tokens (   86.98 ms per token,    11.50 tokens per second)\n",
      "llama_print_timings:        eval time =   14353.12 ms /    21 runs   (  683.48 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   15376.74 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    19 runs   (    0.42 ms per token,  2362.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1025.02 ms /    12 tokens (   85.42 ms per token,    11.71 tokens per second)\n",
      "llama_print_timings:        eval time =   12462.74 ms /    18 runs   (  692.37 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   13545.15 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.27 ms /    22 runs   (    0.42 ms per token,  2374.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1031.98 ms /    12 tokens (   86.00 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:        eval time =   14276.77 ms /    21 runs   (  679.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15375.42 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.45 ms /    19 runs   (    0.44 ms per token,  2249.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1031.34 ms /    12 tokens (   85.94 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:        eval time =   12294.05 ms /    18 runs   (  683.00 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13384.50 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.51 ms /    37 runs   (    0.42 ms per token,  2386.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1109.24 ms /    13 tokens (   85.33 ms per token,    11.72 tokens per second)\n",
      "llama_print_timings:        eval time =   24744.74 ms /    36 runs   (  687.35 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   25967.68 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.00 ms /    31 runs   (    0.42 ms per token,  2384.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1032.13 ms /    12 tokens (   86.01 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:        eval time =   20609.99 ms /    30 runs   (  687.00 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   21737.89 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.99 ms /    38 runs   (    0.42 ms per token,  2376.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1031.89 ms /    12 tokens (   85.99 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:        eval time =   25550.66 ms /    37 runs   (  690.56 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   26698.91 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.38 ms /    30 runs   (    0.41 ms per token,  2422.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1033.18 ms /    12 tokens (   86.10 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:        eval time =   19816.30 ms /    29 runs   (  683.32 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20940.86 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.92 ms /    43 runs   (    0.42 ms per token,  2399.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1032.51 ms /    12 tokens (   86.04 ms per token,    11.62 tokens per second)\n",
      "llama_print_timings:        eval time =   28557.71 ms /    42 runs   (  679.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   29722.52 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.47 ms /    20 runs   (    0.42 ms per token,  2361.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     950.71 ms /    11 tokens (   86.43 ms per token,    11.57 tokens per second)\n",
      "llama_print_timings:        eval time =   12856.81 ms /    19 runs   (  676.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13868.39 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.46 ms /    32 runs   (    0.42 ms per token,  2376.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1040.80 ms /    12 tokens (   86.73 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:        eval time =   21422.88 ms /    31 runs   (  691.06 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   22561.78 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.00 ms /    24 runs   (    0.42 ms per token,  2399.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1105.53 ms /    13 tokens (   85.04 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:        eval time =   16002.93 ms /    23 runs   (  695.78 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   17181.57 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.18 ms /    22 runs   (    0.42 ms per token,  2397.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     952.61 ms /    11 tokens (   86.60 ms per token,    11.55 tokens per second)\n",
      "llama_print_timings:        eval time =   14464.68 ms /    21 runs   (  688.79 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   15483.66 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.30 ms /    19 runs   (    0.44 ms per token,  2288.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1032.54 ms /    12 tokens (   86.04 ms per token,    11.62 tokens per second)\n",
      "llama_print_timings:        eval time =   12385.72 ms /    18 runs   (  688.10 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13475.86 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.77 ms /    47 runs   (    0.44 ms per token,  2263.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1027.70 ms /    12 tokens (   85.64 ms per token,    11.68 tokens per second)\n",
      "llama_print_timings:        eval time =   32073.26 ms /    46 runs   (  697.24 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   33250.85 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.23 ms /    19 runs   (    0.43 ms per token,  2308.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1032.95 ms /    12 tokens (   86.08 ms per token,    11.62 tokens per second)\n",
      "llama_print_timings:        eval time =   12613.34 ms /    18 runs   (  700.74 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   13704.56 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.81 ms /    33 runs   (    0.42 ms per token,  2388.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1031.71 ms /    12 tokens (   85.98 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:        eval time =   22160.11 ms /    32 runs   (  692.50 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   23291.69 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.65 ms /    31 runs   (    0.44 ms per token,  2271.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     960.35 ms /    11 tokens (   87.30 ms per token,    11.45 tokens per second)\n",
      "llama_print_timings:        eval time =   20735.09 ms /    30 runs   (  691.17 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   21795.07 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.71 ms /    30 runs   (    0.42 ms per token,  2360.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     957.25 ms /    11 tokens (   87.02 ms per token,    11.49 tokens per second)\n",
      "llama_print_timings:        eval time =   19813.80 ms /    29 runs   (  683.23 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20863.23 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.24 ms /    29 runs   (    0.42 ms per token,  2369.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1110.05 ms /    13 tokens (   85.39 ms per token,    11.71 tokens per second)\n",
      "llama_print_timings:        eval time =   19394.06 ms /    28 runs   (  692.64 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   20592.19 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.05 ms /    19 runs   (    0.42 ms per token,  2360.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1027.91 ms /    12 tokens (   85.66 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:        eval time =   12266.66 ms /    18 runs   (  681.48 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13351.77 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.68 ms /    35 runs   (    0.42 ms per token,  2383.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1182.00 ms /    14 tokens (   84.43 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:        eval time =   23536.74 ms /    34 runs   (  692.26 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   24826.34 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.41 ms /    37 runs   (    0.42 ms per token,  2400.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1039.30 ms /    12 tokens (   86.61 ms per token,    11.55 tokens per second)\n",
      "llama_print_timings:        eval time =   25149.32 ms /    36 runs   (  698.59 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   26302.67 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.46 ms /    30 runs   (    0.42 ms per token,  2407.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1035.70 ms /    12 tokens (   86.31 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:        eval time =   20265.23 ms /    29 runs   (  698.80 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   21393.49 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.25 ms /    50 runs   (    0.43 ms per token,  2352.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     960.64 ms /    11 tokens (   87.33 ms per token,    11.45 tokens per second)\n",
      "llama_print_timings:        eval time =   34304.89 ms /    49 runs   (  700.10 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   35418.53 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.45 ms /    35 runs   (    0.41 ms per token,  2422.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1117.70 ms /    13 tokens (   85.98 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:        eval time =   23600.60 ms /    34 runs   (  694.14 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   24823.78 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.90 ms /    19 runs   (    0.42 ms per token,  2405.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     948.97 ms /    11 tokens (   86.27 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:        eval time =   12365.39 ms /    18 runs   (  686.97 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13371.63 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.03 ms /    43 runs   (    0.42 ms per token,  2385.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1028.88 ms /    12 tokens (   85.74 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:        eval time =   29136.71 ms /    42 runs   (  693.73 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   30299.11 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    19 runs   (    0.42 ms per token,  2364.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1113.93 ms /    13 tokens (   85.69 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:        eval time =   12471.10 ms /    18 runs   (  692.84 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   13646.08 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.18 ms /    47 runs   (    0.43 ms per token,  2329.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     950.52 ms /    11 tokens (   86.41 ms per token,    11.57 tokens per second)\n",
      "llama_print_timings:        eval time =   31367.07 ms /    46 runs   (  681.89 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   32462.45 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      33.05 ms /    78 runs   (    0.42 ms per token,  2360.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     941.33 ms /    11 tokens (   85.58 ms per token,    11.69 tokens per second)\n",
      "llama_print_timings:        eval time =   53072.78 ms /    77 runs   (  689.26 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   54253.85 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.13 ms /    43 runs   (    0.42 ms per token,  2372.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1033.16 ms /    12 tokens (   86.10 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:        eval time =   28594.07 ms /    42 runs   (  680.81 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   29759.58 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      38.06 ms /    87 runs   (    0.44 ms per token,  2285.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1021.01 ms /    12 tokens (   85.08 ms per token,    11.75 tokens per second)\n",
      "llama_print_timings:        eval time =   59228.92 ms /    86 runs   (  688.71 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   60520.59 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    18 runs   (    0.42 ms per token,  2360.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1042.56 ms /    12 tokens (   86.88 ms per token,    11.51 tokens per second)\n",
      "llama_print_timings:        eval time =   11877.09 ms /    17 runs   (  698.65 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   12974.86 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    19 runs   (    0.43 ms per token,  2341.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1117.25 ms /    13 tokens (   85.94 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:        eval time =   12529.07 ms /    18 runs   (  696.06 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   13705.12 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      34.10 ms /    82 runs   (    0.42 ms per token,  2404.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     954.95 ms /    11 tokens (   86.81 ms per token,    11.52 tokens per second)\n",
      "llama_print_timings:        eval time =   56492.64 ms /    81 runs   (  697.44 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   57700.71 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.40 ms /    58 runs   (    0.44 ms per token,  2283.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1029.26 ms /    12 tokens (   85.77 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:        eval time =   39912.48 ms /    57 runs   (  700.22 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   41121.33 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.78 ms /    64 runs   (    0.42 ms per token,  2390.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     960.75 ms /    11 tokens (   87.34 ms per token,    11.45 tokens per second)\n",
      "llama_print_timings:        eval time =   43896.16 ms /    63 runs   (  696.76 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   45052.92 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.03 ms /    19 runs   (    0.42 ms per token,  2366.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1012.18 ms /    12 tokens (   84.35 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:        eval time =   12332.28 ms /    18 runs   (  685.13 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13401.33 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.15 ms /    22 runs   (    0.42 ms per token,  2404.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     845.37 ms /    13 tokens (   65.03 ms per token,    15.38 tokens per second)\n",
      "llama_print_timings:        eval time =   14006.43 ms /    21 runs   (  666.97 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14916.18 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.75 ms /    29 runs   (    0.44 ms per token,  2274.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.66 ms /    12 tokens (   53.47 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   18574.45 ms /    28 runs   (  663.37 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19307.18 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      30.73 ms /    74 runs   (    0.42 ms per token,  2407.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.37 ms /    12 tokens (   54.11 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   48849.81 ms /    73 runs   (  669.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   49717.58 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.35 ms /    23 runs   (    0.41 ms per token,  2460.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.46 ms /    12 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   14784.69 ms /    22 runs   (  672.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15495.03 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    19 runs   (    0.42 ms per token,  2397.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.45 ms /    12 tokens (   53.54 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   12181.73 ms /    18 runs   (  676.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12881.23 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.69 ms /    50 runs   (    0.41 ms per token,  2416.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     696.59 ms /    13 tokens (   53.58 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   32700.84 ms /    49 runs   (  667.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   33545.41 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.33 ms /    38 runs   (    0.40 ms per token,  2478.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.48 ms /    12 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   25270.97 ms /    37 runs   (  683.00 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   26025.59 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.91 ms /    19 runs   (    0.42 ms per token,  2402.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.80 ms /    12 tokens (   56.90 ms per token,    17.57 tokens per second)\n",
      "llama_print_timings:        eval time =   11973.49 ms /    18 runs   (  665.19 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12712.23 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.87 ms /    19 runs   (    0.47 ms per token,  2142.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.10 ms /    12 tokens (   54.26 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   12135.23 ms /    18 runs   (  674.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12848.28 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.36 ms /    23 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     674.43 ms /    12 tokens (   56.20 ms per token,    17.79 tokens per second)\n",
      "llama_print_timings:        eval time =   14885.43 ms /    22 runs   (  676.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15628.16 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.85 ms /    46 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     722.76 ms /    13 tokens (   55.60 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =   30319.06 ms /    45 runs   (  673.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   31184.09 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.64 ms /    31 runs   (    0.41 ms per token,  2451.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     625.63 ms /    11 tokens (   56.88 ms per token,    17.58 tokens per second)\n",
      "llama_print_timings:        eval time =   20113.99 ms /    30 runs   (  670.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20830.64 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.34 ms /    29 runs   (    0.43 ms per token,  2349.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.34 ms /    12 tokens (   56.86 ms per token,    17.59 tokens per second)\n",
      "llama_print_timings:        eval time =   19243.61 ms /    28 runs   (  687.27 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20011.98 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.61 ms /    52 runs   (    0.51 ms per token,  1954.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     710.00 ms /    12 tokens (   59.17 ms per token,    16.90 tokens per second)\n",
      "llama_print_timings:        eval time =   36931.94 ms /    51 runs   (  724.16 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =   37816.77 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.73 ms /    19 runs   (    0.46 ms per token,  2176.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     835.69 ms /    12 tokens (   69.64 ms per token,    14.36 tokens per second)\n",
      "llama_print_timings:        eval time =   13659.69 ms /    18 runs   (  758.87 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =   14557.59 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.35 ms /    30 runs   (    0.44 ms per token,  2247.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     897.72 ms /    13 tokens (   69.06 ms per token,    14.48 tokens per second)\n",
      "llama_print_timings:        eval time =   22728.96 ms /    29 runs   (  783.76 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =   23721.33 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.52 ms /    43 runs   (    0.48 ms per token,  2096.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     923.66 ms /    12 tokens (   76.97 ms per token,    12.99 tokens per second)\n",
      "llama_print_timings:        eval time =   32268.94 ms /    42 runs   (  768.31 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =   33339.70 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.60 ms /    31 runs   (    0.47 ms per token,  2123.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     793.45 ms /    12 tokens (   66.12 ms per token,    15.12 tokens per second)\n",
      "llama_print_timings:        eval time =   23085.63 ms /    30 runs   (  769.52 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =   23978.75 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.32 ms /    41 runs   (    0.50 ms per token,  2017.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     851.49 ms /    13 tokens (   65.50 ms per token,    15.27 tokens per second)\n",
      "llama_print_timings:        eval time =   30659.06 ms /    40 runs   (  766.48 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =   31651.89 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.97 ms /    36 runs   (    0.47 ms per token,  2121.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.97 ms /    12 tokens (   65.08 ms per token,    15.37 tokens per second)\n",
      "llama_print_timings:        eval time =   27556.74 ms /    35 runs   (  787.34 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =   28455.43 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.70 ms /    31 runs   (    0.51 ms per token,  1974.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     799.31 ms /    12 tokens (   66.61 ms per token,    15.01 tokens per second)\n",
      "llama_print_timings:        eval time =   23079.82 ms /    30 runs   (  769.33 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =   23992.63 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      31.56 ms /    67 runs   (    0.47 ms per token,  2123.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.04 ms /    12 tokens (   64.50 ms per token,    15.50 tokens per second)\n",
      "llama_print_timings:        eval time =   49890.68 ms /    66 runs   (  755.92 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =   50888.14 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.42 ms /    22 runs   (    0.43 ms per token,  2334.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     961.85 ms /    13 tokens (   73.99 ms per token,    13.52 tokens per second)\n",
      "llama_print_timings:        eval time =   14583.50 ms /    21 runs   (  694.45 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   15614.26 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.33 ms /    32 runs   (    0.42 ms per token,  2401.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     669.11 ms /    12 tokens (   55.76 ms per token,    17.93 tokens per second)\n",
      "llama_print_timings:        eval time =   21584.40 ms /    31 runs   (  696.27 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   22354.79 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.17 ms /    32 runs   (    0.41 ms per token,  2430.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     696.94 ms /    11 tokens (   63.36 ms per token,    15.78 tokens per second)\n",
      "llama_print_timings:        eval time =   21602.25 ms /    31 runs   (  696.85 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   22396.38 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.42 ms /    32 runs   (    0.42 ms per token,  2384.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.81 ms /    12 tokens (   57.82 ms per token,    17.30 tokens per second)\n",
      "llama_print_timings:        eval time =   21416.46 ms /    31 runs   (  690.85 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   22207.75 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.11 ms /    29 runs   (    0.42 ms per token,  2395.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.67 ms /    12 tokens (   56.97 ms per token,    17.55 tokens per second)\n",
      "llama_print_timings:        eval time =   19214.74 ms /    28 runs   (  686.24 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   19986.47 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.37 ms /    32 runs   (    0.42 ms per token,  2394.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.63 ms /    12 tokens (   57.14 ms per token,    17.50 tokens per second)\n",
      "llama_print_timings:        eval time =   20924.44 ms /    31 runs   (  674.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21705.71 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.35 ms /    39 runs   (    0.42 ms per token,  2384.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     675.69 ms /    12 tokens (   56.31 ms per token,    17.76 tokens per second)\n",
      "llama_print_timings:        eval time =   25644.90 ms /    38 runs   (  674.87 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26439.26 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.27 ms /    31 runs   (    0.43 ms per token,  2335.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     783.82 ms /    15 tokens (   52.25 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   20965.21 ms /    30 runs   (  698.84 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   21844.42 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.87 ms /    37 runs   (    0.43 ms per token,  2332.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     671.55 ms /    12 tokens (   55.96 ms per token,    17.87 tokens per second)\n",
      "llama_print_timings:        eval time =   25226.14 ms /    36 runs   (  700.73 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   26011.95 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.03 ms /    38 runs   (    0.42 ms per token,  2370.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     701.78 ms /    12 tokens (   58.48 ms per token,    17.10 tokens per second)\n",
      "llama_print_timings:        eval time =   25652.60 ms /    37 runs   (  693.31 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   26471.92 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.13 ms /    34 runs   (    0.42 ms per token,  2406.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.38 ms /    11 tokens (   58.67 ms per token,    17.04 tokens per second)\n",
      "llama_print_timings:        eval time =   23155.90 ms /    33 runs   (  701.69 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   23901.64 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.21 ms /    37 runs   (    0.41 ms per token,  2433.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.89 ms /    12 tokens (   53.57 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   25214.00 ms /    36 runs   (  700.39 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   25966.39 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.20 ms /    59 runs   (    0.44 ms per token,  2251.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     717.46 ms /    11 tokens (   65.22 ms per token,    15.33 tokens per second)\n",
      "llama_print_timings:        eval time =   40536.27 ms /    58 runs   (  698.90 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   41439.59 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.17 ms /    28 runs   (    0.43 ms per token,  2300.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     669.01 ms /    12 tokens (   55.75 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =   18134.94 ms /    27 runs   (  671.66 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18889.52 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.57 ms /    39 runs   (    0.42 ms per token,  2353.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     660.30 ms /    12 tokens (   55.02 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =   25756.43 ms /    38 runs   (  677.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26539.62 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.30 ms /    30 runs   (    0.41 ms per token,  2438.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     719.56 ms /    13 tokens (   55.35 ms per token,    18.07 tokens per second)\n",
      "llama_print_timings:        eval time =   19525.70 ms /    29 runs   (  673.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20335.39 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.18 ms /    22 runs   (    0.42 ms per token,  2395.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.31 ms /    12 tokens (   56.61 ms per token,    17.66 tokens per second)\n",
      "llama_print_timings:        eval time =   14019.26 ms /    21 runs   (  667.58 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14765.18 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.64 ms /    39 runs   (    0.43 ms per token,  2343.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.83 ms /    12 tokens (   54.49 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =   25700.79 ms /    38 runs   (  676.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26474.25 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.68 ms /    20 runs   (    0.43 ms per token,  2303.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     716.95 ms /    13 tokens (   55.15 ms per token,    18.13 tokens per second)\n",
      "llama_print_timings:        eval time =   13123.81 ms /    19 runs   (  690.73 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13900.89 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.42 ms /    30 runs   (    0.41 ms per token,  2415.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     723.95 ms /    13 tokens (   55.69 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:        eval time =   19784.00 ms /    29 runs   (  682.21 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20598.85 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.37 ms /    30 runs   (    0.41 ms per token,  2425.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.26 ms /    13 tokens (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   19326.39 ms /    29 runs   (  666.43 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20111.16 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.23 ms /    52 runs   (    0.43 ms per token,  2339.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.78 ms /    12 tokens (   54.40 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   35219.82 ms /    51 runs   (  690.58 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   36030.79 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.84 ms /    25 runs   (    0.43 ms per token,  2307.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     726.68 ms /    12 tokens (   60.56 ms per token,    16.51 tokens per second)\n",
      "llama_print_timings:        eval time =   16445.86 ms /    24 runs   (  685.24 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   17247.68 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.07 ms /    32 runs   (    0.41 ms per token,  2448.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     696.52 ms /    13 tokens (   53.58 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   20843.22 ms /    31 runs   (  672.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21636.26 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.51 ms /    30 runs   (    0.42 ms per token,  2398.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     707.90 ms /    12 tokens (   58.99 ms per token,    16.95 tokens per second)\n",
      "llama_print_timings:        eval time =   19245.99 ms /    29 runs   (  663.65 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20045.45 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.29 ms /    25 runs   (    0.41 ms per token,  2430.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.93 ms /    12 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   16257.57 ms /    24 runs   (  677.40 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16966.69 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 500 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.94 ms /    43 runs   (    0.42 ms per token,  2397.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     694.80 ms /    13 tokens (   53.45 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   28775.07 ms /    42 runs   (  685.12 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   29597.44 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.22 ms /    27 runs   (    0.42 ms per token,  2406.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     671.08 ms /    12 tokens (   55.92 ms per token,    17.88 tokens per second)\n",
      "llama_print_timings:        eval time =   17701.50 ms /    26 runs   (  680.83 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18452.50 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.66 ms /    30 runs   (    0.42 ms per token,  2368.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.67 ms /    11 tokens (   53.79 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   19784.15 ms /    29 runs   (  682.21 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20464.63 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.67 ms /    18 runs   (    0.43 ms per token,  2346.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.12 ms /    13 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   11420.91 ms /    17 runs   (  671.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12160.40 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.34 ms /    30 runs   (    0.41 ms per token,  2431.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     627.46 ms /    11 tokens (   57.04 ms per token,    17.53 tokens per second)\n",
      "llama_print_timings:        eval time =   20002.55 ms /    29 runs   (  689.74 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   20719.71 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.42 ms /    35 runs   (    0.41 ms per token,  2427.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.99 ms /    12 tokens (   54.25 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   22792.47 ms /    34 runs   (  670.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   23549.06 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.83 ms /    43 runs   (    0.41 ms per token,  2411.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.21 ms /    12 tokens (   53.77 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   28940.01 ms /    42 runs   (  689.05 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   29712.24 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.23 ms /    29 runs   (    0.42 ms per token,  2370.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.42 ms /    11 tokens (   54.58 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   19037.92 ms /    28 runs   (  679.93 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19724.59 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.84 ms /    31 runs   (    0.41 ms per token,  2413.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     660.81 ms /    12 tokens (   55.07 ms per token,    18.16 tokens per second)\n",
      "llama_print_timings:        eval time =   19660.72 ms /    30 runs   (  655.36 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   20412.80 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.06 ms /    34 runs   (    0.41 ms per token,  2417.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.17 ms /    12 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   21985.39 ms /    33 runs   (  666.22 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22721.52 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    20 runs   (    0.41 ms per token,  2457.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     726.61 ms /    13 tokens (   55.89 ms per token,    17.89 tokens per second)\n",
      "llama_print_timings:        eval time =   12784.66 ms /    19 runs   (  672.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13570.10 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.93 ms /    37 runs   (    0.40 ms per token,  2477.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.82 ms /    12 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   24087.94 ms /    36 runs   (  669.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24841.81 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.22 ms /    42 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.19 ms /    12 tokens (   53.77 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   27532.36 ms /    41 runs   (  671.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28301.94 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.25 ms /    42 runs   (    0.41 ms per token,  2435.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     626.75 ms /    11 tokens (   56.98 ms per token,    17.55 tokens per second)\n",
      "llama_print_timings:        eval time =   27620.64 ms /    41 runs   (  673.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   28371.44 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.69 ms /    37 runs   (    0.42 ms per token,  2357.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.04 ms /    12 tokens (   52.84 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   23612.98 ms /    36 runs   (  655.92 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   24362.28 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.42 ms /    59 runs   (    0.41 ms per token,  2416.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     727.52 ms /    14 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   39317.67 ms /    58 runs   (  677.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   40222.03 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.08 ms /    30 runs   (    0.40 ms per token,  2484.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     601.56 ms /    11 tokens (   54.69 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =   19569.44 ms /    29 runs   (  674.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20258.76 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    20 runs   (    0.40 ms per token,  2473.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.25 ms /    12 tokens (   53.27 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   12811.96 ms /    19 runs   (  674.31 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13510.70 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.81 ms /    21 runs   (    0.42 ms per token,  2384.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.24 ms /    12 tokens (   53.10 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   13408.87 ms /    20 runs   (  670.44 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14108.26 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.52 ms /    30 runs   (    0.42 ms per token,  2395.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.73 ms /    12 tokens (   52.81 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   19854.19 ms /    29 runs   (  684.63 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20577.60 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.52 ms /    30 runs   (    0.42 ms per token,  2396.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     625.43 ms /    11 tokens (   56.86 ms per token,    17.59 tokens per second)\n",
      "llama_print_timings:        eval time =   19781.64 ms /    29 runs   (  682.13 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20496.41 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.59 ms /    30 runs   (    0.42 ms per token,  2383.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.53 ms /    12 tokens (   56.96 ms per token,    17.56 tokens per second)\n",
      "llama_print_timings:        eval time =   19533.92 ms /    29 runs   (  673.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20307.52 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.86 ms /    31 runs   (    0.41 ms per token,  2410.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     740.60 ms /    13 tokens (   56.97 ms per token,    17.55 tokens per second)\n",
      "llama_print_timings:        eval time =   20524.19 ms /    30 runs   (  684.14 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   21356.04 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.24 ms /    53 runs   (    0.40 ms per token,  2495.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     664.57 ms /    12 tokens (   55.38 ms per token,    18.06 tokens per second)\n",
      "llama_print_timings:        eval time =   35009.06 ms /    52 runs   (  673.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   35829.31 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.14 ms /    42 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.55 ms /    12 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   26868.39 ms /    41 runs   (  655.33 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   27641.04 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.62 ms /    60 runs   (    0.41 ms per token,  2436.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     601.61 ms /    11 tokens (   54.69 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =   38766.79 ms /    59 runs   (  657.06 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   39548.91 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.09 ms /    25 runs   (    0.40 ms per token,  2478.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.61 ms /    12 tokens (   53.63 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   15808.09 ms /    24 runs   (  658.67 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   16524.40 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.08 ms /    42 runs   (    0.41 ms per token,  2459.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.53 ms /    13 tokens (   52.66 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   27487.81 ms /    41 runs   (  670.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28294.50 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.30 ms /    30 runs   (    0.41 ms per token,  2439.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.32 ms /    12 tokens (   54.53 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   19291.78 ms /    29 runs   (  665.23 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20034.40 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.15 ms /    30 runs   (    0.40 ms per token,  2469.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.02 ms /    12 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   19558.29 ms /    29 runs   (  674.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20284.51 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.38 ms /    43 runs   (    0.43 ms per token,  2339.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.52 ms /    12 tokens (   54.54 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   27982.92 ms /    42 runs   (  666.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28770.97 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.80 ms /    49 runs   (    0.42 ms per token,  2355.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     706.80 ms /    13 tokens (   54.37 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =   32149.50 ms /    48 runs   (  669.78 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   33004.62 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.81 ms /    24 runs   (    0.41 ms per token,  2447.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.33 ms /    12 tokens (   53.44 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   15462.61 ms /    23 runs   (  672.29 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16175.17 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.73 ms /    66 runs   (    0.40 ms per token,  2469.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     791.29 ms /    12 tokens (   65.94 ms per token,    15.17 tokens per second)\n",
      "llama_print_timings:        eval time =   44133.67 ms /    65 runs   (  678.98 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   45120.71 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.14 ms /    38 runs   (    0.40 ms per token,  2510.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.48 ms /    12 tokens (   52.71 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   24943.67 ms /    37 runs   (  674.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25688.89 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.85 ms /    34 runs   (    0.41 ms per token,  2454.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.75 ms /    12 tokens (   52.73 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   22123.14 ms /    33 runs   (  670.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22854.14 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.16 ms /    30 runs   (    0.41 ms per token,  2466.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.29 ms /    13 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   19591.11 ms /    29 runs   (  675.56 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20365.35 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.96 ms /    37 runs   (    0.40 ms per token,  2472.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.85 ms /    12 tokens (   53.49 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   24071.51 ms /    36 runs   (  668.65 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24821.98 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.67 ms /    41 runs   (    0.41 ms per token,  2459.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.47 ms /    12 tokens (   53.29 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   26779.64 ms /    40 runs   (  669.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   27540.84 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.65 ms /    20 runs   (    0.43 ms per token,  2311.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.69 ms /    12 tokens (   53.06 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   12793.82 ms /    19 runs   (  673.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13493.53 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      38.43 ms /    93 runs   (    0.41 ms per token,  2419.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.52 ms /    12 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   61958.10 ms /    92 runs   (  673.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   62872.15 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.83 ms /    27 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     689.72 ms /    13 tokens (   53.06 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   17255.22 ms /    26 runs   (  663.66 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   18024.12 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.88 ms /    32 runs   (    0.40 ms per token,  2484.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.18 ms /    12 tokens (   54.35 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   20365.75 ms /    31 runs   (  656.96 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21112.52 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.58 ms /    39 runs   (    0.40 ms per token,  2503.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.75 ms /    12 tokens (   54.56 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   25199.87 ms /    38 runs   (  663.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   25971.73 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.13 ms /    30 runs   (    0.40 ms per token,  2473.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     676.16 ms /    13 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   19288.17 ms /    29 runs   (  665.11 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20050.37 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.25 ms /    55 runs   (    0.40 ms per token,  2471.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.40 ms /    12 tokens (   56.70 ms per token,    17.64 tokens per second)\n",
      "llama_print_timings:        eval time =   35924.09 ms /    54 runs   (  665.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   36766.78 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.62 ms /    41 runs   (    0.41 ms per token,  2466.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.65 ms /    12 tokens (   54.22 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   26954.49 ms /    40 runs   (  673.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27724.71 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.06 ms /    22 runs   (    0.41 ms per token,  2429.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.10 ms /    12 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   14015.86 ms /    21 runs   (  667.42 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14725.84 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.75 ms /    31 runs   (    0.41 ms per token,  2430.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.49 ms /    12 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   20138.53 ms /    30 runs   (  671.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20866.64 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.82 ms /    27 runs   (    0.40 ms per token,  2496.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.87 ms /    13 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   17552.58 ms /    26 runs   (  675.10 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18312.39 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.79 ms /    44 runs   (    0.43 ms per token,  2342.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     660.31 ms /    12 tokens (   55.03 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =   28572.47 ms /    43 runs   (  664.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   29366.27 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.94 ms /    24 runs   (    0.41 ms per token,  2413.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     615.40 ms /    11 tokens (   55.95 ms per token,    17.87 tokens per second)\n",
      "llama_print_timings:        eval time =   15089.79 ms /    23 runs   (  656.08 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15775.89 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.47 ms /    43 runs   (    0.41 ms per token,  2461.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.05 ms /    12 tokens (   54.92 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =   28128.17 ms /    42 runs   (  669.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28913.13 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.46 ms /    32 runs   (    0.42 ms per token,  2376.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.33 ms /    11 tokens (   54.30 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   20507.20 ms /    31 runs   (  661.52 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21200.54 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.56 ms /    45 runs   (    0.41 ms per token,  2425.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.67 ms /    12 tokens (   53.39 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   29379.68 ms /    44 runs   (  667.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   30153.98 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.71 ms /    39 runs   (    0.40 ms per token,  2483.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.38 ms /    12 tokens (   53.12 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   25181.06 ms /    38 runs   (  662.66 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   25933.03 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.73 ms /    31 runs   (    0.41 ms per token,  2435.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.93 ms /    12 tokens (   53.74 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   20172.56 ms /    30 runs   (  672.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20908.12 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.19 ms /    40 runs   (    0.40 ms per token,  2470.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.62 ms /    13 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   26290.85 ms /    39 runs   (  674.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27101.64 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.38 ms /    25 runs   (    0.42 ms per token,  2408.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.00 ms /    12 tokens (   53.83 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   16102.25 ms /    24 runs   (  670.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16822.13 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.76 ms /    29 runs   (    0.41 ms per token,  2466.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.12 ms /    13 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   18553.81 ms /    28 runs   (  662.64 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19325.68 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.64 ms /    37 runs   (    0.40 ms per token,  2526.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.52 ms /    12 tokens (   58.21 ms per token,    17.18 tokens per second)\n",
      "llama_print_timings:        eval time =   24079.52 ms /    36 runs   (  668.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24886.11 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.68 ms /    38 runs   (    0.41 ms per token,  2422.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.32 ms /    12 tokens (   53.19 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   24959.06 ms /    37 runs   (  674.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25711.06 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.96 ms /    30 runs   (    0.40 ms per token,  2508.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.93 ms /    12 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   19599.02 ms /    29 runs   (  675.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20319.52 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.85 ms /    39 runs   (    0.41 ms per token,  2460.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.38 ms /    11 tokens (   53.94 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   25704.77 ms /    38 runs   (  676.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26413.18 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.69 ms /    34 runs   (    0.40 ms per token,  2484.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.40 ms /    12 tokens (   53.37 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   22024.94 ms /    33 runs   (  667.42 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22764.75 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.85 ms /    24 runs   (    0.41 ms per token,  2436.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.21 ms /    12 tokens (   53.52 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   15645.45 ms /    23 runs   (  680.24 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16356.99 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.36 ms /    38 runs   (    0.40 ms per token,  2473.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.64 ms /    11 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   24517.12 ms /    37 runs   (  662.62 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   25217.56 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.22 ms /    30 runs   (    0.41 ms per token,  2455.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.97 ms /    12 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   19080.28 ms /    29 runs   (  657.94 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19807.51 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.28 ms /    42 runs   (    0.41 ms per token,  2430.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     744.66 ms /    14 tokens (   53.19 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   27061.02 ms /    41 runs   (  660.02 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   27929.84 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.34 ms /    52 runs   (    0.41 ms per token,  2437.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.63 ms /    11 tokens (   53.78 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   34191.02 ms /    51 runs   (  670.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   34937.84 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.50 ms /    31 runs   (    0.40 ms per token,  2479.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.51 ms /    12 tokens (   54.54 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   20053.39 ms /    30 runs   (  668.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20799.52 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.78 ms /    24 runs   (    0.41 ms per token,  2453.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.10 ms /    12 tokens (   52.84 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   15313.67 ms /    23 runs   (  665.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16019.05 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.87 ms /    40 runs   (    0.40 ms per token,  2521.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.45 ms /    12 tokens (   52.62 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   25908.27 ms /    39 runs   (  664.31 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   26658.24 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.90 ms /    24 runs   (    0.41 ms per token,  2424.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.47 ms /    12 tokens (   53.12 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   15403.11 ms /    23 runs   (  669.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16113.12 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.28 ms /    38 runs   (    0.40 ms per token,  2486.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     729.53 ms /    13 tokens (   56.12 ms per token,    17.82 tokens per second)\n",
      "llama_print_timings:        eval time =   24585.71 ms /    37 runs   (  664.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   25429.30 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.89 ms /    29 runs   (    0.41 ms per token,  2438.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.83 ms /    12 tokens (   52.90 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   18706.63 ms /    28 runs   (  668.09 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19427.59 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.19 ms /    33 runs   (    0.40 ms per token,  2502.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.24 ms /    12 tokens (   53.69 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   21151.64 ms /    32 runs   (  660.99 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21893.99 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.50 ms /    39 runs   (    0.40 ms per token,  2516.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     605.97 ms /    11 tokens (   55.09 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =   25202.62 ms /    38 runs   (  663.23 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   25924.42 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.14 ms /    25 runs   (    0.41 ms per token,  2465.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.41 ms /    12 tokens (   53.12 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   16162.44 ms /    24 runs   (  673.43 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16874.47 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.96 ms /    42 runs   (    0.40 ms per token,  2476.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     604.90 ms /    11 tokens (   54.99 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =   27910.45 ms /    41 runs   (  680.74 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   28640.28 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.11 ms /    30 runs   (    0.40 ms per token,  2477.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.55 ms /    13 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   19653.85 ms /    29 runs   (  677.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20422.74 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.21 ms /    52 runs   (    0.41 ms per token,  2451.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.46 ms /    12 tokens (   53.79 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   34631.88 ms /    51 runs   (  679.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   35430.40 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.29 ms /    20 runs   (    0.46 ms per token,  2151.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.22 ms /    12 tokens (   53.69 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   12965.51 ms /    19 runs   (  682.40 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13675.27 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.79 ms /    45 runs   (    0.42 ms per token,  2394.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.59 ms /    12 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   30016.34 ms /    44 runs   (  682.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   30795.59 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.03 ms /    25 runs   (    0.44 ms per token,  2267.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.51 ms /    12 tokens (   58.21 ms per token,    17.18 tokens per second)\n",
      "llama_print_timings:        eval time =   16308.94 ms /    24 runs   (  679.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17086.88 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.37 ms /    50 runs   (    0.41 ms per token,  2454.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.13 ms /    13 tokens (   52.09 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   33267.27 ms /    49 runs   (  678.92 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   34089.05 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.33 ms /    45 runs   (    0.41 ms per token,  2455.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     669.49 ms /    12 tokens (   55.79 ms per token,    17.92 tokens per second)\n",
      "llama_print_timings:        eval time =   29809.30 ms /    44 runs   (  677.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   30610.72 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.32 ms /    60 runs   (    0.41 ms per token,  2466.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.75 ms /    11 tokens (   53.89 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   39260.75 ms /    59 runs   (  665.44 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   40032.08 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.93 ms /    42 runs   (    0.40 ms per token,  2481.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.32 ms /    12 tokens (   53.69 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   27340.87 ms /    41 runs   (  666.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28110.92 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.03 ms /    30 runs   (    0.40 ms per token,  2492.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.90 ms /    12 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   19132.78 ms /    29 runs   (  659.75 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19858.39 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.08 ms /    30 runs   (    0.40 ms per token,  2483.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.34 ms /    11 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   19641.47 ms /    29 runs   (  677.29 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20321.17 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.12 ms /    42 runs   (    0.41 ms per token,  2453.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.79 ms /    12 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   27622.79 ms /    41 runs   (  673.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   28381.25 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.03 ms /    42 runs   (    0.41 ms per token,  2465.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     599.34 ms /    11 tokens (   54.49 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =   27192.15 ms /    41 runs   (  663.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   27916.36 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.96 ms /    22 runs   (    0.41 ms per token,  2456.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     690.34 ms /    13 tokens (   53.10 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   14124.21 ms /    21 runs   (  672.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14879.15 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.76 ms /    43 runs   (    0.41 ms per token,  2420.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.51 ms /    12 tokens (   53.21 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   28324.74 ms /    42 runs   (  674.40 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   29090.00 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.08 ms /    25 runs   (    0.40 ms per token,  2479.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     977.67 ms /    13 tokens (   75.21 ms per token,    13.30 tokens per second)\n",
      "llama_print_timings:        eval time =   16084.55 ms /    24 runs   (  670.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17135.16 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.24 ms /    34 runs   (    0.39 ms per token,  2568.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.84 ms /    12 tokens (   53.32 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   22138.22 ms /    33 runs   (  670.86 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22876.57 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    20 runs   (    0.41 ms per token,  2434.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.42 ms /    12 tokens (   53.29 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   12615.49 ms /    19 runs   (  663.97 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13313.97 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.96 ms /    27 runs   (    0.41 ms per token,  2463.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.65 ms /    13 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   17496.17 ms /    26 runs   (  672.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18257.24 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.08 ms /    40 runs   (    0.40 ms per token,  2487.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.28 ms /    12 tokens (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   26071.44 ms /    39 runs   (  668.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26825.89 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 600 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.37 ms /    65 runs   (    0.41 ms per token,  2465.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.00 ms /    12 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   42627.49 ms /    64 runs   (  666.05 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   43449.70 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      30.78 ms /    76 runs   (    0.41 ms per token,  2468.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.25 ms /    11 tokens (   54.11 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   49978.03 ms /    75 runs   (  666.37 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   50800.72 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.89 ms /    44 runs   (    0.41 ms per token,  2458.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.72 ms /    12 tokens (   53.64 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   29301.45 ms /    43 runs   (  681.43 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   30076.79 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.08 ms /    30 runs   (    0.40 ms per token,  2483.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.18 ms /    13 tokens (   52.63 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   19305.24 ms /    29 runs   (  665.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20077.65 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.36 ms /    45 runs   (    0.41 ms per token,  2451.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.01 ms /    12 tokens (   56.58 ms per token,    17.67 tokens per second)\n",
      "llama_print_timings:        eval time =   29504.46 ms /    44 runs   (  670.56 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   30317.53 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.82 ms /    31 runs   (    0.41 ms per token,  2417.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.73 ms /    12 tokens (   52.98 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   20079.61 ms /    30 runs   (  669.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20807.95 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.81 ms /    25 runs   (    0.43 ms per token,  2313.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.19 ms /    13 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   16618.73 ms /    24 runs   (  692.45 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   17374.65 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.64 ms /    32 runs   (    0.40 ms per token,  2531.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.59 ms /    12 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   20691.98 ms /    31 runs   (  667.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21423.74 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.22 ms /    30 runs   (    0.41 ms per token,  2455.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.43 ms /    12 tokens (   53.12 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   19230.25 ms /    29 runs   (  663.11 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19956.52 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.11 ms /    30 runs   (    0.40 ms per token,  2477.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.91 ms /    12 tokens (   53.58 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   19239.04 ms /    29 runs   (  663.42 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19969.53 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.88 ms /    24 runs   (    0.41 ms per token,  2428.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     694.86 ms /    13 tokens (   53.45 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   15541.99 ms /    23 runs   (  675.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16307.72 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.37 ms /    55 runs   (    0.41 ms per token,  2459.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.84 ms /    12 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   36683.64 ms /    54 runs   (  679.33 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   37480.81 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.71 ms /    24 runs   (    0.40 ms per token,  2471.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.00 ms /    12 tokens (   53.50 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   15328.54 ms /    23 runs   (  666.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16040.98 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.86 ms /    37 runs   (    0.40 ms per token,  2489.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     730.24 ms /    14 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   24219.51 ms /    36 runs   (  672.76 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   25060.17 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.74 ms /    26 runs   (    0.41 ms per token,  2420.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.12 ms /    12 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   16804.37 ms /    25 runs   (  672.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17525.25 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.11 ms /    44 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.21 ms /    13 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   28887.46 ms /    43 runs   (  671.80 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29708.84 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.48 ms /    60 runs   (    0.42 ms per token,  2354.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     601.93 ms /    11 tokens (   54.72 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =   39747.34 ms /    59 runs   (  673.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   40530.65 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.96 ms /    35 runs   (    0.40 ms per token,  2507.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.07 ms /    12 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   22860.52 ms /    34 runs   (  672.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   23602.32 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.17 ms /    47 runs   (    0.41 ms per token,  2451.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.79 ms /    12 tokens (   54.48 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =   30746.09 ms /    46 runs   (  668.39 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   31538.07 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.29 ms /    30 runs   (    0.41 ms per token,  2441.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.13 ms /    11 tokens (   54.56 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   19448.90 ms /    29 runs   (  670.65 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20137.33 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.48 ms /    60 runs   (    0.41 ms per token,  2451.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.72 ms /    12 tokens (   53.98 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   39698.49 ms /    59 runs   (  672.86 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   40522.89 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      32.77 ms /    80 runs   (    0.41 ms per token,  2440.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     587.23 ms /    11 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   53242.58 ms /    79 runs   (  673.96 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   54068.27 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.70 ms /    39 runs   (    0.40 ms per token,  2484.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.36 ms /    12 tokens (   53.20 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   25644.07 ms /    38 runs   (  674.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26398.39 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.68 ms /    37 runs   (    0.40 ms per token,  2520.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     609.48 ms /    11 tokens (   55.41 ms per token,    18.05 tokens per second)\n",
      "llama_print_timings:        eval time =   24332.39 ms /    36 runs   (  675.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25051.23 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.38 ms /    30 runs   (    0.41 ms per token,  2422.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     697.98 ms /    13 tokens (   53.69 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   19482.08 ms /    29 runs   (  671.80 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20269.57 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.65 ms /    29 runs   (    0.40 ms per token,  2489.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.52 ms /    12 tokens (   54.29 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   18387.42 ms /    28 runs   (  656.69 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19125.54 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.65 ms /    37 runs   (    0.40 ms per token,  2525.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.62 ms /    12 tokens (   53.39 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   24611.70 ms /    36 runs   (  683.66 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   25359.44 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.22 ms /    42 runs   (    0.41 ms per token,  2438.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.06 ms /    12 tokens (   54.01 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   27652.53 ms /    41 runs   (  674.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   28425.05 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.31 ms /    38 runs   (    0.40 ms per token,  2481.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     667.76 ms /    12 tokens (   55.65 ms per token,    17.97 tokens per second)\n",
      "llama_print_timings:        eval time =   24931.88 ms /    37 runs   (  673.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25710.95 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.33 ms /    47 runs   (    0.41 ms per token,  2431.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.61 ms /    12 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   30817.90 ms /    46 runs   (  669.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   31594.85 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.37 ms /    25 runs   (    0.41 ms per token,  2411.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     629.09 ms /    12 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   15812.85 ms /    24 runs   (  658.87 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   16516.31 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.36 ms /    38 runs   (    0.40 ms per token,  2473.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.87 ms /    13 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   24398.98 ms /    37 runs   (  659.43 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   25191.53 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.41 ms /    60 runs   (    0.42 ms per token,  2361.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.09 ms /    12 tokens (   53.09 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   39733.64 ms /    59 runs   (  673.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   40553.48 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.68 ms /    51 runs   (    0.41 ms per token,  2466.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     612.77 ms /    11 tokens (   55.71 ms per token,    17.95 tokens per second)\n",
      "llama_print_timings:        eval time =   33837.37 ms /    50 runs   (  676.75 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   34600.03 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.49 ms /    43 runs   (    0.41 ms per token,  2458.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.77 ms /    12 tokens (   52.98 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   28287.23 ms /    42 runs   (  673.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   29050.49 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.51 ms /    31 runs   (    0.40 ms per token,  2477.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.36 ms /    12 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   20115.15 ms /    30 runs   (  670.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20835.91 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.40 ms /    38 runs   (    0.41 ms per token,  2466.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.92 ms /    12 tokens (   53.41 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   24736.72 ms /    37 runs   (  668.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   25488.49 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.73 ms /    32 runs   (    0.40 ms per token,  2513.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.41 ms /    12 tokens (   52.87 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   20727.16 ms /    31 runs   (  668.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21456.19 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.10 ms /    30 runs   (    0.40 ms per token,  2478.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.22 ms /    13 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   19653.46 ms /    29 runs   (  677.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20440.83 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      54.35 ms /   129 runs   (    0.42 ms per token,  2373.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.65 ms /    12 tokens (   54.14 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   87167.10 ms /   128 runs   (  680.99 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   88214.97 ms /   140 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.07 ms /    30 runs   (    0.40 ms per token,  2485.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.03 ms /    12 tokens (   53.42 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   19042.53 ms /    29 runs   (  656.64 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19772.64 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.78 ms /    34 runs   (    0.41 ms per token,  2467.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.91 ms /    12 tokens (   54.08 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   22109.25 ms /    33 runs   (  669.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22859.33 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.31 ms /    23 runs   (    0.40 ms per token,  2471.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.88 ms /    13 tokens (   52.30 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   14697.24 ms /    22 runs   (  668.06 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15445.45 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.70 ms /    31 runs   (    0.41 ms per token,  2441.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.44 ms /    11 tokens (   53.95 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   19955.32 ms /    30 runs   (  665.18 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20639.82 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.17 ms /    30 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.28 ms /    12 tokens (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   19192.64 ms /    29 runs   (  661.82 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19915.36 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.59 ms /    34 runs   (    0.40 ms per token,  2502.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.09 ms /    12 tokens (   52.51 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   22193.28 ms /    33 runs   (  672.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22922.04 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.56 ms /    31 runs   (    0.41 ms per token,  2467.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.89 ms /    13 tokens (   52.76 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   20387.64 ms /    30 runs   (  679.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   21164.54 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.79 ms /    62 runs   (    0.42 ms per token,  2404.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.89 ms /    12 tokens (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   40595.99 ms /    61 runs   (  665.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   41410.69 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.02 ms /    42 runs   (    0.41 ms per token,  2467.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.33 ms /    12 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   27400.06 ms /    41 runs   (  668.29 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28164.63 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.82 ms /    24 runs   (    0.41 ms per token,  2443.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.74 ms /    11 tokens (   53.61 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   15550.06 ms /    23 runs   (  676.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16209.69 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.74 ms /    29 runs   (    0.40 ms per token,  2470.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.21 ms /    12 tokens (   53.85 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   19202.31 ms /    28 runs   (  685.80 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   19932.97 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.17 ms /    61 runs   (    0.41 ms per token,  2423.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     864.80 ms /    11 tokens (   78.62 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:        eval time =   40592.81 ms /    60 runs   (  676.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   41638.47 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.02 ms /    35 runs   (    0.40 ms per token,  2496.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.69 ms /    12 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   22589.24 ms /    34 runs   (  664.39 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   23327.76 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.84 ms /    29 runs   (    0.41 ms per token,  2449.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.92 ms /    12 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   18769.86 ms /    28 runs   (  670.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19490.73 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.34 ms /    22 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.36 ms /    13 tokens (   52.87 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   13934.16 ms /    21 runs   (  663.53 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14686.26 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.49 ms /    34 runs   (    0.40 ms per token,  2520.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.75 ms /    12 tokens (   52.81 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   22329.57 ms /    33 runs   (  676.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   23063.10 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.75 ms /    34 runs   (    0.40 ms per token,  2472.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1006.50 ms /    12 tokens (   83.88 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:        eval time =   21623.65 ms /    33 runs   (  655.26 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   22730.85 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.22 ms /    30 runs   (    0.41 ms per token,  2454.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     661.45 ms /    12 tokens (   55.12 ms per token,    18.14 tokens per second)\n",
      "llama_print_timings:        eval time =   19458.28 ms /    29 runs   (  670.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20207.42 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.94 ms /    27 runs   (    0.41 ms per token,  2468.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.09 ms /    13 tokens (   52.55 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   17374.64 ms /    26 runs   (  668.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18136.59 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.98 ms /    27 runs   (    0.41 ms per token,  2457.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.56 ms /    12 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   17202.35 ms /    26 runs   (  661.63 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17916.85 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.93 ms /    27 runs   (    0.40 ms per token,  2470.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.33 ms /    12 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   17216.35 ms /    26 runs   (  662.17 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17933.87 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.71 ms /    37 runs   (    0.40 ms per token,  2515.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.28 ms /    13 tokens (   52.56 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   23977.35 ms /    36 runs   (  666.04 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24768.70 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.19 ms /    25 runs   (    0.41 ms per token,  2453.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.80 ms /    11 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   15475.49 ms /    24 runs   (  644.81 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   16138.13 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.17 ms /    25 runs   (    0.41 ms per token,  2459.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.06 ms /    12 tokens (   52.84 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   15994.44 ms /    24 runs   (  666.44 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16701.56 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.85 ms /    34 runs   (    0.41 ms per token,  2455.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.02 ms /    12 tokens (   54.33 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   22146.15 ms /    33 runs   (  671.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22898.70 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.85 ms /    37 runs   (    0.40 ms per token,  2492.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.82 ms /    12 tokens (   54.73 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =   24461.10 ms /    36 runs   (  679.47 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   25226.58 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.65 ms /    58 runs   (    0.42 ms per token,  2353.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.96 ms /    12 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   37940.50 ms /    57 runs   (  665.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   38755.44 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.54 ms /    31 runs   (    0.40 ms per token,  2472.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.67 ms /    12 tokens (   54.06 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   20052.16 ms /    30 runs   (  668.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20792.63 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.36 ms /    36 runs   (    0.40 ms per token,  2506.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     729.15 ms /    14 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   23280.77 ms /    35 runs   (  665.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24115.66 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.74 ms /    37 runs   (    0.40 ms per token,  2509.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.88 ms /    12 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   24067.65 ms /    36 runs   (  668.55 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24816.10 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.96 ms /    22 runs   (    0.41 ms per token,  2454.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.97 ms /    12 tokens (   56.66 ms per token,    17.65 tokens per second)\n",
      "llama_print_timings:        eval time =   14006.14 ms /    21 runs   (  666.96 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14750.20 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.81 ms /    42 runs   (    0.40 ms per token,  2498.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.74 ms /    12 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   27221.92 ms /    41 runs   (  663.95 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   27986.29 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.28 ms /    28 runs   (    0.40 ms per token,  2481.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.40 ms /    13 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   18192.41 ms /    27 runs   (  673.79 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18959.02 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.12 ms /    30 runs   (    0.40 ms per token,  2476.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     586.81 ms /    11 tokens (   53.35 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   19300.73 ms /    29 runs   (  665.54 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19975.73 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.32 ms /    30 runs   (    0.41 ms per token,  2434.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.20 ms /    12 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   19524.95 ms /    29 runs   (  673.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20248.53 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.24 ms /    35 runs   (    0.41 ms per token,  2458.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.19 ms /    13 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   22562.58 ms /    34 runs   (  663.61 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   23357.00 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.01 ms /    56 runs   (    0.41 ms per token,  2433.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.03 ms /    12 tokens (   54.50 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =   37183.73 ms /    55 runs   (  676.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   38001.83 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.92 ms /    22 runs   (    0.41 ms per token,  2465.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.83 ms /    13 tokens (   52.68 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   14076.60 ms /    21 runs   (  670.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14826.43 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.09 ms /    42 runs   (    0.41 ms per token,  2457.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.04 ms /    12 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   27463.64 ms /    41 runs   (  669.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28224.73 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.05 ms /    37 runs   (    0.41 ms per token,  2459.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.72 ms /    12 tokens (   53.14 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   24010.12 ms /    36 runs   (  666.95 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24756.96 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.15 ms /    38 runs   (    0.40 ms per token,  2508.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.31 ms /    12 tokens (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   24901.65 ms /    37 runs   (  673.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   25648.71 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      29.07 ms /    72 runs   (    0.40 ms per token,  2477.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.53 ms /    12 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   47087.84 ms /    71 runs   (  663.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   47935.72 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.74 ms /    31 runs   (    0.41 ms per token,  2432.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.42 ms /    13 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   19816.07 ms /    30 runs   (  660.54 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20590.58 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.22 ms /    36 runs   (    0.39 ms per token,  2532.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.46 ms /    11 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   23018.33 ms /    35 runs   (  657.67 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   23715.09 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.04 ms /    42 runs   (    0.41 ms per token,  2464.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.97 ms /    12 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   27463.48 ms /    41 runs   (  669.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28224.45 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.05 ms /    35 runs   (    0.40 ms per token,  2491.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.53 ms /    12 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   22592.29 ms /    34 runs   (  664.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   23330.97 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.64 ms /    50 runs   (    0.41 ms per token,  2422.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.34 ms /    12 tokens (   55.28 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =   33129.41 ms /    49 runs   (  676.11 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   33940.75 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      29.18 ms /    69 runs   (    0.42 ms per token,  2364.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.69 ms /    12 tokens (   54.72 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =   45556.32 ms /    68 runs   (  669.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   46425.71 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.07 ms /    30 runs   (    0.40 ms per token,  2485.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.65 ms /    13 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   19378.32 ms /    29 runs   (  668.22 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20152.70 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.35 ms /    40 runs   (    0.41 ms per token,  2447.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     588.74 ms /    11 tokens (   53.52 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   26344.78 ms /    39 runs   (  675.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27051.85 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.55 ms /    32 runs   (    0.39 ms per token,  2549.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     668.03 ms /    12 tokens (   55.67 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:        eval time =   20761.00 ms /    31 runs   (  669.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21523.58 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.03 ms /    30 runs   (    0.40 ms per token,  2494.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     664.39 ms /    12 tokens (   55.37 ms per token,    18.06 tokens per second)\n",
      "llama_print_timings:        eval time =   19476.82 ms /    29 runs   (  671.61 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20230.28 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.04 ms /    30 runs   (    0.40 ms per token,  2491.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     612.72 ms /    11 tokens (   55.70 ms per token,    17.95 tokens per second)\n",
      "llama_print_timings:        eval time =   19424.94 ms /    29 runs   (  669.83 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20125.94 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.53 ms /    30 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.86 ms /    13 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   19638.37 ms /    29 runs   (  677.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20427.06 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.56 ms /    31 runs   (    0.41 ms per token,  2467.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.69 ms /    12 tokens (   54.72 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =   20166.71 ms /    30 runs   (  672.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20914.61 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.28 ms /    45 runs   (    0.41 ms per token,  2461.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.14 ms /    12 tokens (   52.68 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   29271.10 ms /    44 runs   (  665.25 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   30036.20 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.82 ms /    63 runs   (    0.41 ms per token,  2439.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.51 ms /    12 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   41833.47 ms /    62 runs   (  674.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   42653.56 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.24 ms /    30 runs   (    0.41 ms per token,  2451.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.22 ms /    13 tokens (   52.25 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   19426.93 ms /    29 runs   (  669.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20194.98 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.29 ms /    22 runs   (    0.42 ms per token,  2367.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.01 ms /    12 tokens (   53.42 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   14150.93 ms /    21 runs   (  673.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14860.84 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.10 ms /    30 runs   (    0.40 ms per token,  2479.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.38 ms /    12 tokens (   53.03 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   19509.39 ms /    29 runs   (  672.74 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20231.88 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 700 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.08 ms /    30 runs   (    0.44 ms per token,  2293.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     662.75 ms /    12 tokens (   55.23 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =   19482.16 ms /    29 runs   (  671.80 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20238.65 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.29 ms /    58 runs   (    0.42 ms per token,  2387.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     721.97 ms /    13 tokens (   55.54 ms per token,    18.01 tokens per second)\n",
      "llama_print_timings:        eval time =   39843.84 ms /    57 runs   (  699.01 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   40739.72 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.06 ms /    46 runs   (    0.41 ms per token,  2413.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     799.76 ms /    12 tokens (   66.65 ms per token,    15.00 tokens per second)\n",
      "llama_print_timings:        eval time =   30718.37 ms /    45 runs   (  682.63 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   31653.31 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.10 ms /    55 runs   (    0.42 ms per token,  2381.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     718.63 ms /    13 tokens (   55.28 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =   37058.46 ms /    54 runs   (  686.27 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   37945.03 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.54 ms /    37 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     706.36 ms /    12 tokens (   58.86 ms per token,    16.99 tokens per second)\n",
      "llama_print_timings:        eval time =   24724.66 ms /    36 runs   (  686.80 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   25542.34 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.25 ms /    53 runs   (    0.42 ms per token,  2382.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.13 ms /    12 tokens (   53.09 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   35673.37 ms /    52 runs   (  686.03 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   36468.24 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.89 ms /    56 runs   (    0.41 ms per token,  2446.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.18 ms /    11 tokens (   54.29 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   36847.34 ms /    55 runs   (  669.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   37608.71 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.85 ms /    37 runs   (    0.40 ms per token,  2491.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.60 ms /    12 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   24246.80 ms /    36 runs   (  673.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   24991.88 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.16 ms /    34 runs   (    0.42 ms per token,  2401.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.03 ms /    12 tokens (   52.92 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   21913.15 ms /    33 runs   (  664.03 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   22648.79 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.49 ms /    31 runs   (    0.40 ms per token,  2482.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     666.23 ms /    12 tokens (   55.52 ms per token,    18.01 tokens per second)\n",
      "llama_print_timings:        eval time =   19807.74 ms /    30 runs   (  660.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20564.98 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.04 ms /    42 runs   (    0.41 ms per token,  2465.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     729.89 ms /    14 tokens (   52.14 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   27536.33 ms /    41 runs   (  671.62 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28391.22 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.24 ms /    30 runs   (    0.41 ms per token,  2450.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.78 ms /    12 tokens (   54.98 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =   19411.89 ms /    29 runs   (  669.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20159.92 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.45 ms /    30 runs   (    0.41 ms per token,  2410.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.48 ms /    11 tokens (   54.41 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   20118.49 ms /    29 runs   (  693.74 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   20807.73 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.38 ms /    20 runs   (    0.42 ms per token,  2387.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.50 ms /    12 tokens (   69.04 ms per token,    14.48 tokens per second)\n",
      "llama_print_timings:        eval time =   12507.25 ms /    19 runs   (  658.28 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13397.02 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.55 ms /    44 runs   (    0.40 ms per token,  2506.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     700.44 ms /    13 tokens (   53.88 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   28501.74 ms /    43 runs   (  662.83 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   29331.63 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.70 ms /    60 runs   (    0.41 ms per token,  2429.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.77 ms /    12 tokens (   54.06 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   39501.43 ms /    59 runs   (  669.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   40331.18 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.77 ms /    27 runs   (    0.44 ms per token,  2294.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     587.36 ms /    11 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   17367.04 ms /    26 runs   (  667.96 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18039.38 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.01 ms /    35 runs   (    0.40 ms per token,  2497.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.92 ms /    12 tokens (   54.33 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   22407.80 ms /    34 runs   (  659.05 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   23162.79 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.00 ms /    27 runs   (    0.41 ms per token,  2454.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     712.61 ms /    13 tokens (   54.82 ms per token,    18.24 tokens per second)\n",
      "llama_print_timings:        eval time =   17567.45 ms /    26 runs   (  675.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18360.06 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.60 ms /    38 runs   (    0.41 ms per token,  2436.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.55 ms /    13 tokens (   64.04 ms per token,    15.61 tokens per second)\n",
      "llama_print_timings:        eval time =   25655.14 ms /    37 runs   (  693.38 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   26602.13 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.89 ms /    29 runs   (    0.41 ms per token,  2438.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     666.61 ms /    11 tokens (   60.60 ms per token,    16.50 tokens per second)\n",
      "llama_print_timings:        eval time =   19373.15 ms /    28 runs   (  691.90 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   20126.76 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.49 ms /    25 runs   (    0.42 ms per token,  2384.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.16 ms /    12 tokens (   56.93 ms per token,    17.57 tokens per second)\n",
      "llama_print_timings:        eval time =   16534.50 ms /    24 runs   (  688.94 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   17291.86 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.35 ms /    60 runs   (    0.44 ms per token,  2277.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.95 ms /    12 tokens (   56.66 ms per token,    17.65 tokens per second)\n",
      "llama_print_timings:        eval time =   40679.58 ms /    59 runs   (  689.48 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   41549.50 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.00 ms /    42 runs   (    0.43 ms per token,  2333.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.47 ms /    12 tokens (   57.29 ms per token,    17.46 tokens per second)\n",
      "llama_print_timings:        eval time =   28899.86 ms /    41 runs   (  704.87 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   29717.29 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.97 ms /    27 runs   (    0.41 ms per token,  2461.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.60 ms /    11 tokens (   57.69 ms per token,    17.33 tokens per second)\n",
      "llama_print_timings:        eval time =   17939.84 ms /    26 runs   (  689.99 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   18654.62 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.58 ms /    38 runs   (    0.41 ms per token,  2438.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.01 ms /    12 tokens (   57.25 ms per token,    17.47 tokens per second)\n",
      "llama_print_timings:        eval time =   25093.49 ms /    37 runs   (  678.20 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   25895.23 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.13 ms /    42 runs   (    0.41 ms per token,  2452.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     661.73 ms /    11 tokens (   60.16 ms per token,    16.62 tokens per second)\n",
      "llama_print_timings:        eval time =   28105.97 ms /    41 runs   (  685.51 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   28893.07 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.58 ms /    52 runs   (    0.41 ms per token,  2409.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.87 ms /    12 tokens (   57.24 ms per token,    17.47 tokens per second)\n",
      "llama_print_timings:        eval time =   35573.85 ms /    51 runs   (  697.53 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   36416.17 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.27 ms /    30 runs   (    0.41 ms per token,  2445.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.46 ms /    11 tokens (   57.95 ms per token,    17.26 tokens per second)\n",
      "llama_print_timings:        eval time =   19410.90 ms /    29 runs   (  669.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20138.75 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.77 ms /    29 runs   (    0.41 ms per token,  2464.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     691.92 ms /    12 tokens (   57.66 ms per token,    17.34 tokens per second)\n",
      "llama_print_timings:        eval time =   19143.23 ms /    28 runs   (  683.69 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   19921.30 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.41 ms /    38 runs   (    0.41 ms per token,  2465.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     729.42 ms /    13 tokens (   56.11 ms per token,    17.82 tokens per second)\n",
      "llama_print_timings:        eval time =   25265.96 ms /    37 runs   (  682.86 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   26108.80 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.60 ms /    42 runs   (    0.42 ms per token,  2386.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     722.21 ms /    12 tokens (   60.18 ms per token,    16.62 tokens per second)\n",
      "llama_print_timings:        eval time =   27719.54 ms /    41 runs   (  676.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   28566.72 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.39 ms /    27 runs   (    0.42 ms per token,  2370.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     740.57 ms /    13 tokens (   56.97 ms per token,    17.55 tokens per second)\n",
      "llama_print_timings:        eval time =   17494.98 ms /    26 runs   (  672.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18316.69 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.28 ms /    49 runs   (    0.43 ms per token,  2302.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.62 ms /    12 tokens (   57.72 ms per token,    17.33 tokens per second)\n",
      "llama_print_timings:        eval time =   32767.76 ms /    48 runs   (  682.66 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   33612.93 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.89 ms /    36 runs   (    0.47 ms per token,  2131.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.38 ms /    11 tokens (   57.76 ms per token,    17.31 tokens per second)\n",
      "llama_print_timings:        eval time =   24393.23 ms /    35 runs   (  696.95 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   25150.63 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.67 ms /    31 runs   (    0.41 ms per token,  2446.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     695.40 ms /    12 tokens (   57.95 ms per token,    17.26 tokens per second)\n",
      "llama_print_timings:        eval time =   20832.35 ms /    30 runs   (  694.41 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   21619.33 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.97 ms /    39 runs   (    0.41 ms per token,  2441.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     668.70 ms /    11 tokens (   60.79 ms per token,    16.45 tokens per second)\n",
      "llama_print_timings:        eval time =   25886.56 ms /    38 runs   (  681.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   26669.90 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.55 ms /    42 runs   (    0.42 ms per token,  2393.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     629.10 ms /    11 tokens (   57.19 ms per token,    17.49 tokens per second)\n",
      "llama_print_timings:        eval time =   28290.69 ms /    41 runs   (  690.02 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   29044.96 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.51 ms /    39 runs   (    0.42 ms per token,  2361.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     707.60 ms /    12 tokens (   58.97 ms per token,    16.96 tokens per second)\n",
      "llama_print_timings:        eval time =   26171.37 ms /    38 runs   (  688.72 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   27001.33 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.92 ms /    24 runs   (    0.41 ms per token,  2419.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.51 ms /    12 tokens (   57.38 ms per token,    17.43 tokens per second)\n",
      "llama_print_timings:        eval time =   15961.53 ms /    23 runs   (  693.98 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   16721.60 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.96 ms /    27 runs   (    0.41 ms per token,  2462.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     666.14 ms /    11 tokens (   60.56 ms per token,    16.51 tokens per second)\n",
      "llama_print_timings:        eval time =   17838.43 ms /    26 runs   (  686.09 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   18586.00 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.45 ms /    42 runs   (    0.42 ms per token,  2406.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     741.27 ms /    13 tokens (   57.02 ms per token,    17.54 tokens per second)\n",
      "llama_print_timings:        eval time =   28032.90 ms /    41 runs   (  683.73 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   28899.68 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.12 ms /    41 runs   (    0.42 ms per token,  2395.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.20 ms /    12 tokens (   56.93 ms per token,    17.56 tokens per second)\n",
      "llama_print_timings:        eval time =   27450.61 ms /    40 runs   (  686.27 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   28257.41 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.60 ms /    31 runs   (    0.41 ms per token,  2459.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     694.34 ms /    12 tokens (   57.86 ms per token,    17.28 tokens per second)\n",
      "llama_print_timings:        eval time =   20466.90 ms /    30 runs   (  682.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   21252.13 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.34 ms /    43 runs   (    0.43 ms per token,  2343.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.23 ms /    11 tokens (   59.20 ms per token,    16.89 tokens per second)\n",
      "llama_print_timings:        eval time =   28665.96 ms /    42 runs   (  682.52 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   29451.95 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.88 ms /    67 runs   (    0.42 ms per token,  2403.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     675.63 ms /    12 tokens (   56.30 ms per token,    17.76 tokens per second)\n",
      "llama_print_timings:        eval time =   45585.82 ms /    66 runs   (  690.69 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   46462.03 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.38 ms /    38 runs   (    0.40 ms per token,  2470.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.99 ms /    11 tokens (   58.00 ms per token,    17.24 tokens per second)\n",
      "llama_print_timings:        eval time =   25866.76 ms /    37 runs   (  699.10 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   26617.61 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.06 ms /    34 runs   (    0.41 ms per token,  2417.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     690.23 ms /    12 tokens (   57.52 ms per token,    17.39 tokens per second)\n",
      "llama_print_timings:        eval time =   22747.62 ms /    33 runs   (  689.32 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   23539.17 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.41 ms /    33 runs   (    0.44 ms per token,  2289.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.62 ms /    12 tokens (   57.72 ms per token,    17.33 tokens per second)\n",
      "llama_print_timings:        eval time =   22017.53 ms /    32 runs   (  688.05 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   22812.36 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.06 ms /    38 runs   (    0.42 ms per token,  2366.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     730.00 ms /    13 tokens (   56.15 ms per token,    17.81 tokens per second)\n",
      "llama_print_timings:        eval time =   25437.11 ms /    37 runs   (  687.49 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   26279.21 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.09 ms /    27 runs   (    0.41 ms per token,  2435.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     690.08 ms /    12 tokens (   57.51 ms per token,    17.39 tokens per second)\n",
      "llama_print_timings:        eval time =   17368.74 ms /    26 runs   (  668.03 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18138.69 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.02 ms /    27 runs   (    0.41 ms per token,  2450.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     702.08 ms /    12 tokens (   58.51 ms per token,    17.09 tokens per second)\n",
      "llama_print_timings:        eval time =   17490.55 ms /    26 runs   (  672.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18272.84 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.26 ms /    27 runs   (    0.42 ms per token,  2397.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.50 ms /    11 tokens (   58.86 ms per token,    16.99 tokens per second)\n",
      "llama_print_timings:        eval time =   17837.02 ms /    26 runs   (  686.04 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   18565.27 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.52 ms /    58 runs   (    0.42 ms per token,  2365.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     758.48 ms /    13 tokens (   58.34 ms per token,    17.14 tokens per second)\n",
      "llama_print_timings:        eval time =   38759.30 ms /    57 runs   (  679.99 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   39695.17 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.93 ms /    33 runs   (    0.42 ms per token,  2368.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.96 ms /    12 tokens (   57.41 ms per token,    17.42 tokens per second)\n",
      "llama_print_timings:        eval time =   21988.40 ms /    32 runs   (  687.14 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   22776.38 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.51 ms /    20 runs   (    0.43 ms per token,  2351.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.18 ms /    11 tokens (   59.11 ms per token,    16.92 tokens per second)\n",
      "llama_print_timings:        eval time =   13000.81 ms /    19 runs   (  684.25 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13709.90 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.10 ms /    27 runs   (    0.41 ms per token,  2432.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     700.57 ms /    12 tokens (   58.38 ms per token,    17.13 tokens per second)\n",
      "llama_print_timings:        eval time =   17839.38 ms /    26 runs   (  686.13 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   18619.82 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.00 ms /    37 runs   (    0.41 ms per token,  2466.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     665.80 ms /    11 tokens (   60.53 ms per token,    16.52 tokens per second)\n",
      "llama_print_timings:        eval time =   24377.90 ms /    36 runs   (  677.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25153.46 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.52 ms /    25 runs   (    0.42 ms per token,  2377.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.47 ms /    12 tokens (   57.29 ms per token,    17.46 tokens per second)\n",
      "llama_print_timings:        eval time =   16542.34 ms /    24 runs   (  689.26 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   17305.11 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.06 ms /    30 runs   (    0.40 ms per token,  2486.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     720.24 ms /    12 tokens (   60.02 ms per token,    16.66 tokens per second)\n",
      "llama_print_timings:        eval time =   19886.90 ms /    29 runs   (  685.76 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20696.73 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.83 ms /    38 runs   (    0.42 ms per token,  2401.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.33 ms /    13 tokens (   56.03 ms per token,    17.85 tokens per second)\n",
      "llama_print_timings:        eval time =   25286.13 ms /    37 runs   (  683.41 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   26129.72 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.21 ms /    32 runs   (    0.41 ms per token,  2423.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.47 ms /    12 tokens (   57.79 ms per token,    17.30 tokens per second)\n",
      "llama_print_timings:        eval time =   21102.60 ms /    31 runs   (  680.73 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   21890.43 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.08 ms /    34 runs   (    0.41 ms per token,  2414.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.70 ms /    12 tokens (   56.56 ms per token,    17.68 tokens per second)\n",
      "llama_print_timings:        eval time =   22385.66 ms /    33 runs   (  678.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   23164.50 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.14 ms /    37 runs   (    0.41 ms per token,  2443.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.72 ms /    12 tokens (   57.73 ms per token,    17.32 tokens per second)\n",
      "llama_print_timings:        eval time =   24669.94 ms /    36 runs   (  685.28 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   25472.32 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.62 ms /    31 runs   (    0.41 ms per token,  2455.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.64 ms /    14 tokens (   55.47 ms per token,    18.03 tokens per second)\n",
      "llama_print_timings:        eval time =   20271.33 ms /    30 runs   (  675.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21142.30 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.61 ms /    35 runs   (    0.42 ms per token,  2395.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     702.25 ms /    12 tokens (   58.52 ms per token,    17.09 tokens per second)\n",
      "llama_print_timings:        eval time =   22690.64 ms /    34 runs   (  667.37 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   23498.63 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.70 ms /    35 runs   (    0.42 ms per token,  2381.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.31 ms /    12 tokens (   57.03 ms per token,    17.54 tokens per second)\n",
      "llama_print_timings:        eval time =   23330.40 ms /    34 runs   (  686.19 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   24120.42 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.96 ms /    36 runs   (    0.42 ms per token,  2406.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.50 ms /    12 tokens (   56.96 ms per token,    17.56 tokens per second)\n",
      "llama_print_timings:        eval time =   24157.44 ms /    35 runs   (  690.21 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   24948.43 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.83 ms /    36 runs   (    0.41 ms per token,  2428.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     694.26 ms /    12 tokens (   57.86 ms per token,    17.28 tokens per second)\n",
      "llama_print_timings:        eval time =   23872.21 ms /    35 runs   (  682.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   24675.05 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.76 ms /    36 runs   (    0.41 ms per token,  2439.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     735.09 ms /    13 tokens (   56.55 ms per token,    17.68 tokens per second)\n",
      "llama_print_timings:        eval time =   23451.19 ms /    35 runs   (  670.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24295.01 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.99 ms /    36 runs   (    0.42 ms per token,  2401.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.01 ms /    11 tokens (   59.91 ms per token,    16.69 tokens per second)\n",
      "llama_print_timings:        eval time =   23432.97 ms /    35 runs   (  669.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24201.33 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.91 ms /    42 runs   (    0.43 ms per token,  2345.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     708.71 ms /    12 tokens (   59.06 ms per token,    16.93 tokens per second)\n",
      "llama_print_timings:        eval time =   28493.89 ms /    41 runs   (  694.97 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   29330.49 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.18 ms /    27 runs   (    0.41 ms per token,  2415.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     734.62 ms /    13 tokens (   56.51 ms per token,    17.70 tokens per second)\n",
      "llama_print_timings:        eval time =   17698.13 ms /    26 runs   (  680.70 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18513.77 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.59 ms /    40 runs   (    0.41 ms per token,  2411.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     627.61 ms /    11 tokens (   57.06 ms per token,    17.53 tokens per second)\n",
      "llama_print_timings:        eval time =   26391.38 ms /    39 runs   (  676.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27139.53 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.12 ms /    27 runs   (    0.41 ms per token,  2428.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     696.34 ms /    12 tokens (   58.03 ms per token,    17.23 tokens per second)\n",
      "llama_print_timings:        eval time =   18083.82 ms /    26 runs   (  695.53 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   18860.43 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.79 ms /    35 runs   (    0.42 ms per token,  2366.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.14 ms /    12 tokens (   56.93 ms per token,    17.57 tokens per second)\n",
      "llama_print_timings:        eval time =   23209.34 ms /    34 runs   (  682.63 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   24000.66 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.65 ms /    40 runs   (    0.42 ms per token,  2402.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     691.43 ms /    12 tokens (   57.62 ms per token,    17.36 tokens per second)\n",
      "llama_print_timings:        eval time =   26805.10 ms /    39 runs   (  687.31 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   27618.91 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.09 ms /    37 runs   (    0.41 ms per token,  2451.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     689.47 ms /    12 tokens (   57.46 ms per token,    17.40 tokens per second)\n",
      "llama_print_timings:        eval time =   24622.75 ms /    36 runs   (  683.97 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   25424.55 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.26 ms /    22 runs   (    0.42 ms per token,  2374.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     752.32 ms /    13 tokens (   57.87 ms per token,    17.28 tokens per second)\n",
      "llama_print_timings:        eval time =   14291.52 ms /    21 runs   (  680.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15111.42 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.71 ms /    60 runs   (    0.41 ms per token,  2427.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.00 ms /    12 tokens (   57.08 ms per token,    17.52 tokens per second)\n",
      "llama_print_timings:        eval time =   40435.96 ms /    59 runs   (  685.36 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   41303.23 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.27 ms /    22 runs   (    0.42 ms per token,  2372.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.92 ms /    12 tokens (   58.24 ms per token,    17.17 tokens per second)\n",
      "llama_print_timings:        eval time =   14319.78 ms /    21 runs   (  681.89 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15084.97 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.23 ms /    30 runs   (    0.41 ms per token,  2452.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.76 ms /    12 tokens (   57.73 ms per token,    17.32 tokens per second)\n",
      "llama_print_timings:        eval time =   19978.40 ms /    29 runs   (  688.91 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   20761.97 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.68 ms /    23 runs   (    0.46 ms per token,  2154.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.03 ms /    13 tokens (   56.00 ms per token,    17.86 tokens per second)\n",
      "llama_print_timings:        eval time =   15066.39 ms /    22 runs   (  684.84 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   15868.86 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.25 ms /    27 runs   (    0.42 ms per token,  2400.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.55 ms /    11 tokens (   58.14 ms per token,    17.20 tokens per second)\n",
      "llama_print_timings:        eval time =   17643.66 ms /    26 runs   (  678.60 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18362.77 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.75 ms /    31 runs   (    0.41 ms per token,  2430.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.93 ms /    12 tokens (   57.24 ms per token,    17.47 tokens per second)\n",
      "llama_print_timings:        eval time =   20589.07 ms /    30 runs   (  686.30 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   21367.77 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.01 ms /    34 runs   (    0.41 ms per token,  2426.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.57 ms /    11 tokens (   58.69 ms per token,    17.04 tokens per second)\n",
      "llama_print_timings:        eval time =   22472.38 ms /    33 runs   (  680.98 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   23219.25 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.27 ms /    44 runs   (    0.42 ms per token,  2408.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     736.90 ms /    13 tokens (   56.68 ms per token,    17.64 tokens per second)\n",
      "llama_print_timings:        eval time =   29675.70 ms /    43 runs   (  690.13 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   30545.27 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.84 ms /    31 runs   (    0.41 ms per token,  2414.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.60 ms /    12 tokens (   56.80 ms per token,    17.61 tokens per second)\n",
      "llama_print_timings:        eval time =   20267.67 ms /    30 runs   (  675.59 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21041.62 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.26 ms /    22 runs   (    0.42 ms per token,  2375.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     741.09 ms /    13 tokens (   57.01 ms per token,    17.54 tokens per second)\n",
      "llama_print_timings:        eval time =   14096.56 ms /    21 runs   (  671.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14903.13 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.09 ms /    27 runs   (    0.41 ms per token,  2434.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     671.74 ms /    11 tokens (   61.07 ms per token,    16.38 tokens per second)\n",
      "llama_print_timings:        eval time =   17715.78 ms /    26 runs   (  681.38 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18467.24 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.90 ms /    34 runs   (    0.41 ms per token,  2446.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.63 ms /    12 tokens (   56.72 ms per token,    17.63 tokens per second)\n",
      "llama_print_timings:        eval time =   22323.52 ms /    33 runs   (  676.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   23106.44 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.96 ms /    34 runs   (    0.41 ms per token,  2435.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.10 ms /    12 tokens (   57.34 ms per token,    17.44 tokens per second)\n",
      "llama_print_timings:        eval time =   23151.96 ms /    33 runs   (  701.57 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   23941.70 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.54 ms /    25 runs   (    0.46 ms per token,  2166.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.32 ms /    11 tokens (   58.03 ms per token,    17.23 tokens per second)\n",
      "llama_print_timings:        eval time =   16360.98 ms /    24 runs   (  681.71 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17079.61 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.09 ms /    27 runs   (    0.41 ms per token,  2435.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     739.70 ms /    13 tokens (   56.90 ms per token,    17.57 tokens per second)\n",
      "llama_print_timings:        eval time =   17935.31 ms /    26 runs   (  689.82 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   18755.84 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.07 ms /    39 runs   (    0.41 ms per token,  2427.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.45 ms /    11 tokens (   59.22 ms per token,    16.89 tokens per second)\n",
      "llama_print_timings:        eval time =   26038.37 ms /    38 runs   (  685.22 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   26806.16 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.40 ms /    27 runs   (    0.42 ms per token,  2367.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     695.78 ms /    12 tokens (   57.98 ms per token,    17.25 tokens per second)\n",
      "llama_print_timings:        eval time =   17700.66 ms /    26 runs   (  680.79 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18476.71 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.27 ms /    20 runs   (    0.41 ms per token,  2418.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     689.82 ms /    12 tokens (   57.48 ms per token,    17.40 tokens per second)\n",
      "llama_print_timings:        eval time =   12725.97 ms /    19 runs   (  669.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13475.74 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.92 ms /    21 runs   (    0.42 ms per token,  2353.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.96 ms /    12 tokens (   56.83 ms per token,    17.60 tokens per second)\n",
      "llama_print_timings:        eval time =   13439.28 ms /    20 runs   (  671.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14183.81 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.02 ms /    39 runs   (    0.41 ms per token,  2434.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     743.96 ms /    13 tokens (   57.23 ms per token,    17.47 tokens per second)\n",
      "llama_print_timings:        eval time =   25833.89 ms /    38 runs   (  679.84 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   26693.71 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.50 ms /    30 runs   (    0.42 ms per token,  2400.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.79 ms /    11 tokens (   58.16 ms per token,    17.19 tokens per second)\n",
      "llama_print_timings:        eval time =   20247.67 ms /    29 runs   (  698.20 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   20978.90 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 800 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.18 ms /    37 runs   (    0.41 ms per token,  2438.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     731.53 ms /    12 tokens (   60.96 ms per token,    16.40 tokens per second)\n",
      "llama_print_timings:        eval time =   24723.28 ms /    36 runs   (  686.76 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   25563.95 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.35 ms /    40 runs   (    0.41 ms per token,  2446.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     702.23 ms /    12 tokens (   58.52 ms per token,    17.09 tokens per second)\n",
      "llama_print_timings:        eval time =   26199.31 ms /    39 runs   (  671.78 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   27020.57 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.79 ms /    31 runs   (    0.41 ms per token,  2423.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     695.94 ms /    12 tokens (   57.99 ms per token,    17.24 tokens per second)\n",
      "llama_print_timings:        eval time =   20262.29 ms /    30 runs   (  675.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21050.71 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.05 ms /    24 runs   (    0.42 ms per token,  2389.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     729.74 ms /    13 tokens (   56.13 ms per token,    17.81 tokens per second)\n",
      "llama_print_timings:        eval time =   15533.09 ms /    23 runs   (  675.35 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16335.07 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.94 ms /    34 runs   (    0.41 ms per token,  2439.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     709.13 ms /    12 tokens (   59.09 ms per token,    16.92 tokens per second)\n",
      "llama_print_timings:        eval time =   23090.85 ms /    33 runs   (  699.72 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   23901.17 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.31 ms /    37 runs   (    0.41 ms per token,  2416.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     793.82 ms /    14 tokens (   56.70 ms per token,    17.64 tokens per second)\n",
      "llama_print_timings:        eval time =   23994.07 ms /    36 runs   (  666.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24897.50 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.49 ms /    30 runs   (    0.42 ms per token,  2401.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.53 ms /    12 tokens (   56.63 ms per token,    17.66 tokens per second)\n",
      "llama_print_timings:        eval time =   19507.25 ms /    29 runs   (  672.66 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20276.25 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.01 ms /    34 runs   (    0.41 ms per token,  2426.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.13 ms /    12 tokens (   57.34 ms per token,    17.44 tokens per second)\n",
      "llama_print_timings:        eval time =   21988.06 ms /    33 runs   (  666.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22777.88 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.70 ms /    40 runs   (    0.42 ms per token,  2395.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.79 ms /    12 tokens (   57.32 ms per token,    17.45 tokens per second)\n",
      "llama_print_timings:        eval time =   26408.67 ms /    39 runs   (  677.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27216.82 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.20 ms /    60 runs   (    0.42 ms per token,  2381.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     747.15 ms /    13 tokens (   57.47 ms per token,    17.40 tokens per second)\n",
      "llama_print_timings:        eval time =   40845.42 ms /    59 runs   (  692.30 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   41773.24 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.21 ms /    27 runs   (    0.42 ms per token,  2407.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     803.66 ms /    12 tokens (   66.97 ms per token,    14.93 tokens per second)\n",
      "llama_print_timings:        eval time =   18401.94 ms /    26 runs   (  707.77 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   19286.49 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.12 ms /    37 runs   (    0.41 ms per token,  2447.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.02 ms /    11 tokens (   58.46 ms per token,    17.11 tokens per second)\n",
      "llama_print_timings:        eval time =   24929.08 ms /    36 runs   (  692.47 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   25683.14 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.59 ms /    33 runs   (    0.41 ms per token,  2428.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     710.37 ms /    12 tokens (   59.20 ms per token,    16.89 tokens per second)\n",
      "llama_print_timings:        eval time =   21819.38 ms /    32 runs   (  681.86 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22628.47 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.99 ms /    37 runs   (    0.41 ms per token,  2468.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.54 ms /    12 tokens (   56.88 ms per token,    17.58 tokens per second)\n",
      "llama_print_timings:        eval time =   24555.00 ms /    36 runs   (  682.08 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   25349.14 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.17 ms /    27 runs   (    0.41 ms per token,  2417.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.31 ms /    11 tokens (   58.03 ms per token,    17.23 tokens per second)\n",
      "llama_print_timings:        eval time =   17629.62 ms /    26 runs   (  678.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18349.40 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.81 ms /    33 runs   (    0.42 ms per token,  2389.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     760.59 ms /    13 tokens (   58.51 ms per token,    17.09 tokens per second)\n",
      "llama_print_timings:        eval time =   21764.44 ms /    32 runs   (  680.14 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22623.40 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.64 ms /    31 runs   (    0.41 ms per token,  2453.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.80 ms /    11 tokens (   59.16 ms per token,    16.90 tokens per second)\n",
      "llama_print_timings:        eval time =   20069.27 ms /    30 runs   (  668.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20810.57 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.82 ms /    41 runs   (    0.41 ms per token,  2438.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.07 ms /    12 tokens (   57.09 ms per token,    17.52 tokens per second)\n",
      "llama_print_timings:        eval time =   27196.97 ms /    40 runs   (  679.92 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   28004.46 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.81 ms /    41 runs   (    0.41 ms per token,  2438.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.16 ms /    12 tokens (   57.01 ms per token,    17.54 tokens per second)\n",
      "llama_print_timings:        eval time =   27417.11 ms /    40 runs   (  685.43 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   28223.74 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.89 ms /    19 runs   (    0.42 ms per token,  2406.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.16 ms /    11 tokens (   58.20 ms per token,    17.18 tokens per second)\n",
      "llama_print_timings:        eval time =   12142.96 ms /    18 runs   (  674.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12839.89 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.39 ms /    30 runs   (    0.41 ms per token,  2421.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.82 ms /    12 tokens (   56.73 ms per token,    17.63 tokens per second)\n",
      "llama_print_timings:        eval time =   19788.46 ms /    29 runs   (  682.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20558.74 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.14 ms /    60 runs   (    0.42 ms per token,  2386.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     730.43 ms /    13 tokens (   56.19 ms per token,    17.80 tokens per second)\n",
      "llama_print_timings:        eval time =   40727.06 ms /    59 runs   (  690.29 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   41634.97 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.92 ms /    23 runs   (    0.43 ms per token,  2319.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     745.45 ms /    13 tokens (   57.34 ms per token,    17.44 tokens per second)\n",
      "llama_print_timings:        eval time =   15746.65 ms /    22 runs   (  715.76 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   16561.02 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.47 ms /    35 runs   (    0.41 ms per token,  2418.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     694.91 ms /    11 tokens (   63.17 ms per token,    15.83 tokens per second)\n",
      "llama_print_timings:        eval time =   22892.02 ms /    34 runs   (  673.29 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   23692.56 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.81 ms /    30 runs   (    0.43 ms per token,  2342.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     696.90 ms /    12 tokens (   58.07 ms per token,    17.22 tokens per second)\n",
      "llama_print_timings:        eval time =   20577.09 ms /    29 runs   (  709.55 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   21366.72 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.32 ms /    30 runs   (    0.41 ms per token,  2435.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.75 ms /    12 tokens (   60.73 ms per token,    16.47 tokens per second)\n",
      "llama_print_timings:        eval time =   19991.32 ms /    29 runs   (  689.36 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   20809.74 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.06 ms /    17 runs   (    0.42 ms per token,  2407.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.24 ms /    12 tokens (   54.27 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   10743.66 ms /    16 runs   (  671.48 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   11444.66 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.87 ms /    37 runs   (    0.40 ms per token,  2487.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.87 ms /    12 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   24014.10 ms /    36 runs   (  667.06 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24756.38 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.29 ms /    57 runs   (    0.44 ms per token,  2253.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     699.15 ms /    12 tokens (   58.26 ms per token,    17.16 tokens per second)\n",
      "llama_print_timings:        eval time =   39865.09 ms /    56 runs   (  711.88 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   40741.78 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.62 ms /    38 runs   (    0.41 ms per token,  2432.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.65 ms /    13 tokens (   59.28 ms per token,    16.87 tokens per second)\n",
      "llama_print_timings:        eval time =   24653.97 ms /    37 runs   (  666.32 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   25537.97 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.16 ms /    52 runs   (    0.41 ms per token,  2457.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     670.04 ms /    12 tokens (   55.84 ms per token,    17.91 tokens per second)\n",
      "llama_print_timings:        eval time =   33839.11 ms /    51 runs   (  663.51 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   34665.00 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.91 ms /    60 runs   (    0.42 ms per token,  2408.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.93 ms /    11 tokens (   54.18 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   40241.23 ms /    59 runs   (  682.05 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   41017.50 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.40 ms /    30 runs   (    0.41 ms per token,  2418.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.12 ms /    12 tokens (   53.84 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   20339.24 ms /    29 runs   (  701.35 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   21075.70 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.61 ms /    60 runs   (    0.44 ms per token,  2254.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     669.96 ms /    11 tokens (   60.91 ms per token,    16.42 tokens per second)\n",
      "llama_print_timings:        eval time =   41479.61 ms /    59 runs   (  703.04 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   42343.16 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.52 ms /    38 runs   (    0.41 ms per token,  2448.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     790.16 ms /    12 tokens (   65.85 ms per token,    15.19 tokens per second)\n",
      "llama_print_timings:        eval time =   24717.84 ms /    37 runs   (  668.05 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   25622.74 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.01 ms /    30 runs   (    0.40 ms per token,  2498.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.46 ms /    12 tokens (   53.54 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   19229.44 ms /    29 runs   (  663.08 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19961.05 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.58 ms /    30 runs   (    0.42 ms per token,  2383.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.99 ms /    13 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   20260.76 ms /    29 runs   (  698.65 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   21030.73 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.26 ms /    22 runs   (    0.42 ms per token,  2376.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.64 ms /    12 tokens (   57.80 ms per token,    17.30 tokens per second)\n",
      "llama_print_timings:        eval time =   14929.80 ms /    21 runs   (  710.94 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   15692.15 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.03 ms /    30 runs   (    0.43 ms per token,  2302.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.48 ms /    12 tokens (   54.54 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   19813.36 ms /    29 runs   (  683.22 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20561.51 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.36 ms /    40 runs   (    0.43 ms per token,  2304.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     811.36 ms /    12 tokens (   67.61 ms per token,    14.79 tokens per second)\n",
      "llama_print_timings:        eval time =   27291.14 ms /    39 runs   (  699.77 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   28228.81 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.30 ms /    30 runs   (    0.41 ms per token,  2438.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     751.38 ms /    12 tokens (   62.62 ms per token,    15.97 tokens per second)\n",
      "llama_print_timings:        eval time =   19733.61 ms /    29 runs   (  680.47 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20575.15 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.50 ms /    30 runs   (    0.42 ms per token,  2400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     764.27 ms /    13 tokens (   58.79 ms per token,    17.01 tokens per second)\n",
      "llama_print_timings:        eval time =   20353.11 ms /    29 runs   (  701.83 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   21206.94 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.48 ms /    35 runs   (    0.41 ms per token,  2417.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1008.68 ms /    13 tokens (   77.59 ms per token,    12.89 tokens per second)\n",
      "llama_print_timings:        eval time =   23582.86 ms /    34 runs   (  693.61 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   24695.59 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.52 ms /    38 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     628.48 ms /    11 tokens (   57.13 ms per token,    17.50 tokens per second)\n",
      "llama_print_timings:        eval time =   25317.81 ms /    37 runs   (  684.27 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   26060.03 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.49 ms /    38 runs   (    0.41 ms per token,  2453.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.99 ms /    12 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   25424.23 ms /    37 runs   (  687.14 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   26175.67 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.43 ms /    30 runs   (    0.41 ms per token,  2413.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     715.51 ms /    12 tokens (   59.63 ms per token,    16.77 tokens per second)\n",
      "llama_print_timings:        eval time =   20007.84 ms /    29 runs   (  689.93 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   20813.57 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.20 ms /    34 runs   (    0.42 ms per token,  2393.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     669.95 ms /    11 tokens (   60.90 ms per token,    16.42 tokens per second)\n",
      "llama_print_timings:        eval time =   22141.67 ms /    33 runs   (  670.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22915.03 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.12 ms /    30 runs   (    0.40 ms per token,  2474.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.63 ms /    13 tokens (   53.74 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   19505.42 ms /    29 runs   (  672.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20290.51 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.92 ms /    39 runs   (    0.43 ms per token,  2304.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     667.45 ms /    12 tokens (   55.62 ms per token,    17.98 tokens per second)\n",
      "llama_print_timings:        eval time =   25721.19 ms /    38 runs   (  676.87 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26510.28 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.20 ms /    37 runs   (    0.41 ms per token,  2433.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.40 ms /    12 tokens (   54.95 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =   24349.30 ms /    36 runs   (  676.37 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25119.21 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.09 ms /    29 runs   (    0.42 ms per token,  2399.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     731.24 ms /    14 tokens (   52.23 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =   18910.94 ms /    28 runs   (  675.39 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19728.59 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.55 ms /    31 runs   (    0.40 ms per token,  2470.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     599.15 ms /    11 tokens (   54.47 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =   20230.12 ms /    30 runs   (  674.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20919.42 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.28 ms /    36 runs   (    0.42 ms per token,  2356.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.45 ms /    12 tokens (   57.29 ms per token,    17.46 tokens per second)\n",
      "llama_print_timings:        eval time =   23337.86 ms /    35 runs   (  666.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24135.26 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      28.80 ms /    70 runs   (    0.41 ms per token,  2430.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.59 ms /    12 tokens (   53.80 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   46741.93 ms /    69 runs   (  677.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   47595.19 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.76 ms /    48 runs   (    0.41 ms per token,  2428.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.21 ms /    12 tokens (   55.27 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =   31798.60 ms /    47 runs   (  676.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   32603.36 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.19 ms /    30 runs   (    0.41 ms per token,  2460.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.43 ms /    12 tokens (   54.70 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =   19508.55 ms /    29 runs   (  672.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20251.73 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.87 ms /    41 runs   (    0.44 ms per token,  2293.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.85 ms /    12 tokens (   53.32 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   26912.74 ms /    40 runs   (  672.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   27678.79 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.49 ms /    30 runs   (    0.42 ms per token,  2402.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     690.21 ms /    13 tokens (   53.09 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   19612.82 ms /    29 runs   (  676.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20391.40 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.27 ms /    25 runs   (    0.41 ms per token,  2433.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     604.19 ms /    11 tokens (   54.93 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =   15960.05 ms /    24 runs   (  665.00 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16640.04 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.97 ms /    30 runs   (    0.40 ms per token,  2507.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.65 ms /    12 tokens (   54.47 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =   19040.34 ms /    29 runs   (  656.56 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19782.36 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.89 ms /    42 runs   (    0.43 ms per token,  2348.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.23 ms /    12 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   27898.73 ms /    41 runs   (  680.46 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   28665.60 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.99 ms /    35 runs   (    0.40 ms per token,  2501.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.54 ms /    12 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   23193.28 ms /    34 runs   (  682.16 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   23932.18 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.85 ms /    37 runs   (    0.43 ms per token,  2334.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     602.42 ms /    11 tokens (   54.77 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =   24019.58 ms /    36 runs   (  667.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24735.33 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.27 ms /    30 runs   (    0.41 ms per token,  2444.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.84 ms /    12 tokens (   55.32 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =   19461.53 ms /    29 runs   (  671.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20212.90 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.00 ms /    49 runs   (    0.41 ms per token,  2450.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.31 ms /    13 tokens (   52.72 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   32538.10 ms /    48 runs   (  677.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   33370.77 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.21 ms /    25 runs   (    0.41 ms per token,  2449.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.28 ms /    13 tokens (   52.48 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   16204.08 ms /    24 runs   (  675.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16959.90 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.32 ms /    30 runs   (    0.41 ms per token,  2434.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.38 ms /    12 tokens (   53.37 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   19397.28 ms /    29 runs   (  668.87 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20124.51 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.25 ms /    30 runs   (    0.41 ms per token,  2448.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.11 ms /    12 tokens (   53.18 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   19385.05 ms /    29 runs   (  668.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20109.10 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.95 ms /    38 runs   (    0.39 ms per token,  2542.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.90 ms /    12 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   24708.67 ms /    37 runs   (  667.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   25454.71 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.61 ms /    53 runs   (    0.41 ms per token,  2452.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.02 ms /    12 tokens (   52.84 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   34848.24 ms /    52 runs   (  670.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   35638.70 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.55 ms /    31 runs   (    0.40 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.50 ms /    12 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   20132.41 ms /    30 runs   (  671.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20856.29 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.03 ms /    30 runs   (    0.40 ms per token,  2494.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     588.29 ms /    11 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   19804.20 ms /    29 runs   (  682.90 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20479.14 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.11 ms /    30 runs   (    0.40 ms per token,  2477.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.64 ms /    13 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   19211.50 ms /    29 runs   (  662.47 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19984.39 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.14 ms /    30 runs   (    0.40 ms per token,  2470.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.84 ms /    12 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   19051.10 ms /    29 runs   (  656.93 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19775.33 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.58 ms /    39 runs   (    0.40 ms per token,  2503.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.90 ms /    12 tokens (   53.58 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   25515.76 ms /    38 runs   (  671.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26272.33 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.71 ms /    41 runs   (    0.41 ms per token,  2454.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.95 ms /    11 tokens (   53.90 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   27080.56 ms /    40 runs   (  677.01 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27793.83 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.30 ms /    62 runs   (    0.41 ms per token,  2450.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.53 ms /    12 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   40890.49 ms /    61 runs   (  670.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   41707.98 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.22 ms /    30 runs   (    0.41 ms per token,  2454.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.11 ms /    11 tokens (   53.92 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   19201.80 ms /    29 runs   (  662.13 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19882.77 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.62 ms /    61 runs   (    0.40 ms per token,  2477.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.39 ms /    12 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   40434.82 ms /    60 runs   (  673.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   41247.84 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.30 ms /    25 runs   (    0.41 ms per token,  2427.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.06 ms /    12 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   16082.03 ms /    24 runs   (  670.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16787.83 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.28 ms /    30 runs   (    0.41 ms per token,  2442.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.45 ms /    13 tokens (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   19752.33 ms /    29 runs   (  681.11 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20524.78 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.86 ms /    24 runs   (    0.41 ms per token,  2435.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.00 ms /    12 tokens (   53.58 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   15560.37 ms /    23 runs   (  676.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16273.41 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.13 ms /    25 runs   (    0.41 ms per token,  2468.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.91 ms /    12 tokens (   52.83 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   16188.38 ms /    24 runs   (  674.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16894.65 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.03 ms /    22 runs   (    0.41 ms per token,  2437.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.65 ms /    12 tokens (   54.97 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =   13999.48 ms /    21 runs   (  666.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14724.05 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.25 ms /    29 runs   (    0.42 ms per token,  2367.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.69 ms /    12 tokens (   53.31 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   18412.20 ms /    28 runs   (  657.58 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19139.08 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.70 ms /    24 runs   (    0.40 ms per token,  2473.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.54 ms /    11 tokens (   57.78 ms per token,    17.31 tokens per second)\n",
      "llama_print_timings:        eval time =   15550.71 ms /    23 runs   (  676.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16256.53 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.01 ms /    24 runs   (    0.46 ms per token,  2179.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.06 ms /    12 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   15394.79 ms /    23 runs   (  669.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16112.87 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.87 ms /    24 runs   (    0.41 ms per token,  2432.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.79 ms /    11 tokens (   54.07 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   15042.51 ms /    23 runs   (  654.02 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   15708.58 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.55 ms /    45 runs   (    0.41 ms per token,  2426.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     675.77 ms /    13 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   29751.61 ms /    44 runs   (  676.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   30557.69 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.22 ms /    27 runs   (    0.42 ms per token,  2406.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.77 ms /    12 tokens (   53.65 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   17475.74 ms /    26 runs   (  672.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18198.42 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.83 ms /    31 runs   (    0.41 ms per token,  2416.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.15 ms /    12 tokens (   52.51 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   20060.40 ms /    30 runs   (  668.68 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20781.09 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    17 runs   (    0.42 ms per token,  2393.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     610.05 ms /    11 tokens (   55.46 ms per token,    18.03 tokens per second)\n",
      "llama_print_timings:        eval time =   10636.00 ms /    16 runs   (  664.75 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11295.39 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.00 ms /    22 runs   (    0.41 ms per token,  2444.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.58 ms /    12 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   13948.11 ms /    21 runs   (  664.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14656.35 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.32 ms /    31 runs   (    0.40 ms per token,  2516.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     660.53 ms /    12 tokens (   55.04 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =   19753.02 ms /    30 runs   (  658.43 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   20504.72 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.92 ms /    25 runs   (    0.40 ms per token,  2519.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.26 ms /    11 tokens (   53.75 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   15757.88 ms /    24 runs   (  656.58 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   16422.77 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    19 runs   (    0.41 ms per token,  2409.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.63 ms /    12 tokens (   52.80 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   12150.18 ms /    18 runs   (  675.01 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12839.49 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.01 ms /    30 runs   (    0.40 ms per token,  2498.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.78 ms /    13 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   19376.56 ms /    29 runs   (  668.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20151.18 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.93 ms /    30 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.84 ms /    11 tokens (   53.89 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   19380.98 ms /    29 runs   (  668.31 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20061.00 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.21 ms /    30 runs   (    0.41 ms per token,  2458.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.57 ms /    12 tokens (   54.13 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   19589.74 ms /    29 runs   (  675.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20327.67 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.20 ms /    20 runs   (    0.41 ms per token,  2440.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     662.22 ms /    12 tokens (   55.18 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =   12956.17 ms /    19 runs   (  681.90 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13677.53 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 900 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.16 ms /    30 runs   (    0.44 ms per token,  2278.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.76 ms /    11 tokens (   54.25 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   19213.62 ms /    29 runs   (  662.54 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19905.53 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.12 ms /    44 runs   (    0.43 ms per token,  2301.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.10 ms /    13 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   29085.30 ms /    43 runs   (  676.40 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   29897.28 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.22 ms /    28 runs   (    0.40 ms per token,  2495.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     675.27 ms /    12 tokens (   56.27 ms per token,    17.77 tokens per second)\n",
      "llama_print_timings:        eval time =   18079.16 ms /    27 runs   (  669.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18837.35 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.12 ms /    45 runs   (    0.42 ms per token,  2353.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.87 ms /    12 tokens (   52.91 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   29513.20 ms /    44 runs   (  670.75 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   30286.03 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.02 ms /    30 runs   (    0.40 ms per token,  2495.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.51 ms /    11 tokens (   54.23 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   18877.99 ms /    29 runs   (  650.97 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   19561.66 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.66 ms /    34 runs   (    0.40 ms per token,  2489.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.94 ms /    13 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   22061.87 ms /    33 runs   (  668.54 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22847.26 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.62 ms /    29 runs   (    0.40 ms per token,  2495.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.27 ms /    12 tokens (   53.69 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   18688.12 ms /    28 runs   (  667.43 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19418.96 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.54 ms /    39 runs   (    0.42 ms per token,  2357.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     664.19 ms /    12 tokens (   55.35 ms per token,    18.07 tokens per second)\n",
      "llama_print_timings:        eval time =   25579.24 ms /    38 runs   (  673.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26362.22 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.55 ms /    29 runs   (    0.40 ms per token,  2511.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.67 ms /    12 tokens (   52.72 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   18422.42 ms /    28 runs   (  657.94 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19139.51 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.81 ms /    29 runs   (    0.41 ms per token,  2456.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.51 ms /    11 tokens (   54.59 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   18229.30 ms /    28 runs   (  651.05 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   18914.20 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.62 ms /    55 runs   (    0.41 ms per token,  2431.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     725.74 ms /    14 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   36327.37 ms /    54 runs   (  672.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   37215.39 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.09 ms /    25 runs   (    0.40 ms per token,  2476.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.39 ms /    12 tokens (   52.95 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   16135.80 ms /    24 runs   (  672.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16844.88 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.19 ms /    57 runs   (    0.41 ms per token,  2457.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     583.54 ms /    11 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   37389.25 ms /    56 runs   (  667.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   38138.63 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.53 ms /    31 runs   (    0.40 ms per token,  2473.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     706.20 ms /    11 tokens (   64.20 ms per token,    15.58 tokens per second)\n",
      "llama_print_timings:        eval time =   20048.90 ms /    30 runs   (  668.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20844.65 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.19 ms /    30 runs   (    0.41 ms per token,  2461.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     658.43 ms /    12 tokens (   54.87 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =   19469.15 ms /    29 runs   (  671.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20218.80 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.25 ms /    42 runs   (    0.41 ms per token,  2434.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.67 ms /    12 tokens (   52.81 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   27530.15 ms /    41 runs   (  671.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28287.27 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.55 ms /    42 runs   (    0.42 ms per token,  2392.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.17 ms /    12 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   27420.02 ms /    41 runs   (  668.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28190.40 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.65 ms /    28 runs   (    0.42 ms per token,  2403.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     629.97 ms /    12 tokens (   52.50 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   17898.13 ms /    27 runs   (  662.89 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   18610.52 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.81 ms /    43 runs   (    0.46 ms per token,  2171.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.36 ms /    12 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   27590.09 ms /    42 runs   (  656.91 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   28357.11 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.46 ms /    31 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     723.88 ms /    13 tokens (   55.68 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:        eval time =   20161.73 ms /    30 runs   (  672.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20976.43 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.35 ms /    41 runs   (    0.42 ms per token,  2362.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.59 ms /    12 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   26744.64 ms /    40 runs   (  668.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   27511.57 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.03 ms /    30 runs   (    0.40 ms per token,  2493.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.62 ms /    11 tokens (   53.69 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   18938.35 ms /    29 runs   (  653.05 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   19616.71 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.73 ms /    34 runs   (    0.40 ms per token,  2477.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.41 ms /    12 tokens (   52.62 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   22032.36 ms /    33 runs   (  667.65 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22761.89 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.01 ms /    39 runs   (    0.41 ms per token,  2436.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     599.61 ms /    11 tokens (   54.51 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =   25552.65 ms /    38 runs   (  672.44 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26264.79 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.01 ms /    27 runs   (    0.41 ms per token,  2453.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.65 ms /    12 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   17526.33 ms /    26 runs   (  674.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18240.52 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.23 ms /    25 runs   (    0.41 ms per token,  2444.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.70 ms /    12 tokens (   52.73 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   16071.83 ms /    24 runs   (  669.66 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16776.44 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.61 ms /    39 runs   (    0.40 ms per token,  2499.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.29 ms /    13 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   25506.81 ms /    38 runs   (  671.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26308.31 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.66 ms /    41 runs   (    0.41 ms per token,  2461.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.94 ms /    12 tokens (   53.16 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   26659.22 ms /    40 runs   (  666.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   27417.48 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.01 ms /    53 runs   (    0.42 ms per token,  2408.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.18 ms /    12 tokens (   53.26 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   34639.12 ms /    52 runs   (  666.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   35433.60 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /    20 runs   (    0.41 ms per token,  2434.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.58 ms /    13 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   12822.66 ms /    19 runs   (  674.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13566.59 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.80 ms /    53 runs   (    0.41 ms per token,  2431.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     658.51 ms /    12 tokens (   54.88 ms per token,    18.22 tokens per second)\n",
      "llama_print_timings:        eval time =   35058.75 ms /    52 runs   (  674.21 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   35871.89 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.94 ms /    30 runs   (    0.40 ms per token,  2513.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.05 ms /    12 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   19323.41 ms /    29 runs   (  666.32 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20049.41 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.57 ms /    61 runs   (    0.42 ms per token,  2385.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     689.38 ms /    13 tokens (   53.03 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   39973.88 ms /    60 runs   (  666.23 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   40847.16 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.42 ms /    43 runs   (    0.41 ms per token,  2468.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.60 ms /    12 tokens (   53.22 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   28295.90 ms /    42 runs   (  673.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   29059.13 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.75 ms /    39 runs   (    0.40 ms per token,  2475.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     599.85 ms /    11 tokens (   54.53 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   25315.58 ms /    38 runs   (  666.20 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26030.84 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.79 ms /    29 runs   (    0.41 ms per token,  2460.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.48 ms /    13 tokens (   52.50 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   18561.59 ms /    28 runs   (  662.91 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19330.65 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.21 ms /    25 runs   (    0.41 ms per token,  2449.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     673.30 ms /    13 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   16211.05 ms /    24 runs   (  675.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16955.77 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.63 ms /    34 runs   (    0.40 ms per token,  2494.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.84 ms /    11 tokens (   53.99 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   22180.38 ms /    33 runs   (  672.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22870.80 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.85 ms /    24 runs   (    0.41 ms per token,  2437.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     588.70 ms /    11 tokens (   53.52 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   15548.44 ms /    23 runs   (  676.02 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16206.41 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.11 ms /    25 runs   (    0.40 ms per token,  2472.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.64 ms /    12 tokens (   52.80 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   16437.65 ms /    24 runs   (  684.90 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   17144.63 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.20 ms /    30 runs   (    0.41 ms per token,  2458.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.59 ms /    12 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   19278.14 ms /    29 runs   (  664.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20000.44 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.43 ms /    43 runs   (    0.41 ms per token,  2466.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.99 ms /    11 tokens (   53.91 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   27913.46 ms /    42 runs   (  664.61 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28632.77 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.32 ms /    43 runs   (    0.40 ms per token,  2481.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.65 ms /    12 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   28219.62 ms /    42 runs   (  671.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28975.20 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.90 ms /    27 runs   (    0.40 ms per token,  2476.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     587.06 ms /    11 tokens (   53.37 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   17531.85 ms /    26 runs   (  674.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18196.50 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.13 ms /    42 runs   (    0.41 ms per token,  2451.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     587.33 ms /    11 tokens (   53.39 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   27226.88 ms /    41 runs   (  664.07 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   27937.43 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.62 ms /    33 runs   (    0.41 ms per token,  2422.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     700.81 ms /    13 tokens (   53.91 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   21445.88 ms /    32 runs   (  670.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22243.08 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.80 ms /    42 runs   (    0.40 ms per token,  2499.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     662.92 ms /    12 tokens (   55.24 ms per token,    18.10 tokens per second)\n",
      "llama_print_timings:        eval time =   27694.20 ms /    41 runs   (  675.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   28479.84 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.22 ms /    34 runs   (    0.42 ms per token,  2391.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.94 ms /    12 tokens (   53.49 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   21723.75 ms /    33 runs   (  658.30 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   22466.55 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.60 ms /    39 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     676.66 ms /    13 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   25716.82 ms /    38 runs   (  676.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26506.23 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.62 ms /    37 runs   (    0.40 ms per token,  2530.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.93 ms /    12 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   23984.16 ms /    36 runs   (  666.23 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24728.99 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.72 ms /    50 runs   (    0.41 ms per token,  2413.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.61 ms /    12 tokens (   54.72 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =   32473.42 ms /    49 runs   (  662.72 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   33278.98 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      28.58 ms /    70 runs   (    0.41 ms per token,  2449.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.50 ms /    12 tokens (   53.29 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   45980.00 ms /    69 runs   (  666.38 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   46827.18 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.86 ms /    66 runs   (    0.41 ms per token,  2457.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.31 ms /    12 tokens (   54.19 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =   44067.87 ms /    65 runs   (  677.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   44912.56 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.41 ms /    45 runs   (    0.41 ms per token,  2444.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     668.34 ms /    12 tokens (   55.69 ms per token,    17.95 tokens per second)\n",
      "llama_print_timings:        eval time =   29727.13 ms /    44 runs   (  675.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   30527.94 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.86 ms /    42 runs   (    0.40 ms per token,  2491.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     660.37 ms /    12 tokens (   55.03 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =   27685.79 ms /    41 runs   (  675.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   28468.62 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.61 ms /    33 runs   (    0.41 ms per token,  2424.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.15 ms /    13 tokens (   52.40 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   21421.42 ms /    32 runs   (  669.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22198.31 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.56 ms /    32 runs   (    0.42 ms per token,  2360.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.39 ms /    12 tokens (   53.12 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   21003.92 ms /    31 runs   (  677.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21737.89 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.47 ms /    41 runs   (    0.40 ms per token,  2489.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.97 ms /    11 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   26927.89 ms /    40 runs   (  673.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   27638.47 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.55 ms /    33 runs   (    0.41 ms per token,  2435.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.76 ms /    12 tokens (   54.23 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   21507.38 ms /    32 runs   (  672.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22255.66 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.23 ms /    64 runs   (    0.41 ms per token,  2440.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.88 ms /    12 tokens (   53.41 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   41534.50 ms /    63 runs   (  659.28 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   42367.07 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.24 ms /    36 runs   (    0.40 ms per token,  2527.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.67 ms /    12 tokens (   53.06 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   23572.38 ms /    35 runs   (  673.50 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   24314.65 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.63 ms /    34 runs   (    0.40 ms per token,  2495.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.94 ms /    11 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   22020.65 ms /    33 runs   (  667.29 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22710.29 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.65 ms /    42 runs   (    0.44 ms per token,  2251.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     778.05 ms /    15 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   27494.72 ms /    41 runs   (  670.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28405.54 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.16 ms /    30 runs   (    0.41 ms per token,  2466.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.47 ms /    12 tokens (   53.12 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   19019.25 ms /    29 runs   (  655.84 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19745.59 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.59 ms /    55 runs   (    0.41 ms per token,  2435.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     708.09 ms /    13 tokens (   54.47 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =   36173.75 ms /    54 runs   (  669.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   37043.91 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      39.20 ms /    97 runs   (    0.40 ms per token,  2474.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.44 ms /    12 tokens (   54.54 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   64070.57 ms /    96 runs   (  667.40 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   65012.37 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      34.14 ms /    84 runs   (    0.41 ms per token,  2460.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.12 ms /    12 tokens (   52.84 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   55846.27 ms /    83 runs   (  672.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   56729.21 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.90 ms /    32 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.99 ms /    12 tokens (   52.92 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   20807.38 ms /    31 runs   (  671.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21536.25 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.94 ms /    44 runs   (    0.43 ms per token,  2323.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.60 ms /    12 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   28813.12 ms /    43 runs   (  670.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29586.86 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.13 ms /    27 runs   (    0.41 ms per token,  2426.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.60 ms /    13 tokens (   52.20 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   17507.03 ms /    26 runs   (  673.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18265.74 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.01 ms /    43 runs   (    0.44 ms per token,  2261.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.65 ms /    12 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   28377.02 ms /    42 runs   (  675.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   29152.63 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.60 ms /    48 runs   (    0.41 ms per token,  2449.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.55 ms /    12 tokens (   53.46 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   31845.66 ms /    47 runs   (  677.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   32625.81 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    19 runs   (    0.41 ms per token,  2421.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.95 ms /    12 tokens (   52.91 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   12112.64 ms /    18 runs   (  672.92 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12802.56 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.17 ms /    30 runs   (    0.41 ms per token,  2464.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     672.90 ms /    13 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =   19516.93 ms /    29 runs   (  673.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20277.11 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.06 ms /    30 runs   (    0.40 ms per token,  2487.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.37 ms /    11 tokens (   54.03 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   19600.80 ms /    29 runs   (  675.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20282.11 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.27 ms /    30 runs   (    0.41 ms per token,  2445.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.78 ms /    12 tokens (   52.73 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   19529.41 ms /    29 runs   (  673.43 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20249.85 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.78 ms /    27 runs   (    0.40 ms per token,  2504.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.90 ms /    12 tokens (   54.99 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =   17655.67 ms /    26 runs   (  679.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18393.96 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.09 ms /    25 runs   (    0.40 ms per token,  2478.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     603.87 ms /    11 tokens (   54.90 ms per token,    18.22 tokens per second)\n",
      "llama_print_timings:        eval time =   16066.30 ms /    24 runs   (  669.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16742.54 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.94 ms /    32 runs   (    0.40 ms per token,  2473.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.64 ms /    12 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   20378.03 ms /    31 runs   (  657.36 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21103.32 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.44 ms /    30 runs   (    0.41 ms per token,  2411.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.06 ms /    12 tokens (   53.09 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   19261.63 ms /    29 runs   (  664.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19987.12 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.03 ms /    29 runs   (    0.41 ms per token,  2410.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.93 ms /    12 tokens (   52.91 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   18661.12 ms /    28 runs   (  666.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19381.20 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.94 ms /    22 runs   (    0.41 ms per token,  2461.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.76 ms /    13 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   14084.63 ms /    21 runs   (  670.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14831.20 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.46 ms /    28 runs   (    0.41 ms per token,  2442.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.90 ms /    12 tokens (   52.91 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   18126.30 ms /    27 runs   (  671.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18842.86 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      34.98 ms /    84 runs   (    0.42 ms per token,  2401.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.34 ms /    12 tokens (   53.20 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   56001.89 ms /    83 runs   (  674.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   56893.18 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.28 ms /    20 runs   (    0.41 ms per token,  2414.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.93 ms /    12 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   12599.52 ms /    19 runs   (  663.13 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13288.05 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.95 ms /    60 runs   (    0.42 ms per token,  2405.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.27 ms /    13 tokens (   52.56 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   39999.17 ms /    59 runs   (  677.95 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   40860.78 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.25 ms /    23 runs   (    0.40 ms per token,  2486.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.76 ms /    12 tokens (   52.98 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   14690.70 ms /    22 runs   (  667.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15393.41 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.48 ms /    52 runs   (    0.41 ms per token,  2420.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.12 ms /    12 tokens (   54.26 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   34128.93 ms /    51 runs   (  669.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   34931.73 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.08 ms /    32 runs   (    0.41 ms per token,  2445.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.87 ms /    12 tokens (   53.16 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   20930.52 ms /    31 runs   (  675.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21662.17 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.24 ms /    25 runs   (    0.41 ms per token,  2440.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.08 ms /    12 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   15967.10 ms /    24 runs   (  665.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16671.81 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.25 ms /    30 runs   (    0.41 ms per token,  2448.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     694.01 ms /    13 tokens (   53.39 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   19304.31 ms /    29 runs   (  665.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20087.14 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.48 ms /    50 runs   (    0.43 ms per token,  2327.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.40 ms /    12 tokens (   53.12 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   32918.09 ms /    49 runs   (  671.80 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   33708.20 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.31 ms /    30 runs   (    0.41 ms per token,  2437.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.29 ms /    11 tokens (   53.75 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   19400.16 ms /    29 runs   (  668.97 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20080.23 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.45 ms /    52 runs   (    0.41 ms per token,  2423.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     629.56 ms /    12 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   34584.29 ms /    51 runs   (  678.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   35364.64 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.28 ms /    30 runs   (    0.44 ms per token,  2258.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     676.72 ms /    13 tokens (   52.06 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   19626.80 ms /    29 runs   (  676.79 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20396.23 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.44 ms /    30 runs   (    0.41 ms per token,  2412.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.26 ms /    12 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   19365.02 ms /    29 runs   (  667.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20096.55 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.26 ms /    30 runs   (    0.41 ms per token,  2447.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.47 ms /    12 tokens (   54.21 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =   19497.21 ms /    29 runs   (  672.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20234.67 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.27 ms /    38 runs   (    0.43 ms per token,  2336.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     587.07 ms /    11 tokens (   53.37 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   24737.28 ms /    37 runs   (  668.58 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   25437.38 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.33 ms /    37 runs   (    0.41 ms per token,  2413.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     690.70 ms /    13 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   24005.75 ms /    36 runs   (  666.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24803.67 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.18 ms /    17 runs   (    0.42 ms per token,  2367.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.02 ms /    12 tokens (   52.92 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   10330.83 ms /    16 runs   (  645.68 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   11015.53 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1000 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.32 ms /    20 runs   (    0.42 ms per token,  2403.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     689.54 ms /    13 tokens (   53.04 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   12597.86 ms /    19 runs   (  663.05 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13345.52 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.98 ms /    59 runs   (    0.41 ms per token,  2459.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.65 ms /    12 tokens (   54.55 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   39168.89 ms /    58 runs   (  675.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   39995.70 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.26 ms /    25 runs   (    0.41 ms per token,  2436.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.69 ms /    12 tokens (   52.89 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   15959.38 ms /    24 runs   (  664.97 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16666.75 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.30 ms /    42 runs   (    0.41 ms per token,  2427.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.00 ms /    12 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   27331.35 ms /    41 runs   (  666.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28087.78 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.06 ms /    45 runs   (    0.40 ms per token,  2491.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     725.72 ms /    14 tokens (   51.84 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   28583.63 ms /    44 runs   (  649.63 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   29442.20 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.85 ms /    27 runs   (    0.40 ms per token,  2488.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.08 ms /    12 tokens (   54.34 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   17203.76 ms /    26 runs   (  661.68 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17934.61 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.84 ms /    34 runs   (    0.41 ms per token,  2455.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.27 ms /    11 tokens (   53.75 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   21912.31 ms /    33 runs   (  664.01 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   22603.28 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /    20 runs   (    0.41 ms per token,  2432.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.73 ms /    11 tokens (   54.34 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   12584.49 ms /    19 runs   (  662.34 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13240.67 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.35 ms /    23 runs   (    0.41 ms per token,  2460.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     629.72 ms /    12 tokens (   52.48 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   14731.93 ms /    22 runs   (  669.63 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15429.72 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.27 ms /    38 runs   (    0.43 ms per token,  2335.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.37 ms /    12 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   25290.26 ms /    37 runs   (  683.52 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   26041.95 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      40.66 ms /   100 runs   (    0.41 ms per token,  2459.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.08 ms /    12 tokens (   52.51 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   65854.98 ms /    99 runs   (  665.20 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   66785.05 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.04 ms /    37 runs   (    0.41 ms per token,  2460.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.72 ms /    11 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   23690.28 ms /    36 runs   (  658.06 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   24392.87 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      38.40 ms /    93 runs   (    0.41 ms per token,  2422.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     722.55 ms /    13 tokens (   55.58 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =   61874.18 ms /    92 runs   (  672.55 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   62874.40 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.69 ms /    37 runs   (    0.40 ms per token,  2519.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.74 ms /    12 tokens (   53.81 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   23992.26 ms /    36 runs   (  666.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24744.69 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.17 ms /    20 runs   (    0.41 ms per token,  2447.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.53 ms /    12 tokens (   53.29 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   12673.22 ms /    19 runs   (  667.01 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13370.70 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.89 ms /    46 runs   (    0.41 ms per token,  2435.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.44 ms /    11 tokens (   54.40 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   30243.69 ms /    45 runs   (  672.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   30977.26 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.98 ms /    30 runs   (    0.40 ms per token,  2504.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     587.20 ms /    11 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   19083.27 ms /    29 runs   (  658.04 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19758.22 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.22 ms /    66 runs   (    0.41 ms per token,  2424.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.89 ms /    13 tokens (   52.15 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   43650.30 ms /    65 runs   (  671.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   44530.93 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.49 ms /    41 runs   (    0.43 ms per token,  2343.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.26 ms /    12 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   27075.46 ms /    40 runs   (  676.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27836.36 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.81 ms /    27 runs   (    0.40 ms per token,  2498.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.79 ms /    11 tokens (   53.80 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   17372.17 ms /    26 runs   (  668.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18042.70 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.99 ms /    30 runs   (    0.40 ms per token,  2501.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.91 ms /    12 tokens (   53.41 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   19157.69 ms /    29 runs   (  660.61 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19886.61 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.10 ms /    30 runs   (    0.40 ms per token,  2480.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     586.89 ms /    11 tokens (   53.35 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   19272.12 ms /    29 runs   (  664.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19947.76 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    19 runs   (    0.41 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.40 ms /    12 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   11958.02 ms /    18 runs   (  664.33 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12644.33 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.01 ms /    35 runs   (    0.40 ms per token,  2498.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.22 ms /    13 tokens (   52.63 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   22585.82 ms /    34 runs   (  664.29 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   23371.29 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.95 ms /    23 runs   (    0.43 ms per token,  2312.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     629.98 ms /    12 tokens (   52.50 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   14506.02 ms /    22 runs   (  659.36 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15207.05 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.50 ms /    39 runs   (    0.40 ms per token,  2516.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     585.01 ms /    11 tokens (   53.18 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   25162.30 ms /    38 runs   (  662.17 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   25861.53 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.91 ms /    49 runs   (    0.41 ms per token,  2461.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.33 ms /    12 tokens (   53.86 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   32039.13 ms /    48 runs   (  667.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   32830.22 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.16 ms /    25 runs   (    0.41 ms per token,  2460.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     689.82 ms /    13 tokens (   53.06 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   15944.11 ms /    24 runs   (  664.34 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16708.23 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.84 ms /    27 runs   (    0.40 ms per token,  2490.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.28 ms /    12 tokens (   54.44 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   17258.99 ms /    26 runs   (  663.81 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17991.50 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      29.59 ms /    72 runs   (    0.41 ms per token,  2433.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.65 ms /    12 tokens (   52.80 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   47759.56 ms /    71 runs   (  672.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   48605.68 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.02 ms /    27 runs   (    0.41 ms per token,  2449.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     588.66 ms /    11 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   17210.98 ms /    26 runs   (  661.96 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17879.15 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.74 ms /    41 runs   (    0.43 ms per token,  2311.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     603.76 ms /    11 tokens (   54.89 ms per token,    18.22 tokens per second)\n",
      "llama_print_timings:        eval time =   26761.87 ms /    40 runs   (  669.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   27492.23 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.76 ms /    46 runs   (    0.41 ms per token,  2452.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.71 ms /    12 tokens (   52.98 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   30280.84 ms /    45 runs   (  672.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   31052.01 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.73 ms /    58 runs   (    0.41 ms per token,  2444.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.79 ms /    12 tokens (   54.65 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =   38396.77 ms /    57 runs   (  673.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   39222.03 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.09 ms /    30 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     690.00 ms /    13 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   19008.74 ms /    29 runs   (  655.47 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   19787.64 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.92 ms /    27 runs   (    0.44 ms per token,  2265.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.00 ms /    12 tokens (   52.92 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   17316.75 ms /    26 runs   (  666.03 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18035.90 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.28 ms /    30 runs   (    0.41 ms per token,  2443.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.14 ms /    12 tokens (   54.01 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   19384.83 ms /    29 runs   (  668.44 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20122.99 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.12 ms /    30 runs   (    0.40 ms per token,  2476.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.95 ms /    12 tokens (   53.16 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   19524.32 ms /    29 runs   (  673.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20251.01 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.22 ms /    30 runs   (    0.41 ms per token,  2454.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     689.22 ms /    13 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   19121.12 ms /    29 runs   (  659.35 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19898.07 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.29 ms /    30 runs   (    0.41 ms per token,  2441.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.02 ms /    11 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   19172.32 ms /    29 runs   (  661.11 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19850.68 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.71 ms /    43 runs   (    0.41 ms per token,  2428.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     665.31 ms /    12 tokens (   55.44 ms per token,    18.04 tokens per second)\n",
      "llama_print_timings:        eval time =   27407.84 ms /    42 runs   (  652.57 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   28202.77 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.82 ms /    32 runs   (    0.40 ms per token,  2496.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.51 ms /    12 tokens (   54.13 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   20616.09 ms /    31 runs   (  665.04 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21358.95 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      47.90 ms /   115 runs   (    0.42 ms per token,  2400.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.17 ms /    12 tokens (   54.35 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   76577.26 ms /   114 runs   (  671.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   77582.61 ms /   126 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.86 ms /    37 runs   (    0.40 ms per token,  2489.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     588.05 ms /    11 tokens (   53.46 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   24362.81 ms /    36 runs   (  676.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25060.60 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      36.52 ms /    89 runs   (    0.41 ms per token,  2436.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.81 ms /    12 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   59134.90 ms /    88 runs   (  671.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   60039.80 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.25 ms /    30 runs   (    0.41 ms per token,  2449.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.90 ms /    13 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   19637.85 ms /    29 runs   (  677.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20407.70 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.28 ms /    38 runs   (    0.40 ms per token,  2486.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.33 ms /    12 tokens (   52.69 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   24282.01 ms /    37 runs   (  656.27 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   25023.70 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      49.11 ms /   119 runs   (    0.41 ms per token,  2422.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.49 ms /    11 tokens (   54.04 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   78611.60 ms /   118 runs   (  666.20 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   79562.78 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.89 ms /    37 runs   (    0.40 ms per token,  2485.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.31 ms /    11 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   23333.79 ms /    36 runs   (  648.16 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   24033.04 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.23 ms /    25 runs   (    0.41 ms per token,  2444.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.04 ms /    12 tokens (   52.50 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   15909.66 ms /    24 runs   (  662.90 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16612.76 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.57 ms /    46 runs   (    0.40 ms per token,  2477.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     705.08 ms /    13 tokens (   54.24 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   30331.76 ms /    45 runs   (  674.04 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   31170.81 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.92 ms /    22 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     588.21 ms /    11 tokens (   53.47 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   14071.01 ms /    21 runs   (  670.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14723.47 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.40 ms /    23 runs   (    0.41 ms per token,  2447.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.19 ms /    12 tokens (   52.77 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   14646.67 ms /    22 runs   (  665.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15347.00 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.85 ms /    32 runs   (    0.40 ms per token,  2490.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.54 ms /    11 tokens (   54.32 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   20899.43 ms /    31 runs   (  674.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21589.97 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.54 ms /    23 runs   (    0.41 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.83 ms /    12 tokens (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   14993.15 ms /    22 runs   (  681.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15706.22 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.62 ms /    23 runs   (    0.46 ms per token,  2165.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.91 ms /    12 tokens (   58.74 ms per token,    17.02 tokens per second)\n",
      "llama_print_timings:        eval time =   14471.34 ms /    22 runs   (  657.79 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15251.06 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.54 ms /    53 runs   (    0.43 ms per token,  2351.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.27 ms /    12 tokens (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   35670.24 ms /    52 runs   (  685.97 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   36465.70 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.90 ms /    26 runs   (    0.42 ms per token,  2385.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     619.51 ms /    11 tokens (   56.32 ms per token,    17.76 tokens per second)\n",
      "llama_print_timings:        eval time =   17075.72 ms /    25 runs   (  683.03 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   17772.23 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.41 ms /    20 runs   (    0.42 ms per token,  2377.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     702.81 ms /    13 tokens (   54.06 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   12668.62 ms /    19 runs   (  666.77 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13431.20 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.13 ms /    30 runs   (    0.40 ms per token,  2473.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.84 ms /    12 tokens (   54.07 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   19567.22 ms /    29 runs   (  674.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20305.92 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.82 ms /    52 runs   (    0.42 ms per token,  2382.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.07 ms /    12 tokens (   53.92 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   35031.20 ms /    51 runs   (  686.89 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   35831.77 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.27 ms /    27 runs   (    0.42 ms per token,  2395.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     750.42 ms /    14 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   17464.08 ms /    26 runs   (  671.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18295.14 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.41 ms /    20 runs   (    0.47 ms per token,  2126.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     669.82 ms /    12 tokens (   55.82 ms per token,    17.92 tokens per second)\n",
      "llama_print_timings:        eval time =   12650.07 ms /    19 runs   (  665.79 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13384.47 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.21 ms /    33 runs   (    0.40 ms per token,  2497.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     708.76 ms /    12 tokens (   59.06 ms per token,    16.93 tokens per second)\n",
      "llama_print_timings:        eval time =   21103.24 ms /    32 runs   (  659.48 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21909.48 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      30.17 ms /    74 runs   (    0.41 ms per token,  2452.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.08 ms /    12 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   49356.86 ms /    73 runs   (  676.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   50222.82 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.91 ms /    27 runs   (    0.40 ms per token,  2475.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.58 ms /    13 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   17453.99 ms /    26 runs   (  671.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18221.26 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.52 ms /    23 runs   (    0.41 ms per token,  2416.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     661.31 ms /    12 tokens (   55.11 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =   14978.02 ms /    22 runs   (  680.82 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15707.28 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.93 ms /    27 runs   (    0.40 ms per token,  2470.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.96 ms /    12 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   17757.72 ms /    26 runs   (  682.99 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   18475.88 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.10 ms /    20 runs   (    0.40 ms per token,  2470.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.61 ms /    12 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   12791.79 ms /    19 runs   (  673.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13491.37 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.31 ms /    20 runs   (    0.42 ms per token,  2407.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     623.65 ms /    11 tokens (   56.70 ms per token,    17.64 tokens per second)\n",
      "llama_print_timings:        eval time =   12775.30 ms /    19 runs   (  672.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13458.15 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    20 runs   (    0.41 ms per token,  2455.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.46 ms /    12 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   12591.21 ms /    19 runs   (  662.70 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13283.24 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.64 ms /    41 runs   (    0.41 ms per token,  2464.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     587.47 ms /    11 tokens (   53.41 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   26465.99 ms /    40 runs   (  661.65 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   27174.88 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      31.24 ms /    75 runs   (    0.42 ms per token,  2400.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     710.52 ms /    13 tokens (   54.66 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =   49788.62 ms /    74 runs   (  672.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   50727.40 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      29.73 ms /    73 runs   (    0.41 ms per token,  2455.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.66 ms /    12 tokens (   53.55 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   48518.45 ms /    72 runs   (  673.87 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   49377.50 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.19 ms /    30 runs   (    0.41 ms per token,  2462.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.45 ms /    12 tokens (   54.04 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   19428.84 ms /    29 runs   (  669.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20166.87 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.02 ms /    29 runs   (    0.41 ms per token,  2412.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.90 ms /    12 tokens (   53.83 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   19273.54 ms /    28 runs   (  688.34 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   20004.39 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.76 ms /    68 runs   (    0.41 ms per token,  2449.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.56 ms /    13 tokens (   52.81 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   44761.44 ms /    67 runs   (  668.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   45648.48 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.08 ms /    27 runs   (    0.41 ms per token,  2437.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     625.63 ms /    11 tokens (   56.88 ms per token,    17.58 tokens per second)\n",
      "llama_print_timings:        eval time =   17530.88 ms /    26 runs   (  674.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18237.20 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.32 ms /    25 runs   (    0.41 ms per token,  2421.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.61 ms /    12 tokens (   54.05 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   15969.78 ms /    24 runs   (  665.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16694.13 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      36.46 ms /    88 runs   (    0.41 ms per token,  2413.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.36 ms /    13 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   58548.41 ms /    87 runs   (  672.97 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   59499.39 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.27 ms /    30 runs   (    0.41 ms per token,  2444.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.47 ms /    12 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   19494.56 ms /    29 runs   (  672.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20216.30 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.23 ms /    30 runs   (    0.41 ms per token,  2452.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.49 ms /    12 tokens (   53.12 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   19404.66 ms /    29 runs   (  669.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20131.36 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      39.85 ms /    97 runs   (    0.41 ms per token,  2434.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.08 ms /    12 tokens (   53.67 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   64819.48 ms /    96 runs   (  675.20 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   65753.42 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.26 ms /    30 runs   (    0.41 ms per token,  2446.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     668.82 ms /    12 tokens (   55.73 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =   19502.42 ms /    29 runs   (  672.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20259.35 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.78 ms /    24 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.65 ms /    13 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   15515.11 ms /    23 runs   (  674.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16272.70 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.83 ms /    37 runs   (    0.40 ms per token,  2495.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.86 ms /    12 tokens (   54.24 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   23875.52 ms /    36 runs   (  663.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   24636.61 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.65 ms /    63 runs   (    0.41 ms per token,  2456.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     697.65 ms /    13 tokens (   53.67 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   42528.15 ms /    62 runs   (  685.94 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   43412.71 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.87 ms /    30 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     793.02 ms /    12 tokens (   66.09 ms per token,    15.13 tokens per second)\n",
      "llama_print_timings:        eval time =   20116.93 ms /    29 runs   (  693.69 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   21001.29 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.40 ms /    23 runs   (    0.41 ms per token,  2446.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     857.80 ms /    12 tokens (   71.48 ms per token,    13.99 tokens per second)\n",
      "llama_print_timings:        eval time =   14793.16 ms /    22 runs   (  672.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15717.10 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.13 ms /    34 runs   (    0.42 ms per token,  2406.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     709.59 ms /    12 tokens (   59.13 ms per token,    16.91 tokens per second)\n",
      "llama_print_timings:        eval time =   22354.83 ms /    33 runs   (  677.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   23165.64 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    17 runs   (    0.42 ms per token,  2394.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.21 ms /    12 tokens (   53.52 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   10880.35 ms /    16 runs   (  680.02 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   11571.62 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.39 ms /    37 runs   (    0.42 ms per token,  2403.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     696.79 ms /    13 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   25307.02 ms /    36 runs   (  702.97 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   26116.94 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.36 ms /    30 runs   (    0.41 ms per token,  2426.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     778.95 ms /    12 tokens (   64.91 ms per token,    15.41 tokens per second)\n",
      "llama_print_timings:        eval time =   19932.92 ms /    29 runs   (  687.34 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   20801.48 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.12 ms /    30 runs   (    0.40 ms per token,  2475.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.29 ms /    11 tokens (   53.84 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   19223.29 ms /    29 runs   (  662.87 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19903.11 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.99 ms /    35 runs   (    0.40 ms per token,  2501.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.64 ms /    11 tokens (   54.15 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   22924.30 ms /    34 runs   (  674.24 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   23622.56 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.35 ms /    30 runs   (    0.41 ms per token,  2429.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.91 ms /    12 tokens (   56.74 ms per token,    17.62 tokens per second)\n",
      "llama_print_timings:        eval time =   20038.04 ms /    29 runs   (  690.97 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   20807.25 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.05 ms /    39 runs   (    0.41 ms per token,  2430.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.46 ms /    12 tokens (   54.12 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   26589.04 ms /    38 runs   (  699.71 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   27355.32 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.13 ms /    31 runs   (    0.49 ms per token,  2048.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     866.39 ms /    12 tokens (   72.20 ms per token,    13.85 tokens per second)\n",
      "llama_print_timings:        eval time =   21466.89 ms /    30 runs   (  715.56 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   22439.50 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.14 ms /    41 runs   (    0.42 ms per token,  2391.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     790.63 ms /    13 tokens (   60.82 ms per token,    16.44 tokens per second)\n",
      "llama_print_timings:        eval time =   27242.87 ms /    40 runs   (  681.07 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   28158.84 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.28 ms /    56 runs   (    0.42 ms per token,  2405.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.89 ms /    12 tokens (   56.57 ms per token,    17.68 tokens per second)\n",
      "llama_print_timings:        eval time =   37640.07 ms /    55 runs   (  684.36 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   38485.55 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1100 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.52 ms /    40 runs   (    0.41 ms per token,  2421.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.03 ms /    12 tokens (   57.67 ms per token,    17.34 tokens per second)\n",
      "llama_print_timings:        eval time =   26395.07 ms /    39 runs   (  676.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27205.46 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.92 ms /    60 runs   (    0.42 ms per token,  2407.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.52 ms /    12 tokens (   54.96 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =   39834.19 ms /    59 runs   (  675.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   40671.06 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    19 runs   (    0.41 ms per token,  2436.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     808.53 ms /    13 tokens (   62.19 ms per token,    16.08 tokens per second)\n",
      "llama_print_timings:        eval time =   12138.12 ms /    18 runs   (  674.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13002.38 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.48 ms /    23 runs   (    0.41 ms per token,  2426.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.17 ms /    12 tokens (   53.35 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   14895.47 ms /    22 runs   (  677.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15603.66 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    20 runs   (    0.41 ms per token,  2436.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.05 ms /    12 tokens (   54.92 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =   12918.35 ms /    19 runs   (  679.91 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13635.59 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.23 ms /    47 runs   (    0.41 ms per token,  2444.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     748.29 ms /    14 tokens (   53.45 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   31107.55 ms /    46 runs   (  676.25 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   31994.26 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.58 ms /    34 runs   (    0.40 ms per token,  2503.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.18 ms /    12 tokens (   53.26 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   22136.99 ms /    33 runs   (  670.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22875.71 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    19 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.80 ms /    12 tokens (   56.73 ms per token,    17.63 tokens per second)\n",
      "llama_print_timings:        eval time =   12201.98 ms /    18 runs   (  677.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12938.90 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.65 ms /    23 runs   (    0.42 ms per token,  2383.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     717.03 ms /    13 tokens (   55.16 ms per token,    18.13 tokens per second)\n",
      "llama_print_timings:        eval time =   14903.00 ms /    22 runs   (  677.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15687.50 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    19 runs   (    0.42 ms per token,  2397.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.18 ms /    12 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   12237.17 ms /    18 runs   (  679.84 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   12935.54 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.56 ms /    23 runs   (    0.42 ms per token,  2405.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.75 ms /    12 tokens (   54.48 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =   15006.62 ms /    22 runs   (  682.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15727.30 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.41 ms /    25 runs   (    0.42 ms per token,  2401.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     723.07 ms /    12 tokens (   60.26 ms per token,    16.60 tokens per second)\n",
      "llama_print_timings:        eval time =   16289.26 ms /    24 runs   (  678.72 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17086.22 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.96 ms /    41 runs   (    0.41 ms per token,  2417.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     705.83 ms /    13 tokens (   54.29 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   27382.71 ms /    40 runs   (  684.57 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   28211.55 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.33 ms /    41 runs   (    0.42 ms per token,  2366.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     608.44 ms /    11 tokens (   55.31 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =   27603.82 ms /    40 runs   (  690.10 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   28338.21 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.73 ms /    37 runs   (    0.40 ms per token,  2512.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     722.71 ms /    12 tokens (   60.23 ms per token,    16.60 tokens per second)\n",
      "llama_print_timings:        eval time =   24092.51 ms /    36 runs   (  669.24 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24925.25 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.41 ms /    54 runs   (    0.41 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.05 ms /    12 tokens (   53.84 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   35490.54 ms /    53 runs   (  669.63 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   36299.58 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.59 ms /    62 runs   (    0.41 ms per token,  2423.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     605.76 ms /    11 tokens (   55.07 ms per token,    18.16 tokens per second)\n",
      "llama_print_timings:        eval time =   41225.61 ms /    61 runs   (  675.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   42017.28 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.99 ms /    44 runs   (    0.43 ms per token,  2317.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     690.66 ms /    13 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   29260.41 ms /    43 runs   (  680.47 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   30088.63 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.61 ms /    38 runs   (    0.41 ms per token,  2434.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.34 ms /    12 tokens (   53.95 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   25313.03 ms /    37 runs   (  684.14 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   26073.76 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    19 runs   (    0.40 ms per token,  2479.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.29 ms /    12 tokens (   54.11 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   12006.91 ms /    18 runs   (  667.05 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12711.54 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    19 runs   (    0.41 ms per token,  2456.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.46 ms /    11 tokens (   57.86 ms per token,    17.28 tokens per second)\n",
      "llama_print_timings:        eval time =   11865.00 ms /    18 runs   (  659.17 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12557.68 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.56 ms /    30 runs   (    0.42 ms per token,  2387.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.02 ms /    12 tokens (   54.50 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =   20157.17 ms /    29 runs   (  695.07 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   20900.71 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    19 runs   (    0.41 ms per token,  2440.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.56 ms /    12 tokens (   54.05 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   12319.10 ms /    18 runs   (  684.39 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13023.43 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.53 ms /    19 runs   (    0.45 ms per token,  2227.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.09 ms /    11 tokens (   54.19 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =   11957.52 ms /    18 runs   (  664.31 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12610.46 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.54 ms /    28 runs   (    0.41 ms per token,  2426.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.96 ms /    12 tokens (   54.58 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   17750.30 ms /    27 runs   (  657.42 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   18487.99 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.86 ms /    34 runs   (    0.41 ms per token,  2453.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.58 ms /    12 tokens (   56.55 ms per token,    17.68 tokens per second)\n",
      "llama_print_timings:        eval time =   21760.42 ms /    33 runs   (  659.41 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   22541.34 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.15 ms /    22 runs   (    0.42 ms per token,  2405.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     713.51 ms /    13 tokens (   54.89 ms per token,    18.22 tokens per second)\n",
      "llama_print_timings:        eval time =   14447.94 ms /    21 runs   (  688.00 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   15226.84 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.69 ms /    28 runs   (    0.42 ms per token,  2395.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.81 ms /    12 tokens (   53.57 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   18510.14 ms /    27 runs   (  685.56 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   19235.71 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.02 ms /    56 runs   (    0.41 ms per token,  2432.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.90 ms /    12 tokens (   54.07 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   37004.30 ms /    55 runs   (  672.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   37818.98 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.73 ms /    31 runs   (    0.41 ms per token,  2435.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.97 ms /    12 tokens (   53.91 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   20526.80 ms /    30 runs   (  684.23 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   21266.71 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.10 ms /    29 runs   (    0.45 ms per token,  2214.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     669.55 ms /    12 tokens (   55.80 ms per token,    17.92 tokens per second)\n",
      "llama_print_timings:        eval time =   19020.49 ms /    28 runs   (  679.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19780.80 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.95 ms /    32 runs   (    0.40 ms per token,  2471.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     722.79 ms /    13 tokens (   55.60 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =   20859.41 ms /    31 runs   (  672.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21676.63 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.72 ms /    66 runs   (    0.40 ms per token,  2470.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.73 ms /    12 tokens (   53.06 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   43524.35 ms /    65 runs   (  669.61 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   44354.09 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.98 ms /    30 runs   (    0.40 ms per token,  2505.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     657.13 ms /    12 tokens (   54.76 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =   19755.23 ms /    29 runs   (  681.21 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20501.13 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.36 ms /    25 runs   (    0.41 ms per token,  2413.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.13 ms /    13 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   16282.48 ms /    24 runs   (  678.44 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17044.95 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      37.64 ms /    89 runs   (    0.42 ms per token,  2364.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.47 ms /    12 tokens (   53.54 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   60345.72 ms /    88 runs   (  685.75 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   61263.35 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.10 ms /    66 runs   (    0.41 ms per token,  2435.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.05 ms /    12 tokens (   60.67 ms per token,    16.48 tokens per second)\n",
      "llama_print_timings:        eval time =   44682.33 ms /    65 runs   (  687.42 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   45610.27 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.38 ms /    30 runs   (    0.41 ms per token,  2422.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     615.31 ms /    11 tokens (   55.94 ms per token,    17.88 tokens per second)\n",
      "llama_print_timings:        eval time =   19557.51 ms /    29 runs   (  674.40 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20263.61 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.86 ms /    23 runs   (    0.43 ms per token,  2333.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.94 ms /    12 tokens (   57.41 ms per token,    17.42 tokens per second)\n",
      "llama_print_timings:        eval time =   14678.48 ms /    22 runs   (  667.20 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15435.74 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.81 ms /    39 runs   (    0.41 ms per token,  2466.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.28 ms /    12 tokens (   53.86 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   25466.53 ms /    38 runs   (  670.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26229.26 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.59 ms /    23 runs   (    0.42 ms per token,  2399.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     605.74 ms /    11 tokens (   55.07 ms per token,    18.16 tokens per second)\n",
      "llama_print_timings:        eval time =   14842.08 ms /    22 runs   (  674.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15515.46 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.93 ms /    57 runs   (    0.42 ms per token,  2382.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.92 ms /    12 tokens (   53.99 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   38588.14 ms /    56 runs   (  689.07 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   39406.56 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.35 ms /    53 runs   (    0.42 ms per token,  2370.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.21 ms /    13 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   35473.92 ms /    52 runs   (  682.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   36329.31 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.21 ms /    22 runs   (    0.42 ms per token,  2387.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.83 ms /    12 tokens (   54.15 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   14440.55 ms /    21 runs   (  687.65 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   15156.15 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.97 ms /    19 runs   (    0.42 ms per token,  2383.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.74 ms /    11 tokens (   54.61 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   12328.38 ms /    18 runs   (  684.91 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   12984.98 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.70 ms /    30 runs   (    0.42 ms per token,  2362.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     614.89 ms /    11 tokens (   55.90 ms per token,    17.89 tokens per second)\n",
      "llama_print_timings:        eval time =   19698.58 ms /    29 runs   (  679.26 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20402.74 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.24 ms /    30 runs   (    0.41 ms per token,  2451.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.85 ms /    12 tokens (   54.15 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   19791.81 ms /    29 runs   (  682.48 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20529.80 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    19 runs   (    0.41 ms per token,  2425.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.92 ms /    12 tokens (   53.83 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   12066.45 ms /    18 runs   (  670.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12768.21 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.15 ms /    66 runs   (    0.41 ms per token,  2431.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.28 ms /    12 tokens (   53.52 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   44609.66 ms /    65 runs   (  686.30 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   45448.31 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.44 ms /    20 runs   (    0.42 ms per token,  2369.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     699.68 ms /    13 tokens (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   12794.07 ms /    19 runs   (  673.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13552.66 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.33 ms /    30 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.75 ms /    12 tokens (   56.56 ms per token,    17.68 tokens per second)\n",
      "llama_print_timings:        eval time =   19774.54 ms /    29 runs   (  681.88 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20542.73 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.27 ms /    28 runs   (    0.40 ms per token,  2484.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     664.56 ms /    11 tokens (   60.41 ms per token,    16.55 tokens per second)\n",
      "llama_print_timings:        eval time =   18215.49 ms /    27 runs   (  674.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18962.43 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.81 ms /    41 runs   (    0.41 ms per token,  2438.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     664.04 ms /    12 tokens (   55.34 ms per token,    18.07 tokens per second)\n",
      "llama_print_timings:        eval time =   26769.97 ms /    40 runs   (  669.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   27555.43 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.16 ms /    25 runs   (    0.41 ms per token,  2461.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.09 ms /    13 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   16579.19 ms /    24 runs   (  690.80 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   17339.86 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.26 ms /    20 runs   (    0.41 ms per token,  2422.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.81 ms /    11 tokens (   54.16 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   12801.92 ms /    19 runs   (  673.79 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13457.43 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.29 ms /    48 runs   (    0.42 ms per token,  2365.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     658.16 ms /    12 tokens (   54.85 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =   31972.72 ms /    47 runs   (  680.27 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   32775.89 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.36 ms /    25 runs   (    0.41 ms per token,  2413.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.64 ms /    12 tokens (   54.14 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   15967.26 ms /    24 runs   (  665.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16693.00 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.73 ms /    50 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.93 ms /    12 tokens (   57.24 ms per token,    17.47 tokens per second)\n",
      "llama_print_timings:        eval time =   33056.42 ms /    49 runs   (  674.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   33892.27 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.79 ms /    37 runs   (    0.40 ms per token,  2501.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     674.19 ms /    12 tokens (   56.18 ms per token,    17.80 tokens per second)\n",
      "llama_print_timings:        eval time =   24149.20 ms /    36 runs   (  670.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24934.10 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.51 ms /    20 runs   (    0.48 ms per token,  2103.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     810.92 ms /    14 tokens (   57.92 ms per token,    17.26 tokens per second)\n",
      "llama_print_timings:        eval time =   13085.19 ms /    19 runs   (  688.69 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   13961.81 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.21 ms /    39 runs   (    0.47 ms per token,  2141.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     763.37 ms /    12 tokens (   63.61 ms per token,    15.72 tokens per second)\n",
      "llama_print_timings:        eval time =   26878.63 ms /    38 runs   (  707.33 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   27770.78 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.88 ms /    31 runs   (    0.42 ms per token,  2406.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.62 ms /    12 tokens (   54.64 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =   20398.84 ms /    30 runs   (  679.96 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   21148.14 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.19 ms /    49 runs   (    0.41 ms per token,  2427.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     731.62 ms /    13 tokens (   56.28 ms per token,    17.77 tokens per second)\n",
      "llama_print_timings:        eval time =   32940.85 ms /    48 runs   (  686.27 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   33817.26 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.35 ms /    27 runs   (    0.42 ms per token,  2379.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.78 ms /    12 tokens (   54.57 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   17637.44 ms /    26 runs   (  678.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18372.74 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.10 ms /    27 runs   (    0.41 ms per token,  2432.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     662.92 ms /    11 tokens (   60.27 ms per token,    16.59 tokens per second)\n",
      "llama_print_timings:        eval time =   17675.97 ms /    26 runs   (  679.84 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18417.86 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.64 ms /    42 runs   (    0.44 ms per token,  2253.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     667.26 ms /    12 tokens (   55.61 ms per token,    17.98 tokens per second)\n",
      "llama_print_timings:        eval time =   27677.42 ms /    41 runs   (  675.06 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   28475.35 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.99 ms /    27 runs   (    0.41 ms per token,  2456.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     676.08 ms /    12 tokens (   56.34 ms per token,    17.75 tokens per second)\n",
      "llama_print_timings:        eval time =   17596.40 ms /    26 runs   (  676.78 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18352.62 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.61 ms /    23 runs   (    0.42 ms per token,  2393.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.26 ms /    12 tokens (   53.19 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   15176.18 ms /    22 runs   (  689.83 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   15882.14 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.64 ms /    62 runs   (    0.41 ms per token,  2418.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.21 ms /    13 tokens (   52.55 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   41593.47 ms /    61 runs   (  681.86 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   42460.16 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.10 ms /    42 runs   (    0.41 ms per token,  2456.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.34 ms /    12 tokens (   54.11 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   27571.88 ms /    41 runs   (  672.48 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28345.06 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.48 ms /    41 runs   (    0.40 ms per token,  2488.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.35 ms /    12 tokens (   54.36 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   26702.44 ms /    40 runs   (  667.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   27474.75 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.27 ms /    30 runs   (    0.41 ms per token,  2445.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.42 ms /    13 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   19263.44 ms /    29 runs   (  664.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20029.14 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.48 ms /    28 runs   (    0.41 ms per token,  2438.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.66 ms /    11 tokens (   53.88 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   18148.96 ms /    27 runs   (  672.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18823.62 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.62 ms /    42 runs   (    0.42 ms per token,  2384.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.90 ms /    12 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   27534.34 ms /    41 runs   (  671.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28303.59 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.03 ms /    25 runs   (    0.40 ms per token,  2492.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.48 ms /    11 tokens (   54.32 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   15976.77 ms /    24 runs   (  665.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16647.31 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.99 ms /    42 runs   (    0.40 ms per token,  2472.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.91 ms /    12 tokens (   53.91 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   27393.74 ms /    41 runs   (  668.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28164.84 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.07 ms /    30 runs   (    0.40 ms per token,  2484.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.18 ms /    12 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   19345.18 ms /    29 runs   (  667.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20078.14 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.36 ms /    25 runs   (    0.41 ms per token,  2414.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.37 ms /    12 tokens (   53.86 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   15908.73 ms /    24 runs   (  662.86 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16629.54 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.56 ms /    41 runs   (    0.40 ms per token,  2475.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.98 ms /    12 tokens (   53.91 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   26817.80 ms /    40 runs   (  670.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   27584.53 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.70 ms /    55 runs   (    0.41 ms per token,  2423.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.61 ms /    13 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   35807.60 ms /    54 runs   (  663.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   36661.39 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.76 ms /    42 runs   (    0.40 ms per token,  2506.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.24 ms /    12 tokens (   53.10 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   27385.39 ms /    41 runs   (  667.94 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28145.08 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.78 ms /    34 runs   (    0.41 ms per token,  2466.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.76 ms /    12 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   21860.41 ms /    33 runs   (  662.44 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   22591.99 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.05 ms /    52 runs   (    0.42 ms per token,  2357.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     587.84 ms /    11 tokens (   53.44 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   34574.87 ms /    51 runs   (  677.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   35319.14 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.83 ms /    27 runs   (    0.40 ms per token,  2492.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     599.53 ms /    11 tokens (   54.50 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =   17435.18 ms /    26 runs   (  670.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18113.63 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.29 ms /    23 runs   (    0.40 ms per token,  2474.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.35 ms /    12 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   14896.31 ms /    22 runs   (  677.11 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15593.79 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.60 ms /    24 runs   (    0.40 ms per token,  2499.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     722.72 ms /    12 tokens (   60.23 ms per token,    16.60 tokens per second)\n",
      "llama_print_timings:        eval time =   15774.82 ms /    23 runs   (  685.86 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   16567.86 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.20 ms /    20 runs   (    0.41 ms per token,  2437.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     676.31 ms /    13 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   12756.91 ms /    19 runs   (  671.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13492.44 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.86 ms /    19 runs   (    0.47 ms per token,  2144.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     669.27 ms /    12 tokens (   55.77 ms per token,    17.93 tokens per second)\n",
      "llama_print_timings:        eval time =   12143.63 ms /    18 runs   (  674.65 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12874.24 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.13 ms /    25 runs   (    0.41 ms per token,  2466.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.25 ms /    12 tokens (   56.94 ms per token,    17.56 tokens per second)\n",
      "llama_print_timings:        eval time =   16056.41 ms /    24 runs   (  669.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16811.13 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.92 ms /    27 runs   (    0.40 ms per token,  2471.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     613.83 ms /    11 tokens (   55.80 ms per token,    17.92 tokens per second)\n",
      "llama_print_timings:        eval time =   17173.23 ms /    26 runs   (  660.51 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17864.60 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.32 ms /    57 runs   (    0.41 ms per token,  2444.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.59 ms /    13 tokens (   52.51 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   36687.88 ms /    56 runs   (  655.14 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   37536.67 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.82 ms /    37 runs   (    0.40 ms per token,  2496.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.65 ms /    12 tokens (   52.80 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   23969.56 ms /    36 runs   (  665.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24711.23 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      31.29 ms /    77 runs   (    0.41 ms per token,  2460.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.40 ms /    12 tokens (   52.62 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   50271.15 ms /    76 runs   (  661.46 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   51129.31 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.17 ms /    20 runs   (    0.41 ms per token,  2449.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.62 ms /    12 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   12371.74 ms /    19 runs   (  651.14 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   13066.92 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.09 ms /    42 runs   (    0.41 ms per token,  2457.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.25 ms /    12 tokens (   53.10 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   26575.10 ms /    41 runs   (  648.17 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   27335.06 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.86 ms /    68 runs   (    0.41 ms per token,  2441.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.78 ms /    11 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   44977.60 ms /    67 runs   (  671.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   45769.78 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    20 runs   (    0.41 ms per token,  2464.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.71 ms /    12 tokens (   53.14 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   12770.99 ms /    19 runs   (  672.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13467.94 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.71 ms /    19 runs   (    0.41 ms per token,  2463.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     716.93 ms /    13 tokens (   55.15 ms per token,    18.13 tokens per second)\n",
      "llama_print_timings:        eval time =   12174.51 ms /    18 runs   (  676.36 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12946.56 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      36.70 ms /    90 runs   (    0.41 ms per token,  2451.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.68 ms /    12 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   60002.90 ms /    89 runs   (  674.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   60904.74 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.72 ms /    41 runs   (    0.41 ms per token,  2452.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.40 ms /    12 tokens (   53.70 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   26847.83 ms /    40 runs   (  671.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   27613.02 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1200 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.68 ms /    41 runs   (    0.41 ms per token,  2458.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.25 ms /    13 tokens (   52.71 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   26191.30 ms /    40 runs   (  654.78 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   26996.39 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.13 ms /    27 runs   (    0.41 ms per token,  2426.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.12 ms /    12 tokens (   52.59 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   17399.61 ms /    26 runs   (  669.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18109.21 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      34.27 ms /    83 runs   (    0.41 ms per token,  2421.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.48 ms /    11 tokens (   54.41 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   55105.32 ms /    82 runs   (  672.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   55953.75 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.92 ms /    24 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.08 ms /    12 tokens (   52.92 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   15381.42 ms /    23 runs   (  668.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16087.69 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      52.36 ms /   127 runs   (    0.41 ms per token,  2425.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.84 ms /    13 tokens (   52.22 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =   84034.97 ms /   126 runs   (  666.94 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   85097.50 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.02 ms /    25 runs   (    0.44 ms per token,  2269.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.64 ms /    12 tokens (   56.80 ms per token,    17.60 tokens per second)\n",
      "llama_print_timings:        eval time =   16003.01 ms /    24 runs   (  666.79 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16764.48 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.15 ms /    25 runs   (    0.41 ms per token,  2463.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.82 ms /    12 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   15931.78 ms /    24 runs   (  663.82 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16646.78 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.21 ms /    25 runs   (    0.41 ms per token,  2447.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.89 ms /    11 tokens (   57.45 ms per token,    17.41 tokens per second)\n",
      "llama_print_timings:        eval time =   16211.18 ms /    24 runs   (  675.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16917.01 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.29 ms /    25 runs   (    0.41 ms per token,  2428.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.78 ms /    12 tokens (   52.81 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   15982.25 ms /    24 runs   (  665.93 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16689.90 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.28 ms /    45 runs   (    0.41 ms per token,  2462.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     587.28 ms /    11 tokens (   53.39 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   29481.47 ms /    44 runs   (  670.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   30200.78 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.83 ms /    56 runs   (    0.41 ms per token,  2453.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     588.81 ms /    11 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   36980.80 ms /    55 runs   (  672.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   37735.78 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.89 ms /    19 runs   (    0.42 ms per token,  2408.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.23 ms /    12 tokens (   53.27 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   11932.43 ms /    18 runs   (  662.91 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12627.87 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.80 ms /    39 runs   (    0.41 ms per token,  2467.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     727.39 ms /    14 tokens (   51.96 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   25366.98 ms /    38 runs   (  667.55 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26209.99 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.05 ms /    62 runs   (    0.40 ms per token,  2474.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.33 ms /    12 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   40102.66 ms /    61 runs   (  657.42 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   40928.01 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.23 ms /    57 runs   (    0.41 ms per token,  2454.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.16 ms /    12 tokens (   53.26 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   36348.70 ms /    56 runs   (  649.08 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   37156.07 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.10 ms /    30 runs   (    0.40 ms per token,  2479.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.67 ms /    12 tokens (   53.06 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   18868.67 ms /    29 runs   (  650.64 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   19592.64 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.50 ms /    57 runs   (    0.41 ms per token,  2425.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.97 ms /    11 tokens (   54.27 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   37049.01 ms /    56 runs   (  661.59 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   37814.45 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.47 ms /    31 runs   (    0.40 ms per token,  2486.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.79 ms /    13 tokens (   52.14 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   19499.99 ms /    30 runs   (  650.00 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   20266.01 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.17 ms /    30 runs   (    0.44 ms per token,  2278.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.12 ms /    11 tokens (   53.83 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   19356.40 ms /    29 runs   (  667.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20041.37 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.15 ms /    30 runs   (    0.41 ms per token,  2468.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.47 ms /    12 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   19116.58 ms /    29 runs   (  659.19 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19839.95 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.86 ms /    30 runs   (    0.43 ms per token,  2332.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.75 ms /    12 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   18921.14 ms /    29 runs   (  652.45 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   19645.69 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.58 ms /    37 runs   (    0.39 ms per token,  2537.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.63 ms /    13 tokens (   52.89 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   23713.35 ms /    36 runs   (  658.70 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   24508.03 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.17 ms /    38 runs   (    0.40 ms per token,  2505.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.76 ms /    12 tokens (   53.15 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   24940.93 ms /    37 runs   (  674.08 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25691.46 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    17 runs   (    0.42 ms per token,  2403.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     605.38 ms /    11 tokens (   55.03 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =   10798.85 ms /    16 runs   (  674.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11454.17 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.00 ms /    30 runs   (    0.40 ms per token,  2501.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.22 ms /    12 tokens (   54.60 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   19487.64 ms /    29 runs   (  671.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20230.03 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.08 ms /    38 runs   (    0.40 ms per token,  2519.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.62 ms /    12 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   24783.77 ms /    37 runs   (  669.83 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   25530.88 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.00 ms /    30 runs   (    0.43 ms per token,  2307.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.00 ms /    12 tokens (   53.92 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   19319.29 ms /    29 runs   (  666.18 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20061.82 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.04 ms /    25 runs   (    0.40 ms per token,  2489.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.51 ms /    13 tokens (   52.73 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   16357.39 ms /    24 runs   (  681.56 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   17116.95 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.88 ms /    30 runs   (    0.40 ms per token,  2524.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.07 ms /    12 tokens (   52.84 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   19333.24 ms /    29 runs   (  666.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20055.33 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.74 ms /    37 runs   (    0.40 ms per token,  2509.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.85 ms /    12 tokens (   53.15 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   23937.06 ms /    36 runs   (  664.92 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24682.32 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.04 ms /    30 runs   (    0.40 ms per token,  2491.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.39 ms /    12 tokens (   52.70 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   19055.85 ms /    29 runs   (  657.10 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19776.64 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.39 ms /    23 runs   (    0.41 ms per token,  2450.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.38 ms /    13 tokens (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   14758.95 ms /    22 runs   (  670.86 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15508.68 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      39.53 ms /    97 runs   (    0.41 ms per token,  2453.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     769.92 ms /    12 tokens (   64.16 ms per token,    15.59 tokens per second)\n",
      "llama_print_timings:        eval time =   64324.65 ms /    96 runs   (  670.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   65384.97 ms /   108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.86 ms /    27 runs   (    0.40 ms per token,  2486.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     599.02 ms /    11 tokens (   54.46 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =   17316.50 ms /    26 runs   (  666.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17994.15 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /    20 runs   (    0.41 ms per token,  2431.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.88 ms /    12 tokens (   52.91 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   12456.11 ms /    19 runs   (  655.58 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13148.45 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.54 ms /    26 runs   (    0.41 ms per token,  2467.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.45 ms /    13 tokens (   52.34 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   16278.99 ms /    25 runs   (  651.16 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   17034.39 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    17 runs   (    0.41 ms per token,  2457.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.62 ms /    12 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   10840.09 ms /    16 runs   (  677.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   11523.99 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.12 ms /    30 runs   (    0.40 ms per token,  2474.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.29 ms /    12 tokens (   53.27 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   19085.58 ms /    29 runs   (  658.12 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19813.63 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.19 ms /    25 runs   (    0.41 ms per token,  2453.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.85 ms /    12 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   15838.05 ms /    24 runs   (  659.92 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   16547.61 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.80 ms /    37 runs   (    0.40 ms per token,  2500.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.73 ms /    13 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   23118.34 ms /    36 runs   (  642.18 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =   23912.14 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      28.66 ms /    71 runs   (    0.40 ms per token,  2477.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.49 ms /    12 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   46309.89 ms /    70 runs   (  661.57 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   47152.97 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.11 ms /    37 runs   (    0.41 ms per token,  2448.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.41 ms /    12 tokens (   53.87 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   24046.75 ms /    36 runs   (  667.97 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24802.07 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.48 ms /    25 runs   (    0.46 ms per token,  2177.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.82 ms /    12 tokens (   54.48 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =   15827.91 ms /    24 runs   (  659.50 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   16561.03 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.13 ms /    30 runs   (    0.40 ms per token,  2472.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.57 ms /    13 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   19157.98 ms /    29 runs   (  660.62 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19928.22 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.38 ms /    60 runs   (    0.41 ms per token,  2461.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.86 ms /    12 tokens (   53.90 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   39647.57 ms /    59 runs   (  671.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   40471.91 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.14 ms /    30 runs   (    0.40 ms per token,  2470.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.20 ms /    12 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   19367.80 ms /    29 runs   (  667.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20087.11 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.79 ms /    37 runs   (    0.40 ms per token,  2501.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.25 ms /    12 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   23966.19 ms /    36 runs   (  665.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24709.29 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.24 ms /    30 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.90 ms /    12 tokens (   53.41 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   19195.11 ms /    29 runs   (  661.90 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19924.26 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.02 ms /    37 runs   (    0.41 ms per token,  2464.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.49 ms /    12 tokens (   54.21 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =   23649.57 ms /    36 runs   (  656.93 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   24408.91 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.16 ms /    30 runs   (    0.41 ms per token,  2468.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     713.16 ms /    13 tokens (   54.86 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =   19501.37 ms /    29 runs   (  672.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20302.23 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.30 ms /    30 runs   (    0.41 ms per token,  2438.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.53 ms /    12 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   19278.39 ms /    29 runs   (  664.77 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20007.92 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.25 ms /    33 runs   (    0.40 ms per token,  2490.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.86 ms /    12 tokens (   54.99 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =   21749.53 ms /    32 runs   (  679.67 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22505.25 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.81 ms /    30 runs   (    0.43 ms per token,  2341.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     667.40 ms /    12 tokens (   55.62 ms per token,    17.98 tokens per second)\n",
      "llama_print_timings:        eval time =   19389.89 ms /    29 runs   (  668.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20149.59 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.13 ms /    57 runs   (    0.41 ms per token,  2464.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.43 ms /    13 tokens (   52.49 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   37494.34 ms /    56 runs   (  669.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   38343.62 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.32 ms /    25 runs   (    0.41 ms per token,  2423.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     661.13 ms /    12 tokens (   55.09 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =   15789.32 ms /    24 runs   (  657.89 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   16523.85 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    16 runs   (    0.41 ms per token,  2446.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.11 ms /    12 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   10013.46 ms /    15 runs   (  667.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10694.99 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.19 ms /    20 runs   (    0.41 ms per token,  2442.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.29 ms /    12 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   12696.99 ms /    19 runs   (  668.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13394.51 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.33 ms /    30 runs   (    0.41 ms per token,  2433.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     723.12 ms /    14 tokens (   51.65 ms per token,    19.36 tokens per second)\n",
      "llama_print_timings:        eval time =   19500.16 ms /    29 runs   (  672.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20309.78 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.37 ms /    35 runs   (    0.41 ms per token,  2436.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.90 ms /    12 tokens (   53.41 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   22793.34 ms /    34 runs   (  670.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   23536.60 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.37 ms /    20 runs   (    0.42 ms per token,  2388.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.09 ms /    13 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   12824.81 ms /    19 runs   (  674.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13562.10 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.13 ms /    23 runs   (    0.40 ms per token,  2518.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.10 ms /    12 tokens (   53.18 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   14765.53 ms /    22 runs   (  671.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15471.00 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.91 ms /    66 runs   (    0.42 ms per token,  2365.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.50 ms /    12 tokens (   54.71 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =   43409.38 ms /    65 runs   (  667.84 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   44266.55 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.12 ms /    52 runs   (    0.41 ms per token,  2462.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.63 ms /    13 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   33844.49 ms /    51 runs   (  663.62 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   34685.01 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.32 ms /    30 runs   (    0.41 ms per token,  2434.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.05 ms /    11 tokens (   53.64 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   18987.46 ms /    29 runs   (  654.74 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   19666.63 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.50 ms /    34 runs   (    0.40 ms per token,  2519.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.14 ms /    12 tokens (   53.35 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   21890.31 ms /    33 runs   (  663.34 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   22630.31 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.44 ms /    52 runs   (    0.41 ms per token,  2425.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.05 ms /    12 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   34420.37 ms /    51 runs   (  674.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   35210.55 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.26 ms /    30 runs   (    0.41 ms per token,  2447.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.24 ms /    11 tokens (   54.39 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =   19428.57 ms /    29 runs   (  669.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20113.54 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.06 ms /    32 runs   (    0.41 ms per token,  2449.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.81 ms /    12 tokens (   52.73 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   20865.03 ms /    31 runs   (  673.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21591.36 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.40 ms /    35 runs   (    0.41 ms per token,  2430.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.83 ms /    11 tokens (   53.98 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   22397.93 ms /    34 runs   (  658.76 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   23095.56 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.47 ms /    28 runs   (    0.41 ms per token,  2440.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.27 ms /    13 tokens (   52.25 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   18003.40 ms /    27 runs   (  666.79 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18764.47 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.73 ms /    66 runs   (    0.40 ms per token,  2469.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.74 ms /    12 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   43868.82 ms /    65 runs   (  674.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   44705.40 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.51 ms /    41 runs   (    0.40 ms per token,  2483.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.79 ms /    12 tokens (   52.98 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   26998.84 ms /    40 runs   (  674.97 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27754.57 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.90 ms /    44 runs   (    0.41 ms per token,  2458.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.38 ms /    11 tokens (   53.94 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   28548.11 ms /    43 runs   (  663.91 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   29269.26 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.12 ms /    30 runs   (    0.40 ms per token,  2474.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.72 ms /    12 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   19464.81 ms /    29 runs   (  671.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20197.71 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.08 ms /    25 runs   (    0.40 ms per token,  2481.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.39 ms /    12 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   16163.29 ms /    24 runs   (  673.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16869.95 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.63 ms /    39 runs   (    0.40 ms per token,  2495.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.24 ms /    12 tokens (   53.94 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   25610.55 ms /    38 runs   (  673.96 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26372.03 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.23 ms /    20 runs   (    0.41 ms per token,  2429.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.28 ms /    13 tokens (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   12570.56 ms /    19 runs   (  661.61 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13322.01 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.36 ms /    30 runs   (    0.41 ms per token,  2426.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.94 ms /    11 tokens (   53.99 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   19237.51 ms /    29 runs   (  663.36 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19918.62 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.57 ms /    25 runs   (    0.42 ms per token,  2365.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.86 ms /    12 tokens (   53.32 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   16029.01 ms /    24 runs   (  667.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16742.41 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.76 ms /    66 runs   (    0.42 ms per token,  2377.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.37 ms /    12 tokens (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   43071.51 ms /    65 runs   (  662.64 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   43907.78 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.85 ms /    37 runs   (    0.40 ms per token,  2491.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.10 ms /    12 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   23962.39 ms /    36 runs   (  665.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24715.82 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.31 ms /    33 runs   (    0.40 ms per token,  2480.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.07 ms /    13 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   21054.90 ms /    32 runs   (  657.97 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21827.19 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.38 ms /    30 runs   (    0.41 ms per token,  2423.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.51 ms /    11 tokens (   53.86 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   19258.69 ms /    29 runs   (  664.09 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19940.15 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.21 ms /    30 runs   (    0.44 ms per token,  2270.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.13 ms /    12 tokens (   53.59 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   19138.53 ms /    29 runs   (  659.95 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19874.43 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.72 ms /    44 runs   (    0.40 ms per token,  2483.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.22 ms /    12 tokens (   53.18 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   28280.87 ms /    43 runs   (  657.69 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   29047.71 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      35.86 ms /    88 runs   (    0.41 ms per token,  2454.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.18 ms /    12 tokens (   53.93 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   57504.08 ms /    87 runs   (  660.97 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   58413.34 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.50 ms /    41 runs   (    0.40 ms per token,  2484.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     701.83 ms /    13 tokens (   53.99 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   26517.47 ms /    40 runs   (  662.94 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   27338.65 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.49 ms /    39 runs   (    0.40 ms per token,  2517.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     603.06 ms /    11 tokens (   54.82 ms per token,    18.24 tokens per second)\n",
      "llama_print_timings:        eval time =   25185.94 ms /    38 runs   (  662.79 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   25903.34 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.85 ms /    37 runs   (    0.40 ms per token,  2492.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.43 ms /    12 tokens (   52.95 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   23660.15 ms /    36 runs   (  657.23 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   24404.90 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.48 ms /    41 runs   (    0.40 ms per token,  2488.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.44 ms /    11 tokens (   54.13 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   26736.42 ms /    40 runs   (  668.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   27454.17 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.14 ms /    30 runs   (    0.40 ms per token,  2471.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.75 ms /    12 tokens (   53.23 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   19025.24 ms /    29 runs   (  656.04 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19750.19 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.90 ms /    37 runs   (    0.40 ms per token,  2482.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     665.15 ms /    12 tokens (   55.43 ms per token,    18.04 tokens per second)\n",
      "llama_print_timings:        eval time =   23809.79 ms /    36 runs   (  661.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   24582.06 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.02 ms /    57 runs   (    0.42 ms per token,  2373.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.25 ms /    12 tokens (   52.77 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   37426.42 ms /    56 runs   (  668.33 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   38230.48 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.69 ms /    31 runs   (    0.41 ms per token,  2443.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.27 ms /    12 tokens (   54.27 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   19732.81 ms /    30 runs   (  657.76 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   20476.50 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.37 ms /    62 runs   (    0.43 ms per token,  2351.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.42 ms /    13 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   40607.04 ms /    61 runs   (  665.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   41471.71 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.13 ms /    30 runs   (    0.40 ms per token,  2473.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.05 ms /    12 tokens (   53.09 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   19161.41 ms /    29 runs   (  660.74 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19886.01 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.96 ms /    30 runs   (    0.40 ms per token,  2507.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.68 ms /    12 tokens (   53.22 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   19265.71 ms /    29 runs   (  664.33 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19991.83 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.14 ms /    30 runs   (    0.40 ms per token,  2470.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     668.75 ms /    12 tokens (   55.73 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =   19535.00 ms /    29 runs   (  673.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20290.92 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.17 ms /    30 runs   (    0.41 ms per token,  2464.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.27 ms /    12 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   19267.56 ms /    29 runs   (  664.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19991.41 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.12 ms /    32 runs   (    0.41 ms per token,  2438.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.26 ms /    12 tokens (   53.19 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   20693.42 ms /    31 runs   (  667.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21425.65 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1300 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.11 ms /    30 runs   (    0.40 ms per token,  2477.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.09 ms /    13 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   19040.26 ms /    29 runs   (  656.56 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19818.92 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.15 ms /    30 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.84 ms /    12 tokens (   53.15 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   19243.33 ms /    29 runs   (  663.56 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19968.00 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.65 ms /    66 runs   (    0.40 ms per token,  2476.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.67 ms /    12 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   43606.83 ms /    65 runs   (  670.87 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   44448.30 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.34 ms /    35 runs   (    0.41 ms per token,  2441.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.59 ms /    13 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   22344.12 ms /    34 runs   (  657.18 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   23132.82 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.22 ms /    37 runs   (    0.41 ms per token,  2431.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.19 ms /    12 tokens (   53.27 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   23968.33 ms /    36 runs   (  665.79 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24715.59 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.33 ms /    55 runs   (    0.41 ms per token,  2462.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.66 ms /    14 tokens (   51.76 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =   35799.15 ms /    54 runs   (  662.95 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   36685.80 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.36 ms /    41 runs   (    0.40 ms per token,  2506.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     607.37 ms /    11 tokens (   55.22 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =   26612.44 ms /    40 runs   (  665.31 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   27339.46 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.54 ms /    41 runs   (    0.40 ms per token,  2479.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.15 ms /    12 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   26355.96 ms /    40 runs   (  658.90 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   27121.72 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.23 ms /    36 runs   (    0.40 ms per token,  2529.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     664.51 ms /    12 tokens (   55.38 ms per token,    18.06 tokens per second)\n",
      "llama_print_timings:        eval time =   23282.10 ms /    35 runs   (  665.20 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24049.76 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.58 ms /    46 runs   (    0.40 ms per token,  2475.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.41 ms /    13 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   30429.65 ms /    45 runs   (  676.21 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   31250.40 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.23 ms /    23 runs   (    0.40 ms per token,  2490.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.43 ms /    11 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   14617.03 ms /    22 runs   (  664.41 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15274.73 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.08 ms /    59 runs   (    0.41 ms per token,  2450.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     618.31 ms /    11 tokens (   56.21 ms per token,    17.79 tokens per second)\n",
      "llama_print_timings:        eval time =   39053.66 ms /    58 runs   (  673.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   39846.03 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      40.03 ms /    98 runs   (    0.41 ms per token,  2448.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.64 ms /    12 tokens (   53.14 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   65636.15 ms /    97 runs   (  676.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   66564.83 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.31 ms /    40 runs   (    0.41 ms per token,  2452.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.18 ms /    12 tokens (   53.52 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   26047.24 ms /    39 runs   (  667.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26806.91 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.62 ms /    41 runs   (    0.41 ms per token,  2466.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.19 ms /    12 tokens (   53.52 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   26982.93 ms /    40 runs   (  674.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27746.03 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.97 ms /    30 runs   (    0.40 ms per token,  2505.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.03 ms /    12 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   18672.99 ms /    29 runs   (  643.90 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   19397.00 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.13 ms /    32 runs   (    0.41 ms per token,  2436.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.31 ms /    13 tokens (   52.25 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   20738.93 ms /    31 runs   (  669.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21511.69 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.91 ms /    62 runs   (    0.42 ms per token,  2392.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.30 ms /    12 tokens (   53.69 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   40629.18 ms /    61 runs   (  666.05 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   41457.89 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.59 ms /    31 runs   (    0.41 ms per token,  2462.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.20 ms /    11 tokens (   53.75 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   20218.42 ms /    30 runs   (  673.95 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20899.31 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.41 ms /    41 runs   (    0.40 ms per token,  2498.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.45 ms /    11 tokens (   53.86 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   26852.51 ms /    40 runs   (  671.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   27564.97 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.08 ms /    32 runs   (    0.41 ms per token,  2446.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.42 ms /    12 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   20577.91 ms /    31 runs   (  663.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21305.72 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.32 ms /    30 runs   (    0.41 ms per token,  2435.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.63 ms /    12 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   19276.31 ms /    29 runs   (  664.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19999.56 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.82 ms /    44 runs   (    0.41 ms per token,  2468.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.24 ms /    12 tokens (   53.27 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   28584.41 ms /    43 runs   (  664.75 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   29351.61 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.23 ms /    47 runs   (    0.41 ms per token,  2444.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.33 ms /    12 tokens (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   29886.59 ms /    46 runs   (  649.71 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   30659.39 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.94 ms /    45 runs   (    0.42 ms per token,  2376.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.43 ms /    13 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   28772.57 ms /    44 runs   (  653.92 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   29593.27 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.75 ms /    45 runs   (    0.42 ms per token,  2399.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     613.66 ms /    11 tokens (   55.79 ms per token,    17.93 tokens per second)\n",
      "llama_print_timings:        eval time =   29688.89 ms /    44 runs   (  674.75 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   30435.31 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.12 ms /    30 runs   (    0.40 ms per token,  2474.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.92 ms /    11 tokens (   54.08 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   19358.66 ms /    29 runs   (  667.54 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20040.24 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.81 ms /    29 runs   (    0.41 ms per token,  2455.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.55 ms /    11 tokens (   54.14 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   18677.54 ms /    28 runs   (  667.05 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19358.31 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      39.31 ms /    96 runs   (    0.41 ms per token,  2442.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     658.94 ms /    12 tokens (   54.91 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =   63787.31 ms /    95 runs   (  671.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   64731.76 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.23 ms /    36 runs   (    0.40 ms per token,  2529.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.37 ms /    12 tokens (   52.70 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   23407.35 ms /    35 runs   (  668.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24144.32 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.59 ms /    46 runs   (    0.40 ms per token,  2474.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     616.98 ms /    11 tokens (   56.09 ms per token,    17.83 tokens per second)\n",
      "llama_print_timings:        eval time =   29770.49 ms /    45 runs   (  661.57 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   30521.62 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.00 ms /    30 runs   (    0.40 ms per token,  2500.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.41 ms /    13 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   19395.64 ms /    29 runs   (  668.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20161.81 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.34 ms /    30 runs   (    0.41 ms per token,  2430.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.01 ms /    12 tokens (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   19577.77 ms /    29 runs   (  675.10 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20306.21 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.94 ms /    30 runs   (    0.40 ms per token,  2511.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.28 ms /    11 tokens (   53.84 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   19123.85 ms /    29 runs   (  659.44 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19804.93 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.13 ms /    44 runs   (    0.41 ms per token,  2426.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.25 ms /    12 tokens (   54.60 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   28861.42 ms /    43 runs   (  671.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29643.34 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.17 ms /    42 runs   (    0.41 ms per token,  2446.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.63 ms /    11 tokens (   54.24 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   27082.53 ms /    41 runs   (  660.55 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   27800.99 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.16 ms /    27 runs   (    0.41 ms per token,  2419.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.29 ms /    12 tokens (   54.52 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   17411.46 ms /    26 runs   (  669.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18145.61 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.77 ms /    44 runs   (    0.40 ms per token,  2476.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     727.56 ms /    13 tokens (   55.97 ms per token,    17.87 tokens per second)\n",
      "llama_print_timings:        eval time =   28628.65 ms /    43 runs   (  665.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   29485.91 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.34 ms /    30 runs   (    0.41 ms per token,  2431.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.37 ms /    12 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   19242.98 ms /    29 runs   (  663.55 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19967.12 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.15 ms /    30 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.17 ms /    12 tokens (   53.18 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   19290.90 ms /    29 runs   (  665.20 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20015.44 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.61 ms /    29 runs   (    0.40 ms per token,  2498.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.73 ms /    12 tokens (   53.23 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   18659.70 ms /    28 runs   (  666.42 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19383.16 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.85 ms /    37 runs   (    0.40 ms per token,  2492.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.90 ms /    11 tokens (   53.90 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   23871.35 ms /    36 runs   (  663.09 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   24573.63 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.26 ms /    30 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.46 ms /    12 tokens (   54.29 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   18930.93 ms /    29 runs   (  652.79 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   19669.59 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.83 ms /    44 runs   (    0.41 ms per token,  2468.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     711.49 ms /    13 tokens (   54.73 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =   28573.95 ms /    43 runs   (  664.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   29416.86 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.44 ms /    36 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.47 ms /    12 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   23079.16 ms /    35 runs   (  659.40 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   23817.74 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.78 ms /    66 runs   (    0.41 ms per token,  2464.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.67 ms /    12 tokens (   53.81 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   43694.53 ms /    65 runs   (  672.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   44535.61 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.10 ms /    42 runs   (    0.41 ms per token,  2456.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     657.62 ms /    12 tokens (   54.80 ms per token,    18.25 tokens per second)\n",
      "llama_print_timings:        eval time =   27120.96 ms /    41 runs   (  661.49 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   27904.55 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.35 ms /    34 runs   (    0.39 ms per token,  2546.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.97 ms /    13 tokens (   52.77 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   21733.52 ms /    33 runs   (  658.59 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   22519.21 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.08 ms /    42 runs   (    0.41 ms per token,  2458.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.39 ms /    12 tokens (   53.70 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   27212.13 ms /    41 runs   (  663.71 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   27980.63 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.04 ms /    30 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.18 ms /    12 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   19189.03 ms /    29 runs   (  661.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19911.35 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.32 ms /    36 runs   (    0.40 ms per token,  2513.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.82 ms /    11 tokens (   54.17 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   23384.26 ms /    35 runs   (  668.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24085.86 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.85 ms /    37 runs   (    0.40 ms per token,  2492.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.31 ms /    12 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   23847.91 ms /    36 runs   (  662.44 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   24596.61 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.22 ms /    30 runs   (    0.41 ms per token,  2454.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.75 ms /    12 tokens (   53.90 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   19376.17 ms /    29 runs   (  668.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20111.38 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.40 ms /    36 runs   (    0.40 ms per token,  2499.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.87 ms /    12 tokens (   53.57 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   23444.10 ms /    35 runs   (  669.83 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24191.28 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.51 ms /    50 runs   (    0.41 ms per token,  2437.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.53 ms /    13 tokens (   53.35 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   32703.02 ms /    49 runs   (  667.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   33542.64 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.55 ms /    41 runs   (    0.43 ms per token,  2336.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.42 ms /    12 tokens (   53.20 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   26775.67 ms /    40 runs   (  669.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   27539.11 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.91 ms /    41 runs   (    0.41 ms per token,  2425.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.38 ms /    12 tokens (   53.20 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   26567.53 ms /    40 runs   (  664.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   27326.33 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.40 ms /    36 runs   (    0.40 ms per token,  2499.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.65 ms /    13 tokens (   52.59 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   23065.60 ms /    35 runs   (  659.02 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   23853.95 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.18 ms /    44 runs   (    0.41 ms per token,  2420.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.76 ms /    11 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   28311.35 ms /    43 runs   (  658.40 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   29029.08 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.10 ms /    30 runs   (    0.40 ms per token,  2480.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.21 ms /    12 tokens (   54.52 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   19119.67 ms /    29 runs   (  659.30 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19861.19 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.99 ms /    42 runs   (    0.40 ms per token,  2471.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     614.96 ms /    11 tokens (   55.91 ms per token,    17.89 tokens per second)\n",
      "llama_print_timings:        eval time =   27305.21 ms /    41 runs   (  665.98 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28042.88 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.24 ms /    30 runs   (    0.41 ms per token,  2450.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.16 ms /    11 tokens (   53.65 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   19007.06 ms /    29 runs   (  655.42 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   19685.20 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.62 ms /    53 runs   (    0.41 ms per token,  2451.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     739.90 ms /    14 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   34801.17 ms /    52 runs   (  669.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   35698.78 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.50 ms /    39 runs   (    0.40 ms per token,  2515.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.29 ms /    12 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   25342.89 ms /    38 runs   (  666.92 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26092.55 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      30.42 ms /    74 runs   (    0.41 ms per token,  2432.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.91 ms /    11 tokens (   57.36 ms per token,    17.44 tokens per second)\n",
      "llama_print_timings:        eval time =   48475.27 ms /    73 runs   (  664.04 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   49325.82 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.36 ms /    43 runs   (    0.40 ms per token,  2476.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.82 ms /    13 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   27751.00 ms /    42 runs   (  660.74 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   28561.81 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.15 ms /    22 runs   (    0.42 ms per token,  2404.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.99 ms /    12 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   13628.25 ms /    21 runs   (  648.96 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   14321.80 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.20 ms /    38 runs   (    0.40 ms per token,  2499.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.25 ms /    12 tokens (   53.35 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   24429.37 ms /    37 runs   (  660.25 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   25178.60 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.41 ms /    40 runs   (    0.41 ms per token,  2437.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.03 ms /    11 tokens (   54.55 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   25782.35 ms /    39 runs   (  661.09 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   26501.11 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.44 ms /    52 runs   (    0.41 ms per token,  2425.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     662.70 ms /    12 tokens (   55.23 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =   33837.93 ms /    51 runs   (  663.49 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   34652.94 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.61 ms /    43 runs   (    0.41 ms per token,  2442.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.63 ms /    13 tokens (   52.13 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   27876.91 ms /    42 runs   (  663.74 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   28680.84 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.05 ms /    30 runs   (    0.40 ms per token,  2489.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.01 ms /    12 tokens (   54.42 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   19344.86 ms /    29 runs   (  667.06 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20085.17 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.86 ms /    30 runs   (    0.40 ms per token,  2529.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.33 ms /    12 tokens (   54.69 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =   19136.96 ms /    29 runs   (  659.90 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19880.70 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.70 ms /    44 runs   (    0.40 ms per token,  2486.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.46 ms /    12 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   28923.12 ms /    43 runs   (  672.63 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29696.77 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.85 ms /    34 runs   (    0.41 ms per token,  2454.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.28 ms /    12 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   22098.23 ms /    33 runs   (  669.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22835.02 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    20 runs   (    0.41 ms per token,  2458.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.09 ms /    12 tokens (   53.26 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   12760.21 ms /    19 runs   (  671.59 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13459.24 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.02 ms /    32 runs   (    0.41 ms per token,  2457.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.24 ms /    11 tokens (   54.02 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   20763.16 ms /    31 runs   (  669.78 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21451.96 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.65 ms /    28 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     712.09 ms /    13 tokens (   54.78 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =   17767.63 ms /    27 runs   (  658.06 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   18560.73 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.07 ms /    22 runs   (    0.41 ms per token,  2424.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.13 ms /    12 tokens (   53.18 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   14132.00 ms /    21 runs   (  672.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14834.19 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.32 ms /    30 runs   (    0.41 ms per token,  2434.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.35 ms /    12 tokens (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   19377.16 ms /    29 runs   (  668.18 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20101.98 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.00 ms /    30 runs   (    0.40 ms per token,  2499.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.42 ms /    12 tokens (   54.53 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   19322.12 ms /    29 runs   (  666.28 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20064.05 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.47 ms /    31 runs   (    0.40 ms per token,  2485.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.47 ms /    11 tokens (   53.59 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   19828.17 ms /    30 runs   (  660.94 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20509.04 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.53 ms /    41 runs   (    0.40 ms per token,  2480.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.59 ms /    12 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   26635.22 ms /    40 runs   (  665.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   27394.99 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.58 ms /    28 runs   (    0.41 ms per token,  2417.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.42 ms /    12 tokens (   54.04 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   18048.56 ms /    27 runs   (  668.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18778.97 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.38 ms /    25 runs   (    0.42 ms per token,  2408.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.32 ms /    11 tokens (   54.03 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   15897.98 ms /    24 runs   (  662.42 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16566.00 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.26 ms /    36 runs   (    0.40 ms per token,  2524.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.75 ms /    13 tokens (   52.21 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =   23409.03 ms /    35 runs   (  668.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24193.75 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.62 ms /    53 runs   (    0.41 ms per token,  2451.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.94 ms /    12 tokens (   53.91 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   34903.53 ms /    52 runs   (  671.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   35708.42 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.04 ms /    30 runs   (    0.40 ms per token,  2491.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.01 ms /    12 tokens (   53.58 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   19210.19 ms /    29 runs   (  662.42 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19943.46 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.22 ms /    30 runs   (    0.44 ms per token,  2268.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.06 ms /    12 tokens (   54.67 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =   19455.45 ms /    29 runs   (  670.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20205.44 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.79 ms /    41 runs   (    0.41 ms per token,  2442.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.50 ms /    13 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   27106.44 ms /    40 runs   (  677.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27911.97 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.84 ms /    38 runs   (    0.39 ms per token,  2561.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.01 ms /    12 tokens (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   24583.35 ms /    37 runs   (  664.41 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   25336.56 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.28 ms /    37 runs   (    0.41 ms per token,  2420.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.62 ms /    12 tokens (   53.47 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   23830.10 ms /    36 runs   (  661.95 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   24581.84 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.79 ms /    39 runs   (    0.40 ms per token,  2469.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.01 ms /    13 tokens (   53.31 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   25571.36 ms /    38 runs   (  672.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26379.42 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.40 ms /    33 runs   (    0.41 ms per token,  2461.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.43 ms /    12 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   21197.06 ms /    32 runs   (  662.41 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21937.28 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.68 ms /    50 runs   (    0.41 ms per token,  2418.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.25 ms /    13 tokens (   52.56 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   32523.69 ms /    49 runs   (  663.75 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   33351.90 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.75 ms /    46 runs   (    0.41 ms per token,  2453.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.79 ms /    12 tokens (   53.07 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   29788.29 ms /    45 runs   (  661.96 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   30560.52 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.00 ms /    30 runs   (    0.40 ms per token,  2499.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.50 ms /    12 tokens (   54.46 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =   19455.10 ms /    29 runs   (  670.87 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20196.75 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.74 ms /    32 runs   (    0.40 ms per token,  2511.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     719.89 ms /    13 tokens (   55.38 ms per token,    18.06 tokens per second)\n",
      "llama_print_timings:        eval time =   20851.47 ms /    31 runs   (  672.63 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21666.03 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.87 ms /    32 runs   (    0.40 ms per token,  2486.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     609.67 ms /    11 tokens (   55.42 ms per token,    18.04 tokens per second)\n",
      "llama_print_timings:        eval time =   20720.12 ms /    31 runs   (  668.39 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21424.98 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.26 ms /    20 runs   (    0.41 ms per token,  2420.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     657.14 ms /    12 tokens (   54.76 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =   12750.90 ms /    19 runs   (  671.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13467.34 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1400 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.08 ms /    22 runs   (    0.41 ms per token,  2423.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.37 ms /    12 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   13964.55 ms /    21 runs   (  664.98 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14672.87 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.19 ms /    30 runs   (    0.41 ms per token,  2461.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.30 ms /    12 tokens (   54.11 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   19281.09 ms /    29 runs   (  664.87 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20019.91 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.62 ms /    24 runs   (    0.40 ms per token,  2495.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.44 ms /    11 tokens (   54.04 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   15315.55 ms /    23 runs   (  665.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15980.89 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.17 ms /    30 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.15 ms /    12 tokens (   53.26 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   19416.03 ms /    29 runs   (  669.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20144.39 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.07 ms /    30 runs   (    0.40 ms per token,  2485.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.52 ms /    12 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   19182.76 ms /    29 runs   (  661.47 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19912.60 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.66 ms /    61 runs   (    0.40 ms per token,  2473.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.71 ms /    11 tokens (   54.16 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   39898.00 ms /    60 runs   (  664.97 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   40674.94 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.96 ms /    24 runs   (    0.41 ms per token,  2410.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.75 ms /    12 tokens (   52.90 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   15283.87 ms /    23 runs   (  664.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15990.58 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      32.79 ms /    80 runs   (    0.41 ms per token,  2439.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.15 ms /    13 tokens (   52.63 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   52860.83 ms /    79 runs   (  669.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   53783.99 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.16 ms /    27 runs   (    0.41 ms per token,  2419.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.68 ms /    12 tokens (   52.81 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   17446.59 ms /    26 runs   (  671.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18158.82 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.77 ms /    32 runs   (    0.43 ms per token,  2324.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     599.44 ms /    11 tokens (   54.49 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =   20730.41 ms /    31 runs   (  668.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21427.74 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.85 ms /    30 runs   (    0.46 ms per token,  2165.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.31 ms /    11 tokens (   53.57 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   19551.35 ms /    29 runs   (  674.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20237.11 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.93 ms /    40 runs   (    0.40 ms per token,  2511.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     732.39 ms /    14 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   26202.99 ms /    39 runs   (  671.87 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   27053.03 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.66 ms /    66 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.93 ms /    12 tokens (   53.83 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   43658.62 ms /    65 runs   (  671.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   44498.79 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.22 ms /    39 runs   (    0.39 ms per token,  2561.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.40 ms /    12 tokens (   53.12 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   25324.75 ms /    38 runs   (  666.44 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26074.95 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.95 ms /    24 runs   (    0.41 ms per token,  2411.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.85 ms /    12 tokens (   53.65 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   15284.57 ms /    23 runs   (  664.55 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15999.21 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.19 ms /    59 runs   (    0.41 ms per token,  2438.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.48 ms /    12 tokens (   53.04 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   39442.97 ms /    58 runs   (  680.05 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   40253.15 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.51 ms /    57 runs   (    0.41 ms per token,  2424.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     588.82 ms /    11 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   37535.17 ms /    56 runs   (  670.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   38293.42 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.39 ms /    41 runs   (    0.40 ms per token,  2501.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.40 ms /    13 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   26879.95 ms /    40 runs   (  672.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   27683.52 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.07 ms /    40 runs   (    0.40 ms per token,  2488.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.76 ms /    12 tokens (   54.15 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   26078.96 ms /    39 runs   (  668.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26845.56 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.67 ms /    48 runs   (    0.41 ms per token,  2440.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.71 ms /    12 tokens (   54.23 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   31036.35 ms /    47 runs   (  660.35 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   31830.16 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.27 ms /    54 runs   (    0.41 ms per token,  2424.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.57 ms /    12 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   35911.51 ms /    53 runs   (  677.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   36708.42 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.74 ms /    32 runs   (    0.40 ms per token,  2510.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.63 ms /    11 tokens (   54.15 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   20251.81 ms /    31 runs   (  653.28 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   20939.94 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.00 ms /    59 runs   (    0.41 ms per token,  2458.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     690.33 ms /    13 tokens (   53.10 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   38987.95 ms /    58 runs   (  672.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   39852.57 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      33.76 ms /    84 runs   (    0.40 ms per token,  2488.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.36 ms /    12 tokens (   53.95 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   54981.28 ms /    83 runs   (  662.43 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   55880.41 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.59 ms /    53 runs   (    0.41 ms per token,  2454.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.47 ms /    11 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   34894.21 ms /    52 runs   (  671.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   35640.17 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.51 ms /    57 runs   (    0.41 ms per token,  2424.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.22 ms /    12 tokens (   54.35 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   37591.70 ms /    56 runs   (  671.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   38411.75 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.27 ms /    57 runs   (    0.41 ms per token,  2449.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     605.51 ms /    11 tokens (   55.05 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =   37562.26 ms /    56 runs   (  670.75 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   38335.75 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      35.46 ms /    88 runs   (    0.40 ms per token,  2481.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.71 ms /    11 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   57962.16 ms /    87 runs   (  666.23 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   58818.67 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.41 ms /    43 runs   (    0.40 ms per token,  2470.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.63 ms /    12 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   27846.99 ms /    42 runs   (  663.02 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   28622.05 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.23 ms /    52 runs   (    0.41 ms per token,  2449.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.03 ms /    12 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   33651.82 ms /    51 runs   (  659.84 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   34444.75 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.09 ms /    67 runs   (    0.40 ms per token,  2473.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.52 ms /    11 tokens (   54.41 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   44019.79 ms /    66 runs   (  666.97 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   44816.08 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.04 ms /    35 runs   (    0.40 ms per token,  2492.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.87 ms /    12 tokens (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   22838.62 ms /    34 runs   (  671.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   23588.70 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.02 ms /    25 runs   (    0.40 ms per token,  2496.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.27 ms /    13 tokens (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   15994.94 ms /    24 runs   (  666.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16756.35 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.96 ms /    46 runs   (    0.41 ms per token,  2426.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.70 ms /    12 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   30383.41 ms /    45 runs   (  675.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   31160.69 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.08 ms /    59 runs   (    0.41 ms per token,  2450.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.18 ms /    12 tokens (   53.18 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   38921.83 ms /    58 runs   (  671.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   39734.88 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.08 ms /    67 runs   (    0.40 ms per token,  2473.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.19 ms /    11 tokens (   53.84 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   44797.31 ms /    66 runs   (  678.75 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   45588.30 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.65 ms /    39 runs   (    0.40 ms per token,  2492.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.88 ms /    12 tokens (   53.32 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   25507.39 ms /    38 runs   (  671.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26262.57 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.39 ms /    24 runs   (    0.43 ms per token,  2309.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.48 ms /    12 tokens (   53.46 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   15072.49 ms /    23 runs   (  655.33 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   15786.41 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.50 ms /    46 runs   (    0.40 ms per token,  2485.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.00 ms /    13 tokens (   52.38 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   30089.33 ms /    45 runs   (  668.65 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   30907.69 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.14 ms /    64 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.42 ms /    12 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   41937.12 ms /    63 runs   (  665.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   42766.76 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.66 ms /    24 runs   (    0.40 ms per token,  2483.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.36 ms /    12 tokens (   53.78 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   15049.79 ms /    23 runs   (  654.34 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   15765.07 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.65 ms /    53 runs   (    0.41 ms per token,  2447.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.31 ms /    12 tokens (   54.11 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   34872.83 ms /    52 runs   (  670.63 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   35679.38 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.90 ms /    66 runs   (    0.41 ms per token,  2453.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.63 ms /    12 tokens (   53.72 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   43576.21 ms /    65 runs   (  670.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   44417.13 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      46.25 ms /   112 runs   (    0.41 ms per token,  2421.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.23 ms /    12 tokens (   55.27 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =   74635.03 ms /   111 runs   (  672.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   75634.74 ms /   123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.51 ms /    23 runs   (    0.41 ms per token,  2419.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.53 ms /    11 tokens (   54.14 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   14788.38 ms /    22 runs   (  672.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15451.53 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.01 ms /    20 runs   (    0.40 ms per token,  2495.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.96 ms /    13 tokens (   52.92 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   12711.43 ms /    19 runs   (  669.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13458.07 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.13 ms /    25 runs   (    0.41 ms per token,  2466.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.90 ms /    12 tokens (   53.16 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   16217.51 ms /    24 runs   (  675.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16928.50 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.07 ms /    42 runs   (    0.41 ms per token,  2460.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.42 ms /    11 tokens (   53.86 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   27338.81 ms /    41 runs   (  666.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28053.77 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.35 ms /    25 runs   (    0.41 ms per token,  2416.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.77 ms /    11 tokens (   53.89 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   16191.83 ms /    24 runs   (  674.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16858.24 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.98 ms /    47 runs   (    0.40 ms per token,  2475.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.88 ms /    12 tokens (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   31108.06 ms /    46 runs   (  676.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   31876.79 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.87 ms /    39 runs   (    0.41 ms per token,  2457.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     657.78 ms /    12 tokens (   54.82 ms per token,    18.24 tokens per second)\n",
      "llama_print_timings:        eval time =   25287.59 ms /    38 runs   (  665.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26060.73 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.34 ms /    57 runs   (    0.41 ms per token,  2442.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.21 ms /    12 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   37457.68 ms /    56 runs   (  668.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   38267.58 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.91 ms /    44 runs   (    0.41 ms per token,  2456.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.98 ms /    12 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   28651.17 ms /    43 runs   (  666.31 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   29415.58 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.73 ms /    39 runs   (    0.40 ms per token,  2479.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.65 ms /    11 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   25183.67 ms /    38 runs   (  662.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   25891.27 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.63 ms /    24 runs   (    0.40 ms per token,  2491.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.16 ms /    12 tokens (   54.68 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =   15306.88 ms /    23 runs   (  665.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16032.76 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.59 ms /    66 runs   (    0.40 ms per token,  2482.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.79 ms /    13 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   44122.19 ms /    65 runs   (  678.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   44999.66 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      28.42 ms /    70 runs   (    0.41 ms per token,  2462.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.59 ms /    12 tokens (   52.80 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   46692.71 ms /    69 runs   (  676.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   47533.21 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.92 ms /    61 runs   (    0.41 ms per token,  2447.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.24 ms /    12 tokens (   53.52 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   39869.02 ms /    60 runs   (  664.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   40690.06 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.34 ms /    35 runs   (    0.41 ms per token,  2440.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.27 ms /    12 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   22656.50 ms /    34 runs   (  666.37 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   23392.20 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      34.57 ms /    85 runs   (    0.41 ms per token,  2458.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.17 ms /    12 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   56356.39 ms /    84 runs   (  670.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   57236.83 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      48.31 ms /   111 runs   (    0.44 ms per token,  2297.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     602.29 ms /    11 tokens (   54.75 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =   73905.13 ms /   110 runs   (  671.86 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   74854.07 ms /   121 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.88 ms /    24 runs   (    0.41 ms per token,  2429.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.79 ms /    12 tokens (   54.23 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   15323.81 ms /    23 runs   (  666.25 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16044.12 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.44 ms /    39 runs   (    0.40 ms per token,  2525.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.64 ms /    13 tokens (   52.36 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   25022.68 ms /    38 runs   (  658.49 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   25817.03 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      34.48 ms /    85 runs   (    0.41 ms per token,  2465.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.98 ms /    12 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   56676.81 ms /    84 runs   (  674.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   57565.62 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.94 ms /    39 runs   (    0.41 ms per token,  2447.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.75 ms /    12 tokens (   52.81 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   24885.27 ms /    38 runs   (  654.88 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   25630.74 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.38 ms /    30 runs   (    0.41 ms per token,  2422.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.31 ms /    13 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   19394.80 ms /    29 runs   (  668.79 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20165.64 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      29.63 ms /    73 runs   (    0.41 ms per token,  2463.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.93 ms /    12 tokens (   54.16 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   48253.12 ms /    72 runs   (  670.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   49118.65 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.56 ms /    20 runs   (    0.43 ms per token,  2335.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.19 ms /    11 tokens (   53.74 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   12626.01 ms /    19 runs   (  664.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13276.29 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.29 ms /    30 runs   (    0.41 ms per token,  2440.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     706.31 ms /    12 tokens (   58.86 ms per token,    16.99 tokens per second)\n",
      "llama_print_timings:        eval time =   19362.99 ms /    29 runs   (  667.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20158.03 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.26 ms /    30 runs   (    0.41 ms per token,  2447.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     609.41 ms /    11 tokens (   55.40 ms per token,    18.05 tokens per second)\n",
      "llama_print_timings:        eval time =   19463.90 ms /    29 runs   (  671.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20160.67 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      35.86 ms /    87 runs   (    0.41 ms per token,  2426.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     721.39 ms /    13 tokens (   55.49 ms per token,    18.02 tokens per second)\n",
      "llama_print_timings:        eval time =   56350.75 ms /    86 runs   (  655.24 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   57329.56 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.70 ms /    29 runs   (    0.40 ms per token,  2478.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.13 ms /    12 tokens (   53.01 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   18516.24 ms /    28 runs   (  661.29 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19236.82 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.61 ms /    34 runs   (    0.40 ms per token,  2498.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.00 ms /    12 tokens (   52.92 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   21282.02 ms /    33 runs   (  644.91 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   22016.56 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.61 ms /    55 runs   (    0.41 ms per token,  2432.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.65 ms /    12 tokens (   53.14 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   36039.18 ms /    54 runs   (  667.39 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   36837.75 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      29.71 ms /    72 runs   (    0.41 ms per token,  2423.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     773.76 ms /    15 tokens (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_print_timings:        eval time =   45757.14 ms /    71 runs   (  644.47 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   46746.03 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.43 ms /    38 runs   (    0.41 ms per token,  2462.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.39 ms /    12 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   23885.47 ms /    37 runs   (  645.55 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   24640.59 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      28.84 ms /    71 runs   (    0.41 ms per token,  2462.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.63 ms /    12 tokens (   53.39 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   47091.34 ms /    70 runs   (  672.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   47940.89 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.61 ms /    29 runs   (    0.40 ms per token,  2498.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.20 ms /    12 tokens (   52.77 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   18502.33 ms /    28 runs   (  660.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19220.78 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.65 ms /    21 runs   (    0.41 ms per token,  2428.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     588.93 ms /    11 tokens (   53.54 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   13145.76 ms /    20 runs   (  657.29 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13796.26 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.15 ms /    20 runs   (    0.46 ms per token,  2185.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.18 ms /    12 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   12740.91 ms /    19 runs   (  670.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13439.30 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.34 ms /    33 runs   (    0.43 ms per token,  2301.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.27 ms /    12 tokens (   53.44 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   21391.25 ms /    32 runs   (  668.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22135.04 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.61 ms /    39 runs   (    0.40 ms per token,  2498.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.98 ms /    13 tokens (   52.15 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   25425.49 ms /    38 runs   (  669.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26218.23 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.17 ms /    30 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.83 ms /    12 tokens (   54.15 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   18855.56 ms /    29 runs   (  650.19 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   19592.75 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    17 runs   (    0.41 ms per token,  2453.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.05 ms /    11 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   10603.81 ms /    16 runs   (  662.74 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11244.75 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.24 ms /    30 runs   (    0.41 ms per token,  2450.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.30 ms /    12 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   19401.58 ms /    29 runs   (  669.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20128.27 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.65 ms /    24 runs   (    0.40 ms per token,  2487.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.43 ms /    12 tokens (   52.87 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   15392.11 ms /    23 runs   (  669.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16096.30 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.04 ms /    52 runs   (    0.40 ms per token,  2471.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.55 ms /    13 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   34875.31 ms /    51 runs   (  683.83 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   35711.59 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.08 ms /    30 runs   (    0.40 ms per token,  2484.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.52 ms /    12 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   18906.14 ms /    29 runs   (  651.94 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   19625.47 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.65 ms /    26 runs   (    0.41 ms per token,  2440.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     601.16 ms /    11 tokens (   54.65 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =   16614.02 ms /    25 runs   (  664.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17290.68 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.93 ms /    30 runs   (    0.40 ms per token,  2514.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.84 ms /    12 tokens (   53.90 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   19319.07 ms /    29 runs   (  666.17 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20052.20 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.81 ms /    32 runs   (    0.40 ms per token,  2498.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.63 ms /    13 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   20573.36 ms /    31 runs   (  663.66 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21347.91 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    17 runs   (    0.41 ms per token,  2447.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.12 ms /    12 tokens (   52.51 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   10678.68 ms /    16 runs   (  667.42 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11357.65 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.30 ms /    30 runs   (    0.41 ms per token,  2439.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.85 ms /    12 tokens (   53.99 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   19428.82 ms /    29 runs   (  669.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20165.02 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.28 ms /    23 runs   (    0.45 ms per token,  2238.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.32 ms /    12 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   14699.09 ms /    22 runs   (  668.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15412.29 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.58 ms /    26 runs   (    0.41 ms per token,  2457.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.62 ms /    13 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   16790.62 ms /    25 runs   (  671.62 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17548.71 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.16 ms /    25 runs   (    0.41 ms per token,  2461.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     587.97 ms /    11 tokens (   53.45 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   16130.97 ms /    24 runs   (  672.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16791.12 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.10 ms /    30 runs   (    0.40 ms per token,  2479.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.02 ms /    12 tokens (   54.67 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =   19091.51 ms /    29 runs   (  658.33 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19834.52 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.12 ms /    30 runs   (    0.44 ms per token,  2287.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.89 ms /    12 tokens (   53.16 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   19308.23 ms /    29 runs   (  665.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20038.91 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.03 ms /    38 runs   (    0.40 ms per token,  2527.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.79 ms /    13 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   24712.00 ms /    37 runs   (  667.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   25505.57 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.48 ms /    33 runs   (    0.44 ms per token,  2279.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.94 ms /    12 tokens (   53.41 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   21236.24 ms /    32 runs   (  663.63 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21979.87 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1500 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.10 ms /    30 runs   (    0.40 ms per token,  2478.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.56 ms /    11 tokens (   53.78 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   19197.92 ms /    29 runs   (  662.00 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19878.38 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      34.28 ms /    85 runs   (    0.40 ms per token,  2479.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.87 ms /    11 tokens (   53.90 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   57135.06 ms /    84 runs   (  680.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   57982.33 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    20 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.29 ms /    12 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   12559.47 ms /    19 runs   (  661.02 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13249.51 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.72 ms /    26 runs   (    0.41 ms per token,  2424.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.60 ms /    12 tokens (   52.55 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   16361.76 ms /    25 runs   (  654.47 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   17068.42 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.21 ms /    23 runs   (    0.40 ms per token,  2496.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.83 ms /    12 tokens (   53.49 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   14612.42 ms /    22 runs   (  664.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15321.23 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.80 ms /    32 runs   (    0.40 ms per token,  2500.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     706.97 ms /    13 tokens (   54.38 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =   20361.36 ms /    31 runs   (  656.82 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21161.61 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.06 ms /    32 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.55 ms /    11 tokens (   54.23 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   20645.45 ms /    31 runs   (  665.98 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21335.30 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.05 ms /    40 runs   (    0.40 ms per token,  2491.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.79 ms /    12 tokens (   53.07 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   25772.09 ms /    39 runs   (  660.82 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   26526.76 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.58 ms /    21 runs   (    0.41 ms per token,  2447.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.73 ms /    12 tokens (   53.23 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   13225.40 ms /    20 runs   (  661.27 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13926.86 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.98 ms /    32 runs   (    0.41 ms per token,  2464.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.87 ms /    12 tokens (   53.57 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   20743.44 ms /    31 runs   (  669.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21479.42 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.00 ms /    30 runs   (    0.40 ms per token,  2499.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.26 ms /    13 tokens (   52.10 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   19723.27 ms /    29 runs   (  680.11 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20487.88 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      33.77 ms /    80 runs   (    0.42 ms per token,  2369.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.23 ms /    12 tokens (   53.85 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   52726.93 ms /    79 runs   (  667.43 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   53615.29 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.13 ms /    30 runs   (    0.40 ms per token,  2472.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.35 ms /    13 tokens (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   19125.90 ms /    29 runs   (  659.51 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19897.51 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.79 ms /    65 runs   (    0.41 ms per token,  2426.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.69 ms /    11 tokens (   53.88 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   43015.11 ms /    64 runs   (  672.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   43798.46 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.11 ms /    38 runs   (    0.40 ms per token,  2514.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     609.33 ms /    11 tokens (   55.39 ms per token,    18.05 tokens per second)\n",
      "llama_print_timings:        eval time =   24959.21 ms /    37 runs   (  674.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25678.65 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      30.25 ms /    74 runs   (    0.41 ms per token,  2446.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.92 ms /    12 tokens (   52.91 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   49487.66 ms /    73 runs   (  677.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   50343.18 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.85 ms /    39 runs   (    0.41 ms per token,  2460.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.08 ms /    12 tokens (   52.76 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   25478.15 ms /    38 runs   (  670.48 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26224.44 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.38 ms /    45 runs   (    0.41 ms per token,  2448.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.82 ms /    12 tokens (   53.65 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   29286.15 ms /    44 runs   (  665.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   30061.68 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.47 ms /    30 runs   (    0.42 ms per token,  2405.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.64 ms /    12 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   19344.37 ms /    29 runs   (  667.05 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20067.71 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.18 ms /    35 runs   (    0.41 ms per token,  2467.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.25 ms /    12 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   22761.12 ms /    34 runs   (  669.44 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   23495.06 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.76 ms /    29 runs   (    0.41 ms per token,  2465.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     700.10 ms /    13 tokens (   53.85 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   18202.04 ms /    28 runs   (  650.07 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   18987.23 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.89 ms /    37 runs   (    0.40 ms per token,  2485.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.36 ms /    12 tokens (   56.78 ms per token,    17.61 tokens per second)\n",
      "llama_print_timings:        eval time =   23950.25 ms /    36 runs   (  665.28 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24743.01 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.58 ms /    31 runs   (    0.41 ms per token,  2464.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.37 ms /    12 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   19991.56 ms /    30 runs   (  666.39 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20716.56 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      28.80 ms /    71 runs   (    0.41 ms per token,  2465.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     599.64 ms /    11 tokens (   54.51 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   46792.46 ms /    70 runs   (  668.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   47602.22 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.12 ms /    59 runs   (    0.41 ms per token,  2445.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.19 ms /    12 tokens (   53.35 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   38270.06 ms /    58 runs   (  659.83 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   39085.73 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.50 ms /    43 runs   (    0.41 ms per token,  2456.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.26 ms /    12 tokens (   53.86 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   28060.47 ms /    42 runs   (  668.11 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28833.80 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.33 ms /    52 runs   (    0.41 ms per token,  2438.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     731.11 ms /    14 tokens (   52.22 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =   33564.58 ms /    51 runs   (  658.13 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   34449.55 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.22 ms /    38 runs   (    0.40 ms per token,  2496.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.66 ms /    11 tokens (   53.88 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   24454.69 ms /    37 runs   (  660.94 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   25159.25 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.85 ms /    32 runs   (    0.40 ms per token,  2490.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.22 ms /    12 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   20388.55 ms /    31 runs   (  657.70 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21127.46 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.98 ms /    29 runs   (    0.41 ms per token,  2420.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.66 ms /    12 tokens (   52.89 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   18563.35 ms /    28 runs   (  662.98 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19284.24 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      37.49 ms /    92 runs   (    0.41 ms per token,  2454.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.38 ms /    12 tokens (   53.03 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   60323.17 ms /    91 runs   (  662.89 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   61230.64 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.06 ms /    40 runs   (    0.40 ms per token,  2490.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.24 ms /    12 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   26321.70 ms /    39 runs   (  674.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27070.13 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.51 ms /    33 runs   (    0.41 ms per token,  2443.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.55 ms /    12 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   21170.51 ms /    32 runs   (  661.58 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21902.93 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.77 ms /    36 runs   (    0.41 ms per token,  2438.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.09 ms /    12 tokens (   53.42 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   23584.10 ms /    35 runs   (  673.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   24330.38 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.17 ms /    30 runs   (    0.41 ms per token,  2465.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.77 ms /    13 tokens (   52.98 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   18952.67 ms /    29 runs   (  653.54 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   19729.14 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.07 ms /    20 runs   (    0.40 ms per token,  2476.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.92 ms /    12 tokens (   54.24 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   12765.91 ms /    19 runs   (  671.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13474.37 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.14 ms /    44 runs   (    0.41 ms per token,  2425.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     629.74 ms /    12 tokens (   52.48 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   28829.83 ms /    43 runs   (  670.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29590.01 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.90 ms /    26 runs   (    0.42 ms per token,  2385.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.34 ms /    12 tokens (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   16460.17 ms /    25 runs   (  658.41 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   17172.74 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.42 ms /    50 runs   (    0.41 ms per token,  2448.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.65 ms /    13 tokens (   53.74 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   32982.43 ms /    49 runs   (  673.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   33827.11 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.62 ms /    42 runs   (    0.40 ms per token,  2527.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.60 ms /    12 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   27462.62 ms /    41 runs   (  669.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28220.02 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.20 ms /    68 runs   (    0.40 ms per token,  2499.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.69 ms /    12 tokens (   53.81 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   44882.92 ms /    67 runs   (  669.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   45727.67 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.10 ms /    30 runs   (    0.40 ms per token,  2480.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.61 ms /    12 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   19290.44 ms /    29 runs   (  665.19 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20014.95 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.94 ms /    44 runs   (    0.41 ms per token,  2453.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.75 ms /    13 tokens (   52.37 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   28855.28 ms /    43 runs   (  671.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29664.52 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.10 ms /    30 runs   (    0.40 ms per token,  2478.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.99 ms /    12 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   19109.86 ms /    29 runs   (  658.96 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19829.74 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.32 ms /    23 runs   (    0.41 ms per token,  2468.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.88 ms /    13 tokens (   52.84 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   14473.58 ms /    22 runs   (  657.89 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15227.37 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.98 ms /    32 runs   (    0.41 ms per token,  2464.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.17 ms /    11 tokens (   54.02 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   20453.07 ms /    31 runs   (  659.78 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21140.75 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.88 ms /    34 runs   (    0.41 ms per token,  2448.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.99 ms /    12 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   21665.30 ms /    33 runs   (  656.52 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   22403.81 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.55 ms /    29 runs   (    0.40 ms per token,  2511.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.19 ms /    11 tokens (   53.56 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   18565.05 ms /    28 runs   (  663.04 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19239.37 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.70 ms /    29 runs   (    0.40 ms per token,  2478.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.30 ms /    12 tokens (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   18529.60 ms /    28 runs   (  661.77 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19252.63 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.58 ms /    34 runs   (    0.40 ms per token,  2502.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     660.27 ms /    12 tokens (   55.02 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =   21937.99 ms /    33 runs   (  664.79 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22696.50 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.29 ms /    30 runs   (    0.41 ms per token,  2441.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.45 ms /    11 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   18899.83 ms /    29 runs   (  651.72 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   19576.71 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.68 ms /    29 runs   (    0.40 ms per token,  2482.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     675.50 ms /    12 tokens (   56.29 ms per token,    17.76 tokens per second)\n",
      "llama_print_timings:        eval time =   18753.99 ms /    28 runs   (  669.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19513.44 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.12 ms /    30 runs   (    0.40 ms per token,  2476.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     715.94 ms /    13 tokens (   55.07 ms per token,    18.16 tokens per second)\n",
      "llama_print_timings:        eval time =   19260.33 ms /    29 runs   (  664.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20064.21 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.57 ms /    37 runs   (    0.42 ms per token,  2376.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.17 ms /    12 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   24109.25 ms /    36 runs   (  669.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24857.88 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.58 ms /    29 runs   (    0.43 ms per token,  2306.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.18 ms /    12 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   18613.98 ms /    28 runs   (  664.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19335.44 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.27 ms /    30 runs   (    0.41 ms per token,  2445.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.61 ms /    12 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   19379.84 ms /    29 runs   (  668.27 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20106.33 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.07 ms /    47 runs   (    0.41 ms per token,  2464.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     662.08 ms /    12 tokens (   55.17 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =   30469.36 ms /    46 runs   (  662.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   31269.77 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.00 ms /    38 runs   (    0.39 ms per token,  2532.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.52 ms /    13 tokens (   52.35 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   24631.02 ms /    37 runs   (  665.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   25422.06 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.78 ms /    21 runs   (    0.42 ms per token,  2392.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.00 ms /    12 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   13316.20 ms /    20 runs   (  665.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14017.59 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.69 ms /    31 runs   (    0.41 ms per token,  2442.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.85 ms /    12 tokens (   53.07 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   20045.39 ms /    30 runs   (  668.18 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20773.48 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.89 ms /    26 runs   (    0.42 ms per token,  2387.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     673.65 ms /    13 tokens (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   16629.12 ms /    25 runs   (  665.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17379.22 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.22 ms /    30 runs   (    0.41 ms per token,  2455.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     585.00 ms /    11 tokens (   53.18 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   19393.12 ms /    29 runs   (  668.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20064.06 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.76 ms /    29 runs   (    0.41 ms per token,  2465.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.70 ms /    12 tokens (   52.73 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   18531.94 ms /    28 runs   (  661.85 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19247.98 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.60 ms /    31 runs   (    0.41 ms per token,  2459.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.04 ms /    12 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   20373.46 ms /    30 runs   (  679.12 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   21102.29 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.07 ms /    30 runs   (    0.40 ms per token,  2484.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.68 ms /    12 tokens (   53.81 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   19540.28 ms /    29 runs   (  673.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20273.58 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.92 ms /    44 runs   (    0.41 ms per token,  2455.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.25 ms /    12 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   28833.28 ms /    43 runs   (  670.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29605.43 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.97 ms /    30 runs   (    0.40 ms per token,  2506.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.25 ms /    12 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   19079.25 ms /    29 runs   (  657.91 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19801.54 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.26 ms /    47 runs   (    0.41 ms per token,  2440.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.06 ms /    13 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   30437.68 ms /    46 runs   (  661.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   31251.76 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.97 ms /    30 runs   (    0.40 ms per token,  2506.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.11 ms /    12 tokens (   54.26 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   19201.61 ms /    29 runs   (  662.12 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19941.87 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.73 ms /    21 runs   (    0.42 ms per token,  2406.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     611.37 ms /    11 tokens (   55.58 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =   13333.25 ms /    20 runs   (  666.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14006.81 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.99 ms /    44 runs   (    0.41 ms per token,  2445.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.32 ms /    12 tokens (   54.69 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =   28653.17 ms /    43 runs   (  666.35 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   29439.52 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      37.77 ms /    92 runs   (    0.41 ms per token,  2435.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     586.96 ms /    11 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   61319.60 ms /    91 runs   (  673.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   62178.82 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.18 ms /    30 runs   (    0.41 ms per token,  2462.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.28 ms /    12 tokens (   53.61 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   19368.44 ms /    29 runs   (  667.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20099.31 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.54 ms /    26 runs   (    0.41 ms per token,  2467.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.55 ms /    13 tokens (   52.66 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   16815.52 ms /    25 runs   (  672.62 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17576.36 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.32 ms /    20 runs   (    0.42 ms per token,  2403.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.16 ms /    12 tokens (   52.76 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   12562.85 ms /    19 runs   (  661.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13255.08 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.04 ms /    30 runs   (    0.40 ms per token,  2491.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.83 ms /    11 tokens (   54.35 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   19158.70 ms /    29 runs   (  660.64 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19843.95 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.35 ms /    39 runs   (    0.39 ms per token,  2540.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.01 ms /    12 tokens (   52.83 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   25229.47 ms /    38 runs   (  663.93 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   25976.69 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.72 ms /    44 runs   (    0.40 ms per token,  2482.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.53 ms /    12 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   28786.47 ms /    43 runs   (  669.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29549.76 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.93 ms /    32 runs   (    0.40 ms per token,  2475.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.61 ms /    11 tokens (   54.60 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   20737.22 ms /    31 runs   (  668.94 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21430.85 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.22 ms /    30 runs   (    0.41 ms per token,  2454.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.15 ms /    12 tokens (   53.85 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   19250.06 ms /    29 runs   (  663.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19983.52 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.14 ms /    38 runs   (    0.40 ms per token,  2510.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     710.94 ms /    12 tokens (   59.25 ms per token,    16.88 tokens per second)\n",
      "llama_print_timings:        eval time =   24788.53 ms /    37 runs   (  669.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   25610.90 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.29 ms /    30 runs   (    0.41 ms per token,  2441.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.39 ms /    12 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   18860.58 ms /    29 runs   (  650.36 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   19591.06 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.70 ms /    44 runs   (    0.40 ms per token,  2485.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.77 ms /    12 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   28947.89 ms /    43 runs   (  673.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29716.79 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.27 ms /    23 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     582.48 ms /    11 tokens (   52.95 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   14601.17 ms /    22 runs   (  663.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15250.50 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.43 ms /    45 runs   (    0.41 ms per token,  2442.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     727.66 ms /    14 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   29760.63 ms /    44 runs   (  676.38 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   30620.70 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.38 ms /    23 runs   (    0.41 ms per token,  2451.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.98 ms /    11 tokens (   59.45 ms per token,    16.82 tokens per second)\n",
      "llama_print_timings:        eval time =   14958.67 ms /    22 runs   (  679.94 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15679.87 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.53 ms /    66 runs   (    0.40 ms per token,  2487.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.27 ms /    12 tokens (   54.36 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   43765.81 ms /    65 runs   (  673.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   44611.00 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.36 ms /    28 runs   (    0.41 ms per token,  2464.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.83 ms /    12 tokens (   52.90 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   18029.39 ms /    27 runs   (  667.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18746.30 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.81 ms /    30 runs   (    0.46 ms per token,  2172.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.59 ms /    12 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   18769.21 ms /    29 runs   (  647.21 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   19506.16 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.91 ms /    66 runs   (    0.42 ms per token,  2364.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.42 ms /    12 tokens (   53.03 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   43693.58 ms /    65 runs   (  672.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   44533.00 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.42 ms /    31 runs   (    0.40 ms per token,  2496.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.54 ms /    12 tokens (   53.21 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   20061.11 ms /    30 runs   (  668.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20790.77 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.80 ms /    32 runs   (    0.40 ms per token,  2499.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.62 ms /    13 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   20623.51 ms /    31 runs   (  665.27 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21405.03 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.05 ms /    47 runs   (    0.41 ms per token,  2467.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.04 ms /    13 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   30696.35 ms /    46 runs   (  667.31 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   31520.81 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.57 ms /    28 runs   (    0.41 ms per token,  2419.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.85 ms /    12 tokens (   53.49 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   18176.42 ms /    27 runs   (  673.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18900.30 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.60 ms /    41 runs   (    0.40 ms per token,  2470.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     588.97 ms /    11 tokens (   53.54 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   27110.51 ms /    40 runs   (  677.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27820.87 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.66 ms /    29 runs   (    0.40 ms per token,  2487.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.25 ms /    12 tokens (   52.77 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   18346.44 ms /    28 runs   (  655.23 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   19064.39 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.96 ms /    20 runs   (    0.40 ms per token,  2512.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.08 ms /    12 tokens (   52.92 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   12611.68 ms /    19 runs   (  663.77 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13304.93 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.45 ms /    47 runs   (    0.44 ms per token,  2298.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     674.87 ms /    13 tokens (   51.91 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   30714.42 ms /    46 runs   (  667.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   31531.95 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      29.57 ms /    73 runs   (    0.41 ms per token,  2468.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.85 ms /    12 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   48187.62 ms /    72 runs   (  669.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   49036.66 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      28.62 ms /    68 runs   (    0.42 ms per token,  2375.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.91 ms /    12 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   44811.82 ms /    67 runs   (  668.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   45654.54 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1600 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.48 ms /    48 runs   (    0.41 ms per token,  2463.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.50 ms /    13 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   31504.83 ms /    47 runs   (  670.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   32326.96 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.38 ms /    58 runs   (    0.40 ms per token,  2480.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.46 ms /    12 tokens (   53.95 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   38248.62 ms /    57 runs   (  671.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   39065.76 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.80 ms /    29 runs   (    0.41 ms per token,  2457.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.32 ms /    12 tokens (   53.03 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   18616.12 ms /    28 runs   (  664.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19338.17 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.15 ms /    30 runs   (    0.40 ms per token,  2469.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.46 ms /    13 tokens (   52.34 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   19289.64 ms /    29 runs   (  665.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20057.23 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.41 ms /    34 runs   (    0.39 ms per token,  2534.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.93 ms /    12 tokens (   53.16 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   22003.17 ms /    33 runs   (  666.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22739.48 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.94 ms /    30 runs   (    0.40 ms per token,  2511.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.46 ms /    11 tokens (   53.77 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   19370.81 ms /    29 runs   (  667.96 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20049.31 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      32.95 ms /    82 runs   (    0.40 ms per token,  2488.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.88 ms /    12 tokens (   53.91 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   54847.51 ms /    81 runs   (  677.13 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   55736.71 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.23 ms /    30 runs   (    0.41 ms per token,  2452.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.24 ms /    12 tokens (   53.27 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   19496.98 ms /    29 runs   (  672.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20224.11 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.29 ms /    42 runs   (    0.41 ms per token,  2428.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     609.48 ms /    11 tokens (   55.41 ms per token,    18.05 tokens per second)\n",
      "llama_print_timings:        eval time =   27202.98 ms /    41 runs   (  663.49 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   27936.85 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.77 ms /    48 runs   (    0.41 ms per token,  2428.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.33 ms /    11 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   31574.28 ms /    47 runs   (  671.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   32306.74 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.98 ms /    30 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.57 ms /    12 tokens (   54.05 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   19440.44 ms /    29 runs   (  670.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20175.76 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.94 ms /    34 runs   (    0.41 ms per token,  2439.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.06 ms /    12 tokens (   52.92 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   21628.13 ms /    33 runs   (  655.40 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   22362.56 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.71 ms /    32 runs   (    0.40 ms per token,  2516.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.74 ms /    12 tokens (   52.98 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   20329.25 ms /    31 runs   (  655.78 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21059.15 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.84 ms /    32 runs   (    0.40 ms per token,  2492.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     675.65 ms /    13 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   20524.97 ms /    31 runs   (  662.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21293.19 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.73 ms /    37 runs   (    0.40 ms per token,  2511.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.38 ms /    12 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   24121.35 ms /    36 runs   (  670.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24867.13 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.28 ms /    23 runs   (    0.40 ms per token,  2477.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.55 ms /    11 tokens (   53.69 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   14699.52 ms /    22 runs   (  668.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15356.09 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.29 ms /    33 runs   (    0.40 ms per token,  2483.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.65 ms /    12 tokens (   54.14 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   21432.40 ms /    32 runs   (  669.76 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22177.53 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.38 ms /    23 runs   (    0.41 ms per token,  2452.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     673.84 ms /    13 tokens (   51.83 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:        eval time =   14718.32 ms /    22 runs   (  669.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15458.75 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.76 ms /    29 runs   (    0.41 ms per token,  2466.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     588.80 ms /    11 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   18704.89 ms /    28 runs   (  668.03 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19378.33 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.50 ms /    66 runs   (    0.40 ms per token,  2490.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.59 ms /    12 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   43854.40 ms /    65 runs   (  674.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   44685.41 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.18 ms /    38 runs   (    0.40 ms per token,  2502.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.77 ms /    12 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   24638.07 ms /    37 runs   (  665.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   25381.47 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.84 ms /    32 runs   (    0.40 ms per token,  2492.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     675.66 ms /    13 tokens (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   20582.35 ms /    31 runs   (  663.95 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21352.47 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.06 ms /    40 runs   (    0.40 ms per token,  2490.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.08 ms /    12 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   25943.65 ms /    39 runs   (  665.22 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26700.00 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.18 ms /    56 runs   (    0.43 ms per token,  2315.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.46 ms /    12 tokens (   53.12 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   36994.21 ms /    55 runs   (  672.62 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   37802.64 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.48 ms /    43 runs   (    0.41 ms per token,  2459.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.53 ms /    13 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   28196.21 ms /    42 runs   (  671.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29005.92 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.14 ms /    44 runs   (    0.41 ms per token,  2425.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     670.33 ms /    12 tokens (   55.86 ms per token,    17.90 tokens per second)\n",
      "llama_print_timings:        eval time =   28930.20 ms /    43 runs   (  672.80 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29729.21 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.29 ms /    20 runs   (    0.41 ms per token,  2413.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.93 ms /    11 tokens (   53.99 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   12695.99 ms /    19 runs   (  668.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13349.18 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.21 ms /    30 runs   (    0.41 ms per token,  2456.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.66 ms /    12 tokens (   52.89 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   19314.16 ms /    29 runs   (  666.01 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20036.85 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.23 ms /    20 runs   (    0.41 ms per token,  2430.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.69 ms /    11 tokens (   54.24 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   12643.32 ms /    19 runs   (  665.44 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13297.70 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.64 ms /    30 runs   (    0.45 ms per token,  2198.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.65 ms /    12 tokens (   54.30 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   19466.78 ms /    29 runs   (  671.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20216.44 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.17 ms /    20 runs   (    0.41 ms per token,  2446.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.17 ms /    12 tokens (   56.60 ms per token,    17.67 tokens per second)\n",
      "llama_print_timings:        eval time =   12549.84 ms /    19 runs   (  660.52 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13286.71 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.18 ms /    23 runs   (    0.40 ms per token,  2505.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     726.90 ms /    14 tokens (   51.92 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   14601.13 ms /    22 runs   (  663.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15395.64 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.61 ms /    26 runs   (    0.41 ms per token,  2450.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     611.49 ms /    11 tokens (   55.59 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =   15817.55 ms /    25 runs   (  632.70 ms per token,     1.58 tokens per second)\n",
      "llama_print_timings:       total time =   16505.38 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.77 ms /    27 runs   (    0.40 ms per token,  2506.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.85 ms /    12 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   16715.41 ms /    26 runs   (  642.90 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =   17434.94 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.59 ms /    29 runs   (    0.40 ms per token,  2501.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.83 ms /    12 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   17892.37 ms /    28 runs   (  639.01 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =   18616.91 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      30.07 ms /    74 runs   (    0.41 ms per token,  2461.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.55 ms /    12 tokens (   52.80 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   47701.72 ms /    73 runs   (  653.45 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   48553.80 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    20 runs   (    0.40 ms per token,  2486.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.00 ms /    13 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   12425.56 ms /    19 runs   (  653.98 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13164.01 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.78 ms /    27 runs   (    0.40 ms per token,  2504.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.96 ms /    12 tokens (   54.66 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =   16858.94 ms /    26 runs   (  648.42 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   17593.96 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.81 ms /    41 runs   (    0.41 ms per token,  2439.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.80 ms /    12 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   26466.03 ms /    40 runs   (  661.65 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   27232.09 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.53 ms /    39 runs   (    0.40 ms per token,  2511.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     585.60 ms /    11 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   25351.69 ms /    38 runs   (  667.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26051.54 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.16 ms /    38 runs   (    0.40 ms per token,  2506.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.80 ms /    12 tokens (   52.90 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   24863.36 ms /    37 runs   (  671.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   25608.52 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.16 ms /    33 runs   (    0.40 ms per token,  2506.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     689.91 ms /    13 tokens (   53.07 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   20770.26 ms /    32 runs   (  649.07 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   21556.84 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    20 runs   (    0.41 ms per token,  2462.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.48 ms /    12 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   12790.52 ms /    19 runs   (  673.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13478.81 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.36 ms /    54 runs   (    0.41 ms per token,  2415.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.15 ms /    12 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   35619.99 ms /    53 runs   (  672.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   36421.88 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.18 ms /    54 runs   (    0.45 ms per token,  2233.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.28 ms /    11 tokens (   53.66 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   35681.14 ms /    53 runs   (  673.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   36442.06 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.08 ms /    38 runs   (    0.40 ms per token,  2520.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.39 ms /    11 tokens (   54.40 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   24930.45 ms /    37 runs   (  673.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25641.57 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.15 ms /    22 runs   (    0.42 ms per token,  2405.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     722.04 ms /    13 tokens (   55.54 ms per token,    18.00 tokens per second)\n",
      "llama_print_timings:        eval time =   13509.52 ms /    21 runs   (  643.31 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   14296.18 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.31 ms /    23 runs   (    0.40 ms per token,  2471.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.42 ms /    11 tokens (   53.95 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   14310.73 ms /    22 runs   (  650.49 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   14970.96 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.25 ms /    28 runs   (    0.40 ms per token,  2488.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.20 ms /    12 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   18000.32 ms /    27 runs   (  666.68 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18716.35 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.60 ms /    39 runs   (    0.40 ms per token,  2500.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.72 ms /    12 tokens (   52.89 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   25631.77 ms /    38 runs   (  674.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26379.84 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.75 ms /    44 runs   (    0.40 ms per token,  2479.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     699.75 ms /    13 tokens (   53.83 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   28987.41 ms /    43 runs   (  674.13 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   29814.05 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    20 runs   (    0.41 ms per token,  2446.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.51 ms /    12 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   12663.68 ms /    19 runs   (  666.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13356.63 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.55 ms /    50 runs   (    0.41 ms per token,  2432.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.93 ms /    13 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   33231.01 ms /    49 runs   (  678.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   34059.45 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.96 ms /    22 runs   (    0.41 ms per token,  2454.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.81 ms /    11 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   13717.42 ms /    21 runs   (  653.21 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   14371.19 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.22 ms /    28 runs   (    0.40 ms per token,  2495.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.41 ms /    12 tokens (   52.87 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   17828.71 ms /    27 runs   (  660.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   18544.90 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    17 runs   (    0.41 ms per token,  2468.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.22 ms /    12 tokens (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   10579.71 ms /    16 runs   (  661.23 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11264.73 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.83 ms /    32 runs   (    0.40 ms per token,  2494.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     629.89 ms /    12 tokens (   52.49 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   20056.92 ms /    31 runs   (  647.00 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   20779.59 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      35.69 ms /    88 runs   (    0.41 ms per token,  2465.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.19 ms /    12 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   57822.89 ms /    87 runs   (  664.63 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   58718.33 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.77 ms /    34 runs   (    0.41 ms per token,  2468.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.11 ms /    12 tokens (   52.84 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   21531.74 ms /    33 runs   (  652.48 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   22266.07 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.60 ms /    26 runs   (    0.41 ms per token,  2453.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.93 ms /    12 tokens (   53.49 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   16642.18 ms /    25 runs   (  665.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17359.36 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.39 ms /    23 runs   (    0.41 ms per token,  2448.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.51 ms /    13 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   14700.67 ms /    22 runs   (  668.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15450.87 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.79 ms /    37 runs   (    0.40 ms per token,  2502.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     629.39 ms /    12 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   24007.81 ms /    36 runs   (  666.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24744.41 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.28 ms /    30 runs   (    0.41 ms per token,  2442.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.36 ms /    12 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   19417.84 ms /    29 runs   (  669.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20136.49 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.27 ms /    23 runs   (    0.40 ms per token,  2482.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.21 ms /    11 tokens (   53.84 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   14876.25 ms /    22 runs   (  676.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15535.67 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.35 ms /    33 runs   (    0.40 ms per token,  2472.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.79 ms /    12 tokens (   52.73 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   21247.20 ms /    32 runs   (  663.98 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21976.83 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.58 ms /    21 runs   (    0.41 ms per token,  2446.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     697.86 ms /    13 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   12804.62 ms /    20 runs   (  640.23 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =   13564.01 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      29.62 ms /    71 runs   (    0.42 ms per token,  2396.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.84 ms /    12 tokens (   53.32 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   45123.74 ms /    70 runs   (  644.62 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   45978.51 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.72 ms /    29 runs   (    0.40 ms per token,  2473.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     602.31 ms /    11 tokens (   54.76 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =   18200.89 ms /    28 runs   (  650.03 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   18887.19 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.22 ms /    23 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.86 ms /    12 tokens (   53.32 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   14226.40 ms /    22 runs   (  646.65 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   14934.24 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.23 ms /    40 runs   (    0.41 ms per token,  2464.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.45 ms /    12 tokens (   52.62 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   26212.89 ms /    39 runs   (  672.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26961.25 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.36 ms /    55 runs   (    0.41 ms per token,  2460.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.74 ms /    13 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   36349.34 ms /    54 runs   (  673.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   37194.40 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.64 ms /    28 runs   (    0.45 ms per token,  2214.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.68 ms /    11 tokens (   53.79 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   18030.57 ms /    27 runs   (  667.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18709.49 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.00 ms /    38 runs   (    0.39 ms per token,  2532.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     584.75 ms /    11 tokens (   53.16 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   24658.20 ms /    37 runs   (  666.44 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   25351.92 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.62 ms /    31 runs   (    0.41 ms per token,  2455.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.84 ms /    12 tokens (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   19785.69 ms /    30 runs   (  659.52 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   20521.14 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.94 ms /    22 runs   (    0.41 ms per token,  2462.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     611.85 ms /    11 tokens (   55.62 ms per token,    17.98 tokens per second)\n",
      "llama_print_timings:        eval time =   13801.14 ms /    21 runs   (  657.20 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14477.81 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.20 ms /    23 runs   (    0.40 ms per token,  2498.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.95 ms /    11 tokens (   54.36 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   14654.00 ms /    22 runs   (  666.09 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15318.00 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      28.11 ms /    69 runs   (    0.41 ms per token,  2454.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.48 ms /    12 tokens (   53.12 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   45712.75 ms /    68 runs   (  672.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   46552.05 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.44 ms /    50 runs   (    0.41 ms per token,  2446.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.82 ms /    12 tokens (   53.07 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   32569.68 ms /    49 runs   (  664.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   33353.30 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.18 ms /    23 runs   (    0.40 ms per token,  2504.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.56 ms /    12 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   14572.00 ms /    22 runs   (  662.36 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15279.42 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.99 ms /    20 runs   (    0.40 ms per token,  2502.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.89 ms /    11 tokens (   54.26 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   12551.42 ms /    19 runs   (  660.60 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13206.87 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.22 ms /    31 runs   (    0.39 ms per token,  2536.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.03 ms /    13 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   19757.14 ms /    30 runs   (  658.57 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   20525.89 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.95 ms /    27 runs   (    0.41 ms per token,  2466.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.73 ms /    12 tokens (   52.98 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   17490.92 ms /    26 runs   (  672.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18206.26 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.12 ms /    28 runs   (    0.40 ms per token,  2517.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.75 ms /    12 tokens (   52.73 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   17713.00 ms /    27 runs   (  656.04 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   18427.25 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.27 ms /    38 runs   (    0.40 ms per token,  2489.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     730.20 ms /    14 tokens (   52.16 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   24933.97 ms /    37 runs   (  673.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25775.33 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.31 ms /    30 runs   (    0.41 ms per token,  2436.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.03 ms /    12 tokens (   53.75 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   19400.76 ms /    29 runs   (  668.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20133.94 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.49 ms /    60 runs   (    0.41 ms per token,  2450.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     617.88 ms /    11 tokens (   56.17 ms per token,    17.80 tokens per second)\n",
      "llama_print_timings:        eval time =   39490.29 ms /    59 runs   (  669.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   40283.25 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.50 ms /    23 runs   (    0.41 ms per token,  2422.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.60 ms /    12 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   14722.87 ms /    22 runs   (  669.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15425.64 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.93 ms /    29 runs   (    0.41 ms per token,  2431.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.27 ms /    11 tokens (   53.84 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   19003.06 ms /    28 runs   (  678.68 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19678.86 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.93 ms /    29 runs   (    0.41 ms per token,  2431.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.99 ms /    13 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   18775.67 ms /    28 runs   (  670.56 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19539.87 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.43 ms /    28 runs   (    0.41 ms per token,  2449.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.47 ms /    13 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   17985.56 ms /    27 runs   (  666.13 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18751.22 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.38 ms /    62 runs   (    0.41 ms per token,  2442.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     586.80 ms /    11 tokens (   53.35 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   40677.72 ms /    61 runs   (  666.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   41444.98 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.90 ms /    19 runs   (    0.42 ms per token,  2404.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.28 ms /    12 tokens (   54.11 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   12049.70 ms /    18 runs   (  669.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12753.51 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.06 ms /    20 runs   (    0.40 ms per token,  2482.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.12 ms /    11 tokens (   54.56 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   12721.16 ms /    19 runs   (  669.53 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13379.55 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      34.32 ms /    85 runs   (    0.40 ms per token,  2476.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     701.38 ms /    13 tokens (   53.95 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   56494.16 ms /    84 runs   (  672.55 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   57443.87 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.35 ms /    23 runs   (    0.41 ms per token,  2461.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.72 ms /    12 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   14683.89 ms /    22 runs   (  667.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15392.10 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.48 ms /    23 runs   (    0.41 ms per token,  2425.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     584.65 ms /    11 tokens (   53.15 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   14540.47 ms /    22 runs   (  660.93 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15192.45 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.08 ms /    30 runs   (    0.40 ms per token,  2482.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     586.74 ms /    11 tokens (   53.34 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   19393.88 ms /    29 runs   (  668.75 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20067.87 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.90 ms /    32 runs   (    0.43 ms per token,  2302.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.49 ms /    11 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   20785.29 ms /    31 runs   (  670.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21475.17 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      50.17 ms /   122 runs   (    0.41 ms per token,  2431.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.47 ms /    12 tokens (   53.37 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   81542.19 ms /   121 runs   (  673.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   82543.95 ms /   133 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.60 ms /    29 runs   (    0.40 ms per token,  2501.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     627.40 ms /    12 tokens (   52.28 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   18282.49 ms /    28 runs   (  652.95 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   18994.32 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1700 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.39 ms /    30 runs   (    0.41 ms per token,  2420.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.74 ms /    13 tokens (   52.13 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   19320.68 ms /    29 runs   (  666.23 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20085.81 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      38.27 ms /    94 runs   (    0.41 ms per token,  2456.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.54 ms /    12 tokens (   52.71 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   62465.05 ms /    93 runs   (  671.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   63376.86 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.53 ms /    23 runs   (    0.41 ms per token,  2413.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.82 ms /    13 tokens (   52.14 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   14778.84 ms /    22 runs   (  671.77 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15524.57 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.28 ms /    43 runs   (    0.40 ms per token,  2488.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.28 ms /    12 tokens (   52.77 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   28010.09 ms /    42 runs   (  666.91 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28769.57 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.01 ms /    30 runs   (    0.40 ms per token,  2497.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     664.59 ms /    12 tokens (   55.38 ms per token,    18.06 tokens per second)\n",
      "llama_print_timings:        eval time =   19170.90 ms /    29 runs   (  661.07 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19923.93 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.01 ms /    22 runs   (    0.41 ms per token,  2441.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.87 ms /    12 tokens (   54.24 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   13810.04 ms /    21 runs   (  657.62 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14524.63 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.29 ms /    20 runs   (    0.41 ms per token,  2413.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.18 ms /    12 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   13001.34 ms /    19 runs   (  684.28 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13694.16 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      34.25 ms /    84 runs   (    0.41 ms per token,  2452.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.39 ms /    11 tokens (   53.85 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   55383.86 ms /    83 runs   (  667.28 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   56225.50 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.21 ms /    35 runs   (    0.41 ms per token,  2463.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.84 ms /    13 tokens (   52.83 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   22281.92 ms /    34 runs   (  655.35 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   23070.98 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.65 ms /    31 runs   (    0.41 ms per token,  2450.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.19 ms /    12 tokens (   56.52 ms per token,    17.69 tokens per second)\n",
      "llama_print_timings:        eval time =   19873.90 ms /    30 runs   (  662.46 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20642.49 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.57 ms /    18 runs   (    0.42 ms per token,  2378.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     619.66 ms /    11 tokens (   56.33 ms per token,    17.75 tokens per second)\n",
      "llama_print_timings:        eval time =   11435.96 ms /    17 runs   (  672.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12109.16 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.57 ms /    29 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     696.83 ms /    13 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   18803.61 ms /    28 runs   (  671.56 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19583.75 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      44.57 ms /   108 runs   (    0.41 ms per token,  2423.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.75 ms /    12 tokens (   54.98 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =   72168.35 ms /   107 runs   (  674.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   73148.24 ms /   119 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.92 ms /    32 runs   (    0.40 ms per token,  2476.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.80 ms /    11 tokens (   53.80 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   20720.05 ms /    31 runs   (  668.39 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21405.53 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.31 ms /    28 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.38 ms /    13 tokens (   52.11 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =   18134.36 ms /    27 runs   (  671.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18892.26 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.17 ms /    36 runs   (    0.42 ms per token,  2373.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.49 ms /    12 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   23615.87 ms /    35 runs   (  674.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   24359.47 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.04 ms /    46 runs   (    0.41 ms per token,  2416.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     628.52 ms /    12 tokens (   52.38 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   30485.39 ms /    45 runs   (  677.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   31249.30 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.45 ms /    43 runs   (    0.41 ms per token,  2464.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     626.39 ms /    11 tokens (   56.94 ms per token,    17.56 tokens per second)\n",
      "llama_print_timings:        eval time =   28421.51 ms /    42 runs   (  676.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   29174.59 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      38.45 ms /    94 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.79 ms /    12 tokens (   52.73 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   62605.27 ms /    93 runs   (  673.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   63514.81 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.00 ms /    42 runs   (    0.40 ms per token,  2470.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.46 ms /    12 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   27095.82 ms /    41 runs   (  660.87 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   27862.48 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.30 ms /    23 runs   (    0.40 ms per token,  2472.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.96 ms /    11 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   14232.99 ms /    22 runs   (  646.95 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   14890.32 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.82 ms /    29 runs   (    0.41 ms per token,  2452.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.81 ms /    13 tokens (   52.29 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   18378.58 ms /    28 runs   (  656.38 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19143.50 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.49 ms /    45 runs   (    0.41 ms per token,  2434.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.08 ms /    11 tokens (   53.64 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   29586.33 ms /    44 runs   (  672.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   30308.01 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.11 ms /    56 runs   (    0.41 ms per token,  2423.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.86 ms /    12 tokens (   53.57 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   37075.13 ms /    55 runs   (  674.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   37881.25 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      34.69 ms /    86 runs   (    0.40 ms per token,  2479.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.60 ms /    12 tokens (   54.55 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   57137.90 ms /    85 runs   (  672.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   58045.15 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    20 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.50 ms /    12 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   12650.56 ms /    19 runs   (  665.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13352.32 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /    20 runs   (    0.41 ms per token,  2432.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.06 ms /    12 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   13002.37 ms /    19 runs   (  684.34 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13698.56 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.62 ms /    44 runs   (    0.40 ms per token,  2497.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.51 ms /    12 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   28978.98 ms /    43 runs   (  673.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   29741.38 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.73 ms /    63 runs   (    0.41 ms per token,  2448.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.01 ms /    12 tokens (   52.50 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   41764.47 ms /    62 runs   (  673.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   42579.60 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.94 ms /    30 runs   (    0.40 ms per token,  2511.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.73 ms /    12 tokens (   52.89 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   19368.98 ms /    29 runs   (  667.90 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20092.94 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.19 ms /    23 runs   (    0.40 ms per token,  2502.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     725.35 ms /    14 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   14760.46 ms /    22 runs   (  670.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15551.58 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.66 ms /    29 runs   (    0.40 ms per token,  2487.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.52 ms /    12 tokens (   54.38 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =   18661.39 ms /    28 runs   (  666.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19398.61 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.66 ms /    66 runs   (    0.40 ms per token,  2475.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.12 ms /    12 tokens (   53.18 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   43579.04 ms /    65 runs   (  670.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   44409.39 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.68 ms /    24 runs   (    0.40 ms per token,  2480.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.86 ms /    11 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   15152.05 ms /    23 runs   (  658.78 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15813.09 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.86 ms /    44 runs   (    0.41 ms per token,  2463.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.41 ms /    13 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   28502.33 ms /    43 runs   (  662.84 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   29318.58 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.06 ms /    32 runs   (    0.41 ms per token,  2450.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.02 ms /    12 tokens (   57.25 ms per token,    17.47 tokens per second)\n",
      "llama_print_timings:        eval time =   20762.43 ms /    31 runs   (  669.76 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21542.36 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.94 ms /    30 runs   (    0.40 ms per token,  2513.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.89 ms /    12 tokens (   54.32 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   19097.05 ms /    29 runs   (  658.52 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19836.27 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      29.87 ms /    66 runs   (    0.45 ms per token,  2209.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     585.91 ms /    11 tokens (   53.26 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   43725.90 ms /    65 runs   (  672.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   44522.63 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.99 ms /    29 runs   (    0.41 ms per token,  2418.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.07 ms /    12 tokens (   53.01 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   18840.14 ms /    28 runs   (  672.86 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19563.70 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.10 ms /    23 runs   (    0.40 ms per token,  2528.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     602.14 ms /    11 tokens (   54.74 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =   14912.26 ms /    22 runs   (  677.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15581.38 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.55 ms /    29 runs   (    0.40 ms per token,  2510.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     689.32 ms /    13 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   18638.22 ms /    28 runs   (  665.65 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19412.47 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.73 ms /    32 runs   (    0.40 ms per token,  2513.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.89 ms /    12 tokens (   53.66 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   20874.30 ms /    31 runs   (  673.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21611.84 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.64 ms /    66 runs   (    0.40 ms per token,  2477.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.40 ms /    12 tokens (   54.62 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   43559.15 ms /    65 runs   (  670.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   44407.35 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      35.73 ms /    85 runs   (    0.42 ms per token,  2379.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     658.08 ms /    12 tokens (   54.84 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =   55065.93 ms /    84 runs   (  655.55 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   55978.83 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.91 ms /    40 runs   (    0.40 ms per token,  2514.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.92 ms /    13 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   25507.00 ms /    39 runs   (  654.03 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   26304.54 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.25 ms /    33 runs   (    0.40 ms per token,  2490.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.00 ms /    12 tokens (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   21033.57 ms /    32 runs   (  657.30 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21767.88 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.77 ms /    34 runs   (    0.43 ms per token,  2301.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.84 ms /    13 tokens (   52.30 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   21769.70 ms /    33 runs   (  659.69 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   22553.74 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.68 ms /    26 runs   (    0.41 ms per token,  2434.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.49 ms /    11 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   16799.35 ms /    25 runs   (  671.97 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17466.24 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.89 ms /    22 runs   (    0.40 ms per token,  2473.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.91 ms /    12 tokens (   52.91 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   14065.66 ms /    21 runs   (  669.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14765.11 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.90 ms /    42 runs   (    0.40 ms per token,  2485.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.61 ms /    12 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   27454.87 ms /    41 runs   (  669.63 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28215.67 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.70 ms /    29 runs   (    0.40 ms per token,  2478.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.69 ms /    12 tokens (   53.14 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   18557.87 ms /    28 runs   (  662.78 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19279.52 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.16 ms /    25 runs   (    0.41 ms per token,  2459.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.83 ms /    11 tokens (   54.35 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   16382.76 ms /    24 runs   (  682.61 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   17055.90 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.36 ms /    33 runs   (    0.40 ms per token,  2470.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.69 ms /    12 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   21283.84 ms /    32 runs   (  665.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22011.37 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.46 ms /    52 runs   (    0.41 ms per token,  2423.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.13 ms /    12 tokens (   52.76 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   33867.40 ms /    51 runs   (  664.07 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   34652.52 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.52 ms /    30 runs   (    0.42 ms per token,  2395.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.75 ms /    13 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   19416.67 ms /    29 runs   (  669.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20186.15 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.27 ms /    27 runs   (    0.42 ms per token,  2396.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.29 ms /    12 tokens (   53.52 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   17393.62 ms /    26 runs   (  668.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18115.83 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.74 ms /    29 runs   (    0.40 ms per token,  2469.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.83 ms /    12 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   18936.28 ms /    28 runs   (  676.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19650.98 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    20 runs   (    0.41 ms per token,  2453.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.02 ms /    13 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   12632.64 ms /    19 runs   (  664.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13372.29 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.40 ms /    33 runs   (    0.41 ms per token,  2462.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.10 ms /    12 tokens (   53.09 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   21286.55 ms /    32 runs   (  665.20 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22020.63 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.78 ms /    27 runs   (    0.40 ms per token,  2505.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.87 ms /    12 tokens (   53.32 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   17069.08 ms /    26 runs   (  656.50 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   17788.01 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.96 ms /    22 runs   (    0.41 ms per token,  2454.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.32 ms /    13 tokens (   52.26 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   13874.43 ms /    21 runs   (  660.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14619.13 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.87 ms /    30 runs   (    0.40 ms per token,  2527.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.70 ms /    11 tokens (   53.61 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   18915.58 ms /    29 runs   (  652.26 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   19593.34 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.98 ms /    30 runs   (    0.40 ms per token,  2504.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.21 ms /    12 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   19297.37 ms /    29 runs   (  665.43 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20020.42 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.92 ms /    30 runs   (    0.40 ms per token,  2516.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     588.81 ms /    11 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   19443.06 ms /    29 runs   (  670.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20118.45 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.95 ms /    66 runs   (    0.41 ms per token,  2449.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.38 ms /    12 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   43575.68 ms /    65 runs   (  670.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   44405.85 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.73 ms /    31 runs   (    0.41 ms per token,  2435.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.27 ms /    11 tokens (   53.75 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   19892.57 ms /    30 runs   (  663.09 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20574.54 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.75 ms /    36 runs   (    0.41 ms per token,  2440.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.06 ms /    12 tokens (   54.42 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   23081.43 ms /    35 runs   (  659.47 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   23847.26 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.71 ms /    34 runs   (    0.40 ms per token,  2480.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     608.52 ms /    11 tokens (   55.32 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =   22309.67 ms /    33 runs   (  676.05 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   23015.68 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.45 ms /    26 runs   (    0.40 ms per token,  2487.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.35 ms /    12 tokens (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   16835.51 ms /    25 runs   (  673.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17548.76 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.72 ms /    48 runs   (    0.41 ms per token,  2433.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     703.67 ms /    13 tokens (   54.13 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   31412.87 ms /    47 runs   (  668.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   32259.77 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.52 ms /    33 runs   (    0.41 ms per token,  2441.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.18 ms /    12 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   21059.53 ms /    32 runs   (  658.11 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21790.12 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.41 ms /    23 runs   (    0.41 ms per token,  2443.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.83 ms /    11 tokens (   53.80 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   14487.57 ms /    22 runs   (  658.53 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15146.98 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.95 ms /    69 runs   (    0.41 ms per token,  2468.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.87 ms /    12 tokens (   54.07 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   45878.96 ms /    68 runs   (  674.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   46728.52 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.32 ms /    38 runs   (    0.40 ms per token,  2481.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.60 ms /    12 tokens (   53.47 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   24480.78 ms /    37 runs   (  661.64 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   25232.58 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.27 ms /    33 runs   (    0.40 ms per token,  2486.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.77 ms /    12 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   21270.83 ms /    32 runs   (  664.71 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22006.96 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.19 ms /    23 runs   (    0.40 ms per token,  2502.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.46 ms /    12 tokens (   53.79 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   14626.24 ms /    22 runs   (  664.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15339.28 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.04 ms /    30 runs   (    0.40 ms per token,  2492.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     691.02 ms /    13 tokens (   53.16 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   19226.19 ms /    29 runs   (  662.97 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20004.54 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.07 ms /    30 runs   (    0.40 ms per token,  2485.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.26 ms /    12 tokens (   54.61 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   19253.31 ms /    29 runs   (  663.91 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19995.30 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.12 ms /    44 runs   (    0.41 ms per token,  2428.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     729.09 ms /    12 tokens (   60.76 ms per token,    16.46 tokens per second)\n",
      "llama_print_timings:        eval time =   28727.10 ms /    43 runs   (  668.07 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   29584.15 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.71 ms /    45 runs   (    0.42 ms per token,  2405.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     723.96 ms /    14 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   29489.87 ms /    44 runs   (  670.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   30346.34 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.33 ms /    20 runs   (    0.42 ms per token,  2399.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     666.40 ms /    12 tokens (   55.53 ms per token,    18.01 tokens per second)\n",
      "llama_print_timings:        eval time =   12516.77 ms /    19 runs   (  658.78 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13241.55 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.82 ms /    34 runs   (    0.41 ms per token,  2460.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.49 ms /    12 tokens (   52.87 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   22185.35 ms /    33 runs   (  672.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22919.70 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.61 ms /    23 runs   (    0.42 ms per token,  2393.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.07 ms /    13 tokens (   52.70 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   14559.66 ms /    22 runs   (  661.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15312.22 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.26 ms /    44 runs   (    0.42 ms per token,  2409.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.34 ms /    12 tokens (   52.95 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   28658.78 ms /    43 runs   (  666.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   29421.14 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.23 ms /    20 runs   (    0.41 ms per token,  2429.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.44 ms /    12 tokens (   53.20 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   12761.36 ms /    19 runs   (  671.65 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13456.89 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.46 ms /    28 runs   (    0.41 ms per token,  2442.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.88 ms /    13 tokens (   52.38 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   18151.17 ms /    27 runs   (  672.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18913.52 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      28.22 ms /    70 runs   (    0.40 ms per token,  2480.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.08 ms /    12 tokens (   52.76 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   46543.51 ms /    69 runs   (  674.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   47380.89 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.46 ms /    28 runs   (    0.41 ms per token,  2442.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.72 ms /    12 tokens (   52.98 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   18071.68 ms /    27 runs   (  669.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18788.70 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.62 ms /    23 runs   (    0.42 ms per token,  2392.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.75 ms /    12 tokens (   53.23 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   14998.93 ms /    22 runs   (  681.77 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15709.08 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    19 runs   (    0.41 ms per token,  2416.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     629.94 ms /    12 tokens (   52.49 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   12188.98 ms /    18 runs   (  677.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12873.01 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.73 ms /    23 runs   (    0.42 ms per token,  2363.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.36 ms /    13 tokens (   52.34 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =   14816.48 ms /    22 runs   (  673.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15564.35 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.39 ms /    28 runs   (    0.41 ms per token,  2457.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.28 ms /    12 tokens (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   18035.20 ms /    27 runs   (  667.97 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18754.35 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.97 ms /    20 runs   (    0.40 ms per token,  2510.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.52 ms /    12 tokens (   54.29 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   12718.70 ms /    19 runs   (  669.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13427.92 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.14 ms /    25 runs   (    0.41 ms per token,  2464.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.36 ms /    12 tokens (   52.70 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   15993.59 ms /    24 runs   (  666.40 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16698.50 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.45 ms /    31 runs   (    0.40 ms per token,  2489.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.93 ms /    12 tokens (   52.66 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   20177.75 ms /    30 runs   (  672.59 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20901.11 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.98 ms /    22 runs   (    0.41 ms per token,  2449.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.77 ms /    12 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   13903.41 ms /    21 runs   (  662.07 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14607.77 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.48 ms /    50 runs   (    0.41 ms per token,  2441.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     702.19 ms /    13 tokens (   54.01 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   32280.64 ms /    49 runs   (  658.79 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   33128.11 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.15 ms /    22 runs   (    0.42 ms per token,  2403.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.45 ms /    12 tokens (   52.95 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   13582.05 ms /    21 runs   (  646.76 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   14282.26 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.76 ms /    51 runs   (    0.41 ms per token,  2456.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.93 ms /    12 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   32429.96 ms /    50 runs   (  648.60 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   33219.75 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    19 runs   (    0.41 ms per token,  2461.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.94 ms /    12 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   11832.70 ms /    18 runs   (  657.37 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   12526.91 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1800 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.85 ms /    35 runs   (    0.40 ms per token,  2527.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.21 ms /    13 tokens (   52.40 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   21760.39 ms /    34 runs   (  640.01 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =   22542.25 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.71 ms /    21 runs   (    0.41 ms per token,  2411.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.71 ms /    12 tokens (   52.89 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   13221.77 ms /    20 runs   (  661.09 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13918.14 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.60 ms /    31 runs   (    0.41 ms per token,  2459.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.13 ms /    12 tokens (   53.93 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   19377.03 ms /    30 runs   (  645.90 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   20113.82 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    20 runs   (    0.41 ms per token,  2454.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     629.33 ms /    12 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   12139.34 ms /    19 runs   (  638.91 ms per token,     1.57 tokens per second)\n",
      "llama_print_timings:       total time =   12826.32 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.18 ms /    40 runs   (    0.40 ms per token,  2471.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.25 ms /    13 tokens (   52.10 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   26139.20 ms /    39 runs   (  670.24 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26933.81 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.19 ms /    38 runs   (    0.40 ms per token,  2501.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.99 ms /    12 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   24585.75 ms /    37 runs   (  664.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   25331.46 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.98 ms /    22 runs   (    0.41 ms per token,  2448.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.88 ms /    12 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   14096.72 ms /    21 runs   (  671.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14792.78 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.90 ms /    30 runs   (    0.40 ms per token,  2520.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.81 ms /    12 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   19031.05 ms /    29 runs   (  656.24 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19759.65 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.29 ms /    52 runs   (    0.41 ms per token,  2442.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.44 ms /    12 tokens (   53.37 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   33616.30 ms /    51 runs   (  659.14 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   34409.85 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.54 ms /    31 runs   (    0.40 ms per token,  2472.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     701.81 ms /    13 tokens (   53.99 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   20060.80 ms /    30 runs   (  668.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20852.99 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.29 ms /    23 runs   (    0.40 ms per token,  2475.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.62 ms /    12 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   14692.27 ms /    22 runs   (  667.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15395.78 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.64 ms /    29 runs   (    0.40 ms per token,  2492.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.53 ms /    12 tokens (   54.21 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =   19141.61 ms /    28 runs   (  683.63 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   19876.98 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.88 ms /    26 runs   (    0.42 ms per token,  2390.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.50 ms /    13 tokens (   52.19 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   16857.12 ms /    25 runs   (  674.28 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17610.87 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.91 ms /    29 runs   (    0.41 ms per token,  2435.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     587.05 ms /    11 tokens (   53.37 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   18127.26 ms /    28 runs   (  647.40 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   18797.36 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.46 ms /    43 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     629.52 ms /    12 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   27840.87 ms /    42 runs   (  662.88 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   28597.28 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.66 ms /    55 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     699.69 ms /    13 tokens (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   35910.54 ms /    54 runs   (  665.01 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   36773.47 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.25 ms /    30 runs   (    0.41 ms per token,  2448.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.16 ms /    12 tokens (   53.01 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   19477.61 ms /    29 runs   (  671.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20201.69 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.81 ms /    29 runs   (    0.41 ms per token,  2455.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     726.99 ms /    14 tokens (   51.93 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   18796.65 ms /    28 runs   (  671.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19608.82 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.58 ms /    52 runs   (    0.41 ms per token,  2410.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.88 ms /    12 tokens (   54.49 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =   33778.32 ms /    51 runs   (  662.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   34585.61 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.24 ms /    25 runs   (    0.41 ms per token,  2440.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.47 ms /    12 tokens (   52.87 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   15796.30 ms /    24 runs   (  658.18 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   16502.86 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.37 ms /    30 runs   (    0.41 ms per token,  2424.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.86 ms /    12 tokens (   53.57 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   19186.85 ms /    29 runs   (  661.62 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19917.91 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.04 ms /    30 runs   (    0.40 ms per token,  2491.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.80 ms /    13 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   19183.78 ms /    29 runs   (  661.51 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19954.65 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.94 ms /    44 runs   (    0.41 ms per token,  2452.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.80 ms /    12 tokens (   54.15 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   28206.48 ms /    43 runs   (  655.96 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   28985.83 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.97 ms /    40 runs   (    0.40 ms per token,  2505.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.21 ms /    12 tokens (   52.77 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   25590.28 ms /    39 runs   (  656.16 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   26340.96 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.00 ms /    30 runs   (    0.40 ms per token,  2500.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     690.52 ms /    13 tokens (   53.12 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   19458.45 ms /    29 runs   (  670.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20236.99 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.03 ms /    30 runs   (    0.40 ms per token,  2492.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.82 ms /    12 tokens (   54.40 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   19609.19 ms /    29 runs   (  676.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20349.36 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      34.98 ms /    85 runs   (    0.41 ms per token,  2430.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.28 ms /    12 tokens (   52.69 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   56563.96 ms /    84 runs   (  673.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   57451.62 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.06 ms /    52 runs   (    0.41 ms per token,  2468.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.97 ms /    11 tokens (   57.91 ms per token,    17.27 tokens per second)\n",
      "llama_print_timings:        eval time =   34239.34 ms /    51 runs   (  671.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   35030.47 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.92 ms /    30 runs   (    0.40 ms per token,  2516.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.04 ms /    12 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   19516.53 ms /    29 runs   (  672.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20237.43 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.79 ms /    32 runs   (    0.40 ms per token,  2502.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.68 ms /    11 tokens (   58.24 ms per token,    17.17 tokens per second)\n",
      "llama_print_timings:        eval time =   20820.32 ms /    31 runs   (  671.62 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21554.14 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.06 ms /    37 runs   (    0.41 ms per token,  2457.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.57 ms /    12 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   23756.35 ms /    36 runs   (  659.90 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   24503.36 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.16 ms /    23 runs   (    0.40 ms per token,  2511.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     700.31 ms /    13 tokens (   53.87 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   14655.01 ms /    22 runs   (  666.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15421.83 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.49 ms /    26 runs   (    0.40 ms per token,  2477.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     605.72 ms /    11 tokens (   55.07 ms per token,    18.16 tokens per second)\n",
      "llama_print_timings:        eval time =   16782.83 ms /    25 runs   (  671.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17463.66 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      30.10 ms /    72 runs   (    0.42 ms per token,  2392.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.92 ms /    12 tokens (   53.49 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   47227.09 ms /    71 runs   (  665.17 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   48088.18 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.79 ms /    29 runs   (    0.41 ms per token,  2459.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.18 ms /    12 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   18815.98 ms /    28 runs   (  672.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19536.95 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.59 ms /    68 runs   (    0.41 ms per token,  2464.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.73 ms /    12 tokens (   52.81 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   44563.71 ms /    67 runs   (  665.13 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   45400.30 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.18 ms /    65 runs   (    0.40 ms per token,  2483.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.02 ms /    13 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   42973.09 ms /    64 runs   (  671.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   43845.98 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.47 ms /    45 runs   (    0.41 ms per token,  2436.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     657.48 ms /    12 tokens (   54.79 ms per token,    18.25 tokens per second)\n",
      "llama_print_timings:        eval time =   29527.71 ms /    44 runs   (  671.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   30316.78 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.12 ms /    49 runs   (    0.41 ms per token,  2435.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.15 ms /    13 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   31781.45 ms /    48 runs   (  662.11 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   32605.56 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.02 ms /    25 runs   (    0.40 ms per token,  2495.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.13 ms /    12 tokens (   53.93 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   16140.26 ms /    24 runs   (  672.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16859.03 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      31.11 ms /    77 runs   (    0.40 ms per token,  2475.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     586.29 ms /    11 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   51638.15 ms /    76 runs   (  679.45 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   52450.28 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.06 ms /    30 runs   (    0.40 ms per token,  2486.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.36 ms /    12 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   19193.36 ms /    29 runs   (  661.84 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19914.70 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.81 ms /    30 runs   (    0.39 ms per token,  2539.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.84 ms /    12 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   19225.18 ms /    29 runs   (  662.94 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19947.18 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.23 ms /    45 runs   (    0.41 ms per token,  2467.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.26 ms /    12 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   29390.34 ms /    44 runs   (  667.96 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   30159.33 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.27 ms /    30 runs   (    0.41 ms per token,  2444.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.00 ms /    12 tokens (   57.75 ms per token,    17.32 tokens per second)\n",
      "llama_print_timings:        eval time =   19299.19 ms /    29 runs   (  665.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20079.91 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.53 ms /    26 runs   (    0.41 ms per token,  2468.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.54 ms /    13 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   16343.75 ms /    25 runs   (  653.75 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   17099.32 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.13 ms /    30 runs   (    0.40 ms per token,  2472.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.72 ms /    12 tokens (   52.73 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   19046.82 ms /    29 runs   (  656.79 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19768.14 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.97 ms /    54 runs   (    0.41 ms per token,  2457.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.17 ms /    12 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   35291.71 ms /    53 runs   (  665.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   36087.07 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.16 ms /    30 runs   (    0.41 ms per token,  2467.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     668.82 ms /    11 tokens (   60.80 ms per token,    16.45 tokens per second)\n",
      "llama_print_timings:        eval time =   19387.69 ms /    29 runs   (  668.54 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20144.56 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.90 ms /    24 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.32 ms /    12 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   14894.52 ms /    23 runs   (  647.59 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   15594.96 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      29.25 ms /    72 runs   (    0.41 ms per token,  2461.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     699.51 ms /    13 tokens (   53.81 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   47390.64 ms /    71 runs   (  667.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   48302.38 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.23 ms /    30 runs   (    0.41 ms per token,  2453.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.29 ms /    12 tokens (   54.94 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =   19248.03 ms /    29 runs   (  663.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19995.74 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.13 ms /    30 runs   (    0.40 ms per token,  2472.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.80 ms /    11 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   19281.50 ms /    29 runs   (  664.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19960.67 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.74 ms /    48 runs   (    0.43 ms per token,  2314.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.80 ms /    13 tokens (   52.22 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =   31338.16 ms /    47 runs   (  666.77 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   32165.31 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.35 ms /    23 runs   (    0.45 ms per token,  2221.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     675.53 ms /    12 tokens (   56.29 ms per token,    17.76 tokens per second)\n",
      "llama_print_timings:        eval time =   14481.61 ms /    22 runs   (  658.26 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15230.04 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.67 ms /    29 runs   (    0.40 ms per token,  2484.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.82 ms /    11 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   18722.51 ms /    28 runs   (  668.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19397.50 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.49 ms /    63 runs   (    0.40 ms per token,  2471.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.74 ms /    12 tokens (   54.56 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   41500.64 ms /    62 runs   (  669.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   42342.77 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.43 ms /    55 runs   (    0.41 ms per token,  2452.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.98 ms /    13 tokens (   52.23 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =   35600.42 ms /    54 runs   (  659.27 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   36441.99 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.00 ms /    52 runs   (    0.40 ms per token,  2475.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     586.46 ms /    11 tokens (   53.31 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   34123.14 ms /    51 runs   (  669.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   34862.81 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.27 ms /    66 runs   (    0.41 ms per token,  2420.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.28 ms /    11 tokens (   53.57 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   43764.22 ms /    65 runs   (  673.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   44552.86 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.82 ms /    37 runs   (    0.40 ms per token,  2497.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.29 ms /    12 tokens (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   24194.26 ms /    36 runs   (  672.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24941.33 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.45 ms /    33 runs   (    0.41 ms per token,  2453.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.16 ms /    12 tokens (   53.10 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   21606.03 ms /    32 runs   (  675.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22340.77 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.21 ms /    28 runs   (    0.40 ms per token,  2498.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.76 ms /    12 tokens (   54.98 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =   18061.61 ms /    27 runs   (  668.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18803.00 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.42 ms /    38 runs   (    0.41 ms per token,  2464.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     604.72 ms /    11 tokens (   54.97 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =   24582.52 ms /    37 runs   (  664.39 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   25298.10 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.61 ms /    23 runs   (    0.42 ms per token,  2393.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.36 ms /    14 tokens (   51.74 ms per token,    19.33 tokens per second)\n",
      "llama_print_timings:        eval time =   14702.32 ms /    22 runs   (  668.29 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15493.76 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.74 ms /    42 runs   (    0.40 ms per token,  2508.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.56 ms /    12 tokens (   54.05 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   27442.10 ms /    41 runs   (  669.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28213.53 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.96 ms /    44 runs   (    0.41 ms per token,  2449.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.42 ms /    12 tokens (   53.29 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   28754.04 ms /    43 runs   (  668.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   29523.69 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.72 ms /    51 runs   (    0.41 ms per token,  2461.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.57 ms /    11 tokens (   53.78 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   33153.48 ms /    50 runs   (  663.07 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   33893.05 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.09 ms /    46 runs   (    0.41 ms per token,  2410.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.80 ms /    12 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   29915.48 ms /    45 runs   (  664.79 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   30682.77 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.77 ms /    36 runs   (    0.41 ms per token,  2437.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.15 ms /    12 tokens (   54.60 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   23198.83 ms /    35 runs   (  662.82 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   23959.89 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    20 runs   (    0.40 ms per token,  2486.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.30 ms /    12 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   12577.72 ms /    19 runs   (  661.99 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13270.81 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.63 ms /    26 runs   (    0.41 ms per token,  2445.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.24 ms /    13 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   16511.62 ms /    25 runs   (  660.46 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17265.70 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.09 ms /    44 runs   (    0.41 ms per token,  2431.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.47 ms /    12 tokens (   53.54 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   28640.78 ms /    43 runs   (  666.06 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   29412.65 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.90 ms /    61 runs   (    0.41 ms per token,  2449.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.30 ms /    13 tokens (   52.25 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   40387.50 ms /    60 runs   (  673.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   41246.19 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.22 ms /    35 runs   (    0.41 ms per token,  2461.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.73 ms /    12 tokens (   53.56 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   22857.76 ms /    34 runs   (  672.29 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   23603.27 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.24 ms /    20 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.35 ms /    12 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   12682.43 ms /    19 runs   (  667.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13383.01 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.06 ms /    30 runs   (    0.40 ms per token,  2486.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     602.60 ms /    11 tokens (   54.78 ms per token,    18.25 tokens per second)\n",
      "llama_print_timings:        eval time =   19209.58 ms /    29 runs   (  662.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19899.90 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.50 ms /    33 runs   (    0.41 ms per token,  2445.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.33 ms /    12 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   21240.19 ms /    32 runs   (  663.76 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21977.57 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.28 ms /    23 runs   (    0.40 ms per token,  2478.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.19 ms /    12 tokens (   53.10 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   14630.14 ms /    22 runs   (  665.01 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15333.99 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.68 ms /    41 runs   (    0.41 ms per token,  2458.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     676.16 ms /    13 tokens (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   26834.31 ms /    40 runs   (  670.86 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   27630.21 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.57 ms /    23 runs   (    0.42 ms per token,  2402.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.44 ms /    13 tokens (   52.73 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   14717.20 ms /    22 runs   (  668.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15469.48 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.83 ms /    44 runs   (    0.41 ms per token,  2468.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.85 ms /    12 tokens (   52.90 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   28570.35 ms /    43 runs   (  664.43 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   29333.82 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.11 ms /    59 runs   (    0.41 ms per token,  2447.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.20 ms /    11 tokens (   57.65 ms per token,    17.34 tokens per second)\n",
      "llama_print_timings:        eval time =   38862.28 ms /    58 runs   (  670.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   39668.57 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.06 ms /    40 runs   (    0.40 ms per token,  2490.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     586.17 ms /    11 tokens (   53.29 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   25432.21 ms /    39 runs   (  652.11 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   26134.00 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.16 ms /    20 runs   (    0.41 ms per token,  2452.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     603.24 ms /    11 tokens (   54.84 ms per token,    18.24 tokens per second)\n",
      "llama_print_timings:        eval time =   12648.20 ms /    19 runs   (  665.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13309.24 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =     174.93 ms /   415 runs   (    0.42 ms per token,  2372.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.29 ms /    12 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =  280729.85 ms /   414 runs   (  678.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =  282678.96 ms /   426 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      41.03 ms /   102 runs   (    0.40 ms per token,  2486.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     586.88 ms /    11 tokens (   53.35 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   68243.09 ms /   101 runs   (  675.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   69133.04 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.56 ms /    23 runs   (    0.42 ms per token,  2404.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.05 ms /    13 tokens (   52.77 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   14872.38 ms /    22 runs   (  676.02 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15625.74 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.98 ms /    35 runs   (    0.40 ms per token,  2504.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.78 ms /    12 tokens (   52.90 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   22637.20 ms /    34 runs   (  665.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   23373.28 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.26 ms /    23 runs   (    0.40 ms per token,  2483.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     603.32 ms /    11 tokens (   54.85 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =   14533.79 ms /    22 runs   (  660.63 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15204.63 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.17 ms /    33 runs   (    0.40 ms per token,  2505.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.15 ms /    13 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   21388.38 ms /    32 runs   (  668.39 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22164.18 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.29 ms /    38 runs   (    0.40 ms per token,  2485.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.89 ms /    12 tokens (   53.49 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   24425.27 ms /    37 runs   (  660.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   25177.40 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.53 ms /    23 runs   (    0.41 ms per token,  2412.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.07 ms /    11 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   14369.87 ms /    22 runs   (  653.18 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   15028.69 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.45 ms /    33 runs   (    0.41 ms per token,  2453.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.46 ms /    12 tokens (   53.70 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   21257.59 ms /    32 runs   (  664.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21998.14 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.19 ms /    59 runs   (    0.41 ms per token,  2438.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     623.07 ms /    11 tokens (   56.64 ms per token,    17.65 tokens per second)\n",
      "llama_print_timings:        eval time =   38055.96 ms /    58 runs   (  656.14 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   38853.71 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.17 ms /    35 runs   (    0.40 ms per token,  2470.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.28 ms /    12 tokens (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   22009.37 ms /    34 runs   (  647.33 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   22746.97 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.15 ms /    37 runs   (    0.41 ms per token,  2441.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     711.20 ms /    13 tokens (   54.71 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =   24147.40 ms /    36 runs   (  670.76 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24966.65 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.41 ms /    33 runs   (    0.41 ms per token,  2460.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.09 ms /    12 tokens (   53.34 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   21462.03 ms /    32 runs   (  670.69 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22198.34 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.11 ms /    54 runs   (    0.41 ms per token,  2441.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     671.11 ms /    12 tokens (   55.93 ms per token,    17.88 tokens per second)\n",
      "llama_print_timings:        eval time =   35652.63 ms /    53 runs   (  672.69 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   36481.34 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.70 ms /    34 runs   (    0.40 ms per token,  2482.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.52 ms /    12 tokens (   54.54 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   21790.45 ms /    33 runs   (  660.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   22543.64 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1900 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.34 ms /    30 runs   (    0.41 ms per token,  2431.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.31 ms /    13 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =   19232.12 ms /    29 runs   (  663.18 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20000.37 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.98 ms /    42 runs   (    0.40 ms per token,  2472.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.05 ms /    12 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   27554.74 ms /    41 runs   (  672.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28308.49 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.20 ms /    23 runs   (    0.40 ms per token,  2500.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     582.79 ms /    11 tokens (   52.98 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   14643.07 ms /    22 runs   (  665.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15292.88 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.16 ms /    23 runs   (    0.44 ms per token,  2263.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.32 ms /    12 tokens (   53.44 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   14431.66 ms /    22 runs   (  655.98 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15144.08 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.11 ms /    20 runs   (    0.46 ms per token,  2195.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.38 ms /    12 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   12441.47 ms /    19 runs   (  654.81 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13138.78 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.08 ms /    23 runs   (    0.39 ms per token,  2534.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.46 ms /    13 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   14351.27 ms /    22 runs   (  652.33 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   15097.53 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.27 ms /    28 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.08 ms /    12 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   17566.52 ms /    27 runs   (  650.61 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   18293.53 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.17 ms /    33 runs   (    0.40 ms per token,  2504.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.32 ms /    11 tokens (   53.67 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   21121.27 ms /    32 runs   (  660.04 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21807.62 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.25 ms /    28 runs   (    0.40 ms per token,  2489.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.31 ms /    12 tokens (   54.44 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   17612.20 ms /    27 runs   (  652.30 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   18346.01 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.93 ms /    63 runs   (    0.41 ms per token,  2429.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     721.38 ms /    14 tokens (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_print_timings:        eval time =   40151.50 ms /    62 runs   (  647.60 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   41060.01 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.76 ms /    35 runs   (    0.39 ms per token,  2543.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     588.02 ms /    11 tokens (   53.46 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   22591.59 ms /    34 runs   (  664.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   23282.69 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.14 ms /    38 runs   (    0.40 ms per token,  2509.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.68 ms /    12 tokens (   53.39 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   25024.63 ms /    37 runs   (  676.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25776.71 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.33 ms /    54 runs   (    0.41 ms per token,  2418.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.44 ms /    12 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   35109.33 ms /    53 runs   (  662.44 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   35902.52 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.43 ms /    55 runs   (    0.41 ms per token,  2451.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     708.34 ms /    13 tokens (   54.49 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =   36101.83 ms /    54 runs   (  668.55 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   36970.20 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.84 ms /    46 runs   (    0.41 ms per token,  2441.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.09 ms /    12 tokens (   52.51 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   29922.38 ms /    45 runs   (  664.94 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   30686.86 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.19 ms /    28 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     606.45 ms /    11 tokens (   55.13 ms per token,    18.14 tokens per second)\n",
      "llama_print_timings:        eval time =   18036.86 ms /    27 runs   (  668.03 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18724.93 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.49 ms /    68 runs   (    0.40 ms per token,  2473.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.07 ms /    12 tokens (   52.84 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   44390.49 ms /    67 runs   (  662.54 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   45221.67 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.10 ms /    25 runs   (    0.40 ms per token,  2475.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.37 ms /    11 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   15915.78 ms /    24 runs   (  663.16 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16579.26 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.02 ms /    42 runs   (    0.41 ms per token,  2467.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.64 ms /    12 tokens (   57.14 ms per token,    17.50 tokens per second)\n",
      "llama_print_timings:        eval time =   26580.86 ms /    41 runs   (  648.31 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   27391.81 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.06 ms /    56 runs   (    0.41 ms per token,  2428.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     586.32 ms /    11 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   36758.95 ms /    55 runs   (  668.34 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   37510.12 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.01 ms /    30 runs   (    0.40 ms per token,  2497.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.53 ms /    12 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   19146.05 ms /    29 runs   (  660.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19868.06 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.04 ms /    30 runs   (    0.40 ms per token,  2491.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.28 ms /    12 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   19203.65 ms /    29 runs   (  662.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19930.50 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.54 ms /    39 runs   (    0.40 ms per token,  2509.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.43 ms /    12 tokens (   53.12 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   25473.90 ms /    38 runs   (  670.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26225.24 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.97 ms /    22 runs   (    0.41 ms per token,  2452.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.63 ms /    11 tokens (   54.42 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   13747.69 ms /    21 runs   (  654.65 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   14410.01 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.23 ms /    33 runs   (    0.40 ms per token,  2493.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.27 ms /    11 tokens (   54.12 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   21548.50 ms /    32 runs   (  673.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22239.68 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      35.40 ms /    86 runs   (    0.41 ms per token,  2429.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.04 ms /    13 tokens (   52.23 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   55968.55 ms /    85 runs   (  658.45 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   56908.59 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.17 ms /    54 runs   (    0.41 ms per token,  2435.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.34 ms /    11 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   35196.31 ms /    53 runs   (  664.08 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   35950.40 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.22 ms /    38 runs   (    0.40 ms per token,  2496.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.88 ms /    12 tokens (   53.07 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   24759.14 ms /    37 runs   (  669.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   25508.23 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.01 ms /    30 runs   (    0.40 ms per token,  2498.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     587.68 ms /    11 tokens (   53.43 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   19371.43 ms /    29 runs   (  667.98 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20045.87 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.31 ms /    30 runs   (    0.41 ms per token,  2436.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.03 ms /    12 tokens (   52.84 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   18945.11 ms /    29 runs   (  653.28 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   19666.05 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      30.94 ms /    75 runs   (    0.41 ms per token,  2423.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.57 ms /    12 tokens (   52.80 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   49092.87 ms /    74 runs   (  663.42 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   49947.22 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.34 ms /    20 runs   (    0.42 ms per token,  2398.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.20 ms /    12 tokens (   53.18 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   12425.69 ms /    19 runs   (  653.98 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13122.12 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.32 ms /    20 runs   (    0.42 ms per token,  2402.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.69 ms /    11 tokens (   53.61 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   12584.81 ms /    19 runs   (  662.36 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13233.75 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.51 ms /    31 runs   (    0.40 ms per token,  2478.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.02 ms /    13 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   20074.91 ms /    30 runs   (  669.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20846.18 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.33 ms /    33 runs   (    0.40 ms per token,  2476.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.34 ms /    12 tokens (   55.28 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =   21575.48 ms /    32 runs   (  674.23 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22335.63 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.72 ms /    39 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     666.60 ms /    12 tokens (   55.55 ms per token,    18.00 tokens per second)\n",
      "llama_print_timings:        eval time =   25083.67 ms /    38 runs   (  660.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   25863.86 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.81 ms /    37 runs   (    0.40 ms per token,  2498.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.74 ms /    11 tokens (   53.79 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   23813.55 ms /    36 runs   (  661.49 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   24511.91 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.52 ms /    39 runs   (    0.40 ms per token,  2512.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.01 ms /    12 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   25373.33 ms /    38 runs   (  667.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26126.17 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.22 ms /    54 runs   (    0.41 ms per token,  2430.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.96 ms /    13 tokens (   52.15 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   35717.12 ms /    53 runs   (  673.91 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   36555.13 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.32 ms /    38 runs   (    0.40 ms per token,  2479.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.19 ms /    12 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   25261.10 ms /    37 runs   (  682.73 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   26005.78 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.43 ms /    52 runs   (    0.41 ms per token,  2426.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.36 ms /    12 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   34598.22 ms /    51 runs   (  678.40 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   35380.73 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.28 ms /    25 runs   (    0.41 ms per token,  2432.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     601.89 ms /    11 tokens (   54.72 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =   16230.55 ms /    24 runs   (  676.27 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16906.02 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.49 ms /    60 runs   (    0.41 ms per token,  2450.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.75 ms /    12 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   39850.72 ms /    59 runs   (  675.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   40669.12 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.96 ms /    27 runs   (    0.41 ms per token,  2464.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.61 ms /    13 tokens (   52.59 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   17284.17 ms /    26 runs   (  664.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18045.31 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      33.16 ms /    81 runs   (    0.41 ms per token,  2442.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.78 ms /    12 tokens (   53.15 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   53914.48 ms /    80 runs   (  673.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   54790.14 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    20 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.18 ms /    12 tokens (   52.68 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   12677.41 ms /    19 runs   (  667.23 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13367.92 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.54 ms /    26 runs   (    0.41 ms per token,  2467.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.08 ms /    12 tokens (   52.92 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   16606.86 ms /    25 runs   (  664.27 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17318.17 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.78 ms /    49 runs   (    0.40 ms per token,  2477.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     604.61 ms /    11 tokens (   54.96 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =   31826.67 ms /    48 runs   (  663.06 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   32575.83 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.52 ms /    24 runs   (    0.40 ms per token,  2520.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.72 ms /    12 tokens (   53.31 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   15183.40 ms /    23 runs   (  660.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15891.89 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.25 ms /    23 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.95 ms /    12 tokens (   52.91 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   14579.84 ms /    22 runs   (  662.72 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15281.38 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.97 ms /    30 runs   (    0.40 ms per token,  2506.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.53 ms /    11 tokens (   54.05 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   19402.47 ms /    29 runs   (  669.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20084.31 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.66 ms /    39 runs   (    0.40 ms per token,  2489.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.52 ms /    11 tokens (   54.23 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   25215.98 ms /    38 runs   (  663.58 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   25926.87 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.96 ms /    40 runs   (    0.40 ms per token,  2505.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     706.03 ms /    13 tokens (   54.31 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   26388.31 ms /    39 runs   (  676.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27211.24 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.46 ms /    43 runs   (    0.41 ms per token,  2462.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.44 ms /    12 tokens (   54.04 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   28137.65 ms /    42 runs   (  669.94 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28910.53 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.94 ms /    68 runs   (    0.41 ms per token,  2433.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.47 ms /    12 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   44747.90 ms /    67 runs   (  667.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   45583.22 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.50 ms /    26 runs   (    0.40 ms per token,  2477.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.44 ms /    13 tokens (   53.26 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   16646.90 ms /    25 runs   (  665.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17415.60 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    16 runs   (    0.43 ms per token,  2345.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.94 ms /    12 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   10001.74 ms /    15 runs   (  666.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   10686.09 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.99 ms /    39 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     770.47 ms /    11 tokens (   70.04 ms per token,    14.28 tokens per second)\n",
      "llama_print_timings:        eval time =   25475.19 ms /    38 runs   (  670.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26360.31 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.11 ms /    38 runs   (    0.40 ms per token,  2515.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     601.87 ms /    11 tokens (   54.72 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =   24859.94 ms /    37 runs   (  671.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   25571.39 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.28 ms /    38 runs   (    0.40 ms per token,  2486.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     742.47 ms /    12 tokens (   61.87 ms per token,    16.16 tokens per second)\n",
      "llama_print_timings:        eval time =   24705.93 ms /    37 runs   (  667.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   25558.17 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.37 ms /    52 runs   (    0.43 ms per token,  2324.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.84 ms /    11 tokens (   53.99 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   33810.62 ms /    51 runs   (  662.95 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   34562.93 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.21 ms /    52 runs   (    0.41 ms per token,  2451.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.31 ms /    11 tokens (   57.57 ms per token,    17.37 tokens per second)\n",
      "llama_print_timings:        eval time =   34134.97 ms /    51 runs   (  669.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   34921.26 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.92 ms /    32 runs   (    0.40 ms per token,  2476.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     713.76 ms /    13 tokens (   54.91 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =   20333.25 ms /    31 runs   (  655.91 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21139.80 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      32.38 ms /    75 runs   (    0.43 ms per token,  2316.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.87 ms /    12 tokens (   53.07 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   49506.67 ms /    74 runs   (  669.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   50372.68 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.55 ms /    36 runs   (    0.40 ms per token,  2473.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.39 ms /    11 tokens (   53.58 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   23454.64 ms /    35 runs   (  670.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24149.83 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.37 ms /    20 runs   (    0.42 ms per token,  2389.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.49 ms /    12 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   12623.66 ms /    19 runs   (  664.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13326.14 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.03 ms /    20 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.62 ms /    11 tokens (   54.33 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   12666.00 ms /    19 runs   (  666.63 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13321.29 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.89 ms /    31 runs   (    0.42 ms per token,  2405.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.01 ms /    13 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   19564.55 ms /    30 runs   (  652.15 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   20339.13 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.70 ms /    46 runs   (    0.41 ms per token,  2459.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.17 ms /    12 tokens (   54.43 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   30374.32 ms /    45 runs   (  674.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   31162.53 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.08 ms /    30 runs   (    0.40 ms per token,  2483.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.07 ms /    11 tokens (   54.28 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   19166.48 ms /    29 runs   (  660.91 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19851.31 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.46 ms /    39 runs   (    0.40 ms per token,  2521.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.26 ms /    15 tokens (   51.95 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   25203.74 ms /    38 runs   (  663.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   26097.22 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.58 ms /    28 runs   (    0.41 ms per token,  2417.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.06 ms /    12 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   17798.85 ms /    27 runs   (  659.22 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   18518.49 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.78 ms /    41 runs   (    0.41 ms per token,  2442.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.04 ms /    12 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   26844.25 ms /    40 runs   (  671.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   27600.34 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.99 ms /    25 runs   (    0.40 ms per token,  2503.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.53 ms /    13 tokens (   52.35 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   16101.35 ms /    24 runs   (  670.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16853.12 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.83 ms /    29 runs   (    0.41 ms per token,  2450.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     588.54 ms /    11 tokens (   53.50 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   18666.72 ms /    28 runs   (  666.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19339.44 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.15 ms /    30 runs   (    0.40 ms per token,  2469.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.75 ms /    12 tokens (   52.73 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   19336.48 ms /    29 runs   (  666.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20057.00 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.54 ms /    28 runs   (    0.41 ms per token,  2426.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.23 ms /    12 tokens (   54.60 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   18044.19 ms /    27 runs   (  668.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18781.44 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.24 ms /    30 runs   (    0.44 ms per token,  2266.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     675.78 ms /    13 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   19262.39 ms /    29 runs   (  664.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20031.79 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.39 ms /    43 runs   (    0.40 ms per token,  2471.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.66 ms /    11 tokens (   54.61 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   28055.93 ms /    42 runs   (  668.00 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28781.58 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.82 ms /    26 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.90 ms /    12 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   16521.62 ms /    25 runs   (  660.86 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17230.53 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.62 ms /    30 runs   (    0.42 ms per token,  2376.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.49 ms /    12 tokens (   53.12 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   18718.39 ms /    29 runs   (  645.46 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   19443.50 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      31.30 ms /    76 runs   (    0.41 ms per token,  2428.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.50 ms /    13 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   49271.78 ms /    75 runs   (  656.96 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   50175.01 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.33 ms /    30 runs   (    0.41 ms per token,  2432.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.12 ms /    12 tokens (   53.09 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   18803.27 ms /    29 runs   (  648.39 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   19528.54 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.70 ms /    26 runs   (    0.41 ms per token,  2429.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     626.47 ms /    11 tokens (   56.95 ms per token,    17.56 tokens per second)\n",
      "llama_print_timings:        eval time =   16556.39 ms /    25 runs   (  662.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17258.73 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    20 runs   (    0.41 ms per token,  2461.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     588.93 ms /    11 tokens (   53.54 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   12477.69 ms /    19 runs   (  656.72 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13124.99 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    20 runs   (    0.41 ms per token,  2457.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.24 ms /    12 tokens (   53.52 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   12567.01 ms /    19 runs   (  661.42 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13266.12 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.02 ms /    30 runs   (    0.40 ms per token,  2496.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.03 ms /    13 tokens (   53.31 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   19256.10 ms /    29 runs   (  664.00 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20036.50 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.25 ms /    30 runs   (    0.41 ms per token,  2448.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.95 ms /    12 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   19376.73 ms /    29 runs   (  668.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20100.02 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.25 ms /    20 runs   (    0.41 ms per token,  2425.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.02 ms /    12 tokens (   56.58 ms per token,    17.67 tokens per second)\n",
      "llama_print_timings:        eval time =   12705.59 ms /    19 runs   (  668.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13443.36 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.36 ms /    45 runs   (    0.41 ms per token,  2450.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.37 ms /    12 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   29107.96 ms /    44 runs   (  661.54 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   29874.60 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      37.90 ms /    94 runs   (    0.40 ms per token,  2480.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.11 ms /    12 tokens (   54.01 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   62488.24 ms /    93 runs   (  671.92 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   63413.07 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.83 ms /    42 runs   (    0.40 ms per token,  2495.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.79 ms /    11 tokens (   54.34 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   27237.31 ms /    41 runs   (  664.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   27957.58 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.76 ms /    23 runs   (    0.42 ms per token,  2357.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.02 ms /    11 tokens (   57.73 ms per token,    17.32 tokens per second)\n",
      "llama_print_timings:        eval time =   14546.88 ms /    22 runs   (  661.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15251.98 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.26 ms /    20 runs   (    0.41 ms per token,  2421.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.82 ms /    12 tokens (   54.57 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   12732.77 ms /    19 runs   (  670.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13447.01 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.31 ms /    23 runs   (    0.40 ms per token,  2469.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.12 ms /    13 tokens (   52.24 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   14970.97 ms /    22 runs   (  680.50 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15717.39 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.58 ms /    33 runs   (    0.41 ms per token,  2430.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     719.44 ms /    12 tokens (   59.95 ms per token,    16.68 tokens per second)\n",
      "llama_print_timings:        eval time =   21254.80 ms /    32 runs   (  664.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   22071.45 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.14 ms /    30 runs   (    0.40 ms per token,  2471.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.51 ms /    12 tokens (   53.21 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   19453.66 ms /    29 runs   (  670.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20178.70 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.94 ms /    29 runs   (    0.41 ms per token,  2429.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.37 ms /    12 tokens (   53.70 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   18677.96 ms /    28 runs   (  667.07 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19407.62 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.07 ms /    30 runs   (    0.40 ms per token,  2485.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.76 ms /    12 tokens (   53.98 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   19296.06 ms /    29 runs   (  665.38 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20031.56 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.31 ms /    30 runs   (    0.41 ms per token,  2436.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.84 ms /    11 tokens (   54.62 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   19399.58 ms /    29 runs   (  668.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20088.58 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2000 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.47 ms /    23 runs   (    0.41 ms per token,  2427.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.91 ms /    12 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   14897.62 ms /    22 runs   (  677.16 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15597.15 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.03 ms /    27 runs   (    0.41 ms per token,  2447.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     689.39 ms /    13 tokens (   53.03 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   17561.39 ms /    26 runs   (  675.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18329.26 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.55 ms /    23 runs   (    0.42 ms per token,  2408.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     587.26 ms /    11 tokens (   53.39 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   14614.33 ms /    22 runs   (  664.29 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15268.80 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.56 ms /    26 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     629.93 ms /    12 tokens (   52.49 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   16661.33 ms /    25 runs   (  666.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17367.20 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.71 ms /    34 runs   (    0.40 ms per token,  2480.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     599.23 ms /    11 tokens (   54.48 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =   21770.95 ms /    33 runs   (  659.73 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   22469.46 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.42 ms /    23 runs   (    0.41 ms per token,  2440.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.43 ms /    12 tokens (   53.70 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   14448.01 ms /    22 runs   (  656.73 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15159.94 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.88 ms /    23 runs   (    0.43 ms per token,  2326.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.18 ms /    12 tokens (   52.68 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   14568.68 ms /    22 runs   (  662.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15272.15 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.01 ms /    37 runs   (    0.43 ms per token,  2311.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     697.84 ms /    13 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   23939.27 ms /    36 runs   (  664.98 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24750.47 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.10 ms /    30 runs   (    0.40 ms per token,  2479.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.80 ms /    12 tokens (   54.32 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   19239.27 ms /    29 runs   (  663.42 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19978.46 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      36.58 ms /    89 runs   (    0.41 ms per token,  2432.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     587.16 ms /    11 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   58134.72 ms /    88 runs   (  660.62 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   58988.79 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.21 ms /    30 runs   (    0.41 ms per token,  2456.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.78 ms /    12 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   18787.21 ms /    29 runs   (  647.83 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   19516.71 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.94 ms /    32 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.51 ms /    12 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   20356.58 ms /    31 runs   (  656.66 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21086.58 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.06 ms /    22 runs   (    0.41 ms per token,  2428.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.02 ms /    12 tokens (   53.09 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   13968.85 ms /    21 runs   (  665.18 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14669.59 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.00 ms /    24 runs   (    0.42 ms per token,  2399.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.85 ms /    12 tokens (   53.15 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   15343.93 ms /    23 runs   (  667.13 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16052.40 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.83 ms /    24 runs   (    0.41 ms per token,  2441.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.94 ms /    13 tokens (   52.76 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   15607.72 ms /    23 runs   (  678.60 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16363.80 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.24 ms /    25 runs   (    0.41 ms per token,  2442.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.85 ms /    12 tokens (   53.15 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   15953.61 ms /    24 runs   (  664.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16664.44 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.33 ms /    20 runs   (    0.42 ms per token,  2401.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.02 ms /    11 tokens (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   12678.83 ms /    19 runs   (  667.31 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13330.22 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.00 ms /    44 runs   (    0.41 ms per token,  2443.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.45 ms /    13 tokens (   52.80 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   28302.03 ms /    43 runs   (  658.19 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   29119.25 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.35 ms /    23 runs   (    0.41 ms per token,  2460.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.13 ms /    12 tokens (   52.84 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   14540.01 ms /    22 runs   (  660.91 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15241.01 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.12 ms /    30 runs   (    0.40 ms per token,  2475.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.20 ms /    11 tokens (   53.84 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   19515.02 ms /    29 runs   (  672.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20194.59 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.56 ms /    31 runs   (    0.41 ms per token,  2468.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.89 ms /    12 tokens (   53.74 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   19922.55 ms /    30 runs   (  664.09 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20658.64 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.82 ms /    29 runs   (    0.41 ms per token,  2453.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     628.73 ms /    12 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   18782.08 ms /    28 runs   (  670.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19495.71 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.29 ms /    33 runs   (    0.40 ms per token,  2483.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.86 ms /    12 tokens (   53.07 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   20991.87 ms /    32 runs   (  656.00 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21724.81 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.12 ms /    24 runs   (    0.42 ms per token,  2372.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.86 ms /    12 tokens (   53.99 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   15342.21 ms /    23 runs   (  667.05 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16060.88 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.79 ms /    34 runs   (    0.41 ms per token,  2465.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     738.50 ms /    14 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   22339.16 ms /    33 runs   (  676.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   23175.86 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      31.44 ms /    75 runs   (    0.42 ms per token,  2385.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.07 ms /    12 tokens (   53.84 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   49883.01 ms /    74 runs   (  674.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   50753.62 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.70 ms /    31 runs   (    0.41 ms per token,  2441.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.77 ms /    12 tokens (   53.15 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   20188.29 ms /    30 runs   (  672.94 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20917.34 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.43 ms /    23 runs   (    0.41 ms per token,  2439.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.14 ms /    12 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   14691.05 ms /    22 runs   (  667.77 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15402.93 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.30 ms /    51 runs   (    0.42 ms per token,  2394.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.32 ms /    12 tokens (   53.03 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   33368.30 ms /    50 runs   (  667.37 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   34157.15 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.71 ms /    37 runs   (    0.40 ms per token,  2514.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.47 ms /    13 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   24150.29 ms /    36 runs   (  670.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24943.47 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.83 ms /    44 runs   (    0.43 ms per token,  2336.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.63 ms /    12 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   28477.96 ms /    43 runs   (  662.28 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   29250.66 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.91 ms /    32 runs   (    0.40 ms per token,  2478.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.09 ms /    12 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   20184.10 ms /    31 runs   (  651.10 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   20920.97 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.50 ms /    55 runs   (    0.41 ms per token,  2444.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.63 ms /    12 tokens (   52.89 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   36002.31 ms /    54 runs   (  666.71 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   36800.49 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      38.86 ms /    95 runs   (    0.41 ms per token,  2444.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.04 ms /    11 tokens (   54.37 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =   63116.79 ms /    94 runs   (  671.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   63996.31 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.11 ms /    30 runs   (    0.40 ms per token,  2476.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     722.66 ms /    11 tokens (   65.70 ms per token,    15.22 tokens per second)\n",
      "llama_print_timings:        eval time =   19465.83 ms /    29 runs   (  671.24 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20276.61 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.29 ms /    30 runs   (    0.41 ms per token,  2440.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.09 ms /    13 tokens (   52.62 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   19202.85 ms /    29 runs   (  662.17 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19974.70 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.99 ms /    61 runs   (    0.41 ms per token,  2440.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     697.26 ms /    12 tokens (   58.11 ms per token,    17.21 tokens per second)\n",
      "llama_print_timings:        eval time =   40041.85 ms /    60 runs   (  667.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   40919.57 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.12 ms /    25 runs   (    0.40 ms per token,  2470.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.39 ms /    11 tokens (   53.85 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   15814.78 ms /    24 runs   (  658.95 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   16481.14 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    20 runs   (    0.41 ms per token,  2460.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.52 ms /    12 tokens (   54.96 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =   12618.45 ms /    19 runs   (  664.13 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13336.38 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      37.92 ms /    94 runs   (    0.40 ms per token,  2478.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.42 ms /    12 tokens (   53.20 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   61665.79 ms /    93 runs   (  663.07 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   62585.55 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.10 ms /    20 runs   (    0.41 ms per token,  2468.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     700.79 ms /    13 tokens (   53.91 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   12558.39 ms /    19 runs   (  660.97 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13316.84 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.95 ms /    22 runs   (    0.41 ms per token,  2457.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.22 ms /    11 tokens (   54.11 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   13736.57 ms /    21 runs   (  654.12 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   14394.09 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      33.60 ms /    80 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.40 ms /    12 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   52924.85 ms /    79 runs   (  669.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   53806.66 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.25 ms /    59 runs   (    0.41 ms per token,  2433.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.09 ms /    12 tokens (   54.26 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   38737.39 ms /    58 runs   (  667.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   39562.24 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.57 ms /    36 runs   (    0.40 ms per token,  2471.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     725.40 ms /    13 tokens (   55.80 ms per token,    17.92 tokens per second)\n",
      "llama_print_timings:        eval time =   22757.53 ms /    35 runs   (  650.22 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   23586.64 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.24 ms /    40 runs   (    0.41 ms per token,  2462.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.22 ms /    12 tokens (   53.10 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   25565.96 ms /    39 runs   (  655.54 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   26322.68 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.06 ms /    30 runs   (    0.40 ms per token,  2487.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.01 ms /    12 tokens (   53.42 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   19151.55 ms /    29 runs   (  660.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19880.02 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    20 runs   (    0.40 ms per token,  2488.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.01 ms /    12 tokens (   56.83 ms per token,    17.60 tokens per second)\n",
      "llama_print_timings:        eval time =   12502.24 ms /    19 runs   (  658.01 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13242.86 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.09 ms /    30 runs   (    0.44 ms per token,  2292.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     696.73 ms /    13 tokens (   53.59 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   19271.61 ms /    29 runs   (  664.54 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20062.20 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.18 ms /    30 runs   (    0.41 ms per token,  2462.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.34 ms /    12 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   19635.17 ms /    29 runs   (  677.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20355.07 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.93 ms /    32 runs   (    0.40 ms per token,  2475.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     609.85 ms /    11 tokens (   55.44 ms per token,    18.04 tokens per second)\n",
      "llama_print_timings:        eval time =   20326.04 ms /    31 runs   (  655.68 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   21029.09 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.04 ms /    30 runs   (    0.40 ms per token,  2491.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.49 ms /    12 tokens (   53.96 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   18854.43 ms /    29 runs   (  650.15 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   19588.34 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.45 ms /    23 runs   (    0.41 ms per token,  2433.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.68 ms /    13 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   14428.31 ms /    22 runs   (  655.83 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15179.46 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.08 ms /    49 runs   (    0.41 ms per token,  2440.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.30 ms /    12 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   32036.89 ms /    48 runs   (  667.44 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   32810.63 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.06 ms /    32 runs   (    0.41 ms per token,  2450.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.02 ms /    12 tokens (   52.59 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   20675.00 ms /    31 runs   (  666.94 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21400.42 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.00 ms /    32 runs   (    0.41 ms per token,  2462.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.41 ms /    12 tokens (   52.95 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   20722.85 ms /    31 runs   (  668.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21451.22 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      33.72 ms /    82 runs   (    0.41 ms per token,  2431.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     585.28 ms /    11 tokens (   53.21 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   55204.55 ms /    81 runs   (  681.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   56032.44 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      36.42 ms /    90 runs   (    0.40 ms per token,  2471.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.78 ms /    11 tokens (   54.34 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   59602.05 ms /    89 runs   (  669.69 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   60466.21 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.23 ms /    50 runs   (    0.40 ms per token,  2471.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.07 ms /    12 tokens (   52.76 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   32847.37 ms /    49 runs   (  670.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   33627.25 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      36.54 ms /    90 runs   (    0.41 ms per token,  2463.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.74 ms /    12 tokens (   53.39 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   58649.51 ms /    89 runs   (  658.98 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   59559.28 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.57 ms /    28 runs   (    0.41 ms per token,  2420.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.84 ms /    13 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   17779.39 ms /    27 runs   (  658.50 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   18560.43 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.95 ms /    40 runs   (    0.40 ms per token,  2507.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     610.86 ms /    11 tokens (   55.53 ms per token,    18.01 tokens per second)\n",
      "llama_print_timings:        eval time =   25764.26 ms /    39 runs   (  660.62 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   26493.15 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.03 ms /    30 runs   (    0.40 ms per token,  2493.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.29 ms /    12 tokens (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   19146.13 ms /    29 runs   (  660.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19869.69 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.98 ms /    44 runs   (    0.41 ms per token,  2446.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.34 ms /    12 tokens (   53.78 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   28907.31 ms /    43 runs   (  672.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29682.84 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.34 ms /    30 runs   (    0.41 ms per token,  2430.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.08 ms /    11 tokens (   54.10 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   19281.08 ms /    29 runs   (  664.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19964.28 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.24 ms /    30 runs   (    0.41 ms per token,  2450.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     621.08 ms /    11 tokens (   56.46 ms per token,    17.71 tokens per second)\n",
      "llama_print_timings:        eval time =   19288.38 ms /    29 runs   (  665.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19999.53 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.18 ms /    29 runs   (    0.42 ms per token,  2381.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     696.59 ms /    12 tokens (   58.05 ms per token,    17.23 tokens per second)\n",
      "llama_print_timings:        eval time =   18760.65 ms /    28 runs   (  670.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19545.26 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.09 ms /    44 runs   (    0.41 ms per token,  2432.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.14 ms /    13 tokens (   52.09 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   29101.41 ms /    43 runs   (  676.78 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   29906.66 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.32 ms /    25 runs   (    0.45 ms per token,  2208.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.61 ms /    12 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   15751.57 ms /    24 runs   (  656.32 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   16465.78 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.04 ms /    27 runs   (    0.41 ms per token,  2445.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.97 ms /    12 tokens (   53.58 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   17386.06 ms /    26 runs   (  668.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18107.27 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      32.98 ms /    80 runs   (    0.41 ms per token,  2425.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     605.53 ms /    11 tokens (   55.05 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =   53113.72 ms /    79 runs   (  672.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   53955.10 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.07 ms /    30 runs   (    0.44 ms per token,  2294.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.52 ms /    12 tokens (   52.71 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   19523.47 ms /    29 runs   (  673.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20250.33 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.81 ms /    29 runs   (    0.41 ms per token,  2455.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.39 ms /    12 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   18815.56 ms /    28 runs   (  671.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19530.43 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.42 ms /    23 runs   (    0.41 ms per token,  2442.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.30 ms /    12 tokens (   53.69 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   14980.40 ms /    22 runs   (  680.93 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15692.60 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.48 ms /    45 runs   (    0.41 ms per token,  2434.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.83 ms /    12 tokens (   53.15 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   29799.35 ms /    44 runs   (  677.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   30569.88 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.08 ms /    67 runs   (    0.40 ms per token,  2474.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     588.35 ms /    11 tokens (   53.49 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   44224.69 ms /    66 runs   (  670.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   45010.43 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.01 ms /    30 runs   (    0.43 ms per token,  2305.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.07 ms /    12 tokens (   52.92 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   19373.65 ms /    29 runs   (  668.06 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20100.41 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      33.05 ms /    79 runs   (    0.42 ms per token,  2390.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     674.82 ms /    13 tokens (   51.91 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   52520.95 ms /    78 runs   (  673.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   53434.43 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.28 ms /    33 runs   (    0.40 ms per token,  2485.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     719.46 ms /    14 tokens (   51.39 ms per token,    19.46 tokens per second)\n",
      "llama_print_timings:        eval time =   21520.27 ms /    32 runs   (  672.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22335.88 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.37 ms /    45 runs   (    0.41 ms per token,  2450.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.85 ms /    12 tokens (   53.15 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   29397.77 ms /    44 runs   (  668.13 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   30166.39 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.24 ms /    56 runs   (    0.41 ms per token,  2409.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.16 ms /    12 tokens (   52.76 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   37047.73 ms /    55 runs   (  673.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   37845.39 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.17 ms /    30 runs   (    0.41 ms per token,  2464.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.53 ms /    12 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   19259.83 ms /    29 runs   (  664.13 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19986.66 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.87 ms /    51 runs   (    0.41 ms per token,  2443.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.63 ms /    12 tokens (   53.55 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   33629.31 ms /    50 runs   (  672.59 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   34420.96 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      39.45 ms /    98 runs   (    0.40 ms per token,  2484.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.59 ms /    12 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   65090.48 ms /    97 runs   (  671.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   66024.93 ms /   109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.75 ms /    63 runs   (    0.41 ms per token,  2447.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.87 ms /    12 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   41664.35 ms /    62 runs   (  672.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   42483.37 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.94 ms /    27 runs   (    0.41 ms per token,  2468.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.75 ms /    13 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   17557.81 ms /    26 runs   (  675.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18319.43 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.25 ms /    28 runs   (    0.40 ms per token,  2488.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.27 ms /    11 tokens (   53.75 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   17935.86 ms /    27 runs   (  664.29 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   18608.55 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.87 ms /    44 runs   (    0.41 ms per token,  2461.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.53 ms /    12 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   28856.42 ms /    43 runs   (  671.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29623.12 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.91 ms /    27 runs   (    0.40 ms per token,  2474.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     715.64 ms /    13 tokens (   55.05 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =   17427.76 ms /    26 runs   (  670.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18222.12 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.83 ms /    32 runs   (    0.40 ms per token,  2493.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.43 ms /    12 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   20837.41 ms /    31 runs   (  672.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21560.60 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.93 ms /    30 runs   (    0.40 ms per token,  2513.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     694.46 ms /    13 tokens (   53.42 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   19202.24 ms /    29 runs   (  662.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19984.64 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.94 ms /    22 runs   (    0.41 ms per token,  2461.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.46 ms /    12 tokens (   52.95 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   14038.33 ms /    21 runs   (  668.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14737.31 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.56 ms /    34 runs   (    0.40 ms per token,  2506.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.95 ms /    12 tokens (   56.66 ms per token,    17.65 tokens per second)\n",
      "llama_print_timings:        eval time =   21934.02 ms /    33 runs   (  664.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22713.32 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.09 ms /    30 runs   (    0.40 ms per token,  2481.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.14 ms /    12 tokens (   53.01 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   19311.07 ms /    29 runs   (  665.90 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20034.74 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.00 ms /    44 runs   (    0.41 ms per token,  2444.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     699.35 ms /    13 tokens (   53.80 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   28892.64 ms /    43 runs   (  671.92 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29720.53 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.96 ms /    27 runs   (    0.41 ms per token,  2464.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.80 ms /    12 tokens (   52.73 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   17338.11 ms /    26 runs   (  666.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18049.99 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.85 ms /    22 runs   (    0.40 ms per token,  2485.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.59 ms /    12 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   14028.38 ms /    21 runs   (  668.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14728.07 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.14 ms /    28 runs   (    0.40 ms per token,  2513.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.77 ms /    12 tokens (   53.06 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   17879.24 ms /    27 runs   (  662.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   18597.33 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.59 ms /    34 runs   (    0.40 ms per token,  2502.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     612.03 ms /    11 tokens (   55.64 ms per token,    17.97 tokens per second)\n",
      "llama_print_timings:        eval time =   21451.66 ms /    33 runs   (  650.05 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   22163.02 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.08 ms /    46 runs   (    0.41 ms per token,  2410.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.96 ms /    12 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   29918.96 ms /    45 runs   (  664.87 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   30693.29 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2100 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.05 ms /    29 runs   (    0.42 ms per token,  2406.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.29 ms /    12 tokens (   53.86 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   18962.60 ms /    28 runs   (  677.24 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19692.63 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.84 ms /    30 runs   (    0.39 ms per token,  2534.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.65 ms /    13 tokens (   52.36 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   19142.92 ms /    29 runs   (  660.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19909.46 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.45 ms /    31 runs   (    0.40 ms per token,  2489.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.54 ms /    12 tokens (   52.55 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   20141.25 ms /    30 runs   (  671.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20861.97 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      37.37 ms /    88 runs   (    0.42 ms per token,  2355.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.97 ms /    11 tokens (   53.91 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   58947.12 ms /    87 runs   (  677.55 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   59809.13 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.24 ms /    52 runs   (    0.41 ms per token,  2448.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.75 ms /    12 tokens (   53.23 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   34163.54 ms /    51 runs   (  669.87 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   34954.45 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.32 ms /    62 runs   (    0.41 ms per token,  2449.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.93 ms /    11 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   41279.76 ms /    61 runs   (  676.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   42051.20 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.20 ms /    30 runs   (    0.41 ms per token,  2459.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.94 ms /    12 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   19110.29 ms /    29 runs   (  658.98 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19835.53 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.79 ms /    32 runs   (    0.40 ms per token,  2502.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     604.07 ms /    11 tokens (   54.92 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =   20581.08 ms /    31 runs   (  663.91 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21278.54 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.34 ms /    23 runs   (    0.41 ms per token,  2461.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.61 ms /    13 tokens (   52.28 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   14739.53 ms /    22 runs   (  669.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15485.52 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.04 ms /    22 runs   (    0.41 ms per token,  2434.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.94 ms /    12 tokens (   53.49 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   14059.61 ms /    21 runs   (  669.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14764.69 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.02 ms /    32 runs   (    0.41 ms per token,  2457.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.41 ms /    12 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   20553.00 ms /    31 runs   (  663.00 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21285.29 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.20 ms /    32 runs   (    0.41 ms per token,  2423.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.95 ms /    11 tokens (   60.00 ms per token,    16.67 tokens per second)\n",
      "llama_print_timings:        eval time =   20353.12 ms /    31 runs   (  656.55 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21106.94 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.19 ms /    22 runs   (    0.42 ms per token,  2394.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.92 ms /    12 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   14003.16 ms /    21 runs   (  666.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14703.22 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.83 ms /    28 runs   (    0.42 ms per token,  2367.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     676.57 ms /    13 tokens (   52.04 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   17735.02 ms /    27 runs   (  656.85 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   18495.37 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.11 ms /    30 runs   (    0.40 ms per token,  2476.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.39 ms /    12 tokens (   52.70 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   19025.93 ms /    29 runs   (  656.07 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19744.17 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.76 ms /    49 runs   (    0.40 ms per token,  2479.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.66 ms /    11 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   32352.49 ms /    48 runs   (  674.01 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   33090.63 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.06 ms /    30 runs   (    0.40 ms per token,  2487.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.81 ms /    11 tokens (   53.89 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   19509.22 ms /    29 runs   (  672.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20191.65 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.95 ms /    51 runs   (    0.41 ms per token,  2434.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.96 ms /    12 tokens (   53.58 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   33729.18 ms /    50 runs   (  674.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   34521.60 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.55 ms /    30 runs   (    0.42 ms per token,  2389.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.62 ms /    12 tokens (   53.47 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   19122.72 ms /    29 runs   (  659.40 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19856.13 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.98 ms /    30 runs   (    0.40 ms per token,  2505.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     667.13 ms /    12 tokens (   55.59 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =   19227.60 ms /    29 runs   (  663.02 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19982.12 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.02 ms /    23 runs   (    0.44 ms per token,  2295.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.35 ms /    11 tokens (   53.67 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   14714.57 ms /    22 runs   (  668.84 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15374.78 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.78 ms /    32 runs   (    0.43 ms per token,  2322.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.25 ms /    12 tokens (   53.19 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   21134.55 ms /    31 runs   (  681.76 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   21871.97 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.16 ms /    29 runs   (    0.42 ms per token,  2385.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.74 ms /    13 tokens (   52.21 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =   18663.19 ms /    28 runs   (  666.54 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19428.47 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.41 ms /    22 runs   (    0.43 ms per token,  2338.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     689.20 ms /    13 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   14599.17 ms /    21 runs   (  695.20 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   15354.09 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.99 ms /    37 runs   (    0.41 ms per token,  2468.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     732.04 ms /    14 tokens (   52.29 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   24519.10 ms /    36 runs   (  681.09 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   25360.71 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.71 ms /    51 runs   (    0.41 ms per token,  2462.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.97 ms /    13 tokens (   54.23 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   33629.88 ms /    50 runs   (  672.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   34484.89 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.68 ms /    26 runs   (    0.41 ms per token,  2433.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.73 ms /    12 tokens (   53.64 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   16753.17 ms /    25 runs   (  670.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17473.42 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.03 ms /    30 runs   (    0.40 ms per token,  2494.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     612.12 ms /    11 tokens (   55.65 ms per token,    17.97 tokens per second)\n",
      "llama_print_timings:        eval time =   19192.31 ms /    29 runs   (  661.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19891.50 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.11 ms /    30 runs   (    0.40 ms per token,  2476.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.84 ms /    12 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   19322.86 ms /    29 runs   (  666.31 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20046.73 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.54 ms /    45 runs   (    0.41 ms per token,  2427.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.54 ms /    12 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   29262.81 ms /    44 runs   (  665.06 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   30038.50 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.24 ms /    57 runs   (    0.41 ms per token,  2452.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.90 ms /    13 tokens (   52.15 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   37537.09 ms /    56 runs   (  670.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   38380.47 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.05 ms /    24 runs   (    0.42 ms per token,  2389.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.90 ms /    12 tokens (   53.41 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   15420.53 ms /    23 runs   (  670.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16131.71 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.75 ms /    23 runs   (    0.42 ms per token,  2358.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.89 ms /    12 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   14617.05 ms /    22 runs   (  664.41 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15323.42 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.77 ms /    31 runs   (    0.41 ms per token,  2426.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     674.84 ms /    13 tokens (   51.91 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   19922.44 ms /    30 runs   (  664.08 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20689.47 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      32.73 ms /    80 runs   (    0.41 ms per token,  2444.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.86 ms /    12 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   53596.29 ms /    79 runs   (  678.43 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   54464.78 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.15 ms /    30 runs   (    0.40 ms per token,  2469.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.29 ms /    12 tokens (   53.52 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   19379.69 ms /    29 runs   (  668.27 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20109.71 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.70 ms /    26 runs   (    0.41 ms per token,  2430.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.82 ms /    12 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   16870.22 ms /    25 runs   (  674.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   17579.96 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.26 ms /    26 runs   (    0.43 ms per token,  2308.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.04 ms /    13 tokens (   54.16 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   16698.58 ms /    25 runs   (  667.94 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17481.11 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.08 ms /    30 runs   (    0.40 ms per token,  2483.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     697.24 ms /    13 tokens (   53.63 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   19448.88 ms /    29 runs   (  670.65 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20232.33 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.40 ms /    36 runs   (    0.40 ms per token,  2500.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.39 ms /    12 tokens (   52.95 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   23189.53 ms /    35 runs   (  662.56 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   23929.33 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.35 ms /    23 runs   (    0.41 ms per token,  2459.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.26 ms /    12 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   14677.34 ms /    22 runs   (  667.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15377.62 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.44 ms /    30 runs   (    0.41 ms per token,  2411.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.04 ms /    12 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   19327.77 ms /    29 runs   (  666.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20050.67 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.51 ms /    26 runs   (    0.40 ms per token,  2473.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.32 ms /    11 tokens (   53.57 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   16392.01 ms /    25 runs   (  655.68 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   17055.59 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.73 ms /    58 runs   (    0.41 ms per token,  2444.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.39 ms /    12 tokens (   53.87 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   37923.43 ms /    57 runs   (  665.32 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   38739.70 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.10 ms /    25 runs   (    0.40 ms per token,  2474.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.38 ms /    12 tokens (   54.45 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   15678.93 ms /    24 runs   (  653.29 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   16404.55 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.88 ms /    64 runs   (    0.40 ms per token,  2472.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     675.74 ms /    13 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   41640.59 ms /    63 runs   (  660.96 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   42503.41 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.95 ms /    24 runs   (    0.41 ms per token,  2411.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.75 ms /    12 tokens (   53.06 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   15194.55 ms /    23 runs   (  660.63 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15900.71 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.51 ms /    34 runs   (    0.40 ms per token,  2516.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     675.64 ms /    12 tokens (   56.30 ms per token,    17.76 tokens per second)\n",
      "llama_print_timings:        eval time =   21988.85 ms /    33 runs   (  666.33 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22762.67 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.53 ms /    65 runs   (    0.41 ms per token,  2450.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.10 ms /    12 tokens (   52.59 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   42932.67 ms /    64 runs   (  670.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   43754.39 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.30 ms /    33 runs   (    0.40 ms per token,  2481.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.27 ms /    13 tokens (   52.87 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   21366.02 ms /    32 runs   (  667.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22151.03 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.14 ms /    30 runs   (    0.40 ms per token,  2471.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.80 ms /    12 tokens (   54.32 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   19377.90 ms /    29 runs   (  668.20 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20117.01 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.31 ms /    30 runs   (    0.41 ms per token,  2437.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.70 ms /    12 tokens (   52.81 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   19544.52 ms /    29 runs   (  673.95 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20265.72 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      33.98 ms /    80 runs   (    0.42 ms per token,  2354.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     610.14 ms /    11 tokens (   55.47 ms per token,    18.03 tokens per second)\n",
      "llama_print_timings:        eval time =   53063.24 ms /    79 runs   (  671.69 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   53916.56 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.43 ms /    39 runs   (    0.40 ms per token,  2527.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.66 ms /    12 tokens (   52.72 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   25578.06 ms /    38 runs   (  673.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26323.91 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.08 ms /    56 runs   (    0.41 ms per token,  2426.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.38 ms /    13 tokens (   52.26 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   36847.91 ms /    55 runs   (  669.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   37692.30 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.93 ms /    64 runs   (    0.41 ms per token,  2468.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.25 ms /    12 tokens (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   42280.14 ms /    63 runs   (  671.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   43103.27 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      32.33 ms /    79 runs   (    0.41 ms per token,  2443.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     661.18 ms /    12 tokens (   55.10 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =   51993.67 ms /    78 runs   (  666.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   52888.62 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      32.74 ms /    80 runs   (    0.41 ms per token,  2443.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     586.01 ms /    11 tokens (   53.27 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   52814.07 ms /    79 runs   (  668.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   53637.44 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.81 ms /    58 runs   (    0.41 ms per token,  2436.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.40 ms /    11 tokens (   54.31 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   38570.94 ms /    57 runs   (  676.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   39338.77 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.63 ms /    39 runs   (    0.40 ms per token,  2495.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.51 ms /    12 tokens (   53.29 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   25449.47 ms /    38 runs   (  669.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26202.59 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.42 ms /    31 runs   (    0.40 ms per token,  2496.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.26 ms /    13 tokens (   52.25 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   19875.04 ms /    30 runs   (  662.50 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20644.58 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.50 ms /    29 runs   (    0.40 ms per token,  2522.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     586.04 ms /    11 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   18421.94 ms /    28 runs   (  657.93 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19093.21 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.17 ms /    20 runs   (    0.41 ms per token,  2447.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.58 ms /    12 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   12551.62 ms /    19 runs   (  660.61 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13244.05 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.60 ms /    34 runs   (    0.40 ms per token,  2500.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     587.82 ms /    11 tokens (   53.44 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   22275.72 ms /    33 runs   (  675.02 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22962.27 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.59 ms /    45 runs   (    0.41 ms per token,  2420.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.01 ms /    12 tokens (   52.83 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   29509.88 ms /    44 runs   (  670.68 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   30275.57 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.51 ms /    33 runs   (    0.41 ms per token,  2442.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.35 ms /    12 tokens (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   21126.33 ms /    32 runs   (  660.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21860.84 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.15 ms /    32 runs   (    0.41 ms per token,  2432.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.08 ms /    11 tokens (   53.64 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   19991.71 ms /    31 runs   (  644.89 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   20675.20 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.80 ms /    33 runs   (    0.42 ms per token,  2391.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     726.02 ms /    14 tokens (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   20832.15 ms /    32 runs   (  651.00 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   21657.73 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.60 ms /    38 runs   (    0.41 ms per token,  2436.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     668.02 ms /    12 tokens (   55.67 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:        eval time =   24766.07 ms /    37 runs   (  669.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   25544.69 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.30 ms /    33 runs   (    0.40 ms per token,  2480.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.65 ms /    12 tokens (   52.72 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   21315.96 ms /    32 runs   (  666.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22046.25 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.26 ms /    49 runs   (    0.41 ms per token,  2419.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.81 ms /    12 tokens (   52.73 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   32569.67 ms /    48 runs   (  678.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   33347.25 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.19 ms /    20 runs   (    0.41 ms per token,  2441.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.59 ms /    12 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   12497.82 ms /    19 runs   (  657.78 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13191.01 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.52 ms /    44 runs   (    0.42 ms per token,  2376.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.09 ms /    11 tokens (   54.55 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   28211.27 ms /    43 runs   (  656.08 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   28941.91 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.54 ms /    21 runs   (    0.41 ms per token,  2460.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     675.97 ms /    13 tokens (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:        eval time =   13201.00 ms /    20 runs   (  660.05 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13937.04 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.35 ms /    23 runs   (    0.41 ms per token,  2460.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.11 ms /    12 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   14438.82 ms /    22 runs   (  656.31 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15150.02 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.25 ms /    30 runs   (    0.41 ms per token,  2449.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     689.48 ms /    13 tokens (   53.04 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   19132.05 ms /    29 runs   (  659.73 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19908.89 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.19 ms /    36 runs   (    0.39 ms per token,  2537.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.28 ms /    11 tokens (   54.03 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   23609.79 ms /    35 runs   (  674.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   24308.61 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.75 ms /    29 runs   (    0.44 ms per token,  2274.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.18 ms /    12 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   18780.84 ms /    28 runs   (  670.74 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19505.69 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.34 ms /    23 runs   (    0.41 ms per token,  2463.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.83 ms /    12 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   14769.39 ms /    22 runs   (  671.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15474.18 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.06 ms /    32 runs   (    0.44 ms per token,  2275.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.39 ms /    12 tokens (   54.12 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   20689.49 ms /    31 runs   (  667.40 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21437.45 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.92 ms /    29 runs   (    0.41 ms per token,  2432.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     672.07 ms /    13 tokens (   51.70 ms per token,    19.34 tokens per second)\n",
      "llama_print_timings:        eval time =   18679.33 ms /    28 runs   (  667.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19435.47 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.63 ms /    39 runs   (    0.40 ms per token,  2495.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.74 ms /    12 tokens (   53.56 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   25600.45 ms /    38 runs   (  673.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26356.50 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.41 ms /    53 runs   (    0.40 ms per token,  2474.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.19 ms /    11 tokens (   53.84 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   34729.10 ms /    52 runs   (  667.87 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   35475.80 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.10 ms /    44 runs   (    0.41 ms per token,  2430.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.89 ms /    12 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   28545.61 ms /    43 runs   (  663.85 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   29311.01 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.30 ms /    52 runs   (    0.41 ms per token,  2440.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     703.96 ms /    13 tokens (   54.15 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   34009.93 ms /    51 runs   (  666.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   34867.19 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.09 ms /    22 runs   (    0.41 ms per token,  2419.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.34 ms /    12 tokens (   56.53 ms per token,    17.69 tokens per second)\n",
      "llama_print_timings:        eval time =   14017.25 ms /    21 runs   (  667.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14759.49 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.93 ms /    32 runs   (    0.40 ms per token,  2475.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.27 ms /    12 tokens (   53.19 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   20714.92 ms /    31 runs   (  668.22 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21446.67 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.75 ms /    42 runs   (    0.40 ms per token,  2508.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.59 ms /    13 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   27555.69 ms /    41 runs   (  672.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28361.58 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.37 ms /    36 runs   (    0.40 ms per token,  2504.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.56 ms /    12 tokens (   53.96 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   22937.28 ms /    35 runs   (  655.35 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   23689.48 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.11 ms /    62 runs   (    0.41 ms per token,  2468.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.90 ms /    11 tokens (   54.17 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   40631.02 ms /    61 runs   (  666.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   41410.71 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.30 ms /    23 runs   (    0.40 ms per token,  2474.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.49 ms /    12 tokens (   54.04 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   14514.49 ms /    22 runs   (  659.75 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15229.71 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      29.47 ms /    73 runs   (    0.40 ms per token,  2477.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.54 ms /    12 tokens (   52.63 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   48510.07 ms /    72 runs   (  673.75 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   49356.23 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.86 ms /    27 runs   (    0.40 ms per token,  2485.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.87 ms /    13 tokens (   52.84 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   16967.48 ms /    26 runs   (  652.60 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   17731.33 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.63 ms /    21 runs   (    0.46 ms per token,  2179.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.21 ms /    12 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   13411.39 ms /    20 runs   (  670.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14114.13 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.43 ms /    43 runs   (    0.41 ms per token,  2467.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.77 ms /    11 tokens (   54.34 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   28126.64 ms /    42 runs   (  669.68 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28853.45 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.86 ms /    42 runs   (    0.40 ms per token,  2490.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.91 ms /    12 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   27366.31 ms /    41 runs   (  667.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28125.53 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.24 ms /    30 runs   (    0.41 ms per token,  2450.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.84 ms /    13 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   19318.85 ms /    29 runs   (  666.17 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20087.75 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.96 ms /    30 runs   (    0.40 ms per token,  2508.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.28 ms /    12 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   19203.87 ms /    29 runs   (  662.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19924.32 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      28.65 ms /    64 runs   (    0.45 ms per token,  2233.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.67 ms /    12 tokens (   53.22 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   42304.31 ms /    63 runs   (  671.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   43142.07 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.47 ms /    21 runs   (    0.40 ms per token,  2480.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.11 ms /    12 tokens (   53.34 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   13571.60 ms /    20 runs   (  678.58 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14272.91 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2200 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.15 ms /    28 runs   (    0.40 ms per token,  2510.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.04 ms /    12 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   17711.38 ms /    27 runs   (  655.98 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   18432.31 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.87 ms /    44 runs   (    0.43 ms per token,  2331.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.21 ms /    12 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   28770.49 ms /    43 runs   (  669.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29542.19 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.62 ms /    31 runs   (    0.41 ms per token,  2457.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.71 ms /    11 tokens (   54.34 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   20055.12 ms /    30 runs   (  668.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20743.00 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.34 ms /    38 runs   (    0.40 ms per token,  2477.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.31 ms /    12 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   24783.56 ms /    37 runs   (  669.83 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   25528.20 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.67 ms /    39 runs   (    0.40 ms per token,  2488.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.21 ms /    13 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   25736.43 ms /    38 runs   (  677.27 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26549.06 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    20 runs   (    0.40 ms per token,  2488.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.32 ms /    12 tokens (   53.19 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   12836.58 ms /    19 runs   (  675.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13533.32 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.19 ms /    27 runs   (    0.41 ms per token,  2412.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.68 ms /    12 tokens (   53.14 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   17340.27 ms /    26 runs   (  666.93 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18057.25 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.24 ms /    23 runs   (    0.40 ms per token,  2490.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.37 ms /    12 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   14839.82 ms /    22 runs   (  674.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15545.52 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      37.27 ms /    93 runs   (    0.40 ms per token,  2494.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.78 ms /    12 tokens (   52.81 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   61748.17 ms /    92 runs   (  671.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   62652.79 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.42 ms /    41 runs   (    0.40 ms per token,  2496.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.92 ms /    12 tokens (   53.16 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   26793.43 ms /    40 runs   (  669.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   27548.58 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.21 ms /    33 runs   (    0.40 ms per token,  2497.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     676.85 ms /    13 tokens (   52.07 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   21232.24 ms /    32 runs   (  663.51 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   22004.92 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.53 ms /    31 runs   (    0.40 ms per token,  2475.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     700.39 ms /    12 tokens (   58.37 ms per token,    17.13 tokens per second)\n",
      "llama_print_timings:        eval time =   19987.29 ms /    30 runs   (  666.24 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20776.87 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.38 ms /    26 runs   (    0.40 ms per token,  2504.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.94 ms /    11 tokens (   53.81 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   16742.81 ms /    25 runs   (  669.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17409.70 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.12 ms /    44 runs   (    0.41 ms per token,  2427.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     726.95 ms /    14 tokens (   51.93 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   29097.97 ms /    43 runs   (  676.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   29953.01 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.36 ms /    30 runs   (    0.41 ms per token,  2427.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     610.60 ms /    11 tokens (   55.51 ms per token,    18.02 tokens per second)\n",
      "llama_print_timings:        eval time =   19421.72 ms /    29 runs   (  669.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20119.02 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.64 ms /    56 runs   (    0.40 ms per token,  2472.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.78 ms /    12 tokens (   53.15 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   37022.81 ms /    55 runs   (  673.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   37823.38 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      29.75 ms /    73 runs   (    0.41 ms per token,  2453.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.79 ms /    12 tokens (   53.32 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   48668.40 ms /    72 runs   (  675.95 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   49520.97 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.89 ms /    32 runs   (    0.40 ms per token,  2482.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.96 ms /    11 tokens (   54.63 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =   20770.62 ms /    31 runs   (  670.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21464.21 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.43 ms /    26 runs   (    0.40 ms per token,  2491.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.41 ms /    12 tokens (   52.95 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   16733.13 ms /    25 runs   (  669.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17443.70 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.49 ms /    28 runs   (    0.41 ms per token,  2436.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.53 ms /    12 tokens (   53.04 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   18088.16 ms /    27 runs   (  669.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18804.76 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.70 ms /    39 runs   (    0.40 ms per token,  2484.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     610.30 ms /    11 tokens (   55.48 ms per token,    18.02 tokens per second)\n",
      "llama_print_timings:        eval time =   25516.68 ms /    38 runs   (  671.49 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26239.53 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.36 ms /    45 runs   (    0.41 ms per token,  2451.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.90 ms /    11 tokens (   53.72 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   29485.16 ms /    44 runs   (  670.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   30205.83 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.18 ms /    54 runs   (    0.41 ms per token,  2434.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.23 ms /    13 tokens (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   35221.99 ms /    53 runs   (  664.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   36073.43 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.39 ms /    31 runs   (    0.40 ms per token,  2502.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.61 ms /    12 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   20057.53 ms /    30 runs   (  668.58 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20795.95 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.77 ms /    32 runs   (    0.40 ms per token,  2506.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     602.50 ms /    11 tokens (   54.77 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =   20685.16 ms /    31 runs   (  667.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21380.97 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.77 ms /    56 runs   (    0.41 ms per token,  2459.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.11 ms /    12 tokens (   53.34 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   36702.19 ms /    55 runs   (  667.31 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   37504.77 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.88 ms /    32 runs   (    0.40 ms per token,  2484.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.67 ms /    12 tokens (   52.56 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   20533.91 ms /    31 runs   (  662.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21258.00 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.26 ms /    25 runs   (    0.41 ms per token,  2437.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.17 ms /    12 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   15670.80 ms /    24 runs   (  652.95 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   16385.11 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.15 ms /    33 runs   (    0.40 ms per token,  2509.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.98 ms /    13 tokens (   52.23 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =   21124.35 ms /    32 runs   (  660.14 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21899.68 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.11 ms /    64 runs   (    0.41 ms per token,  2451.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.99 ms /    11 tokens (   54.00 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   41900.54 ms /    63 runs   (  665.09 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   42683.59 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.61 ms /    50 runs   (    0.43 ms per token,  2313.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.50 ms /    12 tokens (   53.38 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   32571.10 ms /    49 runs   (  664.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   33364.30 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.29 ms /    52 runs   (    0.41 ms per token,  2442.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.81 ms /    11 tokens (   53.89 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   33414.26 ms /    51 runs   (  655.18 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   34158.61 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.75 ms /    32 runs   (    0.40 ms per token,  2509.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     603.27 ms /    11 tokens (   54.84 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =   20633.93 ms /    31 runs   (  665.61 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21331.53 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.19 ms /    36 runs   (    0.39 ms per token,  2537.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.19 ms /    12 tokens (   54.43 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   22570.21 ms /    35 runs   (  644.86 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   23328.81 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.53 ms /    57 runs   (    0.41 ms per token,  2422.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.83 ms /    12 tokens (   53.32 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   37507.35 ms /    56 runs   (  669.77 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   38311.82 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.71 ms /    32 runs   (    0.43 ms per token,  2333.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     664.01 ms /    12 tokens (   55.33 ms per token,    18.07 tokens per second)\n",
      "llama_print_timings:        eval time =   20509.78 ms /    31 runs   (  661.61 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21271.59 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.28 ms /    28 runs   (    0.40 ms per token,  2481.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.23 ms /    12 tokens (   52.69 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   17729.18 ms /    27 runs   (  656.64 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   18442.33 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.83 ms /    32 runs   (    0.40 ms per token,  2493.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     608.50 ms /    11 tokens (   55.32 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =   20735.38 ms /    31 runs   (  668.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21436.26 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.76 ms /    53 runs   (    0.41 ms per token,  2435.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.23 ms /    13 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   34383.58 ms /    52 runs   (  661.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   35230.04 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      35.03 ms /    86 runs   (    0.41 ms per token,  2455.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.61 ms /    12 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   56716.38 ms /    85 runs   (  667.25 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   57605.99 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      29.61 ms /    73 runs   (    0.41 ms per token,  2465.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.10 ms /    12 tokens (   53.43 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   48449.54 ms /    72 runs   (  672.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   49302.07 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.96 ms /    30 runs   (    0.40 ms per token,  2507.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.94 ms /    12 tokens (   54.58 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   19386.80 ms /    29 runs   (  668.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20128.34 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      33.48 ms /    82 runs   (    0.41 ms per token,  2449.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     586.28 ms /    11 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   54159.11 ms /    81 runs   (  668.63 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   54986.09 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.57 ms /    53 runs   (    0.41 ms per token,  2457.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     750.17 ms /    13 tokens (   57.71 ms per token,    17.33 tokens per second)\n",
      "llama_print_timings:        eval time =   34433.87 ms /    52 runs   (  662.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   35338.66 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.71 ms /    32 runs   (    0.43 ms per token,  2333.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.18 ms /    12 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   20644.25 ms /    31 runs   (  665.94 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21376.43 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.13 ms /    38 runs   (    0.40 ms per token,  2512.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.63 ms /    12 tokens (   53.22 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   24942.58 ms /    37 runs   (  674.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25690.66 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.20 ms /    30 runs   (    0.41 ms per token,  2459.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.04 ms /    12 tokens (   54.42 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   19423.67 ms /    29 runs   (  669.78 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20162.86 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.14 ms /    33 runs   (    0.40 ms per token,  2512.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.29 ms /    12 tokens (   54.19 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =   21392.51 ms /    32 runs   (  668.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22137.84 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.38 ms /    47 runs   (    0.41 ms per token,  2425.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.37 ms /    13 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   31232.12 ms /    46 runs   (  678.96 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   32054.69 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.45 ms /    28 runs   (    0.41 ms per token,  2446.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     599.71 ms /    11 tokens (   54.52 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   17889.39 ms /    27 runs   (  662.57 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   18570.94 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.59 ms /    30 runs   (    0.42 ms per token,  2382.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.39 ms /    12 tokens (   53.12 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   19430.76 ms /    29 runs   (  670.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20156.88 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.93 ms /    35 runs   (    0.40 ms per token,  2513.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     690.91 ms /    12 tokens (   57.58 ms per token,    17.37 tokens per second)\n",
      "llama_print_timings:        eval time =   22239.06 ms /    34 runs   (  654.09 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   23032.08 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      32.18 ms /    77 runs   (    0.42 ms per token,  2392.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.94 ms /    12 tokens (   53.66 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   51333.21 ms /    76 runs   (  675.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   52209.26 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.18 ms /    30 runs   (    0.41 ms per token,  2462.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.28 ms /    13 tokens (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   19504.80 ms /    29 runs   (  672.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20281.12 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.55 ms /    36 runs   (    0.40 ms per token,  2474.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.52 ms /    12 tokens (   53.96 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   23351.38 ms /    35 runs   (  667.18 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24105.08 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.15 ms /    30 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.56 ms /    12 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   19216.35 ms /    29 runs   (  662.63 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19947.59 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.04 ms /    30 runs   (    0.40 ms per token,  2490.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     618.54 ms /    11 tokens (   56.23 ms per token,    17.78 tokens per second)\n",
      "llama_print_timings:        eval time =   19297.32 ms /    29 runs   (  665.42 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20003.15 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      36.72 ms /    90 runs   (    0.41 ms per token,  2450.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.75 ms /    12 tokens (   53.31 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   59867.31 ms /    89 runs   (  672.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   60772.93 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.23 ms /    23 runs   (    0.40 ms per token,  2491.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.01 ms /    13 tokens (   52.62 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   14683.29 ms /    22 runs   (  667.42 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15434.77 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.20 ms /    30 runs   (    0.41 ms per token,  2458.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.57 ms /    12 tokens (   53.46 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   19735.42 ms /    29 runs   (  680.53 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20464.11 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.99 ms /    32 runs   (    0.41 ms per token,  2463.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.38 ms /    12 tokens (   54.45 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   20698.95 ms /    31 runs   (  667.71 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21445.05 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.31 ms /    58 runs   (    0.42 ms per token,  2385.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.06 ms /    12 tokens (   53.50 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   38499.78 ms /    57 runs   (  675.43 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   39312.56 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.38 ms /    23 runs   (    0.41 ms per token,  2452.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.82 ms /    12 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   14782.58 ms /    22 runs   (  671.94 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15492.17 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.23 ms /    62 runs   (    0.41 ms per token,  2457.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     673.52 ms /    13 tokens (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:        eval time =   41033.99 ms /    61 runs   (  672.69 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   41890.83 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.20 ms /    25 runs   (    0.41 ms per token,  2451.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.97 ms /    12 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   16165.73 ms /    24 runs   (  673.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16872.23 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      38.11 ms /    93 runs   (    0.41 ms per token,  2440.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.35 ms /    11 tokens (   54.12 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   61615.42 ms /    92 runs   (  669.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   62488.38 ms /   103 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.21 ms /    25 runs   (    0.41 ms per token,  2448.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.13 ms /    12 tokens (   53.43 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   15997.34 ms /    24 runs   (  666.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16711.85 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.97 ms /    29 runs   (    0.41 ms per token,  2422.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     587.88 ms /    11 tokens (   53.44 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   18656.13 ms /    28 runs   (  666.29 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19328.85 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      36.13 ms /    85 runs   (    0.43 ms per token,  2352.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.16 ms /    12 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   56958.66 ms /    84 runs   (  678.08 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   57856.79 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.14 ms /    30 runs   (    0.40 ms per token,  2471.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     666.75 ms /    12 tokens (   55.56 ms per token,    18.00 tokens per second)\n",
      "llama_print_timings:        eval time =   19274.51 ms /    29 runs   (  664.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20028.99 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.27 ms /    30 runs   (    0.41 ms per token,  2444.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     736.86 ms /    14 tokens (   52.63 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   19295.70 ms /    29 runs   (  665.37 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20120.49 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.37 ms /    23 runs   (    0.41 ms per token,  2455.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.45 ms /    11 tokens (   54.13 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   14449.16 ms /    22 runs   (  656.78 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15111.34 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.29 ms /    32 runs   (    0.42 ms per token,  2408.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.07 ms /    12 tokens (   53.67 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   20358.55 ms /    31 runs   (  656.73 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21096.51 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.37 ms /    23 runs   (    0.41 ms per token,  2455.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     629.75 ms /    12 tokens (   52.48 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   14740.71 ms /    22 runs   (  670.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15436.70 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.03 ms /    27 runs   (    0.41 ms per token,  2447.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.64 ms /    13 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   17317.68 ms /    26 runs   (  666.06 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18077.02 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.33 ms /    36 runs   (    0.40 ms per token,  2511.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.52 ms /    11 tokens (   53.77 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   22784.15 ms /    35 runs   (  650.98 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   23480.77 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.69 ms /    34 runs   (    0.40 ms per token,  2483.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.72 ms /    12 tokens (   53.64 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   21535.19 ms /    33 runs   (  652.58 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   22278.90 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.89 ms /    27 runs   (    0.40 ms per token,  2479.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.77 ms /    12 tokens (   53.15 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   17234.83 ms /    26 runs   (  662.88 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17951.10 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.21 ms /    23 runs   (    0.40 ms per token,  2496.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.91 ms /    12 tokens (   54.58 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   14455.73 ms /    22 runs   (  657.08 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15177.23 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.83 ms /    29 runs   (    0.41 ms per token,  2450.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.18 ms /    12 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   18108.55 ms /    28 runs   (  646.73 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   18823.38 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.58 ms /    23 runs   (    0.42 ms per token,  2401.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.48 ms /    13 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   14341.36 ms /    22 runs   (  651.88 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   15091.84 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.48 ms /    36 runs   (    0.40 ms per token,  2486.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.29 ms /    12 tokens (   57.36 ms per token,    17.43 tokens per second)\n",
      "llama_print_timings:        eval time =   23326.66 ms /    35 runs   (  666.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24120.32 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.73 ms /    51 runs   (    0.41 ms per token,  2459.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.81 ms /    12 tokens (   53.07 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   32963.25 ms /    50 runs   (  659.27 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   33751.46 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.45 ms /    43 runs   (    0.41 ms per token,  2464.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.00 ms /    12 tokens (   54.00 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   26972.15 ms /    42 runs   (  642.19 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =   27750.71 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.10 ms /    20 runs   (    0.40 ms per token,  2469.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.44 ms /    12 tokens (   53.45 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   12496.43 ms /    19 runs   (  657.71 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13195.65 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.05 ms /    30 runs   (    0.40 ms per token,  2490.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.72 ms /    13 tokens (   52.59 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   19605.68 ms /    29 runs   (  676.06 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20376.07 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.27 ms /    23 runs   (    0.40 ms per token,  2481.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.14 ms /    12 tokens (   53.18 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   14638.63 ms /    22 runs   (  665.39 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15343.88 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.25 ms /    30 runs   (    0.41 ms per token,  2448.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     661.91 ms /    12 tokens (   55.16 ms per token,    18.13 tokens per second)\n",
      "llama_print_timings:        eval time =   19437.33 ms /    29 runs   (  670.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20187.78 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.27 ms /    25 runs   (    0.41 ms per token,  2434.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     606.76 ms /    11 tokens (   55.16 ms per token,    18.13 tokens per second)\n",
      "llama_print_timings:        eval time =   16030.55 ms /    24 runs   (  667.94 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16712.60 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.30 ms /    30 runs   (    0.41 ms per token,  2438.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.85 ms /    12 tokens (   53.32 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   19427.38 ms /    29 runs   (  669.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20155.39 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      38.47 ms /    93 runs   (    0.41 ms per token,  2417.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.51 ms /    13 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =   61785.50 ms /    92 runs   (  671.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   62735.21 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.22 ms /    61 runs   (    0.41 ms per token,  2418.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.53 ms /    12 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   40461.13 ms /    60 runs   (  674.35 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   41278.71 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.38 ms /    23 runs   (    0.41 ms per token,  2452.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.69 ms /    12 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   14809.05 ms /    22 runs   (  673.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15524.24 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.74 ms /    26 runs   (    0.41 ms per token,  2420.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     611.93 ms /    11 tokens (   55.63 ms per token,    17.98 tokens per second)\n",
      "llama_print_timings:        eval time =   16564.99 ms /    25 runs   (  662.60 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17252.90 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.41 ms /    32 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.49 ms /    13 tokens (   54.19 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =   20393.61 ms /    31 runs   (  657.86 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21191.36 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.99 ms /    32 runs   (    0.41 ms per token,  2463.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.78 ms /    12 tokens (   53.06 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   20913.20 ms /    31 runs   (  674.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21642.42 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.00 ms /    32 runs   (    0.41 ms per token,  2461.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.15 ms /    12 tokens (   53.43 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   21155.88 ms /    31 runs   (  682.45 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   21890.37 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.36 ms /    25 runs   (    0.41 ms per token,  2413.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.08 ms /    12 tokens (   54.01 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   16172.13 ms /    24 runs   (  673.84 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16892.85 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.50 ms /    23 runs   (    0.41 ms per token,  2421.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.07 ms /    12 tokens (   53.26 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   14510.74 ms /    22 runs   (  659.58 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15216.78 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.90 ms /    64 runs   (    0.40 ms per token,  2471.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.73 ms /    13 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   42253.81 ms /    63 runs   (  670.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   43125.07 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2300 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.97 ms /    22 runs   (    0.41 ms per token,  2452.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.91 ms /    12 tokens (   53.66 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   14045.06 ms /    21 runs   (  668.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14753.39 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.00 ms /    37 runs   (    0.41 ms per token,  2466.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.70 ms /    12 tokens (   53.89 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   24323.84 ms /    36 runs   (  675.66 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25080.03 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.98 ms /    37 runs   (    0.40 ms per token,  2469.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.15 ms /    11 tokens (   54.01 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   23937.89 ms /    36 runs   (  664.94 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24639.42 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      29.36 ms /    73 runs   (    0.40 ms per token,  2486.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.07 ms /    12 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   48230.69 ms /    72 runs   (  669.87 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   49090.48 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.47 ms /    34 runs   (    0.40 ms per token,  2523.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.61 ms /    11 tokens (   57.69 ms per token,    17.33 tokens per second)\n",
      "llama_print_timings:        eval time =   22137.63 ms /    33 runs   (  670.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22871.20 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.85 ms /    32 runs   (    0.40 ms per token,  2490.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.50 ms /    13 tokens (   52.73 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   20583.43 ms /    31 runs   (  663.98 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21361.33 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.72 ms /    36 runs   (    0.41 ms per token,  2445.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.38 ms /    13 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   22865.43 ms /    35 runs   (  653.30 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   23658.26 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.65 ms /    23 runs   (    0.46 ms per token,  2160.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.76 ms /    12 tokens (   53.81 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   14431.05 ms /    22 runs   (  655.96 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15148.86 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.77 ms /    46 runs   (    0.41 ms per token,  2451.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.45 ms /    12 tokens (   54.95 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =   30583.21 ms /    45 runs   (  679.63 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   31377.47 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.18 ms /    64 runs   (    0.41 ms per token,  2444.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     611.62 ms /    11 tokens (   55.60 ms per token,    17.98 tokens per second)\n",
      "llama_print_timings:        eval time =   41948.13 ms /    63 runs   (  665.84 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   42749.81 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.87 ms /    29 runs   (    0.41 ms per token,  2443.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.16 ms /    12 tokens (   53.35 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   18447.04 ms /    28 runs   (  658.82 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19172.01 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.49 ms /    23 runs   (    0.41 ms per token,  2422.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.87 ms /    13 tokens (   52.37 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   14575.76 ms /    22 runs   (  662.53 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15324.95 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.03 ms /    20 runs   (    0.40 ms per token,  2491.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.65 ms /    12 tokens (   53.89 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   12491.71 ms /    19 runs   (  657.46 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13196.32 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.77 ms /    29 runs   (    0.41 ms per token,  2463.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.08 ms /    12 tokens (   54.09 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   18655.50 ms /    28 runs   (  666.27 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19392.02 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.51 ms /    23 runs   (    0.41 ms per token,  2419.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.20 ms /    11 tokens (   53.84 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   14656.65 ms /    22 runs   (  666.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15315.30 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.35 ms /    40 runs   (    0.41 ms per token,  2446.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.01 ms /    12 tokens (   53.75 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   25367.54 ms /    39 runs   (  650.45 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   26130.71 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      31.07 ms /    76 runs   (    0.41 ms per token,  2445.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.41 ms /    12 tokens (   53.87 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   50557.59 ms /    75 runs   (  674.10 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   51428.83 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.19 ms /    27 runs   (    0.41 ms per token,  2413.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.20 ms /    12 tokens (   53.52 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   17371.35 ms /    26 runs   (  668.13 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18093.18 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.01 ms /    32 runs   (    0.41 ms per token,  2458.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     727.33 ms /    14 tokens (   51.95 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   20425.24 ms /    31 runs   (  658.88 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21246.93 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.89 ms /    37 runs   (    0.40 ms per token,  2484.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.19 ms /    12 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   24276.10 ms /    36 runs   (  674.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25027.62 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.97 ms /    32 runs   (    0.41 ms per token,  2467.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.92 ms /    11 tokens (   54.36 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   20740.58 ms /    31 runs   (  669.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21432.21 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.72 ms /    46 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.46 ms /    11 tokens (   53.77 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   29786.71 ms /    45 runs   (  661.93 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   30513.74 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      35.45 ms /    85 runs   (    0.42 ms per token,  2397.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.71 ms /    12 tokens (   52.98 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   56324.84 ms /    84 runs   (  670.53 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   57216.91 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.71 ms /    50 runs   (    0.41 ms per token,  2414.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     625.82 ms /    11 tokens (   56.89 ms per token,    17.58 tokens per second)\n",
      "llama_print_timings:        eval time =   32400.78 ms /    49 runs   (  661.24 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   33174.34 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.12 ms /    51 runs   (    0.43 ms per token,  2305.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.23 ms /    12 tokens (   53.94 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   33516.72 ms /    50 runs   (  670.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   34325.98 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.40 ms /    32 runs   (    0.42 ms per token,  2388.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     611.88 ms /    11 tokens (   55.63 ms per token,    17.98 tokens per second)\n",
      "llama_print_timings:        eval time =   20786.84 ms /    31 runs   (  670.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21495.93 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.67 ms /    31 runs   (    0.41 ms per token,  2447.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.19 ms /    12 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   20168.31 ms /    30 runs   (  672.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20902.61 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.82 ms /    60 runs   (    0.41 ms per token,  2417.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.29 ms /    12 tokens (   55.27 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =   39793.42 ms /    59 runs   (  674.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   40631.52 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.16 ms /    30 runs   (    0.41 ms per token,  2467.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.42 ms /    13 tokens (   52.49 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   19468.47 ms /    29 runs   (  671.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20239.06 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.66 ms /    32 runs   (    0.40 ms per token,  2528.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.16 ms /    12 tokens (   54.43 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   20529.07 ms /    31 runs   (  662.23 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21275.25 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.98 ms /    46 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.21 ms /    12 tokens (   53.18 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   29699.07 ms /    45 runs   (  659.98 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   30473.96 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.05 ms /    30 runs   (    0.40 ms per token,  2489.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.50 ms /    12 tokens (   53.21 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   19177.81 ms /    29 runs   (  661.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19903.39 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.42 ms /    41 runs   (    0.40 ms per token,  2497.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.50 ms /    13 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   26448.28 ms /    40 runs   (  661.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   27252.67 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      42.89 ms /   104 runs   (    0.41 ms per token,  2424.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     610.95 ms /    11 tokens (   55.54 ms per token,    18.00 tokens per second)\n",
      "llama_print_timings:        eval time =   68966.31 ms /   103 runs   (  669.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   69888.65 ms /   114 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.73 ms /    51 runs   (    0.41 ms per token,  2460.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     657.96 ms /    12 tokens (   54.83 ms per token,    18.24 tokens per second)\n",
      "llama_print_timings:        eval time =   33618.33 ms /    50 runs   (  672.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   34425.03 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.88 ms /    51 runs   (    0.43 ms per token,  2331.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     607.08 ms /    11 tokens (   55.19 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =   33755.30 ms /    50 runs   (  675.11 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   34519.53 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.42 ms /    65 runs   (    0.41 ms per token,  2460.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.33 ms /    12 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   42980.97 ms /    64 runs   (  671.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   43812.50 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.92 ms /    32 runs   (    0.40 ms per token,  2476.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.86 ms /    12 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   20826.29 ms /    31 runs   (  671.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21559.22 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.71 ms /    51 runs   (    0.43 ms per token,  2348.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.99 ms /    12 tokens (   53.50 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   33217.54 ms /    50 runs   (  664.35 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   34013.16 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.95 ms /    64 runs   (    0.41 ms per token,  2466.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.15 ms /    12 tokens (   54.68 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =   42331.56 ms /    63 runs   (  671.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   43177.23 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.59 ms /    26 runs   (    0.41 ms per token,  2455.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.62 ms /    13 tokens (   52.28 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   16780.05 ms /    25 runs   (  671.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17535.92 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.25 ms /    38 runs   (    0.40 ms per token,  2491.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.07 ms /    11 tokens (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   24851.86 ms /    37 runs   (  671.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   25555.89 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.11 ms /    30 runs   (    0.40 ms per token,  2477.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.44 ms /    12 tokens (   54.20 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =   19354.69 ms /    29 runs   (  667.40 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20092.72 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.09 ms /    30 runs   (    0.40 ms per token,  2481.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.64 ms /    12 tokens (   52.89 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   19175.22 ms /    29 runs   (  661.21 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19897.48 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.29 ms /    30 runs   (    0.41 ms per token,  2441.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.84 ms /    13 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   19400.54 ms /    29 runs   (  668.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20172.71 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.50 ms /    41 runs   (    0.40 ms per token,  2485.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.30 ms /    12 tokens (   53.44 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   26369.78 ms /    40 runs   (  659.24 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   27131.86 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.96 ms /    32 runs   (    0.41 ms per token,  2468.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.80 ms /    12 tokens (   54.65 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =   20575.42 ms /    31 runs   (  663.72 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21325.70 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.33 ms /    33 runs   (    0.40 ms per token,  2475.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     587.52 ms /    11 tokens (   53.41 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   20798.87 ms /    32 runs   (  649.96 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   21482.97 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      50.19 ms /   119 runs   (    0.42 ms per token,  2370.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.34 ms /    13 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   79378.92 ms /   118 runs   (  672.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   80424.78 ms /   131 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.82 ms /    51 runs   (    0.41 ms per token,  2449.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.24 ms /    11 tokens (   54.57 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   34118.53 ms /    50 runs   (  682.37 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   34868.87 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.99 ms /    30 runs   (    0.40 ms per token,  2501.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.29 ms /    12 tokens (   53.52 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   19361.78 ms /    29 runs   (  667.65 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20090.77 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.82 ms /    29 runs   (    0.41 ms per token,  2452.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.16 ms /    12 tokens (   53.26 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   18615.22 ms /    28 runs   (  664.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19338.60 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.09 ms /    38 runs   (    0.40 ms per token,  2518.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     662.15 ms /    12 tokens (   55.18 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =   24767.40 ms /    37 runs   (  669.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   25539.85 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      30.85 ms /    73 runs   (    0.42 ms per token,  2366.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     752.07 ms /    13 tokens (   57.85 ms per token,    17.29 tokens per second)\n",
      "llama_print_timings:        eval time =   48762.53 ms /    72 runs   (  677.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   49739.77 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.00 ms /    44 runs   (    0.43 ms per token,  2315.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.56 ms /    12 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   29133.46 ms /    43 runs   (  677.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   29913.14 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      29.24 ms /    71 runs   (    0.41 ms per token,  2427.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     697.47 ms /    12 tokens (   58.12 ms per token,    17.21 tokens per second)\n",
      "llama_print_timings:        eval time =   47449.16 ms /    70 runs   (  677.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   48356.47 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.38 ms /    23 runs   (    0.41 ms per token,  2452.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.84 ms /    12 tokens (   53.49 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   14690.49 ms /    22 runs   (  667.75 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15399.99 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.26 ms /    30 runs   (    0.41 ms per token,  2447.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.54 ms /    12 tokens (   54.71 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =   19310.36 ms /    29 runs   (  665.87 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20055.78 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.82 ms /    31 runs   (    0.45 ms per token,  2243.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.15 ms /    12 tokens (   53.01 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   20209.99 ms /    30 runs   (  673.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20943.45 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.98 ms /    51 runs   (    0.41 ms per token,  2431.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     748.81 ms /    13 tokens (   57.60 ms per token,    17.36 tokens per second)\n",
      "llama_print_timings:        eval time =   33701.50 ms /    50 runs   (  674.03 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   34601.47 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.13 ms /    64 runs   (    0.41 ms per token,  2449.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.00 ms /    12 tokens (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   42159.50 ms /    63 runs   (  669.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   42988.41 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.14 ms /    30 runs   (    0.40 ms per token,  2471.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.45 ms /    12 tokens (   54.62 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   19535.17 ms /    29 runs   (  673.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20282.53 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.21 ms /    30 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.88 ms /    12 tokens (   53.99 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   19420.47 ms /    29 runs   (  669.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20156.59 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      34.37 ms /    84 runs   (    0.41 ms per token,  2443.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.92 ms /    12 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   55741.09 ms /    83 runs   (  671.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   56623.04 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      41.86 ms /   102 runs   (    0.41 ms per token,  2436.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     605.66 ms /    11 tokens (   55.06 ms per token,    18.16 tokens per second)\n",
      "llama_print_timings:        eval time =   68265.43 ms /   101 runs   (  675.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   69173.26 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.56 ms /    43 runs   (    0.43 ms per token,  2316.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.98 ms /    13 tokens (   52.77 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   28253.85 ms /    42 runs   (  672.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29071.57 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.88 ms /    37 runs   (    0.40 ms per token,  2487.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.81 ms /    12 tokens (   53.15 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   24373.18 ms /    36 runs   (  677.03 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25119.55 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.34 ms /    30 runs   (    0.41 ms per token,  2430.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     601.37 ms /    11 tokens (   54.67 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =   19596.66 ms /    29 runs   (  675.75 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20286.21 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.41 ms /    23 runs   (    0.41 ms per token,  2445.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     605.86 ms /    11 tokens (   55.08 ms per token,    18.16 tokens per second)\n",
      "llama_print_timings:        eval time =   15148.77 ms /    22 runs   (  688.58 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   15822.98 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.93 ms /    51 runs   (    0.41 ms per token,  2436.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     664.38 ms /    12 tokens (   55.36 ms per token,    18.06 tokens per second)\n",
      "llama_print_timings:        eval time =   33681.42 ms /    50 runs   (  673.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   34496.22 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.83 ms /    51 runs   (    0.41 ms per token,  2448.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.00 ms /    12 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   33777.01 ms /    50 runs   (  675.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   34563.67 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.67 ms /    21 runs   (    0.41 ms per token,  2422.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.63 ms /    13 tokens (   56.05 ms per token,    17.84 tokens per second)\n",
      "llama_print_timings:        eval time =   13551.92 ms /    20 runs   (  677.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14341.70 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.19 ms /    30 runs   (    0.41 ms per token,  2461.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.69 ms /    12 tokens (   54.31 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   19383.19 ms /    29 runs   (  668.39 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20122.83 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.29 ms /    40 runs   (    0.41 ms per token,  2455.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.94 ms /    12 tokens (   56.75 ms per token,    17.62 tokens per second)\n",
      "llama_print_timings:        eval time =   26141.35 ms /    39 runs   (  670.29 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26941.96 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.27 ms /    20 runs   (    0.41 ms per token,  2417.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.21 ms /    11 tokens (   54.38 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =   12752.09 ms /    19 runs   (  671.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13409.39 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.24 ms /    30 runs   (    0.41 ms per token,  2451.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.14 ms /    12 tokens (   53.18 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   19461.09 ms /    29 runs   (  671.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20190.46 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.08 ms /    41 runs   (    0.44 ms per token,  2267.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     745.40 ms /    14 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   27131.63 ms /    40 runs   (  678.29 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   28009.65 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.34 ms /    59 runs   (    0.41 ms per token,  2424.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.10 ms /    12 tokens (   53.26 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   38792.91 ms /    58 runs   (  668.84 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   39606.28 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.19 ms /    50 runs   (    0.40 ms per token,  2476.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.07 ms /    12 tokens (   53.42 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   33210.57 ms /    49 runs   (  677.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   34002.69 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.70 ms /    30 runs   (    0.42 ms per token,  2362.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     700.35 ms /    13 tokens (   53.87 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   19212.40 ms /    29 runs   (  662.50 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20005.51 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.84 ms /    64 runs   (    0.40 ms per token,  2477.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.65 ms /    12 tokens (   56.55 ms per token,    17.68 tokens per second)\n",
      "llama_print_timings:        eval time =   42556.43 ms /    63 runs   (  675.50 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   43422.58 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.80 ms /    48 runs   (    0.43 ms per token,  2307.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     617.75 ms /    11 tokens (   56.16 ms per token,    17.81 tokens per second)\n",
      "llama_print_timings:        eval time =   31441.66 ms /    47 runs   (  668.97 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   32206.24 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.77 ms /    24 runs   (    0.45 ms per token,  2227.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.03 ms /    12 tokens (   53.67 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   15561.45 ms /    23 runs   (  676.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16280.84 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.45 ms /    65 runs   (    0.41 ms per token,  2457.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.15 ms /    12 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   42526.34 ms /    64 runs   (  664.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   43363.08 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      32.73 ms /    80 runs   (    0.41 ms per token,  2443.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.26 ms /    12 tokens (   53.69 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   53231.35 ms /    79 runs   (  673.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   54111.67 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.99 ms /    61 runs   (    0.41 ms per token,  2441.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     691.96 ms /    13 tokens (   53.23 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   40382.08 ms /    60 runs   (  673.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   41253.74 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.82 ms /    48 runs   (    0.41 ms per token,  2421.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.62 ms /    11 tokens (   54.06 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   31438.03 ms /    47 runs   (  668.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   32175.08 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      29.52 ms /    72 runs   (    0.41 ms per token,  2438.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.30 ms /    12 tokens (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   47906.40 ms /    71 runs   (  674.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   48757.54 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.74 ms /    46 runs   (    0.41 ms per token,  2454.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     665.58 ms /    12 tokens (   55.47 ms per token,    18.03 tokens per second)\n",
      "llama_print_timings:        eval time =   30141.04 ms /    45 runs   (  669.80 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   30940.91 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      32.77 ms /    80 runs   (    0.41 ms per token,  2441.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.09 ms /    11 tokens (   54.01 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   53220.11 ms /    79 runs   (  673.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   54049.99 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.91 ms /    44 runs   (    0.41 ms per token,  2456.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.81 ms /    12 tokens (   52.98 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   28914.22 ms /    43 runs   (  672.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29678.40 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.58 ms /    45 runs   (    0.41 ms per token,  2421.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.28 ms /    11 tokens (   54.12 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   29626.51 ms /    44 runs   (  673.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   30354.04 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.21 ms /    30 runs   (    0.41 ms per token,  2458.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.51 ms /    13 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   19469.04 ms /    29 runs   (  671.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20254.73 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.14 ms /    25 runs   (    0.41 ms per token,  2466.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.47 ms /    12 tokens (   56.54 ms per token,    17.69 tokens per second)\n",
      "llama_print_timings:        eval time =   16089.03 ms /    24 runs   (  670.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16841.58 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.06 ms /    64 runs   (    0.41 ms per token,  2455.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.00 ms /    12 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   42047.11 ms /    63 runs   (  667.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   42872.23 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.94 ms /    43 runs   (    0.42 ms per token,  2396.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.75 ms /    12 tokens (   53.56 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   28146.52 ms /    42 runs   (  670.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28920.13 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.74 ms /    41 runs   (    0.41 ms per token,  2449.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.66 ms /    12 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   26566.52 ms /    40 runs   (  664.16 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   27335.26 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.24 ms /    20 runs   (    0.41 ms per token,  2426.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     606.34 ms /    11 tokens (   55.12 ms per token,    18.14 tokens per second)\n",
      "llama_print_timings:        eval time =   13019.29 ms /    19 runs   (  685.23 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13684.46 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.24 ms /    33 runs   (    0.40 ms per token,  2492.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.34 ms /    13 tokens (   53.72 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   21342.66 ms /    32 runs   (  666.96 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22138.28 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.93 ms /    44 runs   (    0.41 ms per token,  2454.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.83 ms /    11 tokens (   53.89 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   28994.38 ms /    43 runs   (  674.29 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   29716.01 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2400 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.89 ms /    27 runs   (    0.40 ms per token,  2480.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.90 ms /    12 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   17464.78 ms /    26 runs   (  671.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18182.19 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      39.62 ms /    96 runs   (    0.41 ms per token,  2423.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.56 ms /    11 tokens (   54.60 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   64128.45 ms /    95 runs   (  675.04 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   65014.06 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.62 ms /    36 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.82 ms /    12 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   23487.53 ms /    35 runs   (  671.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24239.74 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.31 ms /    20 runs   (    0.42 ms per token,  2406.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.06 ms /    12 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   12712.39 ms /    19 runs   (  669.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13407.86 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.00 ms /    42 runs   (    0.40 ms per token,  2471.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.86 ms /    12 tokens (   53.99 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   27579.10 ms /    41 runs   (  672.66 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28349.99 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.62 ms /    24 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.79 ms /    12 tokens (   54.15 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   15348.34 ms /    23 runs   (  667.32 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16068.83 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      38.49 ms /    94 runs   (    0.41 ms per token,  2442.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.69 ms /    13 tokens (   52.59 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   61762.21 ms /    93 runs   (  664.11 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   62726.47 ms /   106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.62 ms /    26 runs   (    0.41 ms per token,  2447.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.23 ms /    12 tokens (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   16650.17 ms /    25 runs   (  666.01 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17361.67 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.29 ms /    30 runs   (    0.41 ms per token,  2440.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.46 ms /    12 tokens (   58.70 ms per token,    17.03 tokens per second)\n",
      "llama_print_timings:        eval time =   19109.31 ms /    29 runs   (  658.94 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19901.61 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.37 ms /    30 runs   (    0.41 ms per token,  2425.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.24 ms /    12 tokens (   53.19 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   18877.45 ms /    29 runs   (  650.95 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   19603.52 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.02 ms /    49 runs   (    0.41 ms per token,  2447.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     670.12 ms /    12 tokens (   55.84 ms per token,    17.91 tokens per second)\n",
      "llama_print_timings:        eval time =   31937.21 ms /    48 runs   (  665.36 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   32751.69 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.13 ms /    27 runs   (    0.41 ms per token,  2425.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.22 ms /    13 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   17245.51 ms /    26 runs   (  663.29 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   18013.04 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.00 ms /    29 runs   (    0.41 ms per token,  2416.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     702.32 ms /    12 tokens (   58.53 ms per token,    17.09 tokens per second)\n",
      "llama_print_timings:        eval time =   18705.14 ms /    28 runs   (  668.04 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19490.70 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.03 ms /    24 runs   (    0.42 ms per token,  2393.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.84 ms /    12 tokens (   53.32 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   15183.70 ms /    23 runs   (  660.16 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15893.71 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.34 ms /    62 runs   (    0.41 ms per token,  2446.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.23 ms /    11 tokens (   54.29 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   41099.67 ms /    61 runs   (  673.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   41880.01 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.74 ms /    34 runs   (    0.40 ms per token,  2474.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.47 ms /    13 tokens (   52.50 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   21910.58 ms /    33 runs   (  663.96 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   22692.40 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      34.68 ms /    84 runs   (    0.41 ms per token,  2422.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.07 ms /    12 tokens (   53.34 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   55632.73 ms /    83 runs   (  670.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   56524.68 ms /    95 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.18 ms /    30 runs   (    0.41 ms per token,  2462.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     603.29 ms /    11 tokens (   54.84 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =   19182.63 ms /    29 runs   (  661.47 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19874.11 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.80 ms /    48 runs   (    0.41 ms per token,  2424.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.89 ms /    12 tokens (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   32070.23 ms /    47 runs   (  682.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   32857.61 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.09 ms /    51 runs   (    0.41 ms per token,  2418.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.43 ms /    12 tokens (   54.54 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   33589.87 ms /    50 runs   (  671.80 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   34395.72 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.11 ms /    30 runs   (    0.40 ms per token,  2476.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.41 ms /    12 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   19313.81 ms /    29 runs   (  665.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20039.80 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      32.28 ms /    79 runs   (    0.41 ms per token,  2447.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.47 ms /    11 tokens (   54.22 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   52423.68 ms /    78 runs   (  672.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   53252.77 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.80 ms /    61 runs   (    0.41 ms per token,  2459.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     755.05 ms /    13 tokens (   58.08 ms per token,    17.22 tokens per second)\n",
      "llama_print_timings:        eval time =   40561.38 ms /    60 runs   (  676.02 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   41498.58 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      32.46 ms /    80 runs   (    0.41 ms per token,  2464.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     615.04 ms /    11 tokens (   55.91 ms per token,    17.89 tokens per second)\n",
      "llama_print_timings:        eval time =   53673.60 ms /    79 runs   (  679.41 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   54524.78 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.96 ms /    46 runs   (    0.43 ms per token,  2304.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.06 ms /    11 tokens (   54.01 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   29922.08 ms /    45 runs   (  664.94 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   30657.98 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.84 ms /    68 runs   (    0.41 ms per token,  2442.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     657.18 ms /    12 tokens (   54.76 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =   44975.00 ms /    67 runs   (  671.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   45832.28 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.95 ms /    32 runs   (    0.40 ms per token,  2472.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.57 ms /    12 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   20849.03 ms /    31 runs   (  672.55 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21577.57 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.93 ms /    31 runs   (    0.42 ms per token,  2396.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     669.36 ms /    12 tokens (   55.78 ms per token,    17.93 tokens per second)\n",
      "llama_print_timings:        eval time =   20087.49 ms /    30 runs   (  669.58 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20848.40 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.68 ms /    34 runs   (    0.40 ms per token,  2485.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     753.86 ms /    13 tokens (   57.99 ms per token,    17.24 tokens per second)\n",
      "llama_print_timings:        eval time =   22177.38 ms /    33 runs   (  672.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   23029.75 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.67 ms /    28 runs   (    0.42 ms per token,  2399.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.42 ms /    12 tokens (   53.29 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   17766.70 ms /    27 runs   (  658.03 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   18489.21 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.26 ms /    30 runs   (    0.41 ms per token,  2447.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     660.83 ms /    12 tokens (   55.07 ms per token,    18.16 tokens per second)\n",
      "llama_print_timings:        eval time =   19304.58 ms /    29 runs   (  665.68 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20053.81 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.36 ms /    33 runs   (    0.44 ms per token,  2298.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.91 ms /    12 tokens (   54.99 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =   21158.55 ms /    32 runs   (  661.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21921.06 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.63 ms /    41 runs   (    0.41 ms per token,  2466.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     601.11 ms /    11 tokens (   54.65 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =   26855.16 ms /    40 runs   (  671.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   27574.43 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.50 ms /    68 runs   (    0.40 ms per token,  2473.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.98 ms /    14 tokens (   51.78 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   44196.74 ms /    67 runs   (  659.65 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   45120.70 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.77 ms /    51 runs   (    0.41 ms per token,  2456.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.51 ms /    12 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   33225.08 ms /    50 runs   (  664.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   34020.66 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      29.54 ms /    73 runs   (    0.40 ms per token,  2471.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.77 ms /    12 tokens (   53.23 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   48138.75 ms /    72 runs   (  668.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   48991.76 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.38 ms /    28 runs   (    0.41 ms per token,  2460.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.47 ms /    12 tokens (   54.04 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   18114.11 ms /    27 runs   (  670.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18844.04 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      89.86 ms /   214 runs   (    0.42 ms per token,  2381.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.20 ms /    11 tokens (   54.11 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =  144269.52 ms /   213 runs   (  677.32 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  145516.79 ms /   224 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.15 ms /    32 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     725.15 ms /    13 tokens (   55.78 ms per token,    17.93 tokens per second)\n",
      "llama_print_timings:        eval time =   20749.42 ms /    31 runs   (  669.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21568.52 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.59 ms /    34 runs   (    0.40 ms per token,  2501.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.48 ms /    12 tokens (   52.87 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   22239.35 ms /    33 runs   (  673.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22972.88 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.52 ms /    34 runs   (    0.43 ms per token,  2342.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     670.32 ms /    12 tokens (   55.86 ms per token,    17.90 tokens per second)\n",
      "llama_print_timings:        eval time =   21759.13 ms /    33 runs   (  659.37 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   22535.42 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.66 ms /    36 runs   (    0.41 ms per token,  2455.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.54 ms /    12 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   23449.94 ms /    35 runs   (  670.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24196.22 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      28.71 ms /    70 runs   (    0.41 ms per token,  2438.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.20 ms /    13 tokens (   52.09 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   45947.72 ms /    69 runs   (  665.91 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   46832.19 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      30.31 ms /    74 runs   (    0.41 ms per token,  2441.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.41 ms /    11 tokens (   54.40 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   49360.17 ms /    73 runs   (  676.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   50180.28 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.68 ms /    63 runs   (    0.41 ms per token,  2453.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.32 ms /    12 tokens (   53.94 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   41992.66 ms /    62 runs   (  677.30 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   42828.77 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.78 ms /    56 runs   (    0.41 ms per token,  2458.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.91 ms /    12 tokens (   54.16 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   37093.42 ms /    55 runs   (  674.43 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   37907.45 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.07 ms /    29 runs   (    0.42 ms per token,  2402.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     613.52 ms /    11 tokens (   55.77 ms per token,    17.93 tokens per second)\n",
      "llama_print_timings:        eval time =   18859.02 ms /    28 runs   (  673.54 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19557.44 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.22 ms /    32 runs   (    0.41 ms per token,  2420.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     701.92 ms /    13 tokens (   53.99 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   20765.40 ms /    31 runs   (  669.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21561.69 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.69 ms /    25 runs   (    0.43 ms per token,  2339.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     609.90 ms /    11 tokens (   55.45 ms per token,    18.04 tokens per second)\n",
      "llama_print_timings:        eval time =   16180.92 ms /    24 runs   (  674.20 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16865.95 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /    20 runs   (    0.41 ms per token,  2434.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.92 ms /    12 tokens (   53.74 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   12633.40 ms /    19 runs   (  664.92 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13336.26 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.20 ms /    54 runs   (    0.41 ms per token,  2432.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.94 ms /    12 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   35257.14 ms /    53 runs   (  665.23 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   36053.44 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.38 ms /    28 runs   (    0.41 ms per token,  2459.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     608.83 ms /    11 tokens (   55.35 ms per token,    18.07 tokens per second)\n",
      "llama_print_timings:        eval time =   18140.50 ms /    27 runs   (  671.87 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18830.91 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.67 ms /    46 runs   (    0.41 ms per token,  2463.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.69 ms /    13 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   30396.31 ms /    45 runs   (  675.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   31216.28 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      37.52 ms /    91 runs   (    0.41 ms per token,  2425.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.18 ms /    12 tokens (   54.01 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   60339.25 ms /    90 runs   (  670.44 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   61255.32 ms /   102 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    20 runs   (    0.41 ms per token,  2453.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.18 ms /    12 tokens (   53.52 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   12777.60 ms /    19 runs   (  672.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13478.08 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      31.90 ms /    78 runs   (    0.41 ms per token,  2445.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.49 ms /    12 tokens (   55.29 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =   51287.68 ms /    77 runs   (  666.07 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   52182.32 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.48 ms /    40 runs   (    0.41 ms per token,  2426.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.17 ms /    12 tokens (   53.35 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   25856.75 ms /    39 runs   (  662.99 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   26613.47 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.52 ms /    39 runs   (    0.40 ms per token,  2513.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.46 ms /    11 tokens (   53.95 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   25295.33 ms /    38 runs   (  665.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26001.91 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.79 ms /    24 runs   (    0.41 ms per token,  2452.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.54 ms /    12 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   15272.30 ms /    23 runs   (  664.01 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15983.83 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.85 ms /    41 runs   (    0.41 ms per token,  2433.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.24 ms /    13 tokens (   52.56 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   26538.42 ms /    40 runs   (  663.46 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   27344.43 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.74 ms /    55 runs   (    0.43 ms per token,  2317.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     665.57 ms /    12 tokens (   55.46 ms per token,    18.03 tokens per second)\n",
      "llama_print_timings:        eval time =   36277.51 ms /    54 runs   (  671.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   37110.93 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.23 ms /    30 runs   (    0.41 ms per token,  2453.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     603.32 ms /    11 tokens (   54.85 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =   19254.03 ms /    29 runs   (  663.93 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19944.41 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.69 ms /    29 runs   (    0.40 ms per token,  2480.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.06 ms /    12 tokens (   53.75 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   18671.85 ms /    28 runs   (  666.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19401.51 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.91 ms /    32 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.38 ms /    12 tokens (   54.53 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   20750.62 ms /    31 runs   (  669.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21498.50 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.74 ms /    63 runs   (    0.41 ms per token,  2447.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.72 ms /    11 tokens (   53.88 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   41894.30 ms /    62 runs   (  675.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   42672.80 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.73 ms /    24 runs   (    0.41 ms per token,  2465.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.95 ms /    12 tokens (   53.83 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   15544.71 ms /    23 runs   (  675.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16260.30 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.69 ms /    39 runs   (    0.40 ms per token,  2486.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.03 ms /    11 tokens (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   25435.73 ms /    38 runs   (  669.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26141.03 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.17 ms /    30 runs   (    0.41 ms per token,  2464.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.33 ms /    11 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   19509.33 ms /    29 runs   (  672.74 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20188.44 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    18 runs   (    0.41 ms per token,  2435.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.50 ms /    12 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   11334.78 ms /    17 runs   (  666.75 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12031.59 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.73 ms /    55 runs   (    0.41 ms per token,  2420.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.27 ms /    11 tokens (   53.66 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   36421.45 ms /    54 runs   (  674.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   37173.82 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.10 ms /    42 runs   (    0.41 ms per token,  2456.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.69 ms /    13 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   27824.67 ms /    41 runs   (  678.65 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   28629.34 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    20 runs   (    0.41 ms per token,  2459.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.88 ms /    12 tokens (   58.74 ms per token,    17.02 tokens per second)\n",
      "llama_print_timings:        eval time =   12738.96 ms /    19 runs   (  670.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13501.56 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      36.52 ms /    87 runs   (    0.42 ms per token,  2382.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.92 ms /    12 tokens (   54.08 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   57844.23 ms /    86 runs   (  672.61 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   58756.64 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.87 ms /    24 runs   (    0.41 ms per token,  2430.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.53 ms /    11 tokens (   53.87 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   15315.16 ms /    23 runs   (  665.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15978.32 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.69 ms /    34 runs   (    0.40 ms per token,  2484.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.17 ms /    13 tokens (   52.63 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   21817.18 ms /    33 runs   (  661.13 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   22601.09 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.12 ms /    52 runs   (    0.41 ms per token,  2461.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.08 ms /    12 tokens (   53.26 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   34114.22 ms /    51 runs   (  668.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   34905.37 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.95 ms /    32 runs   (    0.40 ms per token,  2471.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     622.67 ms /    11 tokens (   56.61 ms per token,    17.67 tokens per second)\n",
      "llama_print_timings:        eval time =   20627.65 ms /    31 runs   (  665.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21344.02 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.50 ms /    49 runs   (    0.42 ms per token,  2389.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     662.76 ms /    12 tokens (   55.23 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =   32348.06 ms /    48 runs   (  673.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   33154.78 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.23 ms /    20 runs   (    0.41 ms per token,  2430.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.92 ms /    12 tokens (   56.99 ms per token,    17.55 tokens per second)\n",
      "llama_print_timings:        eval time =   12486.17 ms /    19 runs   (  657.17 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13229.29 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.36 ms /    52 runs   (    0.41 ms per token,  2434.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.10 ms /    13 tokens (   52.55 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   33940.83 ms /    51 runs   (  665.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   34779.01 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    20 runs   (    0.41 ms per token,  2456.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.59 ms /    12 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   12655.70 ms /    19 runs   (  666.09 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13355.91 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.10 ms /    40 runs   (    0.40 ms per token,  2484.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.60 ms /    12 tokens (   54.13 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   26070.62 ms /    39 runs   (  668.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26838.19 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.43 ms /    38 runs   (    0.41 ms per token,  2462.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.95 ms /    11 tokens (   54.27 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   24876.50 ms /    37 runs   (  672.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   25584.74 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.48 ms /    34 runs   (    0.43 ms per token,  2348.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.27 ms /    13 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =   21881.12 ms /    33 runs   (  663.06 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   22666.93 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.02 ms /    17 runs   (    0.47 ms per token,  2119.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     675.35 ms /    12 tokens (   56.28 ms per token,    17.77 tokens per second)\n",
      "llama_print_timings:        eval time =   10625.82 ms /    16 runs   (  664.11 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   11356.15 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.07 ms /    30 runs   (    0.40 ms per token,  2484.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.53 ms /    15 tokens (   52.04 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   19130.19 ms /    29 runs   (  659.66 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   20000.34 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.88 ms /    39 runs   (    0.41 ms per token,  2455.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.77 ms /    11 tokens (   62.25 ms per token,    16.06 tokens per second)\n",
      "llama_print_timings:        eval time =   25404.64 ms /    38 runs   (  668.54 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26203.37 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.19 ms /    33 runs   (    0.40 ms per token,  2502.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.35 ms /    12 tokens (   53.61 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   21312.27 ms /    32 runs   (  666.01 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22053.87 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.98 ms /    49 runs   (    0.41 ms per token,  2452.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.67 ms /    11 tokens (   54.42 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   32436.05 ms /    48 runs   (  675.75 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   33179.50 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.79 ms /    29 runs   (    0.41 ms per token,  2460.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.56 ms /    13 tokens (   56.04 ms per token,    17.84 tokens per second)\n",
      "llama_print_timings:        eval time =   18740.58 ms /    28 runs   (  669.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19554.55 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.05 ms /    30 runs   (    0.40 ms per token,  2490.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.33 ms /    12 tokens (   53.69 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   19375.77 ms /    29 runs   (  668.13 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20108.67 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.34 ms /    33 runs   (    0.40 ms per token,  2474.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.08 ms /    12 tokens (   53.67 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   21563.30 ms /    32 runs   (  673.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22303.58 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.02 ms /    32 runs   (    0.41 ms per token,  2457.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.59 ms /    12 tokens (   53.72 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   20471.96 ms /    31 runs   (  660.39 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21209.95 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.60 ms /    29 runs   (    0.40 ms per token,  2499.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.46 ms /    13 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   18635.79 ms /    28 runs   (  665.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19408.40 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.22 ms /    47 runs   (    0.41 ms per token,  2445.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.61 ms /    12 tokens (   56.72 ms per token,    17.63 tokens per second)\n",
      "llama_print_timings:        eval time =   31115.93 ms /    46 runs   (  676.43 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   31934.47 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.89 ms /    29 runs   (    0.44 ms per token,  2249.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     660.15 ms /    12 tokens (   55.01 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =   18377.87 ms /    28 runs   (  656.35 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19127.63 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.63 ms /    60 runs   (    0.41 ms per token,  2436.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.75 ms /    12 tokens (   53.15 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   39496.54 ms /    59 runs   (  669.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   40310.78 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.25 ms /    32 runs   (    0.41 ms per token,  2415.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.35 ms /    11 tokens (   58.30 ms per token,    17.15 tokens per second)\n",
      "llama_print_timings:        eval time =   20526.64 ms /    31 runs   (  662.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21261.98 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    17 runs   (    0.41 ms per token,  2411.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     657.52 ms /    12 tokens (   54.79 ms per token,    18.25 tokens per second)\n",
      "llama_print_timings:        eval time =   10682.82 ms /    16 runs   (  667.68 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11390.17 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.26 ms /    49 runs   (    0.41 ms per token,  2418.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.20 ms /    11 tokens (   54.29 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   32105.07 ms /    48 runs   (  668.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   32847.26 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2500 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.89 ms /    19 runs   (    0.42 ms per token,  2408.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.23 ms /    12 tokens (   53.10 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   11945.79 ms /    18 runs   (  663.65 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12638.82 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.30 ms /    20 runs   (    0.42 ms per token,  2408.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.00 ms /    11 tokens (   54.36 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =   12576.75 ms /    19 runs   (  661.93 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13234.14 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.36 ms /    20 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     588.34 ms /    11 tokens (   53.49 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   12800.67 ms /    19 runs   (  673.72 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13448.30 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.71 ms /    21 runs   (    0.46 ms per token,  2162.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.97 ms /    13 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   13307.93 ms /    20 runs   (  665.40 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14064.86 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.29 ms /    23 runs   (    0.40 ms per token,  2477.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.97 ms /    12 tokens (   53.50 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   14735.41 ms /    22 runs   (  669.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15444.83 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.15 ms /    30 runs   (    0.41 ms per token,  2468.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.69 ms /    11 tokens (   53.88 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   19444.94 ms /    29 runs   (  670.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20125.45 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.43 ms /    23 runs   (    0.41 ms per token,  2439.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     707.60 ms /    12 tokens (   58.97 ms per token,    16.96 tokens per second)\n",
      "llama_print_timings:        eval time =   14636.68 ms /    22 runs   (  665.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15411.06 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.00 ms /    32 runs   (    0.41 ms per token,  2462.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     662.79 ms /    12 tokens (   55.23 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =   20702.34 ms /    31 runs   (  667.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21457.61 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.08 ms /    18 runs   (    0.50 ms per token,  1983.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.77 ms /    11 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   11477.54 ms /    17 runs   (  675.15 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12126.65 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.39 ms /    53 runs   (    0.40 ms per token,  2477.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     694.42 ms /    13 tokens (   53.42 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   34703.18 ms /    52 runs   (  667.37 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   35554.04 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    20 runs   (    0.40 ms per token,  2472.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.43 ms /    12 tokens (   53.54 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   12432.44 ms /    19 runs   (  654.34 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13133.09 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.18 ms /    30 runs   (    0.41 ms per token,  2462.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.31 ms /    11 tokens (   54.21 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =   19116.86 ms /    29 runs   (  659.20 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19802.07 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.33 ms /    20 runs   (    0.42 ms per token,  2400.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     602.52 ms /    11 tokens (   54.77 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =   12719.78 ms /    19 runs   (  669.46 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13381.33 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.03 ms /    44 runs   (    0.41 ms per token,  2439.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.81 ms /    12 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   28297.69 ms /    43 runs   (  658.09 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   29069.29 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.89 ms /    53 runs   (    0.41 ms per token,  2420.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.12 ms /    11 tokens (   54.19 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =   34040.86 ms /    52 runs   (  654.63 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   34793.96 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.87 ms /    29 runs   (    0.41 ms per token,  2443.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.72 ms /    12 tokens (   53.81 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   18523.96 ms /    28 runs   (  661.57 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19254.32 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.45 ms /    31 runs   (    0.40 ms per token,  2490.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.93 ms /    11 tokens (   59.45 ms per token,    16.82 tokens per second)\n",
      "llama_print_timings:        eval time =   19934.44 ms /    30 runs   (  664.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20678.70 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.94 ms /    53 runs   (    0.41 ms per token,  2415.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.55 ms /    12 tokens (   53.88 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   34475.82 ms /    52 runs   (  663.00 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   35279.60 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      28.27 ms /    66 runs   (    0.43 ms per token,  2334.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.27 ms /    12 tokens (   53.61 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   43306.64 ms /    65 runs   (  666.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   44150.51 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.59 ms /    26 runs   (    0.41 ms per token,  2454.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.81 ms /    13 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   16728.93 ms /    25 runs   (  669.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17487.30 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.61 ms /    36 runs   (    0.43 ms per token,  2305.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.84 ms /    12 tokens (   53.65 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   23175.85 ms /    35 runs   (  662.17 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   23930.06 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.67 ms /    31 runs   (    0.41 ms per token,  2447.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     691.73 ms /    13 tokens (   53.21 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   19599.87 ms /    30 runs   (  653.33 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   20383.13 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.32 ms /    23 runs   (    0.41 ms per token,  2468.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.01 ms /    11 tokens (   54.18 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   14698.27 ms /    22 runs   (  668.10 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15360.32 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.41 ms /    32 runs   (    0.45 ms per token,  2220.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.69 ms /    12 tokens (   53.47 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   20465.84 ms /    31 runs   (  660.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21205.66 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.03 ms /    34 runs   (    0.41 ms per token,  2423.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     657.24 ms /    11 tokens (   59.75 ms per token,    16.74 tokens per second)\n",
      "llama_print_timings:        eval time =   22284.53 ms /    33 runs   (  675.29 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   23040.70 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.22 ms /    30 runs   (    0.41 ms per token,  2454.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.19 ms /    12 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   19138.35 ms /    29 runs   (  659.94 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19869.58 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.31 ms /    36 runs   (    0.43 ms per token,  2351.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.06 ms /    12 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   23214.30 ms /    35 runs   (  663.27 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   23964.26 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.89 ms /    44 runs   (    0.41 ms per token,  2459.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.91 ms /    12 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   29035.97 ms /    43 runs   (  675.26 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   29802.77 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.92 ms /    32 runs   (    0.40 ms per token,  2477.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.15 ms /    13 tokens (   53.32 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   20784.70 ms /    31 runs   (  670.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21570.66 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.17 ms /    30 runs   (    0.41 ms per token,  2464.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.84 ms /    12 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   19583.04 ms /    29 runs   (  675.28 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20306.19 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.21 ms /    30 runs   (    0.41 ms per token,  2456.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     606.95 ms /    11 tokens (   55.18 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =   19529.06 ms /    29 runs   (  673.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20223.71 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.48 ms /    32 runs   (    0.42 ms per token,  2373.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.51 ms /    11 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   20708.69 ms /    31 runs   (  668.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21396.86 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.23 ms /    30 runs   (    0.41 ms per token,  2453.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.71 ms /    12 tokens (   53.31 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   19489.79 ms /    29 runs   (  672.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20217.37 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.63 ms /    21 runs   (    0.41 ms per token,  2433.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     661.02 ms /    12 tokens (   55.09 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =   13337.77 ms /    20 runs   (  666.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14061.24 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.92 ms /    42 runs   (    0.43 ms per token,  2343.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.66 ms /    12 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   27201.89 ms /    41 runs   (  663.46 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   27964.77 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.69 ms /    31 runs   (    0.41 ms per token,  2443.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     707.58 ms /    13 tokens (   54.43 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   20125.77 ms /    30 runs   (  670.86 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20922.81 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.42 ms /    20 runs   (    0.42 ms per token,  2375.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.98 ms /    12 tokens (   53.16 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   12861.56 ms /    19 runs   (  676.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13558.55 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.38 ms /    38 runs   (    0.40 ms per token,  2470.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     671.68 ms /    12 tokens (   55.97 ms per token,    17.87 tokens per second)\n",
      "llama_print_timings:        eval time =   25113.61 ms /    37 runs   (  678.75 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   25896.75 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.21 ms /    30 runs   (    0.41 ms per token,  2457.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     709.10 ms /    13 tokens (   54.55 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   19576.31 ms /    29 runs   (  675.05 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20371.84 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.58 ms /    21 runs   (    0.41 ms per token,  2447.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     697.38 ms /    12 tokens (   58.11 ms per token,    17.21 tokens per second)\n",
      "llama_print_timings:        eval time =   13391.48 ms /    20 runs   (  669.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14149.92 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.52 ms /    21 runs   (    0.41 ms per token,  2464.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.66 ms /    11 tokens (   53.79 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   13259.07 ms /    20 runs   (  662.95 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13911.02 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.47 ms /    30 runs   (    0.45 ms per token,  2226.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.55 ms /    12 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   19354.28 ms /    29 runs   (  667.39 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20091.37 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.03 ms /    36 runs   (    0.42 ms per token,  2394.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.26 ms /    12 tokens (   53.69 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   23572.36 ms /    35 runs   (  673.50 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   24322.80 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    18 runs   (    0.41 ms per token,  2438.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     607.76 ms /    11 tokens (   55.25 ms per token,    18.10 tokens per second)\n",
      "llama_print_timings:        eval time =   11487.34 ms /    17 runs   (  675.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   12148.03 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.97 ms /    37 runs   (    0.40 ms per token,  2472.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     734.72 ms /    14 tokens (   52.48 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   23811.72 ms /    36 runs   (  661.44 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   24655.34 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.60 ms /    44 runs   (    0.42 ms per token,  2365.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     599.13 ms /    11 tokens (   54.47 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =   29190.59 ms /    43 runs   (  678.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   29922.84 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.21 ms /    28 runs   (    0.40 ms per token,  2498.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     665.01 ms /    12 tokens (   55.42 ms per token,    18.04 tokens per second)\n",
      "llama_print_timings:        eval time =   18225.21 ms /    27 runs   (  675.01 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18971.76 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.43 ms /    28 runs   (    0.41 ms per token,  2449.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     662.13 ms /    12 tokens (   55.18 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =   18142.82 ms /    27 runs   (  671.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18886.95 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.62 ms /    23 runs   (    0.42 ms per token,  2389.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     615.80 ms /    11 tokens (   55.98 ms per token,    17.86 tokens per second)\n",
      "llama_print_timings:        eval time =   14680.99 ms /    22 runs   (  667.32 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15365.00 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.36 ms /    23 runs   (    0.41 ms per token,  2456.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.24 ms /    12 tokens (   54.02 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   14675.18 ms /    22 runs   (  667.05 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15390.26 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.35 ms /    31 runs   (    0.40 ms per token,  2509.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.13 ms /    11 tokens (   53.56 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   20121.15 ms /    30 runs   (  670.71 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20801.11 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    16 runs   (    0.49 ms per token,  2061.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.66 ms /    12 tokens (   54.31 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =    9909.22 ms /    15 runs   (  660.61 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   10613.63 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.52 ms /    33 runs   (    0.44 ms per token,  2272.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.46 ms /    13 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   21360.53 ms /    32 runs   (  667.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22144.54 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.26 ms /    30 runs   (    0.41 ms per token,  2447.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.38 ms /    12 tokens (   53.12 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   19423.63 ms /    29 runs   (  669.78 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20149.06 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.01 ms /    25 runs   (    0.40 ms per token,  2498.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     599.02 ms /    11 tokens (   54.46 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =   16106.10 ms /    24 runs   (  671.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16777.11 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.98 ms /    30 runs   (    0.40 ms per token,  2505.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.50 ms /    12 tokens (   53.54 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   19126.08 ms /    29 runs   (  659.52 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19856.62 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.82 ms /    32 runs   (    0.40 ms per token,  2495.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.51 ms /    12 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   20536.52 ms /    31 runs   (  662.47 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21265.16 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.11 ms /    42 runs   (    0.41 ms per token,  2454.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     751.34 ms /    13 tokens (   57.80 ms per token,    17.30 tokens per second)\n",
      "llama_print_timings:        eval time =   27432.91 ms /    41 runs   (  669.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28307.66 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.02 ms /    30 runs   (    0.40 ms per token,  2495.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.17 ms /    12 tokens (   57.35 ms per token,    17.44 tokens per second)\n",
      "llama_print_timings:        eval time =   19367.24 ms /    29 runs   (  667.84 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20143.23 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.07 ms /    32 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.73 ms /    12 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   20770.42 ms /    31 runs   (  670.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21505.21 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.25 ms /    32 runs   (    0.41 ms per token,  2414.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.93 ms /    13 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   21055.31 ms /    31 runs   (  679.20 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   21844.59 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.61 ms /    66 runs   (    0.40 ms per token,  2480.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     605.03 ms /    11 tokens (   55.00 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =   43862.66 ms /    65 runs   (  674.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   44662.75 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.09 ms /    30 runs   (    0.40 ms per token,  2482.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     618.92 ms /    11 tokens (   56.27 ms per token,    17.77 tokens per second)\n",
      "llama_print_timings:        eval time =   19474.92 ms /    29 runs   (  671.55 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20181.52 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.76 ms /    34 runs   (    0.40 ms per token,  2470.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.67 ms /    12 tokens (   53.89 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   22255.05 ms /    33 runs   (  674.40 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   23001.67 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.22 ms /    29 runs   (    0.42 ms per token,  2373.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.91 ms /    12 tokens (   56.66 ms per token,    17.65 tokens per second)\n",
      "llama_print_timings:        eval time =   18747.14 ms /    28 runs   (  669.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19512.93 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.62 ms /    30 runs   (    0.42 ms per token,  2377.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.75 ms /    12 tokens (   53.15 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   19702.97 ms /    29 runs   (  679.41 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20430.80 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.57 ms /    66 runs   (    0.42 ms per token,  2393.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.24 ms /    12 tokens (   56.77 ms per token,    17.62 tokens per second)\n",
      "llama_print_timings:        eval time =   44230.72 ms /    65 runs   (  680.47 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   45112.18 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.37 ms /    30 runs   (    0.41 ms per token,  2425.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     699.18 ms /    13 tokens (   53.78 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   19488.54 ms /    29 runs   (  672.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20275.88 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.88 ms /    31 runs   (    0.42 ms per token,  2406.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.70 ms /    12 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   19739.71 ms /    30 runs   (  657.99 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   20467.88 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.74 ms /    29 runs   (    0.40 ms per token,  2470.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.54 ms /    12 tokens (   54.13 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   18867.03 ms /    28 runs   (  673.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19600.54 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.79 ms /    29 runs   (    0.41 ms per token,  2459.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.37 ms /    12 tokens (   52.95 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   18699.83 ms /    28 runs   (  667.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19419.01 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.94 ms /    30 runs   (    0.40 ms per token,  2513.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.22 ms /    12 tokens (   53.27 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   19193.82 ms /    29 runs   (  661.86 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19920.71 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.84 ms /    29 runs   (    0.41 ms per token,  2449.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     599.89 ms /    11 tokens (   54.54 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   18956.43 ms /    28 runs   (  677.02 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19641.57 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      30.26 ms /    73 runs   (    0.41 ms per token,  2412.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.09 ms /    12 tokens (   53.92 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   48751.57 ms /    72 runs   (  677.11 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   49616.20 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.13 ms /    30 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     689.84 ms /    13 tokens (   53.06 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   19324.99 ms /    29 runs   (  666.38 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20102.20 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.13 ms /    33 runs   (    0.40 ms per token,  2513.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.09 ms /    12 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   21384.58 ms /    32 runs   (  668.27 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22118.80 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.46 ms /    68 runs   (    0.40 ms per token,  2476.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.67 ms /    12 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   45040.10 ms /    67 runs   (  672.24 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   45888.89 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.23 ms /    35 runs   (    0.41 ms per token,  2459.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.09 ms /    12 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   22637.59 ms /    34 runs   (  665.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   23383.16 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.64 ms /    66 runs   (    0.40 ms per token,  2477.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.81 ms /    13 tokens (   52.29 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   43694.73 ms /    65 runs   (  672.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   44567.73 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.18 ms /    25 runs   (    0.41 ms per token,  2456.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.02 ms /    12 tokens (   53.50 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   15944.09 ms /    24 runs   (  664.34 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16658.68 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.43 ms /    23 runs   (    0.45 ms per token,  2204.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.70 ms /    11 tokens (   53.88 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   14707.11 ms /    22 runs   (  668.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15372.20 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.85 ms /    34 runs   (    0.41 ms per token,  2454.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.26 ms /    12 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   22196.56 ms /    33 runs   (  672.62 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22932.29 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.82 ms /    44 runs   (    0.40 ms per token,  2469.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     605.59 ms /    11 tokens (   55.05 ms per token,    18.16 tokens per second)\n",
      "llama_print_timings:        eval time =   29168.51 ms /    43 runs   (  678.34 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   29902.50 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.44 ms /    33 runs   (    0.41 ms per token,  2454.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.23 ms /    12 tokens (   57.02 ms per token,    17.54 tokens per second)\n",
      "llama_print_timings:        eval time =   21521.26 ms /    32 runs   (  672.54 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22301.27 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.99 ms /    30 runs   (    0.40 ms per token,  2502.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.17 ms /    13 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   19565.79 ms /    29 runs   (  674.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20338.83 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.04 ms /    30 runs   (    0.40 ms per token,  2492.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.65 ms /    11 tokens (   54.33 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   19475.46 ms /    29 runs   (  671.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20159.34 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.70 ms /    29 runs   (    0.40 ms per token,  2479.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.85 ms /    13 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   18474.28 ms /    28 runs   (  659.80 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19241.04 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.42 ms /    30 runs   (    0.41 ms per token,  2415.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.31 ms /    12 tokens (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   19421.96 ms /    29 runs   (  669.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20147.57 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.72 ms /    23 runs   (    0.42 ms per token,  2365.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.57 ms /    12 tokens (   53.55 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   14910.81 ms /    22 runs   (  677.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15622.43 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.65 ms /    44 runs   (    0.40 ms per token,  2492.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.15 ms /    12 tokens (   53.43 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   28838.98 ms /    43 runs   (  670.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29607.55 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.47 ms /    31 runs   (    0.40 ms per token,  2485.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.20 ms /    11 tokens (   53.75 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   19517.82 ms /    30 runs   (  650.59 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   20199.36 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.94 ms /    44 runs   (    0.41 ms per token,  2453.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     602.58 ms /    11 tokens (   54.78 ms per token,    18.25 tokens per second)\n",
      "llama_print_timings:        eval time =   28714.50 ms /    43 runs   (  667.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   29445.70 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.81 ms /    29 runs   (    0.41 ms per token,  2454.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.43 ms /    13 tokens (   54.19 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =   18060.24 ms /    28 runs   (  645.01 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   18849.47 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.76 ms /    29 runs   (    0.41 ms per token,  2465.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.47 ms /    12 tokens (   53.54 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   18595.03 ms /    28 runs   (  664.11 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19323.48 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.24 ms /    33 runs   (    0.40 ms per token,  2492.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.06 ms /    12 tokens (   54.34 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   21456.38 ms /    32 runs   (  670.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22204.42 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    20 runs   (    0.41 ms per token,  2461.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.76 ms /    11 tokens (   54.25 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   12733.58 ms /    19 runs   (  670.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13389.67 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.42 ms /    23 runs   (    0.41 ms per token,  2440.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.72 ms /    12 tokens (   53.98 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   14873.33 ms /    22 runs   (  676.06 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15587.99 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.34 ms /    20 runs   (    0.42 ms per token,  2398.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     727.15 ms /    14 tokens (   51.94 ms per token,    19.25 tokens per second)\n",
      "llama_print_timings:        eval time =   12896.63 ms /    19 runs   (  678.77 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13682.95 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.34 ms /    30 runs   (    0.41 ms per token,  2430.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.90 ms /    12 tokens (   55.33 ms per token,    18.07 tokens per second)\n",
      "llama_print_timings:        eval time =   19580.93 ms /    29 runs   (  675.20 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20333.44 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    19 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     715.03 ms /    12 tokens (   59.59 ms per token,    16.78 tokens per second)\n",
      "llama_print_timings:        eval time =   12017.52 ms /    18 runs   (  667.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12787.16 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2600 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.97 ms /    30 runs   (    0.40 ms per token,  2506.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.19 ms /    13 tokens (   52.63 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   19055.78 ms /    29 runs   (  657.10 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19827.06 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.91 ms /    30 runs   (    0.43 ms per token,  2323.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     609.80 ms /    11 tokens (   55.44 ms per token,    18.04 tokens per second)\n",
      "llama_print_timings:        eval time =   19215.36 ms /    29 runs   (  662.60 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19917.36 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.55 ms /    28 runs   (    0.41 ms per token,  2425.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.70 ms /    12 tokens (   54.98 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =   17979.22 ms /    27 runs   (  665.90 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18720.60 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    17 runs   (    0.40 ms per token,  2475.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.75 ms /    13 tokens (   52.21 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =   10702.27 ms /    16 runs   (  668.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   11430.47 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.10 ms /    49 runs   (    0.41 ms per token,  2437.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.10 ms /    11 tokens (   53.83 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   32226.05 ms /    48 runs   (  671.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   32960.94 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.01 ms /    22 runs   (    0.45 ms per token,  2198.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.80 ms /    12 tokens (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   14044.12 ms /    21 runs   (  668.77 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14758.92 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.98 ms /    30 runs   (    0.40 ms per token,  2504.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.64 ms /    12 tokens (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   19336.38 ms /    29 runs   (  666.77 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20061.74 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.87 ms /    44 runs   (    0.41 ms per token,  2461.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.11 ms /    11 tokens (   53.74 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   28886.43 ms /    43 runs   (  671.78 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29607.16 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.81 ms /    32 runs   (    0.40 ms per token,  2497.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.90 ms /    12 tokens (   53.49 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   20805.33 ms /    31 runs   (  671.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21540.56 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.07 ms /    44 runs   (    0.41 ms per token,  2434.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.47 ms /    12 tokens (   53.37 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   28965.84 ms /    43 runs   (  673.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   29735.86 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.92 ms /    32 runs   (    0.40 ms per token,  2476.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.41 ms /    12 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   20692.48 ms /    31 runs   (  667.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21426.06 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.22 ms /    33 runs   (    0.40 ms per token,  2495.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.28 ms /    12 tokens (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   21400.62 ms /    32 runs   (  668.77 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22132.00 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.39 ms /    50 runs   (    0.41 ms per token,  2451.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.60 ms /    11 tokens (   54.33 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   33106.50 ms /    49 runs   (  675.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   33849.79 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.29 ms /    30 runs   (    0.41 ms per token,  2441.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.66 ms /    13 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   19470.83 ms /    29 runs   (  671.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20243.08 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.54 ms /    21 runs   (    0.41 ms per token,  2458.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.76 ms /    11 tokens (   54.43 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   13384.08 ms /    20 runs   (  669.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14043.84 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.16 ms /    30 runs   (    0.41 ms per token,  2466.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.80 ms /    12 tokens (   54.15 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   19334.22 ms /    29 runs   (  666.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20071.69 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.25 ms /    30 runs   (    0.41 ms per token,  2448.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.70 ms /    13 tokens (   52.44 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   19453.80 ms /    29 runs   (  670.82 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20223.93 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    20 runs   (    0.41 ms per token,  2435.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.86 ms /    12 tokens (   53.57 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   12681.83 ms /    19 runs   (  667.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13383.03 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      35.90 ms /    89 runs   (    0.40 ms per token,  2478.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.77 ms /    12 tokens (   53.31 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   58635.64 ms /    88 runs   (  666.31 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   59534.63 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    16 runs   (    0.42 ms per token,  2356.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     607.23 ms /    11 tokens (   55.20 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =   10075.45 ms /    15 runs   (  671.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   10730.11 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.32 ms /    33 runs   (    0.40 ms per token,  2478.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.21 ms /    12 tokens (   53.43 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   21026.14 ms /    32 runs   (  657.07 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21763.12 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.71 ms /    32 runs   (    0.40 ms per token,  2516.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.82 ms /    13 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   20501.85 ms /    31 runs   (  661.35 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21278.42 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.86 ms /    30 runs   (    0.43 ms per token,  2333.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.34 ms /    12 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   19007.97 ms /    29 runs   (  655.45 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   19739.72 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.53 ms /    30 runs   (    0.45 ms per token,  2217.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.74 ms /    12 tokens (   53.06 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   19611.05 ms /    29 runs   (  676.24 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20341.60 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.14 ms /    36 runs   (    0.39 ms per token,  2545.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     706.61 ms /    13 tokens (   54.35 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   23317.78 ms /    35 runs   (  666.22 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24130.74 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.25 ms /    28 runs   (    0.40 ms per token,  2490.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.35 ms /    12 tokens (   53.78 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   18068.24 ms /    27 runs   (  669.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18796.00 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.58 ms /    29 runs   (    0.40 ms per token,  2503.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.78 ms /    11 tokens (   54.62 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   18777.58 ms /    28 runs   (  670.63 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19463.32 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.37 ms /    36 runs   (    0.40 ms per token,  2504.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     666.31 ms /    12 tokens (   55.53 ms per token,    18.01 tokens per second)\n",
      "llama_print_timings:        eval time =   23365.65 ms /    35 runs   (  667.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24138.81 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.21 ms /    36 runs   (    0.39 ms per token,  2532.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.63 ms /    12 tokens (   53.72 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   23079.40 ms /    35 runs   (  659.41 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   23828.11 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.27 ms /    23 runs   (    0.40 ms per token,  2480.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.37 ms /    12 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   14561.59 ms /    22 runs   (  661.89 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15268.64 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.52 ms /    21 runs   (    0.41 ms per token,  2464.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     697.17 ms /    13 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   13608.75 ms /    20 runs   (  680.44 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   14367.49 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.21 ms /    23 runs   (    0.40 ms per token,  2496.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.55 ms /    12 tokens (   53.21 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   14507.04 ms /    22 runs   (  659.41 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15212.71 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.16 ms /    30 runs   (    0.41 ms per token,  2466.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     611.66 ms /    11 tokens (   55.61 ms per token,    17.98 tokens per second)\n",
      "llama_print_timings:        eval time =   19602.58 ms /    29 runs   (  675.95 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20301.73 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.86 ms /    30 runs   (    0.40 ms per token,  2529.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.77 ms /    12 tokens (   53.56 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   19434.07 ms /    29 runs   (  670.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20165.15 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.41 ms /    23 runs   (    0.41 ms per token,  2443.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.34 ms /    12 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   14697.68 ms /    22 runs   (  668.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15405.39 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.37 ms /    23 runs   (    0.41 ms per token,  2455.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.41 ms /    12 tokens (   53.12 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   14644.85 ms /    22 runs   (  665.68 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15349.96 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.12 ms /    61 runs   (    0.41 ms per token,  2427.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.97 ms /    11 tokens (   54.27 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   40815.93 ms /    60 runs   (  680.27 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   41591.30 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.20 ms /    23 runs   (    0.40 ms per token,  2500.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     603.99 ms /    11 tokens (   54.91 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =   14765.20 ms /    22 runs   (  671.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15436.60 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.96 ms /    42 runs   (    0.40 ms per token,  2476.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.32 ms /    12 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   27395.50 ms /    41 runs   (  668.18 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28158.81 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.18 ms /    42 runs   (    0.41 ms per token,  2445.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.72 ms /    11 tokens (   53.79 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   27089.53 ms /    41 runs   (  660.72 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   27805.72 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.50 ms /    23 runs   (    0.41 ms per token,  2422.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.70 ms /    12 tokens (   52.98 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   14775.70 ms /    22 runs   (  671.62 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15478.49 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.23 ms /    20 runs   (    0.41 ms per token,  2431.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.30 ms /    11 tokens (   59.48 ms per token,    16.81 tokens per second)\n",
      "llama_print_timings:        eval time =   12611.17 ms /    19 runs   (  663.75 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13322.58 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    20 runs   (    0.41 ms per token,  2454.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.43 ms /    12 tokens (   54.37 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =   12697.89 ms /    19 runs   (  668.31 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13408.94 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.22 ms /    44 runs   (    0.41 ms per token,  2414.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     700.03 ms /    13 tokens (   53.85 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   28788.31 ms /    43 runs   (  669.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29618.72 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.16 ms /    20 runs   (    0.41 ms per token,  2450.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.98 ms /    12 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   12338.23 ms /    19 runs   (  649.38 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   13033.99 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.06 ms /    44 runs   (    0.41 ms per token,  2436.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.62 ms /    13 tokens (   52.20 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:        eval time =   28617.69 ms /    43 runs   (  665.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   29427.12 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.29 ms /    47 runs   (    0.41 ms per token,  2436.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.32 ms /    11 tokens (   53.94 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   30639.77 ms /    46 runs   (  666.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   31370.13 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.11 ms /    30 runs   (    0.40 ms per token,  2477.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.09 ms /    12 tokens (   52.59 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   19533.92 ms /    29 runs   (  673.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20251.44 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.27 ms /    23 runs   (    0.40 ms per token,  2481.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.04 ms /    12 tokens (   53.59 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   14553.28 ms /    22 runs   (  661.51 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15262.21 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.17 ms /    20 runs   (    0.41 ms per token,  2449.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.08 ms /    11 tokens (   54.55 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   12683.00 ms /    19 runs   (  667.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13341.07 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    18 runs   (    0.41 ms per token,  2468.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.73 ms /    12 tokens (   53.06 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   11333.23 ms /    17 runs   (  666.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12022.63 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.38 ms /    23 runs   (    0.41 ms per token,  2452.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     588.58 ms /    11 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   14500.11 ms /    22 runs   (  659.10 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15156.58 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.95 ms /    44 runs   (    0.41 ms per token,  2451.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.39 ms /    12 tokens (   52.95 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   28583.11 ms /    43 runs   (  664.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   29349.25 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.48 ms /    41 runs   (    0.40 ms per token,  2488.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     733.92 ms /    14 tokens (   52.42 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   26820.83 ms /    40 runs   (  670.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   27673.68 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.75 ms /    31 runs   (    0.41 ms per token,  2430.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.44 ms /    12 tokens (   52.87 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   20168.33 ms /    30 runs   (  672.28 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20894.22 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.97 ms /    44 runs   (    0.41 ms per token,  2448.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.43 ms /    12 tokens (   53.87 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   28367.45 ms /    43 runs   (  659.71 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   29146.23 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /    20 runs   (    0.41 ms per token,  2433.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.18 ms /    12 tokens (   54.35 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   12388.16 ms /    19 runs   (  652.01 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13099.08 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.56 ms /    21 runs   (    0.41 ms per token,  2454.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.19 ms /    13 tokens (   52.09 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   13028.28 ms /    20 runs   (  651.41 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   13767.76 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    20 runs   (    0.41 ms per token,  2458.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.65 ms /    12 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   12741.97 ms /    19 runs   (  670.63 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13439.60 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.60 ms /    44 runs   (    0.40 ms per token,  2499.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.66 ms /    11 tokens (   53.88 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   28304.26 ms /    43 runs   (  658.24 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   29023.89 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.86 ms /    30 runs   (    0.40 ms per token,  2529.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.42 ms /    12 tokens (   53.20 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   19543.03 ms /    29 runs   (  673.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20268.94 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.05 ms /    42 runs   (    0.41 ms per token,  2463.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.59 ms /    13 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   27479.55 ms /    41 runs   (  670.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28288.61 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.75 ms /    66 runs   (    0.42 ms per token,  2378.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     588.48 ms /    11 tokens (   53.50 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   43413.52 ms /    65 runs   (  667.90 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   44204.51 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.11 ms /    33 runs   (    0.40 ms per token,  2517.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     603.65 ms /    11 tokens (   54.88 ms per token,    18.22 tokens per second)\n",
      "llama_print_timings:        eval time =   21085.10 ms /    32 runs   (  658.91 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21786.04 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.24 ms /    52 runs   (    0.41 ms per token,  2448.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     702.30 ms /    12 tokens (   58.53 ms per token,    17.09 tokens per second)\n",
      "llama_print_timings:        eval time =   33452.06 ms /    51 runs   (  655.92 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   34308.08 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.10 ms /    30 runs   (    0.40 ms per token,  2480.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.62 ms /    12 tokens (   53.88 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   19211.34 ms /    29 runs   (  662.46 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19945.87 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.06 ms /    20 runs   (    0.40 ms per token,  2479.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.68 ms /    12 tokens (   52.81 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   12670.38 ms /    19 runs   (  666.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13362.75 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.92 ms /    37 runs   (    0.40 ms per token,  2479.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.27 ms /    13 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   24196.85 ms /    36 runs   (  672.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24991.59 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.01 ms /    44 runs   (    0.41 ms per token,  2442.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.66 ms /    12 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   28403.93 ms /    43 runs   (  660.56 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   29167.31 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.90 ms /    30 runs   (    0.43 ms per token,  2325.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.00 ms /    12 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   19058.26 ms /    29 runs   (  657.18 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19790.40 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.23 ms /    30 runs   (    0.41 ms per token,  2451.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.76 ms /    12 tokens (   53.65 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   19388.35 ms /    29 runs   (  668.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20120.26 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.80 ms /    44 runs   (    0.40 ms per token,  2472.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.16 ms /    11 tokens (   53.83 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   28938.22 ms /    43 runs   (  672.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29660.33 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.13 ms /    30 runs   (    0.40 ms per token,  2472.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.60 ms /    12 tokens (   53.22 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   19408.19 ms /    29 runs   (  669.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20135.62 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.36 ms /    35 runs   (    0.41 ms per token,  2437.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.92 ms /    13 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   22346.20 ms /    34 runs   (  657.24 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   23137.69 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.38 ms /    33 runs   (    0.41 ms per token,  2465.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     599.92 ms /    11 tokens (   54.54 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   21341.64 ms /    32 runs   (  666.93 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22040.69 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.23 ms /    20 runs   (    0.41 ms per token,  2431.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     661.56 ms /    11 tokens (   60.14 ms per token,    16.63 tokens per second)\n",
      "llama_print_timings:        eval time =   12782.70 ms /    19 runs   (  672.77 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13502.89 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.87 ms /    34 runs   (    0.41 ms per token,  2451.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     667.04 ms /    12 tokens (   55.59 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =   21972.06 ms /    33 runs   (  665.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22739.56 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.81 ms /    32 runs   (    0.40 ms per token,  2498.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.97 ms /    13 tokens (   52.92 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   20220.40 ms /    31 runs   (  652.27 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   21006.47 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.89 ms /    32 runs   (    0.40 ms per token,  2481.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.50 ms /    12 tokens (   54.96 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =   20434.55 ms /    31 runs   (  659.18 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21189.36 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.60 ms /    62 runs   (    0.41 ms per token,  2421.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     714.04 ms /    13 tokens (   54.93 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =   40949.60 ms /    61 runs   (  671.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   41847.55 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.10 ms /    20 runs   (    0.40 ms per token,  2469.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.19 ms /    12 tokens (   55.27 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =   12986.17 ms /    19 runs   (  683.48 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13708.22 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.99 ms /    44 runs   (    0.41 ms per token,  2445.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     672.77 ms /    11 tokens (   61.16 ms per token,    16.35 tokens per second)\n",
      "llama_print_timings:        eval time =   29452.76 ms /    43 runs   (  684.95 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   30255.16 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      57.99 ms /   140 runs   (    0.41 ms per token,  2414.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     697.72 ms /    12 tokens (   58.14 ms per token,    17.20 tokens per second)\n",
      "llama_print_timings:        eval time =   92362.72 ms /   139 runs   (  664.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   93485.41 ms /   151 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.13 ms /    32 runs   (    0.41 ms per token,  2437.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     673.39 ms /    12 tokens (   56.12 ms per token,    17.82 tokens per second)\n",
      "llama_print_timings:        eval time =   20612.54 ms /    31 runs   (  664.92 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21379.81 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.54 ms /    28 runs   (    0.41 ms per token,  2426.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.73 ms /    12 tokens (   53.14 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   17927.69 ms /    27 runs   (  663.99 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   18647.21 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.11 ms /    42 runs   (    0.41 ms per token,  2454.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.03 ms /    13 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   27401.21 ms /    41 runs   (  668.32 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28207.22 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.43 ms /    31 runs   (    0.40 ms per token,  2494.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.12 ms /    12 tokens (   54.09 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   19749.78 ms /    30 runs   (  658.33 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   20488.88 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.19 ms /    33 runs   (    0.40 ms per token,  2502.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.76 ms /    11 tokens (   53.98 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   21624.61 ms /    32 runs   (  675.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   22315.56 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.79 ms /    32 runs   (    0.40 ms per token,  2500.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     668.52 ms /    12 tokens (   55.71 ms per token,    17.95 tokens per second)\n",
      "llama_print_timings:        eval time =   20949.58 ms /    31 runs   (  675.79 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21711.65 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.72 ms /    29 runs   (    0.40 ms per token,  2474.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.44 ms /    12 tokens (   52.95 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   19096.31 ms /    28 runs   (  682.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19816.80 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.67 ms /    31 runs   (    0.44 ms per token,  2267.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     700.49 ms /    12 tokens (   58.37 ms per token,    17.13 tokens per second)\n",
      "llama_print_timings:        eval time =   20447.79 ms /    30 runs   (  681.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   21247.66 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    20 runs   (    0.40 ms per token,  2499.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.72 ms /    12 tokens (   54.14 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   12562.57 ms /    19 runs   (  661.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13271.59 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.86 ms /    29 runs   (    0.41 ms per token,  2445.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.00 ms /    13 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   18587.68 ms /    28 runs   (  663.85 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19354.58 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.55 ms /    33 runs   (    0.41 ms per token,  2435.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     599.30 ms /    11 tokens (   54.48 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =   21100.98 ms /    32 runs   (  659.41 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21801.25 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.85 ms /    34 runs   (    0.41 ms per token,  2455.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     703.90 ms /    12 tokens (   58.66 ms per token,    17.05 tokens per second)\n",
      "llama_print_timings:        eval time =   21772.60 ms /    33 runs   (  659.78 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   22577.08 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.38 ms /    23 runs   (    0.41 ms per token,  2451.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.29 ms /    12 tokens (   53.52 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   14524.49 ms /    22 runs   (  660.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15234.40 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.33 ms /    35 runs   (    0.41 ms per token,  2443.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     611.33 ms /    11 tokens (   55.58 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =   22856.60 ms /    34 runs   (  672.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   23571.31 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.32 ms /    30 runs   (    0.41 ms per token,  2435.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     660.77 ms /    12 tokens (   55.06 ms per token,    18.16 tokens per second)\n",
      "llama_print_timings:        eval time =   19398.78 ms /    29 runs   (  668.92 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20148.02 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.95 ms /    26 runs   (    0.42 ms per token,  2375.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     697.41 ms /    13 tokens (   53.65 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   16678.43 ms /    25 runs   (  667.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   17454.68 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.77 ms /    44 runs   (    0.40 ms per token,  2475.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.99 ms /    12 tokens (   53.92 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   28854.55 ms /    43 runs   (  671.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29631.34 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2700 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.88 ms /    44 runs   (    0.41 ms per token,  2461.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.91 ms /    12 tokens (   53.41 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   28788.79 ms /    43 runs   (  669.51 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29559.35 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.98 ms /    20 runs   (    0.40 ms per token,  2506.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.33 ms /    11 tokens (   54.03 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   12613.37 ms /    19 runs   (  663.86 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13266.40 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.85 ms /    69 runs   (    0.40 ms per token,  2477.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     744.17 ms /    14 tokens (   53.16 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   45359.08 ms /    68 runs   (  667.05 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   46310.22 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.42 ms /    25 runs   (    0.42 ms per token,  2399.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     604.44 ms /    11 tokens (   54.95 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =   15975.28 ms /    24 runs   (  665.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16653.77 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.49 ms /    64 runs   (    0.40 ms per token,  2510.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.72 ms /    12 tokens (   53.64 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   41887.74 ms /    63 runs   (  664.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   42722.79 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.27 ms /    30 runs   (    0.41 ms per token,  2444.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.03 ms /    12 tokens (   53.92 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   19113.17 ms /    29 runs   (  659.07 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19848.39 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.90 ms /    32 runs   (    0.40 ms per token,  2480.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.87 ms /    12 tokens (   53.91 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   20446.42 ms /    31 runs   (  659.56 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21187.66 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.77 ms /    27 runs   (    0.40 ms per token,  2506.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.32 ms /    13 tokens (   52.49 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   17414.19 ms /    26 runs   (  669.78 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18175.53 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.18 ms /    40 runs   (    0.40 ms per token,  2472.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     661.41 ms /    12 tokens (   55.12 ms per token,    18.14 tokens per second)\n",
      "llama_print_timings:        eval time =   25956.31 ms /    39 runs   (  665.55 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26734.19 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.37 ms /    62 runs   (    0.43 ms per token,  2351.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.14 ms /    11 tokens (   54.01 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   39725.06 ms /    61 runs   (  651.23 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   40505.79 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    17 runs   (    0.41 ms per token,  2429.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.32 ms /    12 tokens (   53.86 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   10476.78 ms /    16 runs   (  654.80 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   11172.56 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    20 runs   (    0.41 ms per token,  2434.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.35 ms /    12 tokens (   53.86 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   12269.82 ms /    19 runs   (  645.78 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   12976.18 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.07 ms /    30 runs   (    0.40 ms per token,  2485.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.24 ms /    13 tokens (   54.17 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   19283.08 ms /    29 runs   (  664.93 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20075.81 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.36 ms /    60 runs   (    0.42 ms per token,  2365.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.46 ms /    13 tokens (   52.73 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   38777.69 ms /    59 runs   (  657.25 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   39644.82 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.78 ms /    32 runs   (    0.40 ms per token,  2504.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.10 ms /    11 tokens (   53.55 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   20713.44 ms /    31 runs   (  668.18 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21396.02 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.81 ms /    34 runs   (    0.41 ms per token,  2461.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.63 ms /    12 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   22078.12 ms /    33 runs   (  669.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22816.59 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.10 ms /    20 runs   (    0.41 ms per token,  2468.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.05 ms /    12 tokens (   54.42 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   13023.31 ms /    19 runs   (  685.44 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13735.89 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.03 ms /    49 runs   (    0.41 ms per token,  2446.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.44 ms /    11 tokens (   53.59 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   32578.68 ms /    48 runs   (  678.72 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   33311.79 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.30 ms /    20 runs   (    0.42 ms per token,  2408.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     694.70 ms /    13 tokens (   53.44 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   12772.26 ms /    19 runs   (  672.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13525.27 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.05 ms /    20 runs   (    0.40 ms per token,  2485.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.89 ms /    12 tokens (   53.16 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   12663.21 ms /    19 runs   (  666.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13359.48 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.23 ms /    30 runs   (    0.41 ms per token,  2452.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.57 ms /    12 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   19404.54 ms /    29 runs   (  669.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20132.83 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.42 ms /    61 runs   (    0.43 ms per token,  2308.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     700.33 ms /    13 tokens (   53.87 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   40158.77 ms /    60 runs   (  669.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   41049.84 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.50 ms /    52 runs   (    0.43 ms per token,  2311.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.96 ms /    12 tokens (   54.33 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   34348.35 ms /    51 runs   (  673.50 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   35159.57 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.64 ms /    62 runs   (    0.43 ms per token,  2327.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.49 ms /    12 tokens (   53.29 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   40906.26 ms /    61 runs   (  670.59 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   41733.92 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.17 ms /    30 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.95 ms /    13 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   19489.17 ms /    29 runs   (  672.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20268.84 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.36 ms /    62 runs   (    0.41 ms per token,  2444.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.61 ms /    12 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   39465.34 ms /    61 runs   (  646.97 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   40295.79 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.77 ms /    57 runs   (    0.42 ms per token,  2398.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.86 ms /    12 tokens (   53.15 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   37782.18 ms /    56 runs   (  674.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   38589.87 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.05 ms /    20 runs   (    0.45 ms per token,  2210.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     701.47 ms /    13 tokens (   53.96 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   12880.04 ms /    19 runs   (  677.90 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13645.04 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.48 ms /    59 runs   (    0.41 ms per token,  2409.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.09 ms /    12 tokens (   53.26 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   38716.61 ms /    58 runs   (  667.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   39531.01 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.12 ms /    59 runs   (    0.41 ms per token,  2445.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     660.30 ms /    12 tokens (   55.02 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =   38937.19 ms /    58 runs   (  671.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   39773.94 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.45 ms /    36 runs   (    0.40 ms per token,  2491.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     705.24 ms /    12 tokens (   58.77 ms per token,    17.02 tokens per second)\n",
      "llama_print_timings:        eval time =   23427.33 ms /    35 runs   (  669.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24238.00 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.79 ms /    41 runs   (    0.41 ms per token,  2442.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.28 ms /    11 tokens (   54.12 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   27007.69 ms /    40 runs   (  675.19 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27723.91 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.20 ms /    59 runs   (    0.41 ms per token,  2438.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     658.02 ms /    12 tokens (   54.84 ms per token,    18.24 tokens per second)\n",
      "llama_print_timings:        eval time =   39317.22 ms /    58 runs   (  677.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   40150.45 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.45 ms /    20 runs   (    0.42 ms per token,  2368.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.23 ms /    12 tokens (   58.69 ms per token,    17.04 tokens per second)\n",
      "llama_print_timings:        eval time =   12838.84 ms /    19 runs   (  675.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13604.57 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.10 ms /    49 runs   (    0.41 ms per token,  2437.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     694.63 ms /    13 tokens (   53.43 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   32339.69 ms /    48 runs   (  673.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   33179.14 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.94 ms /    30 runs   (    0.43 ms per token,  2318.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.73 ms /    12 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   19643.00 ms /    29 runs   (  677.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20376.99 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.91 ms /    30 runs   (    0.43 ms per token,  2323.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.97 ms /    12 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   18928.74 ms /    29 runs   (  652.72 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   19659.33 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      31.71 ms /    78 runs   (    0.41 ms per token,  2459.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.67 ms /    12 tokens (   53.47 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   52393.31 ms /    77 runs   (  680.43 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   53269.38 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.02 ms /    29 runs   (    0.41 ms per token,  2413.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.80 ms /    12 tokens (   56.65 ms per token,    17.65 tokens per second)\n",
      "llama_print_timings:        eval time =   18886.78 ms /    28 runs   (  674.53 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19652.51 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.04 ms /    30 runs   (    0.40 ms per token,  2491.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.40 ms /    11 tokens (   54.22 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   19244.69 ms /    29 runs   (  663.61 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19929.71 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.82 ms /    26 runs   (    0.42 ms per token,  2403.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     729.97 ms /    14 tokens (   52.14 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   16590.65 ms /    25 runs   (  663.63 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17396.71 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.28 ms /    28 runs   (    0.40 ms per token,  2481.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.76 ms /    12 tokens (   53.90 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   18050.10 ms /    27 runs   (  668.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18778.67 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.16 ms /    30 runs   (    0.41 ms per token,  2467.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.53 ms /    12 tokens (   54.63 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   19487.37 ms /    29 runs   (  671.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20229.60 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.47 ms /    31 runs   (    0.40 ms per token,  2486.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.44 ms /    12 tokens (   58.70 ms per token,    17.03 tokens per second)\n",
      "llama_print_timings:        eval time =   19897.17 ms /    30 runs   (  663.24 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20691.73 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.24 ms /    23 runs   (    0.40 ms per token,  2489.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.52 ms /    12 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   14642.03 ms /    22 runs   (  665.55 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15344.38 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.55 ms /    29 runs   (    0.40 ms per token,  2510.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.81 ms /    11 tokens (   57.35 ms per token,    17.44 tokens per second)\n",
      "llama_print_timings:        eval time =   18485.07 ms /    28 runs   (  660.18 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19200.29 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.53 ms /    29 runs   (    0.40 ms per token,  2514.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.76 ms /    12 tokens (   54.56 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   18647.21 ms /    28 runs   (  665.97 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19386.13 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.00 ms /    30 runs   (    0.40 ms per token,  2499.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     746.53 ms /    13 tokens (   57.43 ms per token,    17.41 tokens per second)\n",
      "llama_print_timings:        eval time =   19398.74 ms /    29 runs   (  668.92 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20233.07 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.63 ms /    29 runs   (    0.40 ms per token,  2494.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     602.64 ms /    11 tokens (   54.79 ms per token,    18.25 tokens per second)\n",
      "llama_print_timings:        eval time =   18710.18 ms /    28 runs   (  668.22 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19398.28 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.73 ms /    31 runs   (    0.41 ms per token,  2434.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     695.88 ms /    13 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   19892.81 ms /    30 runs   (  663.09 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20680.84 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.50 ms /    29 runs   (    0.40 ms per token,  2522.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     609.96 ms /    11 tokens (   55.45 ms per token,    18.03 tokens per second)\n",
      "llama_print_timings:        eval time =   18513.03 ms /    28 runs   (  661.18 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19207.82 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.70 ms /    32 runs   (    0.40 ms per token,  2519.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.10 ms /    12 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   21214.99 ms /    31 runs   (  684.35 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   21953.33 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.55 ms /    31 runs   (    0.40 ms per token,  2469.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     604.15 ms /    11 tokens (   54.92 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =   20136.56 ms /    30 runs   (  671.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20832.33 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.46 ms /    31 runs   (    0.40 ms per token,  2488.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.35 ms /    12 tokens (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   20197.38 ms /    30 runs   (  673.25 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20926.69 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.58 ms /    34 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.51 ms /    13 tokens (   53.35 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   22019.11 ms /    33 runs   (  667.25 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22813.94 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.82 ms /    30 runs   (    0.39 ms per token,  2537.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.68 ms /    12 tokens (   53.14 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   18946.34 ms /    29 runs   (  653.32 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   19672.12 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.06 ms /    35 runs   (    0.40 ms per token,  2490.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.95 ms /    12 tokens (   54.25 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   22435.00 ms /    34 runs   (  659.85 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   23188.74 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      32.08 ms /    76 runs   (    0.42 ms per token,  2369.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.01 ms /    12 tokens (   53.50 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   50171.86 ms /    75 runs   (  668.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   51048.13 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.67 ms /    32 runs   (    0.40 ms per token,  2526.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.01 ms /    11 tokens (   54.00 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   20599.00 ms /    31 runs   (  664.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21286.28 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.17 ms /    30 runs   (    0.41 ms per token,  2464.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.42 ms /    12 tokens (   53.04 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   19422.66 ms /    29 runs   (  669.75 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20147.26 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.19 ms /    42 runs   (    0.41 ms per token,  2443.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.15 ms /    12 tokens (   52.76 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   27921.03 ms /    41 runs   (  681.00 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   28676.70 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.14 ms /    30 runs   (    0.40 ms per token,  2470.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.64 ms /    11 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   19593.64 ms /    29 runs   (  675.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20275.34 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.84 ms /    29 runs   (    0.41 ms per token,  2449.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.94 ms /    13 tokens (   52.69 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   18992.01 ms /    28 runs   (  678.29 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19761.46 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.07 ms /    30 runs   (    0.40 ms per token,  2485.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.14 ms /    11 tokens (   53.83 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   19565.64 ms /    29 runs   (  674.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20246.75 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.32 ms /    57 runs   (    0.41 ms per token,  2444.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     602.85 ms /    11 tokens (   54.80 ms per token,    18.25 tokens per second)\n",
      "llama_print_timings:        eval time =   38322.52 ms /    56 runs   (  684.33 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   39095.30 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.62 ms /    29 runs   (    0.40 ms per token,  2496.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.84 ms /    12 tokens (   53.32 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   18904.65 ms /    28 runs   (  675.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19628.14 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.96 ms /    32 runs   (    0.41 ms per token,  2468.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.91 ms /    12 tokens (   54.16 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   21296.15 ms /    31 runs   (  686.97 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   22040.29 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.65 ms /    29 runs   (    0.40 ms per token,  2488.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     706.72 ms /    12 tokens (   58.89 ms per token,    16.98 tokens per second)\n",
      "llama_print_timings:        eval time =   18743.75 ms /    28 runs   (  669.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19535.10 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.02 ms /    29 runs   (    0.41 ms per token,  2412.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.45 ms /    12 tokens (   53.20 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   18775.92 ms /    28 runs   (  670.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19502.59 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.13 ms /    30 runs   (    0.40 ms per token,  2473.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     701.13 ms /    13 tokens (   53.93 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   19457.68 ms /    29 runs   (  670.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20247.20 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.65 ms /    32 runs   (    0.40 ms per token,  2529.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.39 ms /    12 tokens (   54.03 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   20718.50 ms /    31 runs   (  668.34 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21462.59 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.82 ms /    32 runs   (    0.43 ms per token,  2315.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.72 ms /    12 tokens (   53.39 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   20702.91 ms /    31 runs   (  667.84 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21441.53 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.63 ms /    29 runs   (    0.40 ms per token,  2492.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     668.76 ms /    12 tokens (   55.73 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =   18840.74 ms /    28 runs   (  672.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19593.03 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.67 ms /    31 runs   (    0.44 ms per token,  2268.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     661.01 ms /    12 tokens (   55.08 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =   19847.44 ms /    30 runs   (  661.58 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20605.30 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.62 ms /    63 runs   (    0.42 ms per token,  2366.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.96 ms /    11 tokens (   54.18 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   40908.26 ms /    62 runs   (  659.81 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   41696.67 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.79 ms /    32 runs   (    0.40 ms per token,  2502.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     743.89 ms /    13 tokens (   57.22 ms per token,    17.48 tokens per second)\n",
      "llama_print_timings:        eval time =   20682.38 ms /    31 runs   (  667.17 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21520.45 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.62 ms /    31 runs   (    0.41 ms per token,  2455.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.12 ms /    12 tokens (   52.68 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   19943.98 ms /    30 runs   (  664.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20665.42 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.49 ms /    33 runs   (    0.41 ms per token,  2446.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.25 ms /    12 tokens (   53.94 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   21697.37 ms /    32 runs   (  678.04 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22442.45 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.55 ms /    60 runs   (    0.41 ms per token,  2443.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.26 ms /    12 tokens (   54.11 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   39695.31 ms /    59 runs   (  672.80 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   40522.55 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.63 ms /    48 runs   (    0.41 ms per token,  2445.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.43 ms /    12 tokens (   54.37 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =   31512.19 ms /    47 runs   (  670.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   32307.85 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.97 ms /    30 runs   (    0.40 ms per token,  2506.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     696.20 ms /    13 tokens (   53.55 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   19065.02 ms /    29 runs   (  657.41 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19848.66 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      53.98 ms /   128 runs   (    0.42 ms per token,  2371.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.17 ms /    12 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   85477.94 ms /   127 runs   (  673.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   86513.52 ms /   139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.28 ms /    28 runs   (    0.40 ms per token,  2483.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.71 ms /    12 tokens (   53.89 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   17957.28 ms /    27 runs   (  665.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18687.48 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.79 ms /    29 runs   (    0.41 ms per token,  2459.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.31 ms /    11 tokens (   53.94 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   18598.79 ms /    28 runs   (  664.24 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19277.62 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.33 ms /    30 runs   (    0.41 ms per token,  2434.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.20 ms /    12 tokens (   53.27 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   19353.20 ms /    29 runs   (  667.35 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20081.35 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.28 ms /    23 runs   (    0.40 ms per token,  2478.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.00 ms /    12 tokens (   52.83 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   14469.17 ms /    22 runs   (  657.69 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15170.74 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.67 ms /    29 runs   (    0.40 ms per token,  2484.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.09 ms /    12 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   18659.89 ms /    28 runs   (  666.42 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19387.25 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.42 ms /    30 runs   (    0.41 ms per token,  2416.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.45 ms /    13 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   19538.39 ms /    29 runs   (  673.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20315.80 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      29.62 ms /    72 runs   (    0.41 ms per token,  2430.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     602.13 ms /    11 tokens (   54.74 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =   47339.28 ms /    71 runs   (  666.75 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   48157.88 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.93 ms /    51 runs   (    0.41 ms per token,  2436.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.11 ms /    12 tokens (   57.76 ms per token,    17.31 tokens per second)\n",
      "llama_print_timings:        eval time =   33201.28 ms /    50 runs   (  664.03 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   34045.94 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.35 ms /    47 runs   (    0.41 ms per token,  2429.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.26 ms /    12 tokens (   54.19 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =   30724.79 ms /    46 runs   (  667.93 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   31513.97 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.00 ms /    57 runs   (    0.44 ms per token,  2280.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.42 ms /    12 tokens (   54.12 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   35885.21 ms /    56 runs   (  640.81 ms per token,     1.56 tokens per second)\n",
      "llama_print_timings:       total time =   36712.60 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    20 runs   (    0.40 ms per token,  2472.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.67 ms /    12 tokens (   53.56 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   12442.60 ms /    19 runs   (  654.87 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13142.41 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.71 ms /    34 runs   (    0.40 ms per token,  2479.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     690.28 ms /    13 tokens (   53.10 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   21682.12 ms /    33 runs   (  657.03 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   22471.30 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.36 ms /    33 runs   (    0.40 ms per token,  2470.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.31 ms /    12 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   21111.49 ms /    32 runs   (  659.73 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21849.98 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.18 ms /    23 runs   (    0.40 ms per token,  2506.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     607.88 ms /    11 tokens (   55.26 ms per token,    18.10 tokens per second)\n",
      "llama_print_timings:        eval time =   14653.65 ms /    22 runs   (  666.07 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15328.59 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.46 ms /    36 runs   (    0.40 ms per token,  2488.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     732.65 ms /    14 tokens (   52.33 ms per token,    19.11 tokens per second)\n",
      "llama_print_timings:        eval time =   23269.69 ms /    35 runs   (  664.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24108.68 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.43 ms /    30 runs   (    0.41 ms per token,  2413.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.78 ms /    12 tokens (   56.98 ms per token,    17.55 tokens per second)\n",
      "llama_print_timings:        eval time =   19403.97 ms /    29 runs   (  669.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20175.94 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.12 ms /    32 runs   (    0.41 ms per token,  2439.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     609.96 ms /    11 tokens (   55.45 ms per token,    18.03 tokens per second)\n",
      "llama_print_timings:        eval time =   20806.15 ms /    31 runs   (  671.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21510.64 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.78 ms /    43 runs   (    0.41 ms per token,  2418.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     658.03 ms /    12 tokens (   54.84 ms per token,    18.24 tokens per second)\n",
      "llama_print_timings:        eval time =   27854.30 ms /    42 runs   (  663.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   28640.56 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2800 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.72 ms /    26 runs   (    0.41 ms per token,  2425.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.65 ms /    12 tokens (   53.22 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   16546.38 ms /    25 runs   (  661.86 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17262.49 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.41 ms /    20 runs   (    0.42 ms per token,  2378.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.89 ms /    11 tokens (   54.44 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   12625.27 ms /    19 runs   (  664.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13284.28 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.99 ms /    29 runs   (    0.41 ms per token,  2418.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     709.94 ms /    13 tokens (   54.61 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   18533.07 ms /    28 runs   (  661.90 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19329.27 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.07 ms /    20 runs   (    0.40 ms per token,  2479.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.33 ms /    12 tokens (   54.53 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   12636.81 ms /    19 runs   (  665.10 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13350.69 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.28 ms /    20 runs   (    0.41 ms per token,  2416.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.09 ms /    12 tokens (   53.42 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   12462.29 ms /    19 runs   (  655.91 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13163.72 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.43 ms /    30 runs   (    0.45 ms per token,  2233.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.25 ms /    11 tokens (   54.02 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   19267.07 ms /    29 runs   (  664.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19954.91 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.92 ms /    30 runs   (    0.43 ms per token,  2321.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.56 ms /    12 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   19525.53 ms /    29 runs   (  673.29 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20255.29 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.66 ms /    29 runs   (    0.40 ms per token,  2487.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.76 ms /    12 tokens (   54.31 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   18691.43 ms /    28 runs   (  667.55 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19428.28 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.05 ms /    42 runs   (    0.41 ms per token,  2463.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.65 ms /    13 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   27315.01 ms /    41 runs   (  666.22 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28132.69 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.54 ms /    48 runs   (    0.41 ms per token,  2457.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     608.96 ms /    11 tokens (   55.36 ms per token,    18.06 tokens per second)\n",
      "llama_print_timings:        eval time =   31209.03 ms /    47 runs   (  664.02 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   31960.90 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.98 ms /    58 runs   (    0.41 ms per token,  2419.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     599.78 ms /    11 tokens (   54.53 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   38691.33 ms /    57 runs   (  678.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   39462.73 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.98 ms /    32 runs   (    0.41 ms per token,  2465.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.87 ms /    12 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   20887.57 ms /    31 runs   (  673.79 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21616.97 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.01 ms /    64 runs   (    0.41 ms per token,  2460.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.32 ms /    12 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   42962.18 ms /    63 runs   (  681.94 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   43792.65 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.09 ms /    32 runs   (    0.41 ms per token,  2443.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.75 ms /    12 tokens (   53.06 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   20562.96 ms /    31 runs   (  663.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21294.68 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.57 ms /    58 runs   (    0.41 ms per token,  2460.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.56 ms /    12 tokens (   53.46 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   37671.81 ms /    57 runs   (  660.91 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   38484.56 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.14 ms /    30 runs   (    0.40 ms per token,  2470.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.05 ms /    13 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   19092.09 ms /    29 runs   (  658.35 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19862.66 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.23 ms /    30 runs   (    0.41 ms per token,  2453.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.20 ms /    12 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   19318.38 ms /    29 runs   (  666.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20042.74 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.24 ms /    30 runs   (    0.41 ms per token,  2451.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.56 ms /    12 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   19037.30 ms /    29 runs   (  656.46 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19766.09 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.84 ms /    39 runs   (    0.41 ms per token,  2461.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     660.14 ms /    12 tokens (   55.01 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =   25412.92 ms /    38 runs   (  668.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26188.86 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.84 ms /    29 runs   (    0.41 ms per token,  2450.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.57 ms /    12 tokens (   53.88 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   18568.19 ms /    28 runs   (  663.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19299.67 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      34.47 ms /    84 runs   (    0.41 ms per token,  2436.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     711.24 ms /    13 tokens (   54.71 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =   55997.63 ms /    83 runs   (  674.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   56959.45 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.62 ms /    31 runs   (    0.41 ms per token,  2456.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.41 ms /    12 tokens (   54.70 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =   20138.19 ms /    30 runs   (  671.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20886.27 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      32.97 ms /    81 runs   (    0.41 ms per token,  2456.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.98 ms /    12 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   54290.26 ms /    80 runs   (  678.63 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   55167.72 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.88 ms /    30 runs   (    0.40 ms per token,  2524.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     697.38 ms /    13 tokens (   53.64 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   19469.35 ms /    29 runs   (  671.36 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20255.96 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.40 ms /    23 runs   (    0.41 ms per token,  2447.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.75 ms /    11 tokens (   53.98 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   14654.28 ms /    22 runs   (  666.10 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15315.92 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.01 ms /    32 runs   (    0.41 ms per token,  2459.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.54 ms /    12 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   20670.89 ms /    31 runs   (  666.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21406.83 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.44 ms /    31 runs   (    0.40 ms per token,  2492.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.47 ms /    11 tokens (   54.32 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   19466.10 ms /    30 runs   (  648.87 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   20155.69 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.39 ms /    20 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.26 ms /    12 tokens (   54.27 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   12494.46 ms /    19 runs   (  657.60 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13205.11 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.76 ms /    58 runs   (    0.41 ms per token,  2441.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     702.48 ms /    12 tokens (   58.54 ms per token,    17.08 tokens per second)\n",
      "llama_print_timings:        eval time =   37672.72 ms /    57 runs   (  660.92 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   38543.97 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.23 ms /    20 runs   (    0.41 ms per token,  2431.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     618.56 ms /    11 tokens (   56.23 ms per token,    17.78 tokens per second)\n",
      "llama_print_timings:        eval time =   12767.88 ms /    19 runs   (  671.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13443.67 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.68 ms /    31 runs   (    0.41 ms per token,  2445.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.62 ms /    13 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   19571.42 ms /    30 runs   (  652.38 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   20347.63 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.59 ms /    55 runs   (    0.41 ms per token,  2434.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.37 ms /    11 tokens (   53.67 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   36288.81 ms /    54 runs   (  672.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   37041.88 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.58 ms /    50 runs   (    0.41 ms per token,  2430.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.11 ms /    12 tokens (   53.59 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   32754.71 ms /    49 runs   (  668.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   33546.40 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.26 ms /    37 runs   (    0.41 ms per token,  2425.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.45 ms /    12 tokens (   53.29 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   23751.30 ms /    36 runs   (  659.76 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   24502.95 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.57 ms /    30 runs   (    0.42 ms per token,  2387.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.57 ms /    13 tokens (   53.74 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   19388.50 ms /    29 runs   (  668.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20183.49 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.79 ms /    24 runs   (    0.41 ms per token,  2452.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.87 ms /    11 tokens (   58.44 ms per token,    17.11 tokens per second)\n",
      "llama_print_timings:        eval time =   15284.42 ms /    23 runs   (  664.54 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15999.01 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.19 ms /    42 runs   (    0.43 ms per token,  2309.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.43 ms /    12 tokens (   53.29 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   27144.44 ms /    41 runs   (  662.06 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   27915.39 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      46.87 ms /   114 runs   (    0.41 ms per token,  2432.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     624.37 ms /    11 tokens (   56.76 ms per token,    17.62 tokens per second)\n",
      "llama_print_timings:        eval time =   76246.67 ms /   113 runs   (  674.75 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   77213.85 ms /   124 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.32 ms /    30 runs   (    0.41 ms per token,  2435.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     604.52 ms /    11 tokens (   54.96 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =   19366.07 ms /    29 runs   (  667.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20059.26 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.45 ms /    35 runs   (    0.41 ms per token,  2422.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.44 ms /    12 tokens (   53.29 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   22715.04 ms /    34 runs   (  668.09 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   23457.41 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.09 ms /    42 runs   (    0.41 ms per token,  2458.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.91 ms /    12 tokens (   53.99 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   27116.81 ms /    41 runs   (  661.39 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   27890.21 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.93 ms /    58 runs   (    0.41 ms per token,  2423.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.53 ms /    12 tokens (   53.54 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   38046.06 ms /    57 runs   (  667.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   38860.71 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.36 ms /    31 runs   (    0.40 ms per token,  2508.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     616.00 ms /    11 tokens (   56.00 ms per token,    17.86 tokens per second)\n",
      "llama_print_timings:        eval time =   19667.77 ms /    30 runs   (  655.59 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   20375.35 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.25 ms /    42 runs   (    0.41 ms per token,  2434.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     703.60 ms /    12 tokens (   58.63 ms per token,    17.06 tokens per second)\n",
      "llama_print_timings:        eval time =   27478.65 ms /    41 runs   (  670.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28307.20 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.09 ms /    46 runs   (    0.41 ms per token,  2409.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.31 ms /    13 tokens (   52.49 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   30224.67 ms /    45 runs   (  671.66 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   31044.01 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.99 ms /    42 runs   (    0.40 ms per token,  2471.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.13 ms /    12 tokens (   53.18 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   27450.13 ms /    41 runs   (  669.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28210.94 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.97 ms /    46 runs   (    0.41 ms per token,  2425.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.01 ms /    12 tokens (   52.83 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   30313.36 ms /    45 runs   (  673.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   31083.33 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.42 ms /    38 runs   (    0.41 ms per token,  2464.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.53 ms /    11 tokens (   53.78 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   24923.65 ms /    37 runs   (  673.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25626.75 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.54 ms /    41 runs   (    0.40 ms per token,  2478.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.56 ms /    12 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   26206.18 ms /    40 runs   (  655.15 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   26962.78 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.47 ms /    23 runs   (    0.41 ms per token,  2429.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.11 ms /    13 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   14741.70 ms /    22 runs   (  670.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15498.32 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.34 ms /    23 runs   (    0.41 ms per token,  2461.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.80 ms /    12 tokens (   52.98 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   14610.68 ms /    22 runs   (  664.12 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15313.67 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.84 ms /    32 runs   (    0.40 ms per token,  2491.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     727.68 ms /    14 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   20969.51 ms /    31 runs   (  676.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21790.00 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.35 ms /    30 runs   (    0.41 ms per token,  2429.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.44 ms /    12 tokens (   53.87 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   19214.13 ms /    29 runs   (  662.56 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19949.40 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.39 ms /    50 runs   (    0.41 ms per token,  2452.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.48 ms /    12 tokens (   53.46 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   32436.77 ms /    49 runs   (  661.97 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   33226.02 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.67 ms /    38 runs   (    0.44 ms per token,  2279.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.85 ms /    12 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   24713.49 ms /    37 runs   (  667.93 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   25464.57 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.77 ms /    50 runs   (    0.42 ms per token,  2406.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.29 ms /    12 tokens (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   32777.03 ms /    49 runs   (  668.92 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   33560.22 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.25 ms /    23 runs   (    0.40 ms per token,  2486.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.83 ms /    13 tokens (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   14761.21 ms /    22 runs   (  670.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15511.39 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.25 ms /    23 runs   (    0.40 ms per token,  2485.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     661.86 ms /    12 tokens (   55.15 ms per token,    18.13 tokens per second)\n",
      "llama_print_timings:        eval time =   14841.29 ms /    22 runs   (  674.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15570.03 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.98 ms /    42 runs   (    0.40 ms per token,  2473.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     696.34 ms /    13 tokens (   53.56 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   27516.65 ms /    41 runs   (  671.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28335.83 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.75 ms /    32 runs   (    0.40 ms per token,  2510.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.29 ms /    12 tokens (   53.19 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   20811.82 ms /    31 runs   (  671.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21543.61 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.80 ms /    32 runs   (    0.40 ms per token,  2500.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     661.08 ms /    12 tokens (   55.09 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =   20730.62 ms /    31 runs   (  668.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21486.49 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.23 ms /    38 runs   (    0.43 ms per token,  2341.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.73 ms /    13 tokens (   53.29 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   25340.15 ms /    37 runs   (  684.87 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   26148.91 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.35 ms /    33 runs   (    0.40 ms per token,  2471.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     602.62 ms /    11 tokens (   54.78 ms per token,    18.25 tokens per second)\n",
      "llama_print_timings:        eval time =   21448.46 ms /    32 runs   (  670.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22147.91 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.57 ms /    28 runs   (    0.41 ms per token,  2419.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.12 ms /    12 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   18111.30 ms /    27 runs   (  670.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18837.69 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.51 ms /    31 runs   (    0.40 ms per token,  2477.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.31 ms /    12 tokens (   53.44 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   19986.23 ms /    30 runs   (  666.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20719.78 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.94 ms /    66 runs   (    0.41 ms per token,  2450.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.21 ms /    12 tokens (   53.35 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   43834.47 ms /    65 runs   (  674.38 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   44669.89 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.87 ms /    26 runs   (    0.42 ms per token,  2392.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.24 ms /    13 tokens (   52.40 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   16516.49 ms /    25 runs   (  660.66 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17274.98 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.69 ms /    29 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     725.60 ms /    12 tokens (   60.47 ms per token,    16.54 tokens per second)\n",
      "llama_print_timings:        eval time =   18724.13 ms /    28 runs   (  668.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19536.04 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.09 ms /    30 runs   (    0.40 ms per token,  2482.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.41 ms /    11 tokens (   54.22 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   19633.70 ms /    29 runs   (  677.02 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20318.59 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.04 ms /    30 runs   (    0.40 ms per token,  2492.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.01 ms /    12 tokens (   54.00 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   19346.09 ms /    29 runs   (  667.11 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20082.19 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.02 ms /    29 runs   (    0.41 ms per token,  2413.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.43 ms /    12 tokens (   53.37 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   18921.78 ms /    28 runs   (  675.78 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19647.66 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.09 ms /    30 runs   (    0.40 ms per token,  2482.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     727.89 ms /    13 tokens (   55.99 ms per token,    17.86 tokens per second)\n",
      "llama_print_timings:        eval time =   19287.09 ms /    29 runs   (  665.07 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20102.46 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.13 ms /    30 runs   (    0.40 ms per token,  2473.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.24 ms /    12 tokens (   53.52 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   19390.43 ms /    29 runs   (  668.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20119.70 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.84 ms /    30 runs   (    0.39 ms per token,  2533.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     658.88 ms /    11 tokens (   59.90 ms per token,    16.69 tokens per second)\n",
      "llama_print_timings:        eval time =   19356.35 ms /    29 runs   (  667.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20101.22 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.41 ms /    33 runs   (    0.41 ms per token,  2460.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.97 ms /    12 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   21312.69 ms /    32 runs   (  666.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22046.19 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.35 ms /    23 runs   (    0.45 ms per token,  2222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.36 ms /    12 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   14784.48 ms /    22 runs   (  672.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15498.79 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.94 ms /    30 runs   (    0.40 ms per token,  2511.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     604.53 ms /    11 tokens (   54.96 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =   19403.06 ms /    29 runs   (  669.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20095.75 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.44 ms /    43 runs   (    0.41 ms per token,  2465.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     601.95 ms /    11 tokens (   54.72 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =   28107.56 ms /    42 runs   (  669.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28836.32 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.44 ms /    23 runs   (    0.41 ms per token,  2436.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     694.29 ms /    12 tokens (   57.86 ms per token,    17.28 tokens per second)\n",
      "llama_print_timings:        eval time =   14416.87 ms /    22 runs   (  655.31 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   15178.41 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.87 ms /    29 runs   (    0.41 ms per token,  2443.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     753.54 ms /    13 tokens (   57.96 ms per token,    17.25 tokens per second)\n",
      "llama_print_timings:        eval time =   18761.61 ms /    28 runs   (  670.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19599.24 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.30 ms /    36 runs   (    0.40 ms per token,  2518.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.03 ms /    12 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   23264.15 ms /    35 runs   (  664.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24009.12 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.09 ms /    32 runs   (    0.41 ms per token,  2444.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.85 ms /    11 tokens (   54.17 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   20752.41 ms /    31 runs   (  669.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21442.55 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.30 ms /    30 runs   (    0.41 ms per token,  2438.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.22 ms /    12 tokens (   54.10 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   19221.85 ms /    29 runs   (  662.82 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19958.93 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.37 ms /    23 runs   (    0.41 ms per token,  2454.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.70 ms /    12 tokens (   53.81 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   14825.57 ms /    22 runs   (  673.89 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15538.99 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.21 ms /    32 runs   (    0.41 ms per token,  2422.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.77 ms /    12 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   21191.89 ms /    31 runs   (  683.61 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   21926.15 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.78 ms /    32 runs   (    0.40 ms per token,  2504.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.22 ms /    12 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   20328.06 ms /    31 runs   (  655.74 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21063.09 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.43 ms /    38 runs   (    0.41 ms per token,  2462.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.69 ms /    12 tokens (   53.39 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   24678.12 ms /    37 runs   (  666.98 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   25430.58 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.56 ms /    26 runs   (    0.41 ms per token,  2461.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.21 ms /    13 tokens (   52.25 ms per token,    19.14 tokens per second)\n",
      "llama_print_timings:        eval time =   16768.62 ms /    25 runs   (  670.74 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   17522.63 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.70 ms /    32 runs   (    0.40 ms per token,  2519.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.33 ms /    12 tokens (   53.03 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   20356.50 ms /    31 runs   (  656.66 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21084.75 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.31 ms /    33 runs   (    0.40 ms per token,  2479.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.06 ms /    12 tokens (   53.59 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   21351.03 ms /    32 runs   (  667.22 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22089.59 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.34 ms /    50 runs   (    0.41 ms per token,  2458.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.60 ms /    13 tokens (   53.74 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   33023.77 ms /    49 runs   (  673.95 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   33864.93 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.78 ms /    39 runs   (    0.40 ms per token,  2471.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     602.59 ms /    11 tokens (   54.78 ms per token,    18.25 tokens per second)\n",
      "llama_print_timings:        eval time =   25500.52 ms /    38 runs   (  671.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26214.79 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.46 ms /    23 runs   (    0.41 ms per token,  2432.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.58 ms /    12 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   14668.84 ms /    22 runs   (  666.77 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15378.73 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.31 ms /    23 runs   (    0.40 ms per token,  2470.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.00 ms /    12 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   14771.16 ms /    22 runs   (  671.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15474.46 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.20 ms /    30 runs   (    0.41 ms per token,  2459.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.27 ms /    12 tokens (   53.27 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   19284.54 ms /    29 runs   (  664.98 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20009.77 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.16 ms /    52 runs   (    0.41 ms per token,  2457.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.44 ms /    11 tokens (   54.13 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   33950.48 ms /    51 runs   (  665.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   34696.53 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.34 ms /    20 runs   (    0.42 ms per token,  2397.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.97 ms /    12 tokens (   53.50 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   12607.76 ms /    19 runs   (  663.57 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13306.90 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.64 ms /    31 runs   (    0.41 ms per token,  2452.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.71 ms /    12 tokens (   53.39 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   20095.86 ms /    30 runs   (  669.86 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20825.41 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.31 ms /    23 runs   (    0.40 ms per token,  2470.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     617.75 ms /    11 tokens (   56.16 ms per token,    17.81 tokens per second)\n",
      "llama_print_timings:        eval time =   14733.48 ms /    22 runs   (  669.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15418.62 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.37 ms /    43 runs   (    0.40 ms per token,  2475.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.06 ms /    11 tokens (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   28216.09 ms /    42 runs   (  671.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28932.81 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2900 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.17 ms /    30 runs   (    0.44 ms per token,  2278.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.52 ms /    13 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   19239.65 ms /    29 runs   (  663.44 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20020.30 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.14 ms /    30 runs   (    0.40 ms per token,  2470.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.29 ms /    12 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   19374.13 ms /    29 runs   (  668.07 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20096.13 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.80 ms /    29 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.39 ms /    12 tokens (   53.03 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   18360.36 ms /    28 runs   (  655.73 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   19081.09 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.18 ms /    27 runs   (    0.41 ms per token,  2415.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.80 ms /    12 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   17122.22 ms /    26 runs   (  658.55 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   17841.82 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.16 ms /    23 runs   (    0.40 ms per token,  2511.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.50 ms /    12 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   14706.82 ms /    22 runs   (  668.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15417.16 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.61 ms /    31 runs   (    0.41 ms per token,  2458.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     727.50 ms /    14 tokens (   51.96 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   20036.09 ms /    30 runs   (  667.87 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20853.30 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.77 ms /    43 runs   (    0.41 ms per token,  2420.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     657.86 ms /    12 tokens (   54.82 ms per token,    18.24 tokens per second)\n",
      "llama_print_timings:        eval time =   28035.92 ms /    42 runs   (  667.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28817.87 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.54 ms /    23 runs   (    0.41 ms per token,  2410.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.38 ms /    12 tokens (   53.45 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   14337.36 ms /    22 runs   (  651.70 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   15043.23 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.11 ms /    42 runs   (    0.41 ms per token,  2455.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.59 ms /    12 tokens (   54.55 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   27598.01 ms /    41 runs   (  673.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28373.38 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.26 ms /    30 runs   (    0.41 ms per token,  2447.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.86 ms /    12 tokens (   54.32 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   19311.81 ms /    29 runs   (  665.92 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20050.18 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    20 runs   (    0.40 ms per token,  2471.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.82 ms /    12 tokens (   54.73 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =   12716.82 ms /    19 runs   (  669.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13431.65 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.18 ms /    32 runs   (    0.41 ms per token,  2427.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     696.52 ms /    13 tokens (   53.58 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   20432.89 ms /    31 runs   (  659.13 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21223.07 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.94 ms /    30 runs   (    0.40 ms per token,  2511.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.71 ms /    12 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   19398.80 ms /    29 runs   (  668.92 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20132.52 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.30 ms /    25 runs   (    0.41 ms per token,  2427.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     601.05 ms /    11 tokens (   54.64 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =   16160.78 ms /    24 runs   (  673.37 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16834.49 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.81 ms /    44 runs   (    0.40 ms per token,  2470.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.65 ms /    12 tokens (   53.55 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   28856.65 ms /    43 runs   (  671.08 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29628.22 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.89 ms /    32 runs   (    0.40 ms per token,  2481.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.73 ms /    12 tokens (   52.89 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   20652.44 ms /    31 runs   (  666.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21379.11 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    20 runs   (    0.40 ms per token,  2473.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.67 ms /    13 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   12694.29 ms /    19 runs   (  668.12 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13435.98 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.12 ms /    30 runs   (    0.40 ms per token,  2475.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.14 ms /    12 tokens (   53.59 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   19223.92 ms /    29 runs   (  662.89 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19952.97 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.81 ms /    32 runs   (    0.40 ms per token,  2497.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.74 ms /    12 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   20809.01 ms /    31 runs   (  671.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21546.76 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.58 ms /    55 runs   (    0.41 ms per token,  2435.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.77 ms /    12 tokens (   52.98 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   36214.57 ms /    54 runs   (  670.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   37008.06 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.84 ms /    32 runs   (    0.40 ms per token,  2492.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.79 ms /    12 tokens (   53.65 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   20881.56 ms /    31 runs   (  673.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21616.92 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.98 ms /    30 runs   (    0.40 ms per token,  2504.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     726.74 ms /    13 tokens (   55.90 ms per token,    17.89 tokens per second)\n",
      "llama_print_timings:        eval time =   19512.04 ms /    29 runs   (  672.83 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20323.95 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.81 ms /    32 runs   (    0.40 ms per token,  2498.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.86 ms /    12 tokens (   53.49 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   20737.99 ms /    31 runs   (  668.97 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21471.51 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.04 ms /    44 runs   (    0.41 ms per token,  2438.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     611.53 ms /    11 tokens (   55.59 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =   28773.25 ms /    43 runs   (  669.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29512.17 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.19 ms /    30 runs   (    0.41 ms per token,  2460.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.94 ms /    12 tokens (   52.91 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   19066.55 ms /    29 runs   (  657.47 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19787.71 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    20 runs   (    0.41 ms per token,  2443.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.13 ms /    11 tokens (   53.56 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   12493.81 ms /    19 runs   (  657.57 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13140.06 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.82 ms /    37 runs   (    0.40 ms per token,  2496.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.78 ms /    13 tokens (   52.14 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   24031.99 ms /    36 runs   (  667.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24815.75 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.28 ms /    23 runs   (    0.40 ms per token,  2479.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.74 ms /    12 tokens (   52.73 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   14621.66 ms /    22 runs   (  664.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15320.34 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.89 ms /    42 runs   (    0.40 ms per token,  2486.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.18 ms /    12 tokens (   53.35 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   27174.87 ms /    41 runs   (  662.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   27936.21 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.78 ms /    29 runs   (    0.41 ms per token,  2462.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.03 ms /    12 tokens (   54.00 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   18337.81 ms /    28 runs   (  654.92 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   19069.71 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.46 ms /    43 runs   (    0.41 ms per token,  2462.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.29 ms /    11 tokens (   54.57 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   27724.83 ms /    42 runs   (  660.11 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   28448.60 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.91 ms /    61 runs   (    0.41 ms per token,  2448.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.60 ms /    12 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   40028.19 ms /    60 runs   (  667.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   40843.30 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.95 ms /    30 runs   (    0.40 ms per token,  2510.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.91 ms /    13 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   19025.07 ms /    29 runs   (  656.04 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19799.47 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.16 ms /    20 runs   (    0.41 ms per token,  2450.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.44 ms /    12 tokens (   53.29 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   13019.01 ms /    19 runs   (  685.21 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13715.34 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.69 ms /    58 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     660.69 ms /    12 tokens (   55.06 ms per token,    18.16 tokens per second)\n",
      "llama_print_timings:        eval time =   37355.87 ms /    57 runs   (  655.37 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   38184.89 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.22 ms /    23 runs   (    0.40 ms per token,  2494.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.48 ms /    13 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   14262.57 ms /    22 runs   (  648.30 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   15014.81 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.31 ms /    43 runs   (    0.40 ms per token,  2483.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.21 ms /    12 tokens (   53.43 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   27880.23 ms /    42 runs   (  663.82 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   28644.82 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.22 ms /    30 runs   (    0.41 ms per token,  2455.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.08 ms /    12 tokens (   53.59 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   19239.89 ms /    29 runs   (  663.44 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19968.47 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.32 ms /    20 runs   (    0.42 ms per token,  2405.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     604.30 ms /    11 tokens (   54.94 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =   12665.58 ms /    19 runs   (  666.61 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13326.58 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.72 ms /    28 runs   (    0.42 ms per token,  2388.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.13 ms /    13 tokens (   52.47 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   18163.50 ms /    27 runs   (  672.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18927.55 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.34 ms /    20 runs   (    0.42 ms per token,  2399.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.65 ms /    11 tokens (   54.15 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   12693.39 ms /    19 runs   (  668.07 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13345.86 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.57 ms /    30 runs   (    0.42 ms per token,  2386.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.61 ms /    12 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   19295.90 ms /    29 runs   (  665.38 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20028.76 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.24 ms /    20 runs   (    0.41 ms per token,  2428.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     588.02 ms /    11 tokens (   53.46 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   12706.16 ms /    19 runs   (  668.75 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13352.36 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.29 ms /    23 runs   (    0.40 ms per token,  2474.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.60 ms /    12 tokens (   52.72 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   14814.88 ms /    22 runs   (  673.40 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15513.47 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.31 ms /    23 runs   (    0.40 ms per token,  2470.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.18 ms /    11 tokens (   54.56 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   14702.16 ms /    22 runs   (  668.28 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15368.08 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.38 ms /    23 runs   (    0.41 ms per token,  2450.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.95 ms /    12 tokens (   52.91 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   14951.85 ms /    22 runs   (  679.63 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15652.64 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.56 ms /    55 runs   (    0.41 ms per token,  2437.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.22 ms /    12 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   36245.59 ms /    54 runs   (  671.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   37049.26 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.08 ms /    23 runs   (    0.39 ms per token,  2534.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.15 ms /    12 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   14259.33 ms /    22 runs   (  648.15 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   14966.26 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.16 ms /    29 runs   (    0.42 ms per token,  2385.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.07 ms /    12 tokens (   53.26 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   18710.94 ms /    28 runs   (  668.25 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19433.91 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.39 ms /    52 runs   (    0.41 ms per token,  2431.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.54 ms /    13 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   34553.72 ms /    51 runs   (  677.52 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   35388.09 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.81 ms /    35 runs   (    0.39 ms per token,  2534.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.25 ms /    11 tokens (   54.39 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =   22799.43 ms /    34 runs   (  670.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   23498.23 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.30 ms /    43 runs   (    0.40 ms per token,  2485.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.49 ms /    12 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   27952.92 ms /    42 runs   (  665.55 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28712.20 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.19 ms /    23 runs   (    0.40 ms per token,  2503.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.51 ms /    11 tokens (   53.96 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   14718.04 ms /    22 runs   (  669.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15377.03 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.41 ms /    25 runs   (    0.42 ms per token,  2401.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     625.08 ms /    11 tokens (   56.83 ms per token,    17.60 tokens per second)\n",
      "llama_print_timings:        eval time =   16041.54 ms /    24 runs   (  668.40 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16738.31 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.02 ms /    63 runs   (    0.41 ms per token,  2421.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.79 ms /    12 tokens (   53.07 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   41734.09 ms /    62 runs   (  673.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   42556.94 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.30 ms /    23 runs   (    0.40 ms per token,  2471.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.61 ms /    12 tokens (   54.63 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =   14638.74 ms /    22 runs   (  665.40 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15360.90 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.70 ms /    31 runs   (    0.41 ms per token,  2440.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.38 ms /    11 tokens (   54.03 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   20155.16 ms /    30 runs   (  671.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20838.58 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.38 ms /    36 runs   (    0.40 ms per token,  2504.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.98 ms /    12 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   23357.95 ms /    35 runs   (  667.37 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24096.21 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.52 ms /    55 runs   (    0.41 ms per token,  2442.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     706.28 ms /    13 tokens (   54.33 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   36223.79 ms /    54 runs   (  670.81 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   37088.93 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.69 ms /    34 runs   (    0.40 ms per token,  2484.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.05 ms /    12 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   22047.58 ms /    33 runs   (  668.11 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22782.49 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.07 ms /    30 runs   (    0.40 ms per token,  2485.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.74 ms /    12 tokens (   54.06 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   18757.16 ms /    29 runs   (  646.80 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   19492.14 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.82 ms /    58 runs   (    0.41 ms per token,  2434.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.40 ms /    11 tokens (   58.04 ms per token,    17.23 tokens per second)\n",
      "llama_print_timings:        eval time =   38077.19 ms /    57 runs   (  668.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   38883.00 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.42 ms /    31 runs   (    0.47 ms per token,  2149.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.63 ms /    14 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   20174.30 ms /    30 runs   (  672.48 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21002.32 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.47 ms /    48 runs   (    0.41 ms per token,  2465.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.54 ms /    12 tokens (   53.04 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   31362.10 ms /    47 runs   (  667.28 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   32136.72 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.76 ms /    37 runs   (    0.40 ms per token,  2507.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.93 ms /    12 tokens (   52.91 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   24012.14 ms /    36 runs   (  667.00 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24753.81 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.50 ms /    34 runs   (    0.40 ms per token,  2518.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.37 ms /    12 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   21866.79 ms /    33 runs   (  662.63 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   22605.40 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.78 ms /    44 runs   (    0.40 ms per token,  2474.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     601.10 ms /    11 tokens (   54.65 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =   28584.67 ms /    43 runs   (  664.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   29311.96 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.45 ms /    38 runs   (    0.41 ms per token,  2459.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.99 ms /    12 tokens (   54.08 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   24723.91 ms /    37 runs   (  668.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   25482.27 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.19 ms /    20 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.11 ms /    12 tokens (   53.18 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   12793.45 ms /    19 runs   (  673.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13488.59 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.03 ms /    20 runs   (    0.40 ms per token,  2490.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.71 ms /    11 tokens (   54.06 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   12658.36 ms /    19 runs   (  666.23 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13310.02 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.91 ms /    30 runs   (    0.40 ms per token,  2519.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.61 ms /    13 tokens (   52.35 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   19294.35 ms /    29 runs   (  665.32 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20060.98 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.08 ms /    20 runs   (    0.40 ms per token,  2476.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     599.89 ms /    11 tokens (   54.54 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   12735.65 ms /    19 runs   (  670.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13392.99 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.69 ms /    39 runs   (    0.40 ms per token,  2485.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.91 ms /    12 tokens (   53.66 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   25487.89 ms /    38 runs   (  670.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26243.82 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.44 ms /    33 runs   (    0.41 ms per token,  2456.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.48 ms /    12 tokens (   53.12 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   21380.74 ms /    32 runs   (  668.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22112.32 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.89 ms /    49 runs   (    0.41 ms per token,  2462.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.89 ms /    13 tokens (   52.91 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   32051.70 ms /    48 runs   (  667.74 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   32880.53 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.08 ms /    49 runs   (    0.41 ms per token,  2440.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.20 ms /    12 tokens (   52.68 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   31912.46 ms /    48 runs   (  664.84 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   32685.36 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.79 ms /    67 runs   (    0.40 ms per token,  2501.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.43 ms /    12 tokens (   53.87 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   44392.80 ms /    66 runs   (  672.62 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   45233.41 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.42 ms /    23 runs   (    0.41 ms per token,  2442.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     715.88 ms /    13 tokens (   55.07 ms per token,    18.16 tokens per second)\n",
      "llama_print_timings:        eval time =   14844.39 ms /    22 runs   (  674.74 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15626.78 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.28 ms /    23 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.09 ms /    12 tokens (   54.09 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   14988.69 ms /    22 runs   (  681.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15706.89 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      37.60 ms /    93 runs   (    0.40 ms per token,  2473.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.04 ms /    12 tokens (   54.67 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =   60857.54 ms /    92 runs   (  661.50 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   61783.29 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.32 ms /    23 runs   (    0.41 ms per token,  2467.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.21 ms /    11 tokens (   54.02 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   14866.79 ms /    22 runs   (  675.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15527.07 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.85 ms /    29 runs   (    0.41 ms per token,  2448.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.37 ms /    12 tokens (   54.03 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   18738.07 ms /    28 runs   (  669.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19469.42 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.87 ms /    58 runs   (    0.41 ms per token,  2430.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.02 ms /    13 tokens (   52.54 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   38487.26 ms /    57 runs   (  675.22 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   39336.78 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.05 ms /    20 runs   (    0.40 ms per token,  2485.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.30 ms /    12 tokens (   53.61 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   12843.13 ms /    19 runs   (  675.95 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13543.56 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.91 ms /    51 runs   (    0.41 ms per token,  2439.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.47 ms /    12 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   33494.69 ms /    50 runs   (  669.89 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   34285.20 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.05 ms /    38 runs   (    0.40 ms per token,  2524.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     668.67 ms /    12 tokens (   55.72 ms per token,    17.95 tokens per second)\n",
      "llama_print_timings:        eval time =   25166.03 ms /    37 runs   (  680.16 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   25944.02 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.95 ms /    29 runs   (    0.41 ms per token,  2426.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.81 ms /    12 tokens (   53.07 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   18972.60 ms /    28 runs   (  677.59 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19693.62 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      28.93 ms /    68 runs   (    0.43 ms per token,  2350.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.24 ms /    12 tokens (   54.35 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   44895.81 ms /    67 runs   (  670.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   45751.74 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.09 ms /    44 runs   (    0.41 ms per token,  2431.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     802.97 ms /    13 tokens (   61.77 ms per token,    16.19 tokens per second)\n",
      "llama_print_timings:        eval time =   29194.89 ms /    43 runs   (  678.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   30125.81 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.68 ms /    46 runs   (    0.43 ms per token,  2337.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.84 ms /    12 tokens (   53.32 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   29755.27 ms /    45 runs   (  661.23 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   30532.73 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.52 ms /    33 runs   (    0.41 ms per token,  2440.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     740.02 ms /    12 tokens (   61.67 ms per token,    16.22 tokens per second)\n",
      "llama_print_timings:        eval time =   21273.68 ms /    32 runs   (  664.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22108.46 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.65 ms /    39 runs   (    0.40 ms per token,  2491.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.88 ms /    11 tokens (   54.63 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   25320.92 ms /    38 runs   (  666.34 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26034.09 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.63 ms /    53 runs   (    0.41 ms per token,  2450.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.49 ms /    13 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   34631.93 ms /    52 runs   (  666.00 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   35470.07 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.97 ms /    39 runs   (    0.41 ms per token,  2442.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.48 ms /    12 tokens (   53.54 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   25249.92 ms /    38 runs   (  664.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26004.49 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.26 ms /    49 runs   (    0.45 ms per token,  2201.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.65 ms /    12 tokens (   53.22 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   32215.98 ms /    48 runs   (  671.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   33006.30 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.89 ms /    39 runs   (    0.41 ms per token,  2454.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.84 ms /    11 tokens (   53.89 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   25270.46 ms /    38 runs   (  665.01 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   25974.84 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.69 ms /    68 runs   (    0.41 ms per token,  2455.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.89 ms /    12 tokens (   53.07 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   45049.35 ms /    67 runs   (  672.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   45883.56 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.49 ms /    43 runs   (    0.41 ms per token,  2458.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.19 ms /    12 tokens (   53.35 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   28266.56 ms /    42 runs   (  673.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29031.22 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.21 ms /    38 runs   (    0.40 ms per token,  2498.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     599.68 ms /    11 tokens (   54.52 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   24805.69 ms /    37 runs   (  670.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   25513.71 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.67 ms /    53 runs   (    0.41 ms per token,  2446.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.17 ms /    12 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   34877.40 ms /    52 runs   (  670.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   35673.57 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3000 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.96 ms /    30 runs   (    0.40 ms per token,  2507.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.40 ms /    13 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   19362.42 ms /    29 runs   (  667.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20134.77 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.63 ms /    29 runs   (    0.40 ms per token,  2493.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.25 ms /    12 tokens (   53.19 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   18627.91 ms /    28 runs   (  665.28 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19348.54 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.84 ms /    44 runs   (    0.41 ms per token,  2466.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     697.89 ms /    13 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   28537.69 ms /    43 runs   (  663.67 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   29360.85 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.01 ms /    38 runs   (    0.40 ms per token,  2531.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.78 ms /    11 tokens (   53.98 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   24488.71 ms /    37 runs   (  661.86 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   25191.08 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.84 ms /    20 runs   (    0.44 ms per token,  2263.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.69 ms /    12 tokens (   54.06 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   12539.65 ms /    19 runs   (  659.98 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13249.08 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.76 ms /    49 runs   (    0.40 ms per token,  2480.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.42 ms /    12 tokens (   54.03 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   32099.13 ms /    48 runs   (  668.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   32887.05 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.10 ms /    38 runs   (    0.40 ms per token,  2516.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.52 ms /    12 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   24942.55 ms /    37 runs   (  674.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25692.00 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.39 ms /    31 runs   (    0.40 ms per token,  2502.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.99 ms /    13 tokens (   52.69 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   20311.44 ms /    30 runs   (  677.05 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21086.22 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.01 ms /    20 runs   (    0.40 ms per token,  2497.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.84 ms /    12 tokens (   53.65 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   12775.27 ms /    19 runs   (  672.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13476.61 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.46 ms /    41 runs   (    0.43 ms per token,  2347.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.33 ms /    12 tokens (   56.78 ms per token,    17.61 tokens per second)\n",
      "llama_print_timings:        eval time =   26680.62 ms /    40 runs   (  667.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   27486.02 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.66 ms /    39 runs   (    0.40 ms per token,  2490.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     768.78 ms /    15 tokens (   51.25 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:        eval time =   25475.29 ms /    38 runs   (  670.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26355.92 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.80 ms /    32 runs   (    0.40 ms per token,  2499.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.36 ms /    11 tokens (   57.67 ms per token,    17.34 tokens per second)\n",
      "llama_print_timings:        eval time =   20900.41 ms /    31 runs   (  674.21 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21625.11 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.77 ms /    32 runs   (    0.40 ms per token,  2505.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.51 ms /    12 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   20629.05 ms /    31 runs   (  665.45 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21364.50 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.75 ms /    46 runs   (    0.41 ms per token,  2453.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.19 ms /    12 tokens (   54.27 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   30209.38 ms /    45 runs   (  671.32 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   30993.48 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.15 ms /    32 runs   (    0.41 ms per token,  2432.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.58 ms /    11 tokens (   53.78 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   20881.80 ms /    31 runs   (  673.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21566.07 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.86 ms /    27 runs   (    0.40 ms per token,  2485.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     690.68 ms /    12 tokens (   57.56 ms per token,    17.37 tokens per second)\n",
      "llama_print_timings:        eval time =   17678.69 ms /    26 runs   (  679.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18447.15 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.40 ms /    50 runs   (    0.41 ms per token,  2450.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.61 ms /    13 tokens (   52.28 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   33056.83 ms /    49 runs   (  674.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   33880.78 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.28 ms /    30 runs   (    0.41 ms per token,  2443.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.53 ms /    11 tokens (   54.23 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   19310.51 ms /    29 runs   (  665.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19994.25 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.04 ms /    42 runs   (    0.41 ms per token,  2465.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.92 ms /    12 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   27261.25 ms /    41 runs   (  664.91 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   28017.93 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.25 ms /    32 runs   (    0.41 ms per token,  2415.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.23 ms /    11 tokens (   53.57 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   20397.89 ms /    31 runs   (  658.00 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21078.55 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.65 ms /    31 runs   (    0.41 ms per token,  2450.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.29 ms /    12 tokens (   54.44 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   19979.47 ms /    30 runs   (  665.98 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20720.69 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.19 ms /    20 runs   (    0.41 ms per token,  2443.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     612.89 ms /    11 tokens (   55.72 ms per token,    17.95 tokens per second)\n",
      "llama_print_timings:        eval time =   12697.45 ms /    19 runs   (  668.29 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13367.48 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.01 ms /    32 runs   (    0.41 ms per token,  2460.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.18 ms /    11 tokens (   54.02 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   20491.67 ms /    31 runs   (  661.02 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21176.93 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.94 ms /    32 runs   (    0.40 ms per token,  2473.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     588.18 ms /    11 tokens (   53.47 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   20773.10 ms /    31 runs   (  670.10 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21453.09 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.67 ms /    37 runs   (    0.40 ms per token,  2521.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.95 ms /    13 tokens (   52.92 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   24067.12 ms /    36 runs   (  668.53 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24861.51 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.68 ms /    23 runs   (    0.42 ms per token,  2376.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.47 ms /    11 tokens (   53.95 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   14496.37 ms /    22 runs   (  658.93 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   15158.22 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.96 ms /    32 runs   (    0.41 ms per token,  2468.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.47 ms /    12 tokens (   53.04 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   20380.12 ms /    31 runs   (  657.42 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21107.85 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.09 ms /    40 runs   (    0.40 ms per token,  2486.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.13 ms /    12 tokens (   53.34 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   25658.61 ms /    39 runs   (  657.91 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   26412.84 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    20 runs   (    0.41 ms per token,  2444.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.84 ms /    11 tokens (   57.53 ms per token,    17.38 tokens per second)\n",
      "llama_print_timings:        eval time =   12592.72 ms /    19 runs   (  662.77 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13283.46 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.96 ms /    40 runs   (    0.40 ms per token,  2506.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.04 ms /    12 tokens (   52.92 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   26209.95 ms /    39 runs   (  672.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26961.00 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    19 runs   (    0.41 ms per token,  2441.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.91 ms /    11 tokens (   54.26 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   11955.58 ms /    18 runs   (  664.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12607.24 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      34.13 ms /    84 runs   (    0.41 ms per token,  2461.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.76 ms /    13 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   55348.61 ms /    83 runs   (  666.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   56276.95 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.27 ms /    33 runs   (    0.40 ms per token,  2486.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.07 ms /    12 tokens (   53.01 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   21259.28 ms /    32 runs   (  664.35 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21990.14 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.43 ms /    30 runs   (    0.41 ms per token,  2414.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.82 ms /    13 tokens (   52.29 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   19372.86 ms /    29 runs   (  668.03 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20139.60 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.43 ms /    20 runs   (    0.42 ms per token,  2373.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.95 ms /    12 tokens (   53.66 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   12696.32 ms /    19 runs   (  668.23 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13398.31 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      29.22 ms /    67 runs   (    0.44 ms per token,  2293.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.38 ms /    12 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   44747.66 ms /    66 runs   (  677.99 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   45595.56 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.13 ms /    32 runs   (    0.41 ms per token,  2436.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.82 ms /    11 tokens (   54.26 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   20671.67 ms /    31 runs   (  666.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21361.68 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.72 ms /    32 runs   (    0.40 ms per token,  2515.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.95 ms /    13 tokens (   52.23 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =   20727.56 ms /    31 runs   (  668.63 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21497.29 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.41 ms /    53 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.70 ms /    12 tokens (   53.56 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   34780.13 ms /    52 runs   (  668.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   35575.88 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.96 ms /    32 runs   (    0.40 ms per token,  2469.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.08 ms /    12 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   20543.54 ms /    31 runs   (  662.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21273.48 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.61 ms /    23 runs   (    0.42 ms per token,  2392.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     699.37 ms /    13 tokens (   53.80 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   14679.26 ms /    22 runs   (  667.24 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15446.08 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.62 ms /    31 runs   (    0.41 ms per token,  2456.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.13 ms /    12 tokens (   53.01 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   19949.76 ms /    30 runs   (  664.99 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20674.41 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.09 ms /    30 runs   (    0.40 ms per token,  2482.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.23 ms /    12 tokens (   54.27 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   19373.39 ms /    29 runs   (  668.05 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20111.21 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.81 ms /    37 runs   (    0.40 ms per token,  2498.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.78 ms /    11 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   24076.63 ms /    36 runs   (  668.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24772.35 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.32 ms /    65 runs   (    0.40 ms per token,  2469.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.53 ms /    12 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   43082.58 ms /    64 runs   (  673.17 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   43917.00 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.20 ms /    30 runs   (    0.41 ms per token,  2458.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.28 ms /    12 tokens (   53.27 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   19322.56 ms /    29 runs   (  666.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20048.51 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.93 ms /    32 runs   (    0.40 ms per token,  2475.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     658.17 ms /    12 tokens (   54.85 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =   20611.57 ms /    31 runs   (  664.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21361.21 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.58 ms /    23 runs   (    0.42 ms per token,  2401.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.82 ms /    11 tokens (   54.26 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   14660.32 ms /    22 runs   (  666.38 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15322.70 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.18 ms /    20 runs   (    0.46 ms per token,  2178.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.48 ms /    12 tokens (   53.37 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   12704.21 ms /    19 runs   (  668.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13407.57 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.12 ms /    27 runs   (    0.41 ms per token,  2428.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.05 ms /    11 tokens (   54.37 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =   17067.73 ms /    26 runs   (  656.45 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   17747.45 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.22 ms /    23 runs   (    0.40 ms per token,  2493.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.66 ms /    13 tokens (   52.36 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   14643.21 ms /    22 runs   (  665.60 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15390.64 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.25 ms /    30 runs   (    0.41 ms per token,  2449.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.35 ms /    12 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   19425.65 ms /    29 runs   (  669.85 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20156.01 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.78 ms /    64 runs   (    0.42 ms per token,  2389.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.23 ms /    12 tokens (   52.77 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   41741.05 ms /    63 runs   (  662.56 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   42564.98 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.54 ms /    23 runs   (    0.41 ms per token,  2411.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     603.26 ms /    11 tokens (   54.84 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =   14769.51 ms /    22 runs   (  671.34 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15438.47 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.31 ms /    20 runs   (    0.47 ms per token,  2148.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     676.42 ms /    13 tokens (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   12579.90 ms /    19 runs   (  662.10 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13319.63 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.26 ms /    30 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.11 ms /    12 tokens (   54.51 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =   19189.03 ms /    29 runs   (  661.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19931.48 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.02 ms /    32 runs   (    0.41 ms per token,  2458.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.75 ms /    12 tokens (   54.73 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =   20528.85 ms /    31 runs   (  662.22 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21279.24 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.33 ms /    36 runs   (    0.40 ms per token,  2512.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.32 ms /    12 tokens (   54.94 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =   23198.97 ms /    35 runs   (  662.83 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   23962.23 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.27 ms /    20 runs   (    0.41 ms per token,  2419.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.34 ms /    13 tokens (   52.80 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   12482.28 ms /    19 runs   (  656.96 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13226.87 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.31 ms /    30 runs   (    0.41 ms per token,  2437.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.45 ms /    11 tokens (   54.31 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   18983.65 ms /    29 runs   (  654.61 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   19667.50 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.81 ms /    31 runs   (    0.41 ms per token,  2420.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     608.43 ms /    11 tokens (   55.31 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =   19837.15 ms /    30 runs   (  661.24 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20535.16 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    18 runs   (    0.41 ms per token,  2456.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.94 ms /    11 tokens (   53.99 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   10935.45 ms /    17 runs   (  643.26 ms per token,     1.55 tokens per second)\n",
      "llama_print_timings:       total time =   11581.86 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.98 ms /    30 runs   (    0.40 ms per token,  2504.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.22 ms /    12 tokens (   53.93 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   19478.27 ms /    29 runs   (  671.66 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20212.57 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    20 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.60 ms /    12 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   12600.71 ms /    19 runs   (  663.20 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13297.94 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.43 ms /    25 runs   (    0.42 ms per token,  2396.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.29 ms /    12 tokens (   53.19 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   15954.72 ms /    24 runs   (  664.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16667.80 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.42 ms /    34 runs   (    0.39 ms per token,  2534.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     757.59 ms /    14 tokens (   54.11 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   21904.68 ms /    33 runs   (  663.78 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   22761.20 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.74 ms /    66 runs   (    0.41 ms per token,  2468.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.38 ms /    12 tokens (   52.87 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   43792.47 ms /    65 runs   (  673.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   44618.82 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.55 ms /    34 runs   (    0.43 ms per token,  2336.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     695.08 ms /    13 tokens (   53.47 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   21974.73 ms /    33 runs   (  665.90 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22774.30 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.68 ms /    32 runs   (    0.40 ms per token,  2523.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.78 ms /    12 tokens (   53.31 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   20603.67 ms /    31 runs   (  664.63 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21336.76 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.39 ms /    50 runs   (    0.41 ms per token,  2452.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.54 ms /    12 tokens (   56.46 ms per token,    17.71 tokens per second)\n",
      "llama_print_timings:        eval time =   32529.83 ms /    49 runs   (  663.87 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   33352.58 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.33 ms /    52 runs   (    0.41 ms per token,  2437.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.10 ms /    12 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   33912.80 ms /    51 runs   (  664.96 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   34709.58 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.56 ms /    34 runs   (    0.40 ms per token,  2508.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.10 ms /    12 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   21770.87 ms /    33 runs   (  659.72 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   22511.95 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.28 ms /    25 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.98 ms /    11 tokens (   53.91 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   15780.38 ms /    24 runs   (  657.52 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   16446.19 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      35.75 ms /    89 runs   (    0.40 ms per token,  2489.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.35 ms /    13 tokens (   52.95 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   58532.12 ms /    88 runs   (  665.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   59482.12 ms /   101 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.26 ms /    32 runs   (    0.41 ms per token,  2413.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.12 ms /    12 tokens (   53.01 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   21017.33 ms /    31 runs   (  677.98 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   21747.72 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.07 ms /    30 runs   (    0.40 ms per token,  2486.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.40 ms /    12 tokens (   54.03 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   19367.17 ms /    29 runs   (  667.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20103.61 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.04 ms /    30 runs   (    0.40 ms per token,  2492.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.16 ms /    12 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   19093.97 ms /    29 runs   (  658.41 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19824.60 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.24 ms /    20 runs   (    0.41 ms per token,  2428.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.50 ms /    12 tokens (   53.38 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   12655.56 ms /    19 runs   (  666.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13354.01 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.29 ms /    63 runs   (    0.40 ms per token,  2490.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     803.57 ms /    13 tokens (   61.81 ms per token,    16.18 tokens per second)\n",
      "llama_print_timings:        eval time =   41466.39 ms /    62 runs   (  668.81 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   42453.48 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.23 ms /    30 runs   (    0.41 ms per token,  2453.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.93 ms /    12 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   19514.10 ms /    29 runs   (  672.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20238.97 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.11 ms /    30 runs   (    0.40 ms per token,  2477.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.34 ms /    11 tokens (   54.30 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   19214.05 ms /    29 runs   (  662.55 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19899.24 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.03 ms /    30 runs   (    0.40 ms per token,  2493.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.47 ms /    12 tokens (   53.46 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   19417.03 ms /    29 runs   (  669.55 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20146.22 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.90 ms /    30 runs   (    0.40 ms per token,  2519.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.70 ms /    11 tokens (   54.06 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   19202.27 ms /    29 runs   (  662.15 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19883.55 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.68 ms /    66 runs   (    0.42 ms per token,  2384.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.66 ms /    12 tokens (   53.39 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   43432.05 ms /    65 runs   (  668.19 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   44271.98 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.40 ms /    34 runs   (    0.39 ms per token,  2536.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     612.64 ms /    11 tokens (   55.69 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:        eval time =   22025.00 ms /    33 runs   (  667.42 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22735.38 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.08 ms /    30 runs   (    0.40 ms per token,  2484.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     676.24 ms /    13 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   19367.90 ms /    29 runs   (  667.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20130.30 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.88 ms /    32 runs   (    0.40 ms per token,  2483.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.14 ms /    12 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   20498.47 ms /    31 runs   (  661.24 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21235.07 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      39.43 ms /    96 runs   (    0.41 ms per token,  2434.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.72 ms /    12 tokens (   53.89 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   63481.41 ms /    95 runs   (  668.23 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   64414.23 ms /   107 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.85 ms /    29 runs   (    0.41 ms per token,  2447.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.24 ms /    12 tokens (   53.19 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   18452.91 ms /    28 runs   (  659.03 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19175.49 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.66 ms /    48 runs   (    0.41 ms per token,  2441.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.54 ms /    12 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   31426.40 ms /    47 runs   (  668.65 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   32205.43 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.52 ms /    67 runs   (    0.40 ms per token,  2526.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     610.20 ms /    11 tokens (   55.47 ms per token,    18.03 tokens per second)\n",
      "llama_print_timings:        eval time =   44582.94 ms /    66 runs   (  675.50 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   45389.26 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.71 ms /    21 runs   (    0.41 ms per token,  2411.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.28 ms /    11 tokens (   54.57 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   13377.57 ms /    20 runs   (  668.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14038.15 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.13 ms /    37 runs   (    0.41 ms per token,  2445.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     601.55 ms /    11 tokens (   54.69 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =   24163.83 ms /    36 runs   (  671.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24871.71 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.45 ms /    31 runs   (    0.40 ms per token,  2490.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.72 ms /    12 tokens (   54.48 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =   19938.92 ms /    30 runs   (  664.63 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20681.77 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.87 ms /    30 runs   (    0.40 ms per token,  2526.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.98 ms /    12 tokens (   53.50 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   19330.77 ms /    29 runs   (  666.58 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20057.36 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.94 ms /    30 runs   (    0.40 ms per token,  2513.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     716.81 ms /    13 tokens (   55.14 ms per token,    18.14 tokens per second)\n",
      "llama_print_timings:        eval time =   19318.01 ms /    29 runs   (  666.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20122.01 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.12 ms /    32 runs   (    0.41 ms per token,  2438.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.87 ms /    12 tokens (   53.16 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   20538.20 ms /    31 runs   (  662.52 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21268.57 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.69 ms /    32 runs   (    0.43 ms per token,  2337.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.01 ms /    11 tokens (   54.36 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =   20453.93 ms /    31 runs   (  659.80 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21150.05 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.02 ms /    32 runs   (    0.44 ms per token,  2282.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.53 ms /    12 tokens (   53.79 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   20945.84 ms /    31 runs   (  675.67 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21691.96 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.79 ms /    34 runs   (    0.41 ms per token,  2464.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.10 ms /    12 tokens (   53.67 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   22078.72 ms /    33 runs   (  669.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22819.90 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3100 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.80 ms /    49 runs   (    0.40 ms per token,  2475.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.91 ms /    12 tokens (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   32104.80 ms /    48 runs   (  668.85 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   32886.27 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.77 ms /    46 runs   (    0.41 ms per token,  2451.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     713.99 ms /    13 tokens (   54.92 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =   30064.09 ms /    45 runs   (  668.09 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   30911.10 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.11 ms /    67 runs   (    0.40 ms per token,  2471.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.06 ms /    12 tokens (   53.34 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   44106.72 ms /    66 runs   (  668.28 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   44943.49 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.10 ms /    27 runs   (    0.41 ms per token,  2432.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.59 ms /    12 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   17451.98 ms /    26 runs   (  671.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18171.20 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.33 ms /    39 runs   (    0.39 ms per token,  2544.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.05 ms /    12 tokens (   54.67 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =   25497.34 ms /    38 runs   (  670.98 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26265.92 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.51 ms /    37 runs   (    0.39 ms per token,  2550.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.13 ms /    12 tokens (   53.26 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   24106.77 ms /    36 runs   (  669.63 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24851.52 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.49 ms /    41 runs   (    0.40 ms per token,  2486.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.10 ms /    12 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   26600.68 ms /    40 runs   (  665.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   27365.03 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.89 ms /    67 runs   (    0.40 ms per token,  2491.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.76 ms /    13 tokens (   52.67 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   44496.00 ms /    66 runs   (  674.18 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   45375.17 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.02 ms /    32 runs   (    0.41 ms per token,  2457.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.83 ms /    12 tokens (   54.07 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   20751.82 ms /    31 runs   (  669.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21495.12 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.00 ms /    67 runs   (    0.40 ms per token,  2481.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.33 ms /    11 tokens (   53.94 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   44271.15 ms /    66 runs   (  670.78 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   45063.05 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.58 ms /    31 runs   (    0.41 ms per token,  2465.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.02 ms /    12 tokens (   54.17 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   19900.87 ms /    30 runs   (  663.36 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20640.89 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.43 ms /    41 runs   (    0.43 ms per token,  2352.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.58 ms /    12 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   26620.03 ms /    40 runs   (  665.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   27384.37 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.27 ms /    49 runs   (    0.41 ms per token,  2417.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.37 ms /    12 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   32192.95 ms /    48 runs   (  670.69 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   32969.95 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.51 ms /    50 runs   (    0.41 ms per token,  2437.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.22 ms /    13 tokens (   52.48 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   33040.39 ms /    49 runs   (  674.29 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   33870.96 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.75 ms /    31 runs   (    0.41 ms per token,  2430.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.10 ms /    12 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   20120.11 ms /    30 runs   (  670.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20851.58 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      50.46 ms /   123 runs   (    0.41 ms per token,  2437.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.17 ms /    12 tokens (   53.18 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   81821.71 ms /   122 runs   (  670.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   82825.08 ms /   134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.67 ms /    50 runs   (    0.41 ms per token,  2418.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.34 ms /    12 tokens (   54.11 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   33047.09 ms /    49 runs   (  674.43 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   33844.42 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.57 ms /    50 runs   (    0.41 ms per token,  2430.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.71 ms /    12 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   32720.14 ms /    49 runs   (  667.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   33512.27 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.18 ms /    45 runs   (    0.40 ms per token,  2475.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.56 ms /    13 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   29380.31 ms /    44 runs   (  667.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   30197.02 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.92 ms /    32 runs   (    0.40 ms per token,  2477.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.06 ms /    11 tokens (   54.37 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =   20885.13 ms /    31 runs   (  673.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21575.68 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.44 ms /    67 runs   (    0.41 ms per token,  2441.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     599.10 ms /    11 tokens (   54.46 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =   44600.35 ms /    66 runs   (  675.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   45395.52 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.22 ms /    33 runs   (    0.40 ms per token,  2496.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.44 ms /    11 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   21446.94 ms /    32 runs   (  670.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22133.07 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.15 ms /    30 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.27 ms /    12 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   19512.33 ms /    29 runs   (  672.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20238.75 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.75 ms /    56 runs   (    0.41 ms per token,  2461.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.44 ms /    12 tokens (   53.37 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   37294.01 ms /    55 runs   (  678.07 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   38096.87 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.82 ms /    29 runs   (    0.41 ms per token,  2454.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.78 ms /    12 tokens (   52.98 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   18686.88 ms /    28 runs   (  667.39 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19407.54 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.11 ms /    44 runs   (    0.41 ms per token,  2430.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.36 ms /    11 tokens (   58.67 ms per token,    17.04 tokens per second)\n",
      "llama_print_timings:        eval time =   28957.06 ms /    43 runs   (  673.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   29731.15 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.11 ms /    42 runs   (    0.41 ms per token,  2454.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.01 ms /    12 tokens (   54.58 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   27912.83 ms /    41 runs   (  680.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   28691.50 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.86 ms /    32 runs   (    0.40 ms per token,  2488.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     620.88 ms /    11 tokens (   56.44 ms per token,    17.72 tokens per second)\n",
      "llama_print_timings:        eval time =   20659.03 ms /    31 runs   (  666.42 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21373.18 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.84 ms /    67 runs   (    0.40 ms per token,  2496.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.95 ms /    12 tokens (   53.75 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   44197.36 ms /    66 runs   (  669.66 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   45042.04 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.19 ms /    47 runs   (    0.41 ms per token,  2448.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.69 ms /    12 tokens (   54.47 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =   30325.80 ms /    46 runs   (  659.26 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   31115.54 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.03 ms /    20 runs   (    0.40 ms per token,  2490.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     603.46 ms /    11 tokens (   54.86 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =   12672.39 ms /    19 runs   (  666.97 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13333.60 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.04 ms /    40 runs   (    0.40 ms per token,  2493.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     729.44 ms /    14 tokens (   52.10 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =   26269.59 ms /    39 runs   (  673.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27116.37 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.57 ms /    55 runs   (    0.41 ms per token,  2437.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.74 ms /    12 tokens (   53.06 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   36033.45 ms /    54 runs   (  667.29 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   36833.18 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.68 ms /    63 runs   (    0.41 ms per token,  2453.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.32 ms /    12 tokens (   53.78 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   41328.58 ms /    62 runs   (  666.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   42157.86 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.38 ms /    48 runs   (    0.40 ms per token,  2477.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.84 ms /    13 tokens (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   31490.20 ms /    47 runs   (  670.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   32313.32 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.59 ms /    31 runs   (    0.41 ms per token,  2462.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.93 ms /    12 tokens (   53.58 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   20038.70 ms /    30 runs   (  667.96 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20772.10 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.92 ms /    32 runs   (    0.40 ms per token,  2476.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.37 ms /    12 tokens (   54.53 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   20636.17 ms /    31 runs   (  665.68 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21383.23 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.04 ms /    32 runs   (    0.41 ms per token,  2454.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.29 ms /    11 tokens (   53.66 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   20905.26 ms /    31 runs   (  674.36 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21589.98 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.51 ms /    50 runs   (    0.41 ms per token,  2437.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     614.58 ms /    11 tokens (   55.87 ms per token,    17.90 tokens per second)\n",
      "llama_print_timings:        eval time =   33036.51 ms /    49 runs   (  674.21 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   33794.74 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.05 ms /    58 runs   (    0.43 ms per token,  2315.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.22 ms /    13 tokens (   52.09 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   38307.35 ms /    57 runs   (  672.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   39158.44 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.40 ms /    31 runs   (    0.40 ms per token,  2500.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.31 ms /    12 tokens (   53.94 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   19950.06 ms /    30 runs   (  665.00 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20686.33 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.82 ms /    37 runs   (    0.40 ms per token,  2495.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.04 ms /    12 tokens (   53.09 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   23893.06 ms /    36 runs   (  663.70 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   24637.03 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.93 ms /    32 runs   (    0.40 ms per token,  2474.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     601.65 ms /    11 tokens (   54.70 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =   20642.39 ms /    31 runs   (  665.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21336.01 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.61 ms /    32 runs   (    0.39 ms per token,  2537.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.57 ms /    12 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   20811.31 ms /    31 runs   (  671.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21540.11 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.31 ms /    52 runs   (    0.41 ms per token,  2440.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.35 ms /    13 tokens (   52.95 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   34147.84 ms /    51 runs   (  669.57 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   34986.76 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.20 ms /    35 runs   (    0.43 ms per token,  2303.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.06 ms /    12 tokens (   53.67 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   22812.01 ms /    34 runs   (  670.94 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   23564.77 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.49 ms /    30 runs   (    0.42 ms per token,  2401.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.68 ms /    12 tokens (   53.89 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   19316.62 ms /    29 runs   (  666.09 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20051.37 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.54 ms /    23 runs   (    0.41 ms per token,  2411.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.35 ms /    12 tokens (   55.28 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =   14630.40 ms /    22 runs   (  665.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15360.25 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.92 ms /    48 runs   (    0.42 ms per token,  2409.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     610.76 ms /    11 tokens (   55.52 ms per token,    18.01 tokens per second)\n",
      "llama_print_timings:        eval time =   31231.75 ms /    47 runs   (  664.51 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   31983.60 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.36 ms /    20 runs   (    0.42 ms per token,  2391.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     711.24 ms /    13 tokens (   54.71 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =   12692.91 ms /    19 runs   (  668.05 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13463.34 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.39 ms /    20 runs   (    0.42 ms per token,  2384.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.29 ms /    12 tokens (   53.27 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   12496.90 ms /    19 runs   (  657.73 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13195.41 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.16 ms /    20 runs   (    0.41 ms per token,  2450.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.98 ms /    12 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   12479.84 ms /    19 runs   (  656.83 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13174.35 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.02 ms /    51 runs   (    0.41 ms per token,  2426.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.07 ms /    12 tokens (   53.59 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   33288.94 ms /    50 runs   (  665.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   34082.91 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.11 ms /    40 runs   (    0.40 ms per token,  2483.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.76 ms /    11 tokens (   54.16 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   25760.89 ms /    39 runs   (  660.54 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   26474.65 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.12 ms /    61 runs   (    0.41 ms per token,  2428.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.52 ms /    12 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   39748.36 ms /    60 runs   (  662.47 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   40571.78 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.14 ms /    32 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.78 ms /    13 tokens (   52.68 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:        eval time =   20725.48 ms /    31 runs   (  668.56 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21503.88 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.86 ms /    30 runs   (    0.40 ms per token,  2529.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.05 ms /    12 tokens (   54.17 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   19463.15 ms /    29 runs   (  671.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20199.60 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.44 ms /    30 runs   (    0.41 ms per token,  2412.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.71 ms /    12 tokens (   54.31 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   19505.85 ms /    29 runs   (  672.62 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20248.05 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.21 ms /    30 runs   (    0.41 ms per token,  2457.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.80 ms /    12 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   19401.37 ms /    29 runs   (  669.01 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20129.48 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.77 ms /    31 runs   (    0.41 ms per token,  2427.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.08 ms /    12 tokens (   53.59 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   20153.25 ms /    30 runs   (  671.78 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20888.39 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.19 ms /    30 runs   (    0.41 ms per token,  2461.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.11 ms /    12 tokens (   53.43 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   19294.32 ms /    29 runs   (  665.32 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20022.78 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.30 ms /    30 runs   (    0.41 ms per token,  2439.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     609.52 ms /    11 tokens (   55.41 ms per token,    18.05 tokens per second)\n",
      "llama_print_timings:        eval time =   19335.96 ms /    29 runs   (  666.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20033.87 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.70 ms /    39 runs   (    0.40 ms per token,  2483.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.85 ms /    13 tokens (   52.37 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   25600.08 ms /    38 runs   (  673.69 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   26395.55 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.80 ms /    49 runs   (    0.40 ms per token,  2474.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     607.65 ms /    11 tokens (   55.24 ms per token,    18.10 tokens per second)\n",
      "llama_print_timings:        eval time =   31440.26 ms /    48 runs   (  655.01 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   32194.93 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.02 ms /    27 runs   (    0.41 ms per token,  2449.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     612.17 ms /    11 tokens (   55.65 ms per token,    17.97 tokens per second)\n",
      "llama_print_timings:        eval time =   17412.08 ms /    26 runs   (  669.70 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18102.91 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.89 ms /    56 runs   (    0.41 ms per token,  2446.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.00 ms /    12 tokens (   53.42 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   36039.99 ms /    55 runs   (  655.27 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   36843.85 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      38.26 ms /    88 runs   (    0.43 ms per token,  2300.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.60 ms /    12 tokens (   53.22 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   58777.48 ms /    87 runs   (  675.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   59690.90 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.70 ms /    27 runs   (    0.40 ms per token,  2524.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.92 ms /    12 tokens (   53.41 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   17114.65 ms /    26 runs   (  658.26 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   17833.22 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.62 ms /    63 runs   (    0.41 ms per token,  2459.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.01 ms /    12 tokens (   52.83 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   40311.21 ms /    62 runs   (  650.18 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   41127.44 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.01 ms /    49 runs   (    0.41 ms per token,  2448.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.71 ms /    12 tokens (   53.39 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   31160.15 ms /    48 runs   (  649.17 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   31944.01 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.23 ms /    30 runs   (    0.41 ms per token,  2452.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     955.38 ms /    13 tokens (   73.49 ms per token,    13.61 tokens per second)\n",
      "llama_print_timings:        eval time =   19232.12 ms /    29 runs   (  663.18 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20276.25 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.72 ms /    56 runs   (    0.41 ms per token,  2465.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.62 ms /    12 tokens (   53.14 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   36602.01 ms /    55 runs   (  665.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   37402.81 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.46 ms /    30 runs   (    0.42 ms per token,  2408.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.49 ms /    12 tokens (   54.62 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   19105.55 ms /    29 runs   (  658.81 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19849.51 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.81 ms /    32 runs   (    0.40 ms per token,  2498.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.22 ms /    12 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   20541.02 ms /    31 runs   (  662.61 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21276.71 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.12 ms /    30 runs   (    0.40 ms per token,  2476.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     588.04 ms /    11 tokens (   53.46 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   19287.25 ms /    29 runs   (  665.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19963.67 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.89 ms /    63 runs   (    0.41 ms per token,  2433.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     691.19 ms /    13 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   41502.71 ms /    62 runs   (  669.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   42380.71 ms /    75 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.75 ms /    31 runs   (    0.41 ms per token,  2430.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.29 ms /    12 tokens (   53.61 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   19940.45 ms /    30 runs   (  664.68 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20673.88 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.00 ms /    30 runs   (    0.40 ms per token,  2499.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.90 ms /    11 tokens (   54.17 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   19157.27 ms /    29 runs   (  660.60 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19840.62 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.25 ms /    62 runs   (    0.41 ms per token,  2455.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.20 ms /    12 tokens (   54.10 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   41040.30 ms /    61 runs   (  672.79 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   41872.91 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.72 ms /    51 runs   (    0.41 ms per token,  2461.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.12 ms /    12 tokens (   53.84 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   33300.74 ms /    50 runs   (  666.01 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   34096.08 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.19 ms /    46 runs   (    0.42 ms per token,  2396.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     661.08 ms /    12 tokens (   55.09 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =   29778.25 ms /    45 runs   (  661.74 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   30577.44 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.73 ms /    46 runs   (    0.41 ms per token,  2455.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.72 ms /    12 tokens (   53.98 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   29998.76 ms /    45 runs   (  666.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   30779.42 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.54 ms /    18 runs   (    0.42 ms per token,  2387.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     709.54 ms /    13 tokens (   54.58 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   11302.32 ms /    17 runs   (  664.84 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12065.44 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.23 ms /    20 runs   (    0.41 ms per token,  2428.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.57 ms /    12 tokens (   53.21 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   13032.27 ms /    19 runs   (  685.91 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13730.14 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.10 ms /    30 runs   (    0.40 ms per token,  2480.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.89 ms /    12 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   19575.58 ms /    29 runs   (  675.02 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20295.81 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.23 ms /    20 runs   (    0.41 ms per token,  2431.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.01 ms /    12 tokens (   53.83 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   12538.86 ms /    19 runs   (  659.94 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   13242.32 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      29.35 ms /    70 runs   (    0.42 ms per token,  2385.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     726.22 ms /    14 tokens (   51.87 ms per token,    19.28 tokens per second)\n",
      "llama_print_timings:        eval time =   45969.54 ms /    69 runs   (  666.23 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   46905.83 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.02 ms /    32 runs   (    0.41 ms per token,  2458.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.95 ms /    12 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   20667.74 ms /    31 runs   (  666.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21397.09 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.29 ms /    20 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.31 ms /    12 tokens (   53.61 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   12742.21 ms /    19 runs   (  670.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13443.66 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.21 ms /    40 runs   (    0.41 ms per token,  2467.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.59 ms /    12 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   26258.82 ms /    39 runs   (  673.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   27016.48 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.38 ms /    20 runs   (    0.42 ms per token,  2388.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.91 ms /    13 tokens (   52.45 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   12661.17 ms /    19 runs   (  666.38 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13401.14 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    20 runs   (    0.40 ms per token,  2486.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.69 ms /    12 tokens (   53.72 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   12596.50 ms /    19 runs   (  662.97 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13299.62 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.51 ms /    31 runs   (    0.40 ms per token,  2478.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     662.42 ms /    12 tokens (   55.20 ms per token,    18.12 tokens per second)\n",
      "llama_print_timings:        eval time =   19941.61 ms /    30 runs   (  664.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20693.90 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.70 ms /    32 runs   (    0.40 ms per token,  2519.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     617.83 ms /    11 tokens (   56.17 ms per token,    17.80 tokens per second)\n",
      "llama_print_timings:        eval time =   20499.83 ms /    31 runs   (  661.28 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21210.25 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.15 ms /    67 runs   (    0.41 ms per token,  2467.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.83 ms /    13 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   44270.37 ms /    66 runs   (  670.76 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   45147.77 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      30.34 ms /    73 runs   (    0.42 ms per token,  2406.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.35 ms /    12 tokens (   53.70 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   48190.48 ms /    72 runs   (  669.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   49055.65 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      37.52 ms /    93 runs   (    0.40 ms per token,  2478.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.73 ms /    12 tokens (   53.81 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   61681.53 ms /    92 runs   (  670.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   62602.03 ms /   104 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.94 ms /    32 runs   (    0.40 ms per token,  2473.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.02 ms /    12 tokens (   54.42 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   20564.85 ms /    31 runs   (  663.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21310.72 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.94 ms /    27 runs   (    0.41 ms per token,  2467.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     700.95 ms /    13 tokens (   53.92 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   17043.83 ms /    26 runs   (  655.53 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   17822.65 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.77 ms /    41 runs   (    0.41 ms per token,  2444.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.01 ms /    11 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   26988.58 ms /    40 runs   (  674.71 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27698.16 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3200 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.07 ms /    30 runs   (    0.40 ms per token,  2485.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.85 ms /    12 tokens (   53.15 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   18902.96 ms /    29 runs   (  651.83 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   19627.36 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.35 ms /    28 runs   (    0.41 ms per token,  2467.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.96 ms /    13 tokens (   52.84 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   17909.02 ms /    27 runs   (  663.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   18678.63 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.77 ms /    32 runs   (    0.40 ms per token,  2506.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     708.47 ms /    13 tokens (   54.50 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =   20691.28 ms /    31 runs   (  667.46 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21491.82 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.12 ms /    32 runs   (    0.44 ms per token,  2266.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.34 ms /    12 tokens (   53.61 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   20689.94 ms /    31 runs   (  667.42 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21431.90 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    20 runs   (    0.41 ms per token,  2436.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.79 ms /    12 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   12667.76 ms /    19 runs   (  666.72 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13367.09 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.56 ms /    28 runs   (    0.45 ms per token,  2230.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.39 ms /    12 tokens (   54.03 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   17936.17 ms /    27 runs   (  664.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   18670.33 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.00 ms /    30 runs   (    0.40 ms per token,  2500.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.59 ms /    11 tokens (   54.42 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   19063.17 ms /    29 runs   (  657.35 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19748.58 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.06 ms /    30 runs   (    0.40 ms per token,  2487.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.84 ms /    12 tokens (   53.49 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   19465.51 ms /    29 runs   (  671.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20195.21 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.34 ms /    30 runs   (    0.41 ms per token,  2430.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.78 ms /    11 tokens (   53.98 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   19588.65 ms /    29 runs   (  675.47 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20271.67 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.33 ms /    30 runs   (    0.41 ms per token,  2433.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.72 ms /    12 tokens (   53.23 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   19067.14 ms /    29 runs   (  657.49 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19793.44 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.75 ms /    64 runs   (    0.40 ms per token,  2485.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.35 ms /    13 tokens (   52.49 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   42111.16 ms /    63 runs   (  668.43 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   42980.82 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.25 ms /    36 runs   (    0.40 ms per token,  2525.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     658.40 ms /    12 tokens (   54.87 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =   23191.51 ms /    35 runs   (  662.61 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   23953.89 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    20 runs   (    0.41 ms per token,  2437.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.10 ms /    12 tokens (   54.43 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   12616.88 ms /    19 runs   (  664.05 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13328.84 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.60 ms /    21 runs   (    0.41 ms per token,  2442.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     676.62 ms /    13 tokens (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   13289.79 ms /    20 runs   (  664.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14027.82 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.21 ms /    30 runs   (    0.41 ms per token,  2457.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.99 ms /    12 tokens (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   19221.23 ms /    29 runs   (  662.80 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19949.93 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.27 ms /    30 runs   (    0.41 ms per token,  2445.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.70 ms /    12 tokens (   52.81 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   19435.11 ms /    29 runs   (  670.18 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20155.85 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.85 ms /    30 runs   (    0.40 ms per token,  2531.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.62 ms /    12 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   19354.90 ms /    29 runs   (  667.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20081.96 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.90 ms /    32 runs   (    0.40 ms per token,  2480.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.35 ms /    11 tokens (   54.30 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   20790.89 ms /    31 runs   (  670.67 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21480.62 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.09 ms /    32 runs   (    0.41 ms per token,  2445.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.38 ms /    11 tokens (   53.94 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   20820.71 ms /    31 runs   (  671.64 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21506.56 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.20 ms /    30 runs   (    0.41 ms per token,  2458.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     731.25 ms /    13 tokens (   56.25 ms per token,    17.78 tokens per second)\n",
      "llama_print_timings:        eval time =   19285.44 ms /    29 runs   (  665.02 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20104.40 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.24 ms /    30 runs   (    0.41 ms per token,  2451.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.89 ms /    11 tokens (   54.26 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   18825.55 ms /    29 runs   (  649.16 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   19510.53 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      33.40 ms /    82 runs   (    0.41 ms per token,  2455.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.74 ms /    12 tokens (   52.98 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   54839.11 ms /    81 runs   (  677.03 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   55718.69 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.11 ms /    30 runs   (    0.40 ms per token,  2476.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.10 ms /    12 tokens (   54.43 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   19349.39 ms /    29 runs   (  667.22 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20090.32 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.07 ms /    35 runs   (    0.40 ms per token,  2487.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.00 ms /    12 tokens (   54.92 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =   22475.50 ms /    34 runs   (  661.04 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   23237.26 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    20 runs   (    0.41 ms per token,  2436.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.02 ms /    13 tokens (   54.16 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   12645.43 ms /    19 runs   (  665.55 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13408.44 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.10 ms /    31 runs   (    0.42 ms per token,  2366.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.50 ms /    12 tokens (   53.79 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   19865.31 ms /    30 runs   (  662.18 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20603.45 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.04 ms /    25 runs   (    0.40 ms per token,  2491.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.42 ms /    12 tokens (   53.45 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   16002.03 ms /    24 runs   (  666.75 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16715.71 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.94 ms /    40 runs   (    0.40 ms per token,  2508.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.38 ms /    12 tokens (   54.37 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =   26020.44 ms /    39 runs   (  667.19 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26789.51 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.00 ms /    30 runs   (    0.43 ms per token,  2307.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.48 ms /    12 tokens (   53.54 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   19088.05 ms /    29 runs   (  658.21 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19823.18 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.89 ms /    24 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     747.43 ms /    14 tokens (   53.39 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   15286.30 ms /    23 runs   (  664.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16104.38 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.71 ms /    51 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.23 ms /    12 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   33374.52 ms /    50 runs   (  667.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   34160.18 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.33 ms /    60 runs   (    0.41 ms per token,  2465.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.79 ms /    12 tokens (   54.40 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   39051.63 ms /    59 runs   (  661.89 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   39882.13 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.82 ms /    60 runs   (    0.43 ms per token,  2323.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.13 ms /    11 tokens (   54.28 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   39702.19 ms /    59 runs   (  672.92 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   40480.65 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.24 ms /    54 runs   (    0.41 ms per token,  2428.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.77 ms /    13 tokens (   52.29 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   35755.16 ms /    53 runs   (  674.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   36593.38 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.31 ms /    20 runs   (    0.42 ms per token,  2406.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.00 ms /    12 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   12602.05 ms /    19 runs   (  663.27 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13298.61 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.23 ms /    30 runs   (    0.41 ms per token,  2452.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.59 ms /    13 tokens (   52.28 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   19230.60 ms /    29 runs   (  663.12 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19997.19 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.30 ms /    20 runs   (    0.42 ms per token,  2408.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.99 ms /    12 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   12690.54 ms /    19 runs   (  667.92 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13385.77 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.43 ms /    50 runs   (    0.41 ms per token,  2447.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.53 ms /    12 tokens (   53.04 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   32776.19 ms /    49 runs   (  668.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   33559.00 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.36 ms /    20 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.97 ms /    12 tokens (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   12568.56 ms /    19 runs   (  661.50 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13266.57 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.18 ms /    30 runs   (    0.44 ms per token,  2275.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.51 ms /    13 tokens (   52.81 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   19257.06 ms /    29 runs   (  664.04 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20036.70 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.11 ms /    30 runs   (    0.40 ms per token,  2476.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.34 ms /    11 tokens (   54.03 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   19306.86 ms /    29 runs   (  665.75 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19988.70 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.29 ms /    30 runs   (    0.41 ms per token,  2442.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.40 ms /    12 tokens (   54.45 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   19274.45 ms /    29 runs   (  664.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20013.86 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.28 ms /    30 runs   (    0.41 ms per token,  2442.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.54 ms /    11 tokens (   53.78 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   19486.49 ms /    29 runs   (  671.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20164.51 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.44 ms /    25 runs   (    0.42 ms per token,  2395.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.53 ms /    12 tokens (   54.38 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =   15987.20 ms /    24 runs   (  666.13 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16711.37 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.64 ms /    37 runs   (    0.40 ms per token,  2527.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.63 ms /    13 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   24135.51 ms /    36 runs   (  670.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24931.10 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.28 ms /    30 runs   (    0.41 ms per token,  2443.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.63 ms /    12 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   19240.07 ms /    29 runs   (  663.45 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19966.45 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.96 ms /    20 runs   (    0.40 ms per token,  2513.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.72 ms /    12 tokens (   53.64 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   12656.57 ms /    19 runs   (  666.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13357.68 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.47 ms /    66 runs   (    0.40 ms per token,  2493.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.43 ms /    13 tokens (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   44139.16 ms /    65 runs   (  679.06 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   45015.98 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.06 ms /    30 runs   (    0.40 ms per token,  2486.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.67 ms /    12 tokens (   53.72 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   18824.93 ms /    29 runs   (  649.14 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   19556.74 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.13 ms /    30 runs   (    0.40 ms per token,  2473.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.54 ms /    11 tokens (   53.96 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   19166.86 ms /    29 runs   (  660.93 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19849.32 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.14 ms /    25 runs   (    0.41 ms per token,  2465.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.78 ms /    11 tokens (   53.89 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   16000.78 ms /    24 runs   (  666.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16665.89 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      33.44 ms /    83 runs   (    0.40 ms per token,  2482.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.00 ms /    12 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   55137.78 ms /    82 runs   (  672.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   56019.58 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.56 ms /    29 runs   (    0.40 ms per token,  2508.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.90 ms /    11 tokens (   54.63 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   18644.47 ms /    28 runs   (  665.87 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19329.86 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.00 ms /    22 runs   (    0.41 ms per token,  2443.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.18 ms /    13 tokens (   52.40 ms per token,    19.08 tokens per second)\n",
      "llama_print_timings:        eval time =   13807.97 ms /    21 runs   (  657.52 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   14553.84 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.23 ms /    30 runs   (    0.41 ms per token,  2452.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     601.04 ms /    11 tokens (   54.64 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =   18897.71 ms /    29 runs   (  651.65 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   19587.62 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.59 ms /    37 runs   (    0.39 ms per token,  2536.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.59 ms /    12 tokens (   54.22 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   23645.83 ms /    36 runs   (  656.83 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   24403.26 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.02 ms /    35 runs   (    0.40 ms per token,  2496.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.51 ms /    12 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   22588.22 ms /    34 runs   (  664.36 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   23327.33 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      30.61 ms /    75 runs   (    0.41 ms per token,  2450.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.69 ms /    12 tokens (   54.97 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =   49633.03 ms /    74 runs   (  670.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   50513.32 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.00 ms /    64 runs   (    0.42 ms per token,  2370.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.75 ms /    11 tokens (   53.89 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   42576.10 ms /    63 runs   (  675.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   43363.19 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.32 ms /    30 runs   (    0.41 ms per token,  2434.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     702.72 ms /    13 tokens (   54.06 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   19321.17 ms /    29 runs   (  666.25 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20110.85 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.54 ms /    21 runs   (    0.41 ms per token,  2458.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.13 ms /    12 tokens (   54.43 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   13408.98 ms /    20 runs   (  670.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14123.70 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.37 ms /    38 runs   (    0.40 ms per token,  2472.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     695.73 ms /    13 tokens (   53.52 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   24781.11 ms /    37 runs   (  669.76 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   25586.86 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.32 ms /    20 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.56 ms /    11 tokens (   54.41 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   12636.82 ms /    19 runs   (  665.10 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13293.79 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.92 ms /    34 runs   (    0.41 ms per token,  2442.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.93 ms /    12 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   22006.25 ms /    33 runs   (  666.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22741.91 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.12 ms /    54 runs   (    0.41 ms per token,  2440.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.06 ms /    13 tokens (   52.62 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   35798.08 ms /    53 runs   (  675.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   36639.23 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.45 ms /    23 runs   (    0.41 ms per token,  2434.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.27 ms /    12 tokens (   53.44 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   14609.58 ms /    22 runs   (  664.07 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15317.92 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.14 ms /    36 runs   (    0.39 ms per token,  2546.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.56 ms /    12 tokens (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   23306.74 ms /    35 runs   (  665.91 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24053.55 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.72 ms /    29 runs   (    0.40 ms per token,  2473.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.78 ms /    12 tokens (   54.07 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   18983.22 ms /    28 runs   (  677.97 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19715.68 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      28.18 ms /    66 runs   (    0.43 ms per token,  2342.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.12 ms /    12 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   43920.27 ms /    65 runs   (  675.70 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   44769.49 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    20 runs   (    0.41 ms per token,  2443.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.11 ms /    12 tokens (   53.43 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   12684.54 ms /    19 runs   (  667.61 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13384.08 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.12 ms /    35 runs   (    0.40 ms per token,  2478.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.12 ms /    12 tokens (   53.93 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   23184.11 ms /    34 runs   (  681.89 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   23933.68 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.41 ms /    41 runs   (    0.40 ms per token,  2498.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.75 ms /    14 tokens (   51.77 ms per token,    19.32 tokens per second)\n",
      "llama_print_timings:        eval time =   26952.72 ms /    40 runs   (  673.82 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27798.15 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.04 ms /    32 runs   (    0.41 ms per token,  2454.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.57 ms /    12 tokens (   53.46 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   20671.69 ms /    31 runs   (  666.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21407.67 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.39 ms /    33 runs   (    0.41 ms per token,  2465.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.16 ms /    12 tokens (   53.85 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   21281.79 ms /    32 runs   (  665.06 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22024.13 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.41 ms /    34 runs   (    0.39 ms per token,  2535.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.96 ms /    12 tokens (   53.66 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   22067.22 ms /    33 runs   (  668.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22808.76 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.02 ms /    33 runs   (    0.39 ms per token,  2534.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     696.97 ms /    13 tokens (   53.61 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   20938.14 ms /    32 runs   (  654.32 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   21731.44 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.78 ms /    30 runs   (    0.39 ms per token,  2546.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.19 ms /    12 tokens (   53.52 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   19100.83 ms /    29 runs   (  658.65 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19830.27 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.10 ms /    30 runs   (    0.40 ms per token,  2480.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.99 ms /    12 tokens (   53.67 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   19178.25 ms /    29 runs   (  661.32 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19910.53 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.88 ms /    49 runs   (    0.41 ms per token,  2464.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.12 ms /    13 tokens (   52.62 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   32508.10 ms /    48 runs   (  677.25 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   33337.65 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.25 ms /    30 runs   (    0.41 ms per token,  2449.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.65 ms /    11 tokens (   54.42 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   19257.78 ms /    29 runs   (  664.06 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19944.04 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.66 ms /    46 runs   (    0.41 ms per token,  2464.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.34 ms /    12 tokens (   53.03 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   30160.06 ms /    45 runs   (  670.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   30931.69 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.03 ms /    49 runs   (    0.41 ms per token,  2445.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.28 ms /    11 tokens (   54.30 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   32042.60 ms /    48 runs   (  667.55 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   32783.91 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.83 ms /    60 runs   (    0.43 ms per token,  2322.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.53 ms /    13 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   39605.06 ms /    59 runs   (  671.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   40478.01 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.91 ms /    29 runs   (    0.41 ms per token,  2434.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     803.38 ms /    12 tokens (   66.95 ms per token,    14.94 tokens per second)\n",
      "llama_print_timings:        eval time =   18684.36 ms /    28 runs   (  667.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19571.88 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.68 ms /    37 runs   (    0.42 ms per token,  2359.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.40 ms /    12 tokens (   54.37 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =   24315.91 ms /    36 runs   (  675.44 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25081.25 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    19 runs   (    0.40 ms per token,  2483.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.31 ms /    12 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   11926.50 ms /    18 runs   (  662.58 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12620.09 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.46 ms /    33 runs   (    0.41 ms per token,  2452.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     690.05 ms /    13 tokens (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   21364.92 ms /    32 runs   (  667.65 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22151.59 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.90 ms /    30 runs   (    0.40 ms per token,  2521.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     667.39 ms /    12 tokens (   55.62 ms per token,    17.98 tokens per second)\n",
      "llama_print_timings:        eval time =   19320.64 ms /    29 runs   (  666.23 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20077.34 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.19 ms /    33 runs   (    0.40 ms per token,  2501.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.16 ms /    12 tokens (   54.26 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   21355.32 ms /    32 runs   (  667.35 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22102.73 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.21 ms /    38 runs   (    0.40 ms per token,  2498.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     694.72 ms /    13 tokens (   53.44 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   24817.92 ms /    37 runs   (  670.75 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   25622.40 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.07 ms /    30 runs   (    0.40 ms per token,  2484.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.39 ms /    12 tokens (   53.12 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   19351.70 ms /    29 runs   (  667.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20075.06 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.43 ms /    31 runs   (    0.40 ms per token,  2493.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.34 ms /    12 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   20166.84 ms /    30 runs   (  672.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20898.77 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.54 ms /    34 runs   (    0.40 ms per token,  2511.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     691.74 ms /    13 tokens (   53.21 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   22141.10 ms /    33 runs   (  670.94 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22932.23 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.96 ms /    30 runs   (    0.40 ms per token,  2508.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     664.84 ms /    12 tokens (   55.40 ms per token,    18.05 tokens per second)\n",
      "llama_print_timings:        eval time =   19455.12 ms /    29 runs   (  670.87 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20209.20 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      28.05 ms /    67 runs   (    0.42 ms per token,  2388.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.24 ms /    12 tokens (   54.27 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:        eval time =   44518.93 ms /    66 runs   (  674.53 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   45373.75 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.25 ms /    20 runs   (    0.41 ms per token,  2423.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     723.36 ms /    13 tokens (   55.64 ms per token,    17.97 tokens per second)\n",
      "llama_print_timings:        eval time =   12759.02 ms /    19 runs   (  671.53 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13540.70 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.83 ms /    34 runs   (    0.41 ms per token,  2458.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.47 ms /    12 tokens (   55.29 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =   21907.61 ms /    33 runs   (  663.87 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   22670.45 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.28 ms /    20 runs   (    0.41 ms per token,  2416.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.14 ms /    13 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   12774.58 ms /    19 runs   (  672.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13520.91 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.08 ms /    20 runs   (    0.40 ms per token,  2475.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.37 ms /    12 tokens (   53.61 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   12799.88 ms /    19 runs   (  673.68 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13502.35 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.16 ms /    20 runs   (    0.41 ms per token,  2449.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.41 ms /    12 tokens (   54.03 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   12615.00 ms /    19 runs   (  663.95 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13320.91 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3300 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.65 ms /    29 runs   (    0.40 ms per token,  2488.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.95 ms /    12 tokens (   54.00 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   18659.16 ms /    28 runs   (  666.40 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19391.99 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.78 ms /    60 runs   (    0.41 ms per token,  2421.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.57 ms /    12 tokens (   53.55 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   39787.73 ms /    59 runs   (  674.37 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   40606.53 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.25 ms /    49 runs   (    0.43 ms per token,  2305.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.93 ms /    12 tokens (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   32118.17 ms /    48 runs   (  669.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   32907.50 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.86 ms /    29 runs   (    0.41 ms per token,  2445.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.22 ms /    12 tokens (   53.43 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   18744.05 ms /    28 runs   (  669.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19473.19 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.35 ms /    28 runs   (    0.41 ms per token,  2468.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     742.36 ms /    14 tokens (   53.03 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   17775.62 ms /    27 runs   (  658.36 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   18599.93 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.08 ms /    32 runs   (    0.41 ms per token,  2445.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.04 ms /    12 tokens (   53.42 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   20570.85 ms /    31 runs   (  663.58 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21306.10 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.90 ms /    29 runs   (    0.41 ms per token,  2436.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     664.77 ms /    12 tokens (   55.40 ms per token,    18.05 tokens per second)\n",
      "llama_print_timings:        eval time =   18588.13 ms /    28 runs   (  663.86 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19338.08 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.64 ms /    29 runs   (    0.40 ms per token,  2490.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.14 ms /    12 tokens (   53.26 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   18611.47 ms /    28 runs   (  664.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19335.37 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.95 ms /    32 runs   (    0.40 ms per token,  2471.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.79 ms /    13 tokens (   52.37 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   20642.56 ms /    31 runs   (  665.89 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21416.47 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.30 ms /    44 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.93 ms /    11 tokens (   54.08 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   29151.22 ms /    43 runs   (  677.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   29877.41 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.73 ms /    37 runs   (    0.43 ms per token,  2352.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.40 ms /    12 tokens (   53.37 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   23950.96 ms /    36 runs   (  665.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24706.36 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.88 ms /    49 runs   (    0.41 ms per token,  2464.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.51 ms /    12 tokens (   53.54 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   31849.98 ms /    48 runs   (  663.54 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   32635.52 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.68 ms /    29 runs   (    0.40 ms per token,  2483.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.82 ms /    11 tokens (   54.44 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   18605.28 ms /    28 runs   (  664.47 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19288.59 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.39 ms /    41 runs   (    0.40 ms per token,  2501.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.13 ms /    12 tokens (   53.01 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   26498.79 ms /    40 runs   (  662.47 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   27255.28 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.01 ms /    32 runs   (    0.41 ms per token,  2460.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.54 ms /    13 tokens (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_print_timings:        eval time =   20481.83 ms /    31 runs   (  660.70 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21255.68 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.67 ms /    53 runs   (    0.41 ms per token,  2445.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.03 ms /    12 tokens (   52.84 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   34914.39 ms /    52 runs   (  671.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   35702.81 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.91 ms /    56 runs   (    0.41 ms per token,  2444.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.66 ms /    12 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   36482.96 ms /    55 runs   (  663.33 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   37294.10 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.00 ms /    30 runs   (    0.40 ms per token,  2499.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.84 ms /    12 tokens (   53.74 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   19254.60 ms /    29 runs   (  663.95 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19986.20 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    19 runs   (    0.40 ms per token,  2479.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     690.93 ms /    13 tokens (   53.15 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   11985.44 ms /    18 runs   (  665.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12732.39 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.79 ms /    49 runs   (    0.40 ms per token,  2476.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.86 ms /    12 tokens (   53.99 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   31923.96 ms /    48 runs   (  665.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   32715.34 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.99 ms /    25 runs   (    0.40 ms per token,  2501.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.26 ms /    12 tokens (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   15988.60 ms /    24 runs   (  666.19 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16696.05 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.84 ms /    49 runs   (    0.40 ms per token,  2469.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.94 ms /    12 tokens (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   32267.04 ms /    48 runs   (  672.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   33047.30 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.17 ms /    49 runs   (    0.41 ms per token,  2429.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.87 ms /    12 tokens (   53.49 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   32111.55 ms /    48 runs   (  668.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   32896.40 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.28 ms /    49 runs   (    0.41 ms per token,  2416.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.37 ms /    13 tokens (   52.87 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   31812.63 ms /    48 runs   (  662.76 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   32644.20 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.06 ms /    30 runs   (    0.40 ms per token,  2487.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.62 ms /    11 tokens (   54.06 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   19414.11 ms /    29 runs   (  669.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20096.50 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.91 ms /    67 runs   (    0.40 ms per token,  2489.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.72 ms /    12 tokens (   53.06 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   44325.30 ms /    66 runs   (  671.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   45157.30 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.38 ms /    33 runs   (    0.41 ms per token,  2466.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.03 ms /    12 tokens (   53.25 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   21299.90 ms /    32 runs   (  665.62 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22034.56 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.79 ms /    32 runs   (    0.40 ms per token,  2502.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.73 ms /    13 tokens (   52.98 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   20723.19 ms /    31 runs   (  668.49 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21506.59 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.07 ms /    49 runs   (    0.41 ms per token,  2440.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.39 ms /    12 tokens (   54.03 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   32175.71 ms /    48 runs   (  670.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   32968.03 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.02 ms /    30 runs   (    0.40 ms per token,  2496.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     610.70 ms /    11 tokens (   55.52 ms per token,    18.01 tokens per second)\n",
      "llama_print_timings:        eval time =   19347.76 ms /    29 runs   (  667.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20046.04 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.17 ms /    36 runs   (    0.39 ms per token,  2540.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.14 ms /    12 tokens (   53.01 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   23141.25 ms /    35 runs   (  661.18 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   23881.52 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.34 ms /    33 runs   (    0.40 ms per token,  2474.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.44 ms /    12 tokens (   53.79 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   21308.19 ms /    32 runs   (  665.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22049.39 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.13 ms /    25 runs   (    0.41 ms per token,  2467.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.04 ms /    12 tokens (   53.34 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   15852.98 ms /    24 runs   (  660.54 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16565.69 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.00 ms /    30 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     603.92 ms /    11 tokens (   54.90 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =   19282.72 ms /    29 runs   (  664.92 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19973.68 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.25 ms /    30 runs   (    0.41 ms per token,  2448.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     584.85 ms /    11 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_print_timings:        eval time =   19268.11 ms /    29 runs   (  664.42 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19939.96 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.55 ms /    31 runs   (    0.40 ms per token,  2470.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     586.90 ms /    11 tokens (   53.35 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   19931.99 ms /    30 runs   (  664.40 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20608.04 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.78 ms /    49 runs   (    0.40 ms per token,  2477.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     720.27 ms /    13 tokens (   55.41 ms per token,    18.05 tokens per second)\n",
      "llama_print_timings:        eval time =   32156.19 ms /    48 runs   (  669.92 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   33021.20 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.12 ms /    32 runs   (    0.41 ms per token,  2438.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.78 ms /    11 tokens (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   20505.58 ms /    31 runs   (  661.47 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21191.41 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.69 ms /    39 runs   (    0.40 ms per token,  2485.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     591.33 ms /    11 tokens (   53.76 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   25365.80 ms /    38 runs   (  667.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26071.91 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.54 ms /    37 runs   (    0.39 ms per token,  2544.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.18 ms /    12 tokens (   52.76 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   24164.01 ms /    36 runs   (  671.22 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24903.81 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.05 ms /    32 runs   (    0.41 ms per token,  2452.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.77 ms /    12 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   20617.59 ms /    31 runs   (  665.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21340.88 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.11 ms /    30 runs   (    0.40 ms per token,  2476.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     676.23 ms /    13 tokens (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_print_timings:        eval time =   19493.72 ms /    29 runs   (  672.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20257.02 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.89 ms /    35 runs   (    0.40 ms per token,  2520.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.13 ms /    12 tokens (   52.76 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   22565.54 ms /    34 runs   (  663.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   23300.77 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.22 ms /    30 runs   (    0.41 ms per token,  2455.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.78 ms /    12 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   19112.98 ms /    29 runs   (  659.07 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19833.75 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      34.35 ms /    86 runs   (    0.40 ms per token,  2503.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.89 ms /    12 tokens (   52.74 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   57448.51 ms /    85 runs   (  675.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   58336.05 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.71 ms /    39 runs   (    0.40 ms per token,  2483.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.44 ms /    12 tokens (   52.70 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   25140.30 ms /    38 runs   (  661.59 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   25887.25 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.44 ms /    33 runs   (    0.41 ms per token,  2456.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     587.60 ms /    11 tokens (   53.42 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   21163.65 ms /    32 runs   (  661.36 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21847.71 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.95 ms /    32 runs   (    0.40 ms per token,  2471.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     675.12 ms /    13 tokens (   51.93 ms per token,    19.26 tokens per second)\n",
      "llama_print_timings:        eval time =   20474.46 ms /    31 runs   (  660.47 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21242.03 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.47 ms /    31 runs   (    0.40 ms per token,  2485.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.21 ms /    12 tokens (   53.10 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   19940.39 ms /    30 runs   (  664.68 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20667.57 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      30.86 ms /    74 runs   (    0.42 ms per token,  2397.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     586.95 ms /    11 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   48741.50 ms /    73 runs   (  667.69 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   49553.41 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.33 ms /    25 runs   (    0.41 ms per token,  2421.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.74 ms /    12 tokens (   54.14 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   16004.94 ms /    24 runs   (  666.87 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16727.13 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.62 ms /    48 runs   (    0.41 ms per token,  2446.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     629.97 ms /    12 tokens (   52.50 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   31414.90 ms /    47 runs   (  668.40 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   32185.04 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.60 ms /    45 runs   (    0.41 ms per token,  2418.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     588.28 ms /    11 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   29467.78 ms /    44 runs   (  669.72 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   30189.90 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.87 ms /    30 runs   (    0.40 ms per token,  2527.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.28 ms /    13 tokens (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   19237.76 ms /    29 runs   (  663.37 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   20019.25 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.77 ms /    48 runs   (    0.41 ms per token,  2427.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.57 ms /    11 tokens (   54.05 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   31243.53 ms /    47 runs   (  664.76 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   31979.46 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.57 ms /    59 runs   (    0.42 ms per token,  2401.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.59 ms /    14 tokens (   60.04 ms per token,    16.65 tokens per second)\n",
      "llama_print_timings:        eval time =   39226.60 ms /    58 runs   (  676.32 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   40244.94 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.46 ms /    43 runs   (    0.41 ms per token,  2463.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     586.48 ms /    11 tokens (   53.32 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   28217.47 ms /    42 runs   (  671.84 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   28929.38 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.25 ms /    57 runs   (    0.41 ms per token,  2451.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.26 ms /    11 tokens (   57.48 ms per token,    17.40 tokens per second)\n",
      "llama_print_timings:        eval time =   37521.10 ms /    56 runs   (  670.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   38321.22 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.89 ms /    29 runs   (    0.41 ms per token,  2438.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.53 ms /    12 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   18584.44 ms /    28 runs   (  663.73 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19303.13 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.06 ms /    67 runs   (    0.40 ms per token,  2475.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.43 ms /    11 tokens (   54.22 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   44157.61 ms /    66 runs   (  669.05 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   44953.57 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.52 ms /    66 runs   (    0.40 ms per token,  2489.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.59 ms /    12 tokens (   54.38 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:        eval time =   43479.31 ms /    65 runs   (  668.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   44327.47 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      34.90 ms /    83 runs   (    0.42 ms per token,  2378.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.63 ms /    12 tokens (   52.80 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   55195.45 ms /    82 runs   (  673.12 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   56080.75 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    19 runs   (    0.41 ms per token,  2438.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.43 ms /    12 tokens (   53.79 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   12002.72 ms /    18 runs   (  666.82 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   12703.53 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.18 ms /    45 runs   (    0.40 ms per token,  2475.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.30 ms /    12 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   29807.80 ms /    44 runs   (  677.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   30581.62 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.33 ms /    20 runs   (    0.42 ms per token,  2402.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.69 ms /    12 tokens (   53.14 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   12553.68 ms /    19 runs   (  660.72 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13248.95 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.52 ms /    23 runs   (    0.41 ms per token,  2415.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     603.68 ms /    11 tokens (   54.88 ms per token,    18.22 tokens per second)\n",
      "llama_print_timings:        eval time =   14583.60 ms /    22 runs   (  662.89 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15253.62 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.66 ms /    23 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.10 ms /    12 tokens (   52.76 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   14625.52 ms /    22 runs   (  664.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   15325.01 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.61 ms /    21 runs   (    0.41 ms per token,  2439.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.99 ms /    13 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   13298.02 ms /    20 runs   (  664.90 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   14038.33 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.92 ms /    32 runs   (    0.40 ms per token,  2477.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.79 ms /    12 tokens (   57.07 ms per token,    17.52 tokens per second)\n",
      "llama_print_timings:        eval time =   20287.15 ms /    31 runs   (  654.42 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   21065.50 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    19 runs   (    0.41 ms per token,  2418.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.12 ms /    13 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11783.85 ms /    18 runs   (  654.66 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   12527.03 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.24 ms /    66 runs   (    0.40 ms per token,  2515.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     680.75 ms /    13 tokens (   52.37 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   43374.60 ms /    65 runs   (  667.30 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   44249.78 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.11 ms /    30 runs   (    0.40 ms per token,  2478.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.04 ms /    12 tokens (   53.67 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   19234.59 ms /    29 runs   (  663.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19965.69 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.89 ms /    67 runs   (    0.40 ms per token,  2491.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.51 ms /    11 tokens (   53.86 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   44409.70 ms /    66 runs   (  672.87 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   45202.91 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.22 ms /    30 runs   (    0.41 ms per token,  2454.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     664.03 ms /    12 tokens (   55.34 ms per token,    18.07 tokens per second)\n",
      "llama_print_timings:        eval time =   19330.75 ms /    29 runs   (  666.58 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20082.31 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.87 ms /    53 runs   (    0.43 ms per token,  2317.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.87 ms /    12 tokens (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   34848.19 ms /    52 runs   (  670.16 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   35656.18 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.31 ms /    59 runs   (    0.41 ms per token,  2426.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.62 ms /    12 tokens (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   38829.97 ms /    58 runs   (  669.48 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   39644.43 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.98 ms /    51 runs   (    0.41 ms per token,  2431.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.97 ms /    13 tokens (   52.46 ms per token,    19.06 tokens per second)\n",
      "llama_print_timings:        eval time =   33257.62 ms /    50 runs   (  665.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   34089.89 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.29 ms /    25 runs   (    0.41 ms per token,  2430.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.12 ms /    12 tokens (   53.01 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   15921.05 ms /    24 runs   (  663.38 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   16631.83 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.54 ms /    53 runs   (    0.41 ms per token,  2460.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.67 ms /    12 tokens (   52.72 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   34437.94 ms /    52 runs   (  662.27 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   35227.34 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      91.97 ms /   219 runs   (    0.42 ms per token,  2381.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.22 ms /    12 tokens (   53.27 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =  143791.14 ms /   218 runs   (  659.59 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =  145110.52 ms /   230 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.14 ms /    30 runs   (    0.40 ms per token,  2470.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.81 ms /    12 tokens (   52.65 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   19215.57 ms /    29 runs   (  662.61 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19933.97 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      47.71 ms /   113 runs   (    0.42 ms per token,  2368.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.00 ms /    12 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   75259.28 ms /   112 runs   (  671.96 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   76240.90 ms /   124 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.48 ms /    35 runs   (    0.41 ms per token,  2417.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.33 ms /    12 tokens (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   22978.15 ms /    34 runs   (  675.83 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   23716.75 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.24 ms /    30 runs   (    0.41 ms per token,  2451.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     689.16 ms /    13 tokens (   53.01 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   19922.08 ms /    29 runs   (  686.97 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20700.72 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.22 ms /    30 runs   (    0.44 ms per token,  2268.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     695.79 ms /    12 tokens (   57.98 ms per token,    17.25 tokens per second)\n",
      "llama_print_timings:        eval time =   19375.64 ms /    29 runs   (  668.13 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20164.85 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.49 ms /    65 runs   (    0.41 ms per token,  2454.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     676.76 ms /    13 tokens (   52.06 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:        eval time =   42888.44 ms /    64 runs   (  670.13 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   43756.19 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      36.26 ms /    88 runs   (    0.41 ms per token,  2427.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     628.14 ms /    12 tokens (   52.34 ms per token,    19.10 tokens per second)\n",
      "llama_print_timings:        eval time =   58527.61 ms /    87 runs   (  672.73 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   59415.26 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.51 ms /    50 runs   (    0.41 ms per token,  2437.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     620.19 ms /    11 tokens (   56.38 ms per token,    17.74 tokens per second)\n",
      "llama_print_timings:        eval time =   32839.08 ms /    49 runs   (  670.19 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   33605.77 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.14 ms /    33 runs   (    0.40 ms per token,  2511.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     658.16 ms /    12 tokens (   54.85 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =   21376.85 ms /    32 runs   (  668.03 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22130.87 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.06 ms /    30 runs   (    0.40 ms per token,  2487.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     708.15 ms /    13 tokens (   54.47 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =   19283.72 ms /    29 runs   (  664.96 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20079.51 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.90 ms /    49 runs   (    0.41 ms per token,  2462.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.35 ms /    12 tokens (   53.78 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   32132.19 ms /    48 runs   (  669.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   32920.03 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.27 ms /    44 runs   (    0.42 ms per token,  2407.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.17 ms /    12 tokens (   53.85 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   28611.30 ms /    43 runs   (  665.38 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   29386.10 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.11 ms /    44 runs   (    0.41 ms per token,  2430.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.88 ms /    12 tokens (   52.91 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   28818.39 ms /    43 runs   (  670.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   29581.84 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.89 ms /    37 runs   (    0.40 ms per token,  2484.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.03 ms /    13 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_print_timings:        eval time =   24155.66 ms /    36 runs   (  670.99 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24940.07 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.19 ms /    30 runs   (    0.41 ms per token,  2461.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.64 ms /    13 tokens (   52.13 ms per token,    19.18 tokens per second)\n",
      "llama_print_timings:        eval time =   19188.65 ms /    29 runs   (  661.68 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19953.50 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.17 ms /    20 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.15 ms /    12 tokens (   53.10 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   12605.67 ms /    19 runs   (  663.46 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13300.14 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.11 ms /    30 runs   (    0.40 ms per token,  2476.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     721.63 ms /    12 tokens (   60.14 ms per token,    16.63 tokens per second)\n",
      "llama_print_timings:        eval time =   19087.95 ms /    29 runs   (  658.21 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19896.63 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.10 ms /    49 runs   (    0.41 ms per token,  2437.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.54 ms /    12 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   31589.26 ms /    48 runs   (  658.11 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   32367.81 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.04 ms /    32 runs   (    0.41 ms per token,  2453.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     727.70 ms /    14 tokens (   51.98 ms per token,    19.24 tokens per second)\n",
      "llama_print_timings:        eval time =   20829.76 ms /    31 runs   (  671.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21651.86 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.29 ms /    30 runs   (    0.44 ms per token,  2258.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.57 ms /    12 tokens (   52.71 ms per token,    18.97 tokens per second)\n",
      "llama_print_timings:        eval time =   19383.83 ms /    29 runs   (  668.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20110.53 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3400 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.22 ms /    31 runs   (    0.43 ms per token,  2345.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.67 ms /    11 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   20144.92 ms /    30 runs   (  671.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20830.82 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.41 ms /    36 runs   (    0.40 ms per token,  2498.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     605.09 ms /    11 tokens (   55.01 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =   23451.53 ms /    35 runs   (  670.04 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24160.88 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.60 ms /    38 runs   (    0.44 ms per token,  2289.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.18 ms /    12 tokens (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:        eval time =   24983.72 ms /    37 runs   (  675.24 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25732.19 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.80 ms /    32 runs   (    0.40 ms per token,  2499.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     587.80 ms /    11 tokens (   53.44 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   20905.44 ms /    31 runs   (  674.37 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   21587.13 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.25 ms /    20 runs   (    0.41 ms per token,  2425.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.46 ms /    12 tokens (   54.29 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   12678.33 ms /    19 runs   (  667.28 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13387.61 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.50 ms /    57 runs   (    0.41 ms per token,  2425.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.70 ms /    13 tokens (   52.21 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:        eval time =   37257.67 ms /    56 runs   (  665.32 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   38102.77 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.38 ms /    20 runs   (    0.42 ms per token,  2386.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.85 ms /    12 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   12390.46 ms /    19 runs   (  652.13 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   13087.81 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      34.52 ms /    85 runs   (    0.41 ms per token,  2462.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.57 ms /    12 tokens (   52.88 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   56197.54 ms /    84 runs   (  669.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   57086.25 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.66 ms /    31 runs   (    0.41 ms per token,  2448.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     628.60 ms /    12 tokens (   52.38 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   20029.59 ms /    30 runs   (  667.65 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20748.47 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.61 ms /    29 runs   (    0.40 ms per token,  2497.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.24 ms /    12 tokens (   53.35 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   18227.39 ms /    28 runs   (  650.98 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   18952.15 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.95 ms /    46 runs   (    0.41 ms per token,  2427.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.30 ms /    11 tokens (   53.66 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   29976.84 ms /    45 runs   (  666.15 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   30701.29 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.55 ms /    48 runs   (    0.41 ms per token,  2455.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.29 ms /    13 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   31324.38 ms /    47 runs   (  666.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   32148.17 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    20 runs   (    0.41 ms per token,  2452.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.99 ms /    12 tokens (   53.92 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   12666.12 ms /    19 runs   (  666.64 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13370.55 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.17 ms /    25 runs   (    0.41 ms per token,  2457.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     673.21 ms /    13 tokens (   51.79 ms per token,    19.31 tokens per second)\n",
      "llama_print_timings:        eval time =   16005.59 ms /    24 runs   (  666.90 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   16751.50 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.42 ms /    27 runs   (    0.42 ms per token,  2365.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.10 ms /    12 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   17245.08 ms /    26 runs   (  663.27 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17966.23 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.21 ms /    30 runs   (    0.41 ms per token,  2456.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.48 ms /    11 tokens (   54.32 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   19591.47 ms /    29 runs   (  675.57 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20276.15 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.76 ms /    29 runs   (    0.41 ms per token,  2467.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.97 ms /    12 tokens (   53.83 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   18687.61 ms /    28 runs   (  667.41 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19416.89 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.09 ms /    30 runs   (    0.40 ms per token,  2481.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.09 ms /    12 tokens (   53.34 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   19367.29 ms /    29 runs   (  667.84 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20094.20 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      34.59 ms /    84 runs   (    0.41 ms per token,  2428.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.23 ms /    13 tokens (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_print_timings:        eval time =   55775.64 ms /    83 runs   (  672.00 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   56703.41 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.78 ms /    34 runs   (    0.41 ms per token,  2467.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.51 ms /    12 tokens (   54.04 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   21965.22 ms /    33 runs   (  665.61 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22712.80 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      35.14 ms /    85 runs   (    0.41 ms per token,  2419.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     667.32 ms /    12 tokens (   55.61 ms per token,    17.98 tokens per second)\n",
      "llama_print_timings:        eval time =   56319.58 ms /    84 runs   (  670.47 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   57238.24 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.98 ms /    44 runs   (    0.41 ms per token,  2447.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.15 ms /    13 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   28677.33 ms /    43 runs   (  666.91 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   29493.73 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.03 ms /    34 runs   (    0.41 ms per token,  2423.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.06 ms /    12 tokens (   53.42 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   22052.72 ms /    33 runs   (  668.26 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22794.33 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.10 ms /    38 runs   (    0.40 ms per token,  2517.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.00 ms /    11 tokens (   54.00 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   24556.60 ms /    37 runs   (  663.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   25260.04 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.22 ms /    33 runs   (    0.40 ms per token,  2495.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.03 ms /    12 tokens (   52.50 ms per token,    19.05 tokens per second)\n",
      "llama_print_timings:        eval time =   21121.88 ms /    32 runs   (  660.06 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21846.23 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.04 ms /    24 runs   (    0.42 ms per token,  2391.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.36 ms /    12 tokens (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   15276.44 ms /    23 runs   (  664.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15986.39 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.27 ms /    30 runs   (    0.41 ms per token,  2444.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     706.32 ms /    13 tokens (   54.33 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   19494.22 ms /    29 runs   (  672.21 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20289.75 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.29 ms /    20 runs   (    0.41 ms per token,  2412.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     590.07 ms /    11 tokens (   53.64 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   12655.57 ms /    19 runs   (  666.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13304.18 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.77 ms /    29 runs   (    0.41 ms per token,  2464.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.27 ms /    12 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   18746.94 ms /    28 runs   (  669.53 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19466.91 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.74 ms /    29 runs   (    0.40 ms per token,  2469.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.70 ms /    12 tokens (   52.81 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   18663.82 ms /    28 runs   (  666.57 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19382.65 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.69 ms /    37 runs   (    0.40 ms per token,  2518.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.44 ms /    12 tokens (   54.29 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   24128.35 ms /    36 runs   (  670.23 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24886.19 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.71 ms /    34 runs   (    0.40 ms per token,  2479.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     596.37 ms /    11 tokens (   54.22 ms per token,    18.44 tokens per second)\n",
      "llama_print_timings:        eval time =   22156.15 ms /    33 runs   (  671.40 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22849.38 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.82 ms /    31 runs   (    0.41 ms per token,  2417.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.85 ms /    12 tokens (   53.49 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   20096.27 ms /    30 runs   (  669.88 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20828.87 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.18 ms /    23 runs   (    0.40 ms per token,  2505.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.70 ms /    11 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   14735.69 ms /    22 runs   (  669.80 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15395.45 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.83 ms /    37 runs   (    0.40 ms per token,  2494.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.38 ms /    12 tokens (   52.87 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   23963.54 ms /    36 runs   (  665.65 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   24706.52 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      29.09 ms /    69 runs   (    0.42 ms per token,  2371.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.61 ms /    13 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   45714.64 ms /    68 runs   (  672.27 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   46609.11 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.26 ms /    30 runs   (    0.41 ms per token,  2447.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.30 ms /    12 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   19337.13 ms /    29 runs   (  666.80 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20058.29 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.65 ms /    29 runs   (    0.40 ms per token,  2488.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.65 ms /    12 tokens (   53.22 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   18613.73 ms /    28 runs   (  664.78 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19337.29 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.79 ms /    24 runs   (    0.41 ms per token,  2450.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.06 ms /    12 tokens (   53.09 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   15407.69 ms /    23 runs   (  669.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16114.89 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.18 ms /    59 runs   (    0.41 ms per token,  2439.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.62 ms /    13 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   39212.06 ms /    58 runs   (  676.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   40074.02 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.60 ms /    47 runs   (    0.42 ms per token,  2397.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     665.37 ms /    12 tokens (   55.45 ms per token,    18.03 tokens per second)\n",
      "llama_print_timings:        eval time =   31001.37 ms /    46 runs   (  673.94 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   31804.95 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.59 ms /    41 runs   (    0.40 ms per token,  2472.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.63 ms /    12 tokens (   54.30 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   26673.12 ms /    40 runs   (  666.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   27444.76 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.16 ms /    25 runs   (    0.41 ms per token,  2459.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.56 ms /    13 tokens (   52.12 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:        eval time =   16065.83 ms /    24 runs   (  669.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16815.69 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      34.81 ms /    86 runs   (    0.40 ms per token,  2470.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.29 ms /    12 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   57631.24 ms /    85 runs   (  678.01 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   58516.23 ms /    97 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.47 ms /    57 runs   (    0.41 ms per token,  2428.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.03 ms /    11 tokens (   54.00 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   37915.82 ms /    56 runs   (  677.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   38676.98 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.24 ms /    40 runs   (    0.41 ms per token,  2463.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.59 ms /    12 tokens (   53.22 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   26211.46 ms /    39 runs   (  672.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   26966.59 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.67 ms /    69 runs   (    0.40 ms per token,  2493.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     732.34 ms /    14 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   45768.49 ms /    68 runs   (  673.07 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   46703.22 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      34.01 ms /    83 runs   (    0.41 ms per token,  2440.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.86 ms /    12 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   55455.32 ms /    82 runs   (  676.28 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   56340.31 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.76 ms /    29 runs   (    0.41 ms per token,  2465.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.89 ms /    12 tokens (   64.41 ms per token,    15.53 tokens per second)\n",
      "llama_print_timings:        eval time =   18592.89 ms /    28 runs   (  664.03 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19449.68 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.71 ms /    34 runs   (    0.40 ms per token,  2480.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.13 ms /    11 tokens (   53.56 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   22048.52 ms /    33 runs   (  668.14 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22736.36 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.61 ms /    67 runs   (    0.41 ms per token,  2427.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.39 ms /    12 tokens (   52.62 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   44214.30 ms /    66 runs   (  669.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   45042.70 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.24 ms /    45 runs   (    0.41 ms per token,  2467.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     634.29 ms /    12 tokens (   52.86 ms per token,    18.92 tokens per second)\n",
      "llama_print_timings:        eval time =   29023.34 ms /    44 runs   (  659.62 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   29788.35 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.50 ms /    57 runs   (    0.41 ms per token,  2425.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.79 ms /    13 tokens (   52.45 ms per token,    19.07 tokens per second)\n",
      "llama_print_timings:        eval time =   38088.61 ms /    56 runs   (  680.15 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   38939.75 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.72 ms /    29 runs   (    0.40 ms per token,  2473.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.52 ms /    12 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   18543.98 ms /    28 runs   (  662.28 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19266.61 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.96 ms /    30 runs   (    0.40 ms per token,  2509.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     588.82 ms /    11 tokens (   53.53 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =   19331.74 ms /    29 runs   (  666.61 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20006.65 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.32 ms /    20 runs   (    0.42 ms per token,  2402.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     753.08 ms /    12 tokens (   62.76 ms per token,    15.93 tokens per second)\n",
      "llama_print_timings:        eval time =   12705.24 ms /    19 runs   (  668.70 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13516.91 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.92 ms /    61 runs   (    0.41 ms per token,  2448.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.07 ms /    13 tokens (   53.31 ms per token,    18.76 tokens per second)\n",
      "llama_print_timings:        eval time =   40438.44 ms /    60 runs   (  673.97 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   41311.02 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.97 ms /    41 runs   (    0.41 ms per token,  2416.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.54 ms /    12 tokens (   53.88 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   26775.36 ms /    40 runs   (  669.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   27542.89 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.26 ms /    20 runs   (    0.41 ms per token,  2422.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.45 ms /    12 tokens (   53.04 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   12703.15 ms /    19 runs   (  668.59 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   13397.91 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      35.93 ms /    87 runs   (    0.41 ms per token,  2421.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.14 ms /    12 tokens (   53.68 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   57873.28 ms /    86 runs   (  672.95 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   58776.32 ms /    98 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      32.92 ms /    80 runs   (    0.41 ms per token,  2429.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.60 ms /    11 tokens (   54.15 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   53397.45 ms /    79 runs   (  675.92 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   54229.62 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.73 ms /    49 runs   (    0.40 ms per token,  2482.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.51 ms /    13 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   32275.80 ms /    48 runs   (  672.41 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   33102.12 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    19 runs   (    0.41 ms per token,  2417.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     674.73 ms /    12 tokens (   56.23 ms per token,    17.78 tokens per second)\n",
      "llama_print_timings:        eval time =   12064.60 ms /    18 runs   (  670.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   12794.69 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.09 ms /    30 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.87 ms /    12 tokens (   52.82 ms per token,    18.93 tokens per second)\n",
      "llama_print_timings:        eval time =   19265.94 ms /    29 runs   (  664.34 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19985.65 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.94 ms /    48 runs   (    0.42 ms per token,  2406.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     657.35 ms /    12 tokens (   54.78 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =   31259.95 ms /    47 runs   (  665.11 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   32059.47 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.18 ms /    22 runs   (    0.42 ms per token,  2397.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.00 ms /    13 tokens (   52.77 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   13951.59 ms /    21 runs   (  664.36 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   14701.36 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.93 ms /    56 runs   (    0.41 ms per token,  2441.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.46 ms /    11 tokens (   53.59 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   36938.87 ms /    55 runs   (  671.62 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   37692.32 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.53 ms /    57 runs   (    0.43 ms per token,  2324.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.97 ms /    12 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   37879.20 ms /    56 runs   (  676.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   38685.71 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.33 ms /    39 runs   (    0.42 ms per token,  2387.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.83 ms /    12 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   25333.53 ms /    38 runs   (  666.67 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   26093.28 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.68 ms /    29 runs   (    0.40 ms per token,  2483.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.93 ms /    12 tokens (   53.41 ms per token,    18.72 tokens per second)\n",
      "llama_print_timings:        eval time =   18616.51 ms /    28 runs   (  664.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   19342.45 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.25 ms /    65 runs   (    0.40 ms per token,  2476.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.14 ms /    13 tokens (   52.63 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   43175.93 ms /    64 runs   (  674.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   44051.02 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.72 ms /    51 runs   (    0.41 ms per token,  2461.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     630.79 ms /    12 tokens (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_print_timings:        eval time =   33066.82 ms /    50 runs   (  661.34 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   33847.12 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.96 ms /    32 runs   (    0.41 ms per token,  2469.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.59 ms /    12 tokens (   52.97 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   20434.53 ms /    31 runs   (  659.18 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21162.81 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.33 ms /    30 runs   (    0.41 ms per token,  2433.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     631.67 ms /    12 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   18963.65 ms /    29 runs   (  653.92 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   19682.80 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.08 ms /    30 runs   (    0.40 ms per token,  2482.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.26 ms /    12 tokens (   53.85 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   19135.80 ms /    29 runs   (  659.86 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   19868.64 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.88 ms /    49 runs   (    0.41 ms per token,  2464.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.19 ms /    12 tokens (   53.27 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   32007.64 ms /    48 runs   (  666.83 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   32791.65 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.57 ms /    67 runs   (    0.40 ms per token,  2522.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.24 ms /    12 tokens (   52.77 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   44248.15 ms /    66 runs   (  670.43 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   45076.05 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    19 runs   (    0.40 ms per token,  2482.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.25 ms /    12 tokens (   54.44 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   11956.66 ms /    18 runs   (  664.26 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   12665.49 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.40 ms /    45 runs   (    0.43 ms per token,  2319.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.75 ms /    11 tokens (   54.43 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   29392.16 ms /    44 runs   (  668.00 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   30130.01 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      30.58 ms /    76 runs   (    0.40 ms per token,  2485.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     690.77 ms /    13 tokens (   53.14 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   50511.37 ms /    75 runs   (  673.48 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   51427.15 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.50 ms /    34 runs   (    0.40 ms per token,  2517.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     658.61 ms /    12 tokens (   54.88 ms per token,    18.22 tokens per second)\n",
      "llama_print_timings:        eval time =   22055.14 ms /    33 runs   (  668.34 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   22812.55 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.10 ms /    49 runs   (    0.41 ms per token,  2438.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.73 ms /    12 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   32272.78 ms /    48 runs   (  672.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   33064.06 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.55 ms /    59 runs   (    0.47 ms per token,  2141.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     712.55 ms /    13 tokens (   54.81 ms per token,    18.24 tokens per second)\n",
      "llama_print_timings:        eval time =   40177.30 ms /    58 runs   (  692.71 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   41079.37 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      30.18 ms /    72 runs   (    0.42 ms per token,  2385.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     731.28 ms /    12 tokens (   60.94 ms per token,    16.41 tokens per second)\n",
      "llama_print_timings:        eval time =   48753.64 ms /    71 runs   (  686.67 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   49702.92 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.66 ms /    50 runs   (    0.43 ms per token,  2308.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     697.12 ms /    12 tokens (   58.09 ms per token,    17.21 tokens per second)\n",
      "llama_print_timings:        eval time =   35131.05 ms /    49 runs   (  716.96 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =   35983.34 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.80 ms /    53 runs   (    0.47 ms per token,  2137.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.81 ms /    12 tokens (   57.73 ms per token,    17.32 tokens per second)\n",
      "llama_print_timings:        eval time =   37499.94 ms /    52 runs   (  721.15 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =   38368.45 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.43 ms /    20 runs   (    0.42 ms per token,  2372.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     792.05 ms /    13 tokens (   60.93 ms per token,    16.41 tokens per second)\n",
      "llama_print_timings:        eval time =   13041.19 ms /    19 runs   (  686.38 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   13894.96 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.09 ms /    22 runs   (    0.46 ms per token,  2181.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     715.56 ms /    12 tokens (   59.63 ms per token,    16.77 tokens per second)\n",
      "llama_print_timings:        eval time =   14181.85 ms /    21 runs   (  675.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   14967.31 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.19 ms /    20 runs   (    0.41 ms per token,  2443.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     606.21 ms /    11 tokens (   55.11 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =   12557.24 ms /    19 runs   (  660.91 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   13223.20 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.16 ms /    20 runs   (    0.41 ms per token,  2450.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.97 ms /    12 tokens (   53.75 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   12831.55 ms /    19 runs   (  675.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   13535.24 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    20 runs   (    0.41 ms per token,  2435.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.99 ms /    12 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   12906.19 ms /    19 runs   (  679.27 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   13602.01 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.14 ms /    29 runs   (    0.42 ms per token,  2389.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.14 ms /    11 tokens (   54.10 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   19141.88 ms /    28 runs   (  683.64 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   19824.45 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.25 ms /    49 runs   (    0.41 ms per token,  2419.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.39 ms /    11 tokens (   62.94 ms per token,    15.89 tokens per second)\n",
      "llama_print_timings:        eval time =   33481.29 ms /    48 runs   (  697.53 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   34320.81 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.26 ms /    20 runs   (    0.41 ms per token,  2421.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     762.79 ms /    13 tokens (   58.68 ms per token,    17.04 tokens per second)\n",
      "llama_print_timings:        eval time =   13423.93 ms /    19 runs   (  706.52 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   14247.23 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.33 ms /    20 runs   (    0.42 ms per token,  2400.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     736.09 ms /    12 tokens (   61.34 ms per token,    16.30 tokens per second)\n",
      "llama_print_timings:        eval time =   13734.90 ms /    19 runs   (  722.89 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =   14532.31 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.83 ms /    32 runs   (    0.43 ms per token,  2313.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     919.63 ms /    12 tokens (   76.64 ms per token,    13.05 tokens per second)\n",
      "llama_print_timings:        eval time =   22548.54 ms /    31 runs   (  727.37 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =   23568.43 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.83 ms /    41 runs   (    0.43 ms per token,  2300.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     938.33 ms /    15 tokens (   62.56 ms per token,    15.99 tokens per second)\n",
      "llama_print_timings:        eval time =   28541.44 ms /    40 runs   (  713.54 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   29609.15 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.42 ms /    32 runs   (    0.48 ms per token,  2074.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.98 ms /    12 tokens (   60.75 ms per token,    16.46 tokens per second)\n",
      "llama_print_timings:        eval time =   21684.61 ms /    31 runs   (  699.50 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   22519.83 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.52 ms /    30 runs   (    0.45 ms per token,  2218.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     776.52 ms /    13 tokens (   59.73 ms per token,    16.74 tokens per second)\n",
      "llama_print_timings:        eval time =   19920.10 ms /    29 runs   (  686.90 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20793.42 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.06 ms /    32 runs   (    0.44 ms per token,  2276.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     739.24 ms /    12 tokens (   61.60 ms per token,    16.23 tokens per second)\n",
      "llama_print_timings:        eval time =   21637.87 ms /    31 runs   (  698.00 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   22478.31 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3500 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.15 ms /    29 runs   (    0.45 ms per token,  2205.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.52 ms /    12 tokens (   69.04 ms per token,    14.48 tokens per second)\n",
      "llama_print_timings:        eval time =   19633.59 ms /    28 runs   (  701.20 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   20555.95 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.38 ms /    32 runs   (    0.42 ms per token,  2391.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     765.99 ms /    12 tokens (   63.83 ms per token,    15.67 tokens per second)\n",
      "llama_print_timings:        eval time =   22165.03 ms /    31 runs   (  715.00 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   23030.96 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.59 ms /    30 runs   (    0.45 ms per token,  2207.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     818.61 ms /    13 tokens (   62.97 ms per token,    15.88 tokens per second)\n",
      "llama_print_timings:        eval time =   20720.94 ms /    29 runs   (  714.52 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   21635.36 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.19 ms /    32 runs   (    0.41 ms per token,  2425.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     746.43 ms /    12 tokens (   62.20 ms per token,    16.08 tokens per second)\n",
      "llama_print_timings:        eval time =   21920.66 ms /    31 runs   (  707.12 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   22764.09 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.83 ms /    32 runs   (    0.43 ms per token,  2313.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     666.80 ms /    12 tokens (   55.57 ms per token,    18.00 tokens per second)\n",
      "llama_print_timings:        eval time =   21428.75 ms /    31 runs   (  691.25 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   22198.38 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.16 ms /    32 runs   (    0.41 ms per token,  2431.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     842.65 ms /    12 tokens (   70.22 ms per token,    14.24 tokens per second)\n",
      "llama_print_timings:        eval time =   21938.56 ms /    31 runs   (  707.70 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   22880.10 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.77 ms /    23 runs   (    0.42 ms per token,  2354.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     731.22 ms /    13 tokens (   56.25 ms per token,    17.78 tokens per second)\n",
      "llama_print_timings:        eval time =   15359.72 ms /    22 runs   (  698.17 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   16160.57 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.54 ms /    30 runs   (    0.42 ms per token,  2393.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     666.04 ms /    12 tokens (   55.50 ms per token,    18.02 tokens per second)\n",
      "llama_print_timings:        eval time =   19737.18 ms /    29 runs   (  680.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20495.69 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.50 ms /    40 runs   (    0.44 ms per token,  2285.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.88 ms /    12 tokens (   55.32 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =   26465.89 ms /    39 runs   (  678.61 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   27257.56 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.86 ms /    42 runs   (    0.43 ms per token,  2352.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     774.75 ms /    13 tokens (   59.60 ms per token,    16.78 tokens per second)\n",
      "llama_print_timings:        eval time =   29251.71 ms /    41 runs   (  713.46 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   30156.88 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.23 ms /    37 runs   (    0.41 ms per token,  2429.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     669.98 ms /    12 tokens (   55.83 ms per token,    17.91 tokens per second)\n",
      "llama_print_timings:        eval time =   24870.88 ms /    36 runs   (  690.86 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   25655.95 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.93 ms /    30 runs   (    0.43 ms per token,  2320.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     676.30 ms /    11 tokens (   61.48 ms per token,    16.26 tokens per second)\n",
      "llama_print_timings:        eval time =   20967.40 ms /    29 runs   (  723.01 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =   21736.75 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.80 ms /    30 runs   (    0.43 ms per token,  2343.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     748.87 ms /    12 tokens (   62.41 ms per token,    16.02 tokens per second)\n",
      "llama_print_timings:        eval time =   20169.49 ms /    29 runs   (  695.50 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   21010.72 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      28.04 ms /    59 runs   (    0.48 ms per token,  2104.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.48 ms /    11 tokens (   58.41 ms per token,    17.12 tokens per second)\n",
      "llama_print_timings:        eval time =   40775.93 ms /    58 runs   (  703.03 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   41616.89 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.29 ms /    22 runs   (    0.42 ms per token,  2367.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     827.77 ms /    13 tokens (   63.67 ms per token,    15.70 tokens per second)\n",
      "llama_print_timings:        eval time =   14552.68 ms /    21 runs   (  692.98 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   15448.31 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.46 ms /    30 runs   (    0.42 ms per token,  2406.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     666.43 ms /    12 tokens (   55.54 ms per token,    18.01 tokens per second)\n",
      "llama_print_timings:        eval time =   20374.17 ms /    29 runs   (  702.56 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   21135.72 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.62 ms /    30 runs   (    0.42 ms per token,  2377.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     730.29 ms /    12 tokens (   60.86 ms per token,    16.43 tokens per second)\n",
      "llama_print_timings:        eval time =   20645.79 ms /    29 runs   (  711.92 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   21467.65 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.31 ms /    29 runs   (    0.42 ms per token,  2356.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     756.80 ms /    12 tokens (   63.07 ms per token,    15.86 tokens per second)\n",
      "llama_print_timings:        eval time =   19275.05 ms /    28 runs   (  688.39 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   20121.24 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.10 ms /    34 runs   (    0.41 ms per token,  2411.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     924.63 ms /    13 tokens (   71.13 ms per token,    14.06 tokens per second)\n",
      "llama_print_timings:        eval time =   22381.73 ms /    33 runs   (  678.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   23411.13 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.51 ms /    30 runs   (    0.42 ms per token,  2397.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     744.59 ms /    13 tokens (   57.28 ms per token,    17.46 tokens per second)\n",
      "llama_print_timings:        eval time =   19385.88 ms /    29 runs   (  668.48 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20222.63 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.62 ms /    30 runs   (    0.42 ms per token,  2376.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     660.93 ms /    11 tokens (   60.08 ms per token,    16.64 tokens per second)\n",
      "llama_print_timings:        eval time =   19952.71 ms /    29 runs   (  688.02 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   20705.24 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.12 ms /    31 runs   (    0.49 ms per token,  2049.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.11 ms /    11 tokens (   59.46 ms per token,    16.82 tokens per second)\n",
      "llama_print_timings:        eval time =   21690.62 ms /    30 runs   (  723.02 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =   22452.86 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.88 ms /    33 runs   (    0.42 ms per token,  2378.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     833.14 ms /    12 tokens (   69.43 ms per token,    14.40 tokens per second)\n",
      "llama_print_timings:        eval time =   22358.03 ms /    32 runs   (  698.69 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   23293.17 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.99 ms /    34 runs   (    0.41 ms per token,  2429.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.41 ms /    13 tokens (   59.42 ms per token,    16.83 tokens per second)\n",
      "llama_print_timings:        eval time =   22871.65 ms /    33 runs   (  693.08 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   23748.75 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.55 ms /    36 runs   (    0.40 ms per token,  2474.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.08 ms /    12 tokens (   56.92 ms per token,    17.57 tokens per second)\n",
      "llama_print_timings:        eval time =   23663.32 ms /    35 runs   (  676.09 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   24455.89 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.64 ms /    23 runs   (    0.42 ms per token,  2385.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     657.29 ms /    12 tokens (   54.77 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =   14728.92 ms /    22 runs   (  669.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   15456.39 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.79 ms /    21 runs   (    0.42 ms per token,  2389.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.27 ms /    12 tokens (   53.69 ms per token,    18.63 tokens per second)\n",
      "llama_print_timings:        eval time =   13673.87 ms /    20 runs   (  683.69 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   14382.14 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.15 ms /    21 runs   (    0.44 ms per token,  2296.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.03 ms /    13 tokens (   55.69 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:        eval time =   14166.14 ms /    20 runs   (  708.31 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   14955.18 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.50 ms /    20 runs   (    0.43 ms per token,  2352.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     665.93 ms /    12 tokens (   55.49 ms per token,    18.02 tokens per second)\n",
      "llama_print_timings:        eval time =   13368.36 ms /    19 runs   (  703.60 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   14095.91 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.07 ms /    30 runs   (    0.44 ms per token,  2294.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     757.78 ms /    12 tokens (   63.15 ms per token,    15.84 tokens per second)\n",
      "llama_print_timings:        eval time =   21281.24 ms /    29 runs   (  733.84 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =   22132.82 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.59 ms /    32 runs   (    0.46 ms per token,  2192.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     876.14 ms /    14 tokens (   62.58 ms per token,    15.98 tokens per second)\n",
      "llama_print_timings:        eval time =   22055.82 ms /    31 runs   (  711.48 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   23038.37 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.36 ms /    37 runs   (    0.44 ms per token,  2261.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     779.46 ms /    12 tokens (   64.96 ms per token,    15.40 tokens per second)\n",
      "llama_print_timings:        eval time =   25465.72 ms /    36 runs   (  707.38 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   26364.85 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.85 ms /    21 runs   (    0.42 ms per token,  2374.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.27 ms /    12 tokens (   58.19 ms per token,    17.19 tokens per second)\n",
      "llama_print_timings:        eval time =   13904.68 ms /    20 runs   (  695.23 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   14667.53 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.92 ms /    38 runs   (    0.42 ms per token,  2386.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.17 ms /    12 tokens (   57.76 ms per token,    17.31 tokens per second)\n",
      "llama_print_timings:        eval time =   25777.92 ms /    37 runs   (  696.70 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   26587.92 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.51 ms /    31 runs   (    0.40 ms per token,  2477.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     719.25 ms /    13 tokens (   55.33 ms per token,    18.07 tokens per second)\n",
      "llama_print_timings:        eval time =   20761.70 ms /    30 runs   (  692.06 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   21575.03 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.84 ms /    32 runs   (    0.40 ms per token,  2491.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.40 ms /    12 tokens (   53.78 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   20871.03 ms /    31 runs   (  673.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   21610.35 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.43 ms /    30 runs   (    0.41 ms per token,  2413.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.16 ms /    12 tokens (   54.01 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   19435.87 ms /    29 runs   (  670.20 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20173.54 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.22 ms /    32 runs   (    0.41 ms per token,  2421.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.38 ms /    12 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   21039.95 ms /    31 runs   (  678.71 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   21775.48 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.94 ms /    62 runs   (    0.42 ms per token,  2389.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     696.38 ms /    13 tokens (   53.57 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   41189.83 ms /    61 runs   (  675.24 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   42073.39 ms /    74 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.06 ms /    30 runs   (    0.40 ms per token,  2488.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.42 ms /    12 tokens (   54.28 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   19545.55 ms /    29 runs   (  673.98 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20286.98 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.32 ms /    30 runs   (    0.41 ms per token,  2435.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.65 ms /    12 tokens (   53.72 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   19232.43 ms /    29 runs   (  663.19 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19965.88 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.63 ms /    62 runs   (    0.41 ms per token,  2419.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.19 ms /    12 tokens (   53.27 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   41486.40 ms /    61 runs   (  680.10 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   42310.91 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.71 ms /    31 runs   (    0.41 ms per token,  2439.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.56 ms /    12 tokens (   54.05 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   19977.34 ms /    30 runs   (  665.91 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20719.15 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.28 ms /    30 runs   (    0.41 ms per token,  2442.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     670.13 ms /    12 tokens (   55.84 ms per token,    17.91 tokens per second)\n",
      "llama_print_timings:        eval time =   19226.38 ms /    29 runs   (  662.98 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19985.83 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.26 ms /    30 runs   (    0.41 ms per token,  2446.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     589.85 ms /    11 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   19177.75 ms /    29 runs   (  661.30 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19856.97 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.47 ms /    38 runs   (    0.41 ms per token,  2456.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.09 ms /    13 tokens (   52.93 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   24916.51 ms /    37 runs   (  673.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25716.48 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.02 ms /    30 runs   (    0.40 ms per token,  2496.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.40 ms /    12 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   19861.32 ms /    29 runs   (  684.87 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20592.64 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.17 ms /    30 runs   (    0.41 ms per token,  2464.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     708.68 ms /    11 tokens (   64.43 ms per token,    15.52 tokens per second)\n",
      "llama_print_timings:        eval time =   19377.94 ms /    29 runs   (  668.20 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20177.12 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.69 ms /    66 runs   (    0.42 ms per token,  2383.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.56 ms /    12 tokens (   54.05 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   43397.64 ms /    65 runs   (  667.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   44251.13 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.25 ms /    49 runs   (    0.41 ms per token,  2420.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.99 ms /    11 tokens (   53.91 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   32014.02 ms /    48 runs   (  666.96 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   32754.52 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.97 ms /    37 runs   (    0.40 ms per token,  2471.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     689.30 ms /    13 tokens (   53.02 ms per token,    18.86 tokens per second)\n",
      "llama_print_timings:        eval time =   24514.21 ms /    36 runs   (  680.95 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   25314.74 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.28 ms /    61 runs   (    0.41 ms per token,  2413.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     673.00 ms /    12 tokens (   56.08 ms per token,    17.83 tokens per second)\n",
      "llama_print_timings:        eval time =   41444.21 ms /    60 runs   (  690.74 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   42301.58 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.43 ms /    59 runs   (    0.41 ms per token,  2415.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.35 ms /    12 tokens (   53.70 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   39527.21 ms /    58 runs   (  681.50 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   40349.32 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.13 ms /    61 runs   (    0.41 ms per token,  2427.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     666.12 ms /    12 tokens (   55.51 ms per token,    18.01 tokens per second)\n",
      "llama_print_timings:        eval time =   40205.45 ms /    60 runs   (  670.09 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   41052.89 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.07 ms /    37 runs   (    0.41 ms per token,  2454.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     668.97 ms /    12 tokens (   55.75 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =   24203.12 ms /    36 runs   (  672.31 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24985.41 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.03 ms /    61 runs   (    0.41 ms per token,  2436.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.59 ms /    12 tokens (   53.72 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   40723.25 ms /    60 runs   (  678.72 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   41552.19 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.49 ms /    61 runs   (    0.42 ms per token,  2392.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.36 ms /    12 tokens (   54.28 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   40488.02 ms /    60 runs   (  674.80 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   41324.17 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.71 ms /    30 runs   (    0.42 ms per token,  2360.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.75 ms /    13 tokens (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:        eval time =   19398.27 ms /    29 runs   (  668.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20174.72 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.36 ms /    67 runs   (    0.41 ms per token,  2448.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     624.96 ms /    11 tokens (   56.81 ms per token,    17.60 tokens per second)\n",
      "llama_print_timings:        eval time =   45143.47 ms /    66 runs   (  683.99 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   45973.39 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.97 ms /    30 runs   (    0.40 ms per token,  2505.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     670.10 ms /    12 tokens (   55.84 ms per token,    17.91 tokens per second)\n",
      "llama_print_timings:        eval time =   19877.26 ms /    29 runs   (  685.42 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20636.50 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.29 ms /    30 runs   (    0.41 ms per token,  2440.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.33 ms /    12 tokens (   54.11 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   19849.25 ms /    29 runs   (  684.46 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20588.51 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.86 ms /    66 runs   (    0.41 ms per token,  2457.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.10 ms /    12 tokens (   54.59 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   44190.68 ms /    65 runs   (  679.86 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   45043.23 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.44 ms /    52 runs   (    0.41 ms per token,  2425.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     608.21 ms /    11 tokens (   55.29 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =   34457.17 ms /    51 runs   (  675.63 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   35220.22 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.83 ms /    55 runs   (    0.42 ms per token,  2409.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     739.26 ms /    12 tokens (   61.60 ms per token,    16.23 tokens per second)\n",
      "llama_print_timings:        eval time =   36277.44 ms /    54 runs   (  671.80 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   37182.25 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.82 ms /    29 runs   (    0.41 ms per token,  2452.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.80 ms /    12 tokens (   53.07 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:        eval time =   18996.84 ms /    28 runs   (  678.46 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19718.58 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.16 ms /    30 runs   (    0.41 ms per token,  2466.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.98 ms /    13 tokens (   53.38 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   19593.59 ms /    29 runs   (  675.64 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20375.41 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.46 ms /    30 runs   (    0.42 ms per token,  2407.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.95 ms /    12 tokens (   53.58 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   19357.55 ms /    29 runs   (  667.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20093.11 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.19 ms /    61 runs   (    0.41 ms per token,  2421.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.64 ms /    12 tokens (   53.22 ms per token,    18.79 tokens per second)\n",
      "llama_print_timings:        eval time =   40770.11 ms /    60 runs   (  679.50 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   41591.56 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.70 ms /    66 runs   (    0.40 ms per token,  2471.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.03 ms /    12 tokens (   57.09 ms per token,    17.52 tokens per second)\n",
      "llama_print_timings:        eval time =   43764.29 ms /    65 runs   (  673.30 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   44646.73 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.25 ms /    67 runs   (    0.41 ms per token,  2458.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.94 ms /    13 tokens (   52.61 ms per token,    19.01 tokens per second)\n",
      "llama_print_timings:        eval time =   44943.56 ms /    66 runs   (  680.96 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   45828.20 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.10 ms /    30 runs   (    0.40 ms per token,  2480.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     662.74 ms /    12 tokens (   55.23 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =   19725.47 ms /    29 runs   (  680.19 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20478.59 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.31 ms /    30 runs   (    0.41 ms per token,  2436.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.12 ms /    12 tokens (   53.93 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   19568.38 ms /    29 runs   (  674.77 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20305.62 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.79 ms /    30 runs   (    0.43 ms per token,  2346.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.19 ms /    12 tokens (   53.35 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   20700.50 ms /    29 runs   (  713.81 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   21438.21 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.82 ms /    31 runs   (    0.45 ms per token,  2243.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     840.45 ms /    12 tokens (   70.04 ms per token,    14.28 tokens per second)\n",
      "llama_print_timings:        eval time =   21337.69 ms /    30 runs   (  711.26 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   22276.11 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.75 ms /    39 runs   (    0.43 ms per token,  2327.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     632.35 ms /    11 tokens (   57.49 ms per token,    17.40 tokens per second)\n",
      "llama_print_timings:        eval time =   27163.40 ms /    38 runs   (  714.83 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   27919.49 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      35.29 ms /    83 runs   (    0.43 ms per token,  2351.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     717.05 ms /    11 tokens (   65.19 ms per token,    15.34 tokens per second)\n",
      "llama_print_timings:        eval time =   59377.55 ms /    82 runs   (  724.12 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =   60352.26 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.42 ms /    37 runs   (    0.42 ms per token,  2399.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.12 ms /    12 tokens (   56.59 ms per token,    17.67 tokens per second)\n",
      "llama_print_timings:        eval time =   24925.19 ms /    36 runs   (  692.37 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   25719.48 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.14 ms /    29 runs   (    0.42 ms per token,  2388.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     704.60 ms /    12 tokens (   58.72 ms per token,    17.03 tokens per second)\n",
      "llama_print_timings:        eval time =   19443.09 ms /    28 runs   (  694.40 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   20238.36 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.48 ms /    38 runs   (    0.41 ms per token,  2455.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     854.57 ms /    13 tokens (   65.74 ms per token,    15.21 tokens per second)\n",
      "llama_print_timings:        eval time =   25359.88 ms /    37 runs   (  685.40 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   26328.02 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      42.51 ms /   101 runs   (    0.42 ms per token,  2376.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     798.44 ms /    12 tokens (   66.54 ms per token,    15.03 tokens per second)\n",
      "llama_print_timings:        eval time =   68449.82 ms /   100 runs   (  684.50 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   69561.55 ms /   112 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.69 ms /    36 runs   (    0.41 ms per token,  2450.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.07 ms /    12 tokens (   53.51 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   23882.39 ms /    35 runs   (  682.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   24633.25 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.71 ms /    31 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     629.90 ms /    11 tokens (   57.26 ms per token,    17.46 tokens per second)\n",
      "llama_print_timings:        eval time =   20423.91 ms /    30 runs   (  680.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   21147.31 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.72 ms /    61 runs   (    0.45 ms per token,  2200.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.99 ms /    12 tokens (   56.50 ms per token,    17.70 tokens per second)\n",
      "llama_print_timings:        eval time =   42622.42 ms /    60 runs   (  710.37 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   43502.94 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.50 ms /    66 runs   (    0.42 ms per token,  2400.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     690.78 ms /    11 tokens (   62.80 ms per token,    15.92 tokens per second)\n",
      "llama_print_timings:        eval time =   44894.94 ms /    65 runs   (  690.69 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   45790.61 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.31 ms /    30 runs   (    0.44 ms per token,  2254.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     615.44 ms /    11 tokens (   55.95 ms per token,    17.87 tokens per second)\n",
      "llama_print_timings:        eval time =   21236.35 ms /    29 runs   (  732.29 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =   21946.56 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.59 ms /    30 runs   (    0.42 ms per token,  2382.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     828.36 ms /    12 tokens (   69.03 ms per token,    14.49 tokens per second)\n",
      "llama_print_timings:        eval time =   20195.76 ms /    29 runs   (  696.41 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   21114.79 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.78 ms /    23 runs   (    0.43 ms per token,  2352.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.63 ms /    13 tokens (   60.05 ms per token,    16.65 tokens per second)\n",
      "llama_print_timings:        eval time =   15487.79 ms /    22 runs   (  703.99 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   16337.88 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.41 ms /    66 runs   (    0.42 ms per token,  2408.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.30 ms /    12 tokens (   55.28 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =   44758.26 ms /    65 runs   (  688.59 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   45622.02 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.11 ms /    24 runs   (    0.42 ms per token,  2374.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     667.61 ms /    12 tokens (   55.63 ms per token,    17.97 tokens per second)\n",
      "llama_print_timings:        eval time =   16361.54 ms /    23 runs   (  711.37 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   17103.27 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.66 ms /    59 runs   (    0.42 ms per token,  2392.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     712.06 ms /    12 tokens (   59.34 ms per token,    16.85 tokens per second)\n",
      "llama_print_timings:        eval time =   40361.33 ms /    58 runs   (  695.89 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   41252.45 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.25 ms /    30 runs   (    0.44 ms per token,  2263.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     787.87 ms /    11 tokens (   71.62 ms per token,    13.96 tokens per second)\n",
      "llama_print_timings:        eval time =   19818.23 ms /    29 runs   (  683.39 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20700.67 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.41 ms /    46 runs   (    0.42 ms per token,  2369.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     747.21 ms /    14 tokens (   53.37 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   30754.60 ms /    45 runs   (  683.44 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   31642.64 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.43 ms /    37 runs   (    0.44 ms per token,  2251.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     702.09 ms /    11 tokens (   63.83 ms per token,    15.67 tokens per second)\n",
      "llama_print_timings:        eval time =   25542.36 ms /    36 runs   (  709.51 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   26364.03 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.44 ms /    38 runs   (    0.41 ms per token,  2460.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     674.10 ms /    12 tokens (   56.17 ms per token,    17.80 tokens per second)\n",
      "llama_print_timings:        eval time =   25228.54 ms /    37 runs   (  681.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   26018.13 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.43 ms /    20 runs   (    0.42 ms per token,  2371.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     717.01 ms /    13 tokens (   55.15 ms per token,    18.13 tokens per second)\n",
      "llama_print_timings:        eval time =   12768.58 ms /    19 runs   (  672.03 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13546.94 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.12 ms /    32 runs   (    0.41 ms per token,  2439.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     690.90 ms /    12 tokens (   57.58 ms per token,    17.37 tokens per second)\n",
      "llama_print_timings:        eval time =   20573.69 ms /    31 runs   (  663.67 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   21361.87 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.71 ms /    52 runs   (    0.48 ms per token,  2104.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     743.58 ms /    12 tokens (   61.97 ms per token,    16.14 tokens per second)\n",
      "llama_print_timings:        eval time =   35092.12 ms /    51 runs   (  688.08 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   36006.58 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.12 ms /    32 runs   (    0.41 ms per token,  2438.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     709.64 ms /    12 tokens (   59.14 ms per token,    16.91 tokens per second)\n",
      "llama_print_timings:        eval time =   21100.67 ms /    31 runs   (  680.67 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   21908.10 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.09 ms /    50 runs   (    0.42 ms per token,  2371.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.52 ms /    12 tokens (   56.63 ms per token,    17.66 tokens per second)\n",
      "llama_print_timings:        eval time =   33651.99 ms /    49 runs   (  686.78 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   34486.22 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.21 ms /    32 runs   (    0.41 ms per token,  2421.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     669.07 ms /    12 tokens (   55.76 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =   21655.89 ms /    31 runs   (  698.58 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   22422.72 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3600 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.37 ms /    32 runs   (    0.42 ms per token,  2394.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     772.49 ms /    13 tokens (   59.42 ms per token,    16.83 tokens per second)\n",
      "llama_print_timings:        eval time =   21543.33 ms /    31 runs   (  694.95 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   22415.69 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.79 ms /    32 runs   (    0.43 ms per token,  2320.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.13 ms /    12 tokens (   54.34 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   21249.04 ms /    31 runs   (  685.45 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   22003.92 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.23 ms /    32 runs   (    0.41 ms per token,  2419.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.45 ms /    12 tokens (   54.54 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   20704.16 ms /    31 runs   (  667.88 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21455.71 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.65 ms /    31 runs   (    0.41 ms per token,  2451.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     610.00 ms /    11 tokens (   55.45 ms per token,    18.03 tokens per second)\n",
      "llama_print_timings:        eval time =   20595.79 ms /    30 runs   (  686.53 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   21299.43 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.57 ms /    30 runs   (    0.42 ms per token,  2387.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     702.09 ms /    13 tokens (   54.01 ms per token,    18.52 tokens per second)\n",
      "llama_print_timings:        eval time =   20045.77 ms /    29 runs   (  691.23 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   20837.76 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.55 ms /    30 runs   (    0.45 ms per token,  2214.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     725.54 ms /    12 tokens (   60.46 ms per token,    16.54 tokens per second)\n",
      "llama_print_timings:        eval time =   19957.56 ms /    29 runs   (  688.19 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   20781.04 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.84 ms /    66 runs   (    0.42 ms per token,  2371.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     752.75 ms /    12 tokens (   62.73 ms per token,    15.94 tokens per second)\n",
      "llama_print_timings:        eval time =   45132.76 ms /    65 runs   (  694.35 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   46087.90 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.48 ms /    30 runs   (    0.42 ms per token,  2404.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     699.86 ms /    12 tokens (   58.32 ms per token,    17.15 tokens per second)\n",
      "llama_print_timings:        eval time =   19357.50 ms /    29 runs   (  667.50 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20150.09 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.50 ms /    30 runs   (    0.42 ms per token,  2399.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.73 ms /    12 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   19456.18 ms /    29 runs   (  670.90 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20188.32 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.81 ms /    45 runs   (    0.42 ms per token,  2392.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.21 ms /    13 tokens (   52.63 ms per token,    19.00 tokens per second)\n",
      "llama_print_timings:        eval time =   30023.61 ms /    44 runs   (  682.35 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   30844.98 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.79 ms /    30 runs   (    0.46 ms per token,  2175.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     658.38 ms /    12 tokens (   54.87 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =   20478.92 ms /    29 runs   (  706.17 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   21230.54 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.88 ms /    30 runs   (    0.43 ms per token,  2329.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     761.58 ms /    12 tokens (   63.46 ms per token,    15.76 tokens per second)\n",
      "llama_print_timings:        eval time =   20275.76 ms /    29 runs   (  699.16 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   21130.83 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.48 ms /    33 runs   (    0.41 ms per token,  2447.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     756.69 ms /    13 tokens (   58.21 ms per token,    17.18 tokens per second)\n",
      "llama_print_timings:        eval time =   22066.20 ms /    32 runs   (  689.57 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   22924.37 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.28 ms /    30 runs   (    0.41 ms per token,  2443.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     606.22 ms /    11 tokens (   55.11 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =   19812.63 ms /    29 runs   (  683.19 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20510.32 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.63 ms /    30 runs   (    0.42 ms per token,  2376.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     817.48 ms /    12 tokens (   68.12 ms per token,    14.68 tokens per second)\n",
      "llama_print_timings:        eval time =   20428.36 ms /    29 runs   (  704.43 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   21339.34 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.62 ms /    30 runs   (    0.42 ms per token,  2378.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     661.17 ms /    12 tokens (   55.10 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =   20286.01 ms /    29 runs   (  699.52 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   21039.62 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.69 ms /    30 runs   (    0.42 ms per token,  2365.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.19 ms /    12 tokens (   57.35 ms per token,    17.44 tokens per second)\n",
      "llama_print_timings:        eval time =   20405.99 ms /    29 runs   (  703.65 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   21187.48 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.06 ms /    39 runs   (    0.41 ms per token,  2428.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     737.23 ms /    12 tokens (   61.44 ms per token,    16.28 tokens per second)\n",
      "llama_print_timings:        eval time =   26809.49 ms /    38 runs   (  705.51 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   27666.93 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.58 ms /    30 runs   (    0.42 ms per token,  2385.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     694.65 ms /    12 tokens (   57.89 ms per token,    17.27 tokens per second)\n",
      "llama_print_timings:        eval time =   20042.27 ms /    29 runs   (  691.11 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   20827.33 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.39 ms /    30 runs   (    0.41 ms per token,  2420.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     633.15 ms /    11 tokens (   57.56 ms per token,    17.37 tokens per second)\n",
      "llama_print_timings:        eval time =   19802.71 ms /    29 runs   (  682.85 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20526.19 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.59 ms /    33 runs   (    0.41 ms per token,  2427.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.36 ms /    13 tokens (   53.26 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   21830.51 ms /    32 runs   (  682.20 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22623.08 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.22 ms /    32 runs   (    0.41 ms per token,  2420.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.43 ms /    11 tokens (   59.49 ms per token,    16.81 tokens per second)\n",
      "llama_print_timings:        eval time =   21036.80 ms /    31 runs   (  678.61 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   21788.73 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.42 ms /    30 runs   (    0.41 ms per token,  2416.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.29 ms /    12 tokens (   54.94 ms per token,    18.20 tokens per second)\n",
      "llama_print_timings:        eval time =   19667.32 ms /    29 runs   (  678.18 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20417.24 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.39 ms /    30 runs   (    0.41 ms per token,  2420.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     700.08 ms /    12 tokens (   58.34 ms per token,    17.14 tokens per second)\n",
      "llama_print_timings:        eval time =   19664.05 ms /    29 runs   (  678.07 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20455.71 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.98 ms /    41 runs   (    0.41 ms per token,  2413.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.89 ms /    11 tokens (   58.08 ms per token,    17.22 tokens per second)\n",
      "llama_print_timings:        eval time =   27104.34 ms /    40 runs   (  677.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   27868.12 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.59 ms /    30 runs   (    0.42 ms per token,  2382.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     722.40 ms /    13 tokens (   55.57 ms per token,    18.00 tokens per second)\n",
      "llama_print_timings:        eval time =   20696.51 ms /    29 runs   (  713.67 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   21511.58 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.43 ms /    30 runs   (    0.41 ms per token,  2412.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.97 ms /    11 tokens (   58.27 ms per token,    17.16 tokens per second)\n",
      "llama_print_timings:        eval time =   19896.29 ms /    29 runs   (  686.08 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20626.62 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.69 ms /    30 runs   (    0.42 ms per token,  2365.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     614.97 ms /    11 tokens (   55.91 ms per token,    17.89 tokens per second)\n",
      "llama_print_timings:        eval time =   20585.16 ms /    29 runs   (  709.83 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   21291.67 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.55 ms /    30 runs   (    0.42 ms per token,  2389.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     723.46 ms /    12 tokens (   60.29 ms per token,    16.59 tokens per second)\n",
      "llama_print_timings:        eval time =   19642.44 ms /    29 runs   (  677.33 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20456.92 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.35 ms /    23 runs   (    0.41 ms per token,  2459.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.79 ms /    12 tokens (   57.07 ms per token,    17.52 tokens per second)\n",
      "llama_print_timings:        eval time =   15201.32 ms /    22 runs   (  690.97 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   15956.90 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.95 ms /    50 runs   (    0.42 ms per token,  2387.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     694.94 ms /    13 tokens (   53.46 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   33258.80 ms /    49 runs   (  678.75 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   34107.06 ms /    62 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      61.77 ms /   146 runs   (    0.42 ms per token,  2363.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.85 ms /    12 tokens (   54.49 ms per token,    18.35 tokens per second)\n",
      "llama_print_timings:        eval time =   99249.53 ms /   145 runs   (  684.48 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =  100358.70 ms /   157 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.19 ms /    55 runs   (    0.42 ms per token,  2371.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     706.30 ms /    12 tokens (   58.86 ms per token,    16.99 tokens per second)\n",
      "llama_print_timings:        eval time =   36890.08 ms /    54 runs   (  683.15 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   37763.84 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.44 ms /    45 runs   (    0.43 ms per token,  2314.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     721.38 ms /    12 tokens (   60.11 ms per token,    16.63 tokens per second)\n",
      "llama_print_timings:        eval time =   30521.49 ms /    44 runs   (  693.67 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   31382.68 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.32 ms /    62 runs   (    0.42 ms per token,  2355.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.48 ms /    11 tokens (   61.59 ms per token,    16.24 tokens per second)\n",
      "llama_print_timings:        eval time =   41945.55 ms /    61 runs   (  687.63 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   42815.51 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.48 ms /    30 runs   (    0.42 ms per token,  2403.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.08 ms /    12 tokens (   54.59 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   20159.24 ms /    29 runs   (  695.15 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   20906.45 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.42 ms /    30 runs   (    0.41 ms per token,  2415.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     705.74 ms /    13 tokens (   54.29 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   20107.83 ms /    29 runs   (  693.37 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   20904.89 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.39 ms /    30 runs   (    0.41 ms per token,  2420.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     667.18 ms /    12 tokens (   55.60 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =   19758.95 ms /    29 runs   (  681.34 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20517.36 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.52 ms /    30 runs   (    0.42 ms per token,  2395.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     690.41 ms /    12 tokens (   57.53 ms per token,    17.38 tokens per second)\n",
      "llama_print_timings:        eval time =   20130.51 ms /    29 runs   (  694.16 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   20912.96 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.53 ms /    30 runs   (    0.42 ms per token,  2395.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.38 ms /    11 tokens (   54.40 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   19556.98 ms /    29 runs   (  674.38 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20246.94 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.13 ms /    30 runs   (    0.40 ms per token,  2473.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.80 ms /    12 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   19553.10 ms /    29 runs   (  674.24 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20289.14 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.52 ms /    30 runs   (    0.42 ms per token,  2396.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.52 ms /    12 tokens (   53.04 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:        eval time =   20368.70 ms /    29 runs   (  702.37 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   21098.89 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.62 ms /    30 runs   (    0.42 ms per token,  2376.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     967.10 ms /    14 tokens (   69.08 ms per token,    14.48 tokens per second)\n",
      "llama_print_timings:        eval time =   20149.68 ms /    29 runs   (  694.82 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   21208.71 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.95 ms /    34 runs   (    0.41 ms per token,  2438.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.41 ms /    12 tokens (   56.62 ms per token,    17.66 tokens per second)\n",
      "llama_print_timings:        eval time =   22577.01 ms /    33 runs   (  684.15 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   23361.52 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.70 ms /    54 runs   (    0.44 ms per token,  2278.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.19 ms /    12 tokens (   54.60 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   36804.97 ms /    53 runs   (  694.43 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   37629.65 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.53 ms /    30 runs   (    0.42 ms per token,  2395.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     863.23 ms /    13 tokens (   66.40 ms per token,    15.06 tokens per second)\n",
      "llama_print_timings:        eval time =   19860.19 ms /    29 runs   (  684.83 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20814.63 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.95 ms /    35 runs   (    0.43 ms per token,  2340.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     601.30 ms /    11 tokens (   54.66 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:        eval time =   22777.55 ms /    34 runs   (  669.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   23488.97 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.53 ms /    30 runs   (    0.42 ms per token,  2394.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.83 ms /    12 tokens (   54.40 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   19705.26 ms /    29 runs   (  679.49 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20450.97 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.00 ms /    30 runs   (    0.43 ms per token,  2308.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     711.79 ms /    12 tokens (   59.32 ms per token,    16.86 tokens per second)\n",
      "llama_print_timings:        eval time =   20866.26 ms /    29 runs   (  719.53 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =   21671.77 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.37 ms /    30 runs   (    0.41 ms per token,  2424.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     689.35 ms /    12 tokens (   57.45 ms per token,    17.41 tokens per second)\n",
      "llama_print_timings:        eval time =   20029.66 ms /    29 runs   (  690.68 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   20809.98 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.39 ms /    33 runs   (    0.41 ms per token,  2463.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     709.29 ms /    13 tokens (   54.56 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   21713.16 ms /    32 runs   (  678.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22521.14 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.33 ms /    58 runs   (    0.42 ms per token,  2383.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.17 ms /    12 tokens (   54.60 ms per token,    18.32 tokens per second)\n",
      "llama_print_timings:        eval time =   39456.52 ms /    57 runs   (  692.22 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   40288.54 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.27 ms /    30 runs   (    0.41 ms per token,  2445.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.21 ms /    13 tokens (   53.32 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:        eval time =   20543.31 ms /    29 runs   (  708.39 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   21327.43 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.72 ms /    28 runs   (    0.42 ms per token,  2388.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.63 ms /    12 tokens (   54.30 ms per token,    18.42 tokens per second)\n",
      "llama_print_timings:        eval time =   18280.76 ms /    27 runs   (  677.07 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19016.61 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.25 ms /    30 runs   (    0.41 ms per token,  2448.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.52 ms /    12 tokens (   53.88 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   19538.23 ms /    29 runs   (  673.73 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20274.65 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.08 ms /    37 runs   (    0.41 ms per token,  2453.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     623.12 ms /    11 tokens (   56.65 ms per token,    17.65 tokens per second)\n",
      "llama_print_timings:        eval time =   24572.48 ms /    36 runs   (  682.57 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   25305.42 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.60 ms /    67 runs   (    0.41 ms per token,  2427.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.13 ms /    12 tokens (   56.43 ms per token,    17.72 tokens per second)\n",
      "llama_print_timings:        eval time =   45470.36 ms /    66 runs   (  688.94 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   46354.71 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.47 ms /    30 runs   (    0.42 ms per token,  2405.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     660.13 ms /    12 tokens (   55.01 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =   19549.49 ms /    29 runs   (  674.12 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20300.61 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.16 ms /    29 runs   (    0.42 ms per token,  2385.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.02 ms /    13 tokens (   56.00 ms per token,    17.86 tokens per second)\n",
      "llama_print_timings:        eval time =   19084.54 ms /    28 runs   (  681.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19901.95 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.39 ms /    30 runs   (    0.41 ms per token,  2422.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     697.43 ms /    12 tokens (   58.12 ms per token,    17.21 tokens per second)\n",
      "llama_print_timings:        eval time =   19980.69 ms /    29 runs   (  688.99 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   20768.45 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.59 ms /    23 runs   (    0.42 ms per token,  2398.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.38 ms /    12 tokens (   53.28 ms per token,    18.77 tokens per second)\n",
      "llama_print_timings:        eval time =   14600.08 ms /    22 runs   (  663.64 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   15307.23 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.36 ms /    27 runs   (    0.42 ms per token,  2376.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     667.15 ms /    12 tokens (   55.60 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =   17791.41 ms /    26 runs   (  684.28 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   18540.59 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.73 ms /    57 runs   (    0.42 ms per token,  2402.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     697.74 ms /    12 tokens (   58.14 ms per token,    17.20 tokens per second)\n",
      "llama_print_timings:        eval time =   37620.62 ms /    56 runs   (  671.80 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   38492.99 ms /    68 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.47 ms /    20 runs   (    0.42 ms per token,  2360.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     651.24 ms /    11 tokens (   59.20 ms per token,    16.89 tokens per second)\n",
      "llama_print_timings:        eval time =   12709.66 ms /    19 runs   (  668.93 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   13422.14 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.32 ms /    30 runs   (    0.41 ms per token,  2434.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     815.63 ms /    13 tokens (   62.74 ms per token,    15.94 tokens per second)\n",
      "llama_print_timings:        eval time =   19563.75 ms /    29 runs   (  674.61 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20469.28 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.18 ms /    30 runs   (    0.41 ms per token,  2464.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.65 ms /    12 tokens (   54.14 ms per token,    18.47 tokens per second)\n",
      "llama_print_timings:        eval time =   19729.33 ms /    29 runs   (  680.32 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20468.41 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.39 ms /    30 runs   (    0.41 ms per token,  2422.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.24 ms /    12 tokens (   53.19 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   19950.93 ms /    29 runs   (  687.96 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   20680.30 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.20 ms /    30 runs   (    0.41 ms per token,  2459.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     718.37 ms /    12 tokens (   59.86 ms per token,    16.70 tokens per second)\n",
      "llama_print_timings:        eval time =   19441.14 ms /    29 runs   (  670.38 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20252.29 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      26.64 ms /    64 runs   (    0.42 ms per token,  2402.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     728.45 ms /    13 tokens (   56.03 ms per token,    17.85 tokens per second)\n",
      "llama_print_timings:        eval time =   43489.32 ms /    63 runs   (  690.31 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   44414.32 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.84 ms /    50 runs   (    0.42 ms per token,  2399.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.19 ms /    12 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   33275.10 ms /    49 runs   (  679.08 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   34074.15 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.22 ms /    50 runs   (    0.42 ms per token,  2356.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.38 ms /    12 tokens (   53.95 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   34050.69 ms /    49 runs   (  694.91 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   34853.59 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.22 ms /    30 runs   (    0.41 ms per token,  2455.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     607.99 ms /    11 tokens (   55.27 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =   19658.04 ms /    29 runs   (  677.86 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20358.35 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      44.58 ms /   106 runs   (    0.42 ms per token,  2377.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     677.19 ms /    12 tokens (   56.43 ms per token,    17.72 tokens per second)\n",
      "llama_print_timings:        eval time =   73122.81 ms /   105 runs   (  696.41 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   74127.72 ms /   117 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.29 ms /    30 runs   (    0.41 ms per token,  2441.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     691.40 ms /    13 tokens (   53.18 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:        eval time =   20044.01 ms /    29 runs   (  691.17 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   20826.98 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.21 ms /    21 runs   (    0.44 ms per token,  2281.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     615.31 ms /    11 tokens (   55.94 ms per token,    17.88 tokens per second)\n",
      "llama_print_timings:        eval time =   13412.13 ms /    20 runs   (  670.61 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14094.40 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.84 ms /    67 runs   (    0.42 ms per token,  2406.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.64 ms /    11 tokens (   58.42 ms per token,    17.12 tokens per second)\n",
      "llama_print_timings:        eval time =   44390.68 ms /    66 runs   (  672.59 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   45239.71 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.05 ms /    30 runs   (    0.40 ms per token,  2490.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     783.00 ms /    12 tokens (   65.25 ms per token,    15.33 tokens per second)\n",
      "llama_print_timings:        eval time =   19405.35 ms /    29 runs   (  669.15 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20280.76 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      16.41 ms /    40 runs   (    0.41 ms per token,  2436.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.53 ms /    12 tokens (   57.71 ms per token,    17.33 tokens per second)\n",
      "llama_print_timings:        eval time =   26639.48 ms /    39 runs   (  683.06 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   27452.33 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.55 ms /    28 runs   (    0.41 ms per token,  2423.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.75 ms /    12 tokens (   54.65 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =   18446.51 ms /    27 runs   (  683.20 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   19187.20 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.72 ms /    47 runs   (    0.42 ms per token,  2383.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     715.15 ms /    13 tokens (   55.01 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =   31248.87 ms /    46 runs   (  679.32 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   32105.87 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.40 ms /    30 runs   (    0.41 ms per token,  2418.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.55 ms /    12 tokens (   54.55 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   19416.16 ms /    29 runs   (  669.52 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20162.56 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.12 ms /    21 runs   (    0.43 ms per token,  2301.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.34 ms /    12 tokens (   54.53 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   13404.80 ms /    20 runs   (  670.24 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   14123.24 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      28.86 ms /    68 runs   (    0.42 ms per token,  2356.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     621.24 ms /    11 tokens (   56.48 ms per token,    17.71 tokens per second)\n",
      "llama_print_timings:        eval time =   45808.00 ms /    67 runs   (  683.70 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   46642.28 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.27 ms /    33 runs   (    0.40 ms per token,  2486.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.67 ms /    12 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   21096.83 ms /    32 runs   (  659.28 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =   21842.99 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.52 ms /    30 runs   (    0.42 ms per token,  2396.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     602.70 ms /    11 tokens (   54.79 ms per token,    18.25 tokens per second)\n",
      "llama_print_timings:        eval time =   19627.61 ms /    29 runs   (  676.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20322.50 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.35 ms /    30 runs   (    0.41 ms per token,  2428.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.51 ms /    11 tokens (   54.32 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   20161.51 ms /    29 runs   (  695.22 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   20850.13 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.46 ms /    38 runs   (    0.41 ms per token,  2457.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.39 ms /    12 tokens (   54.53 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   25462.85 ms /    37 runs   (  688.19 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   26232.58 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.68 ms /    38 runs   (    0.41 ms per token,  2423.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     625.81 ms /    11 tokens (   56.89 ms per token,    17.58 tokens per second)\n",
      "llama_print_timings:        eval time =   25873.86 ms /    37 runs   (  699.29 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   26616.74 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.34 ms /    38 runs   (    0.40 ms per token,  2477.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.39 ms /    11 tokens (   58.13 ms per token,    17.20 tokens per second)\n",
      "llama_print_timings:        eval time =   25254.42 ms /    37 runs   (  682.55 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   26009.00 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.52 ms /    49 runs   (    0.42 ms per token,  2388.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.22 ms /    12 tokens (   54.02 ms per token,    18.51 tokens per second)\n",
      "llama_print_timings:        eval time =   32379.98 ms /    48 runs   (  674.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   33177.99 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.37 ms /    35 runs   (    0.41 ms per token,  2435.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     621.73 ms /    11 tokens (   56.52 ms per token,    17.69 tokens per second)\n",
      "llama_print_timings:        eval time =   23227.06 ms /    34 runs   (  683.15 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   23955.48 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      21.46 ms /    51 runs   (    0.42 ms per token,  2377.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     785.94 ms /    13 tokens (   60.46 ms per token,    16.54 tokens per second)\n",
      "llama_print_timings:        eval time =   34143.04 ms /    50 runs   (  682.86 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   35085.89 ms /    63 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.30 ms /    30 runs   (    0.41 ms per token,  2438.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     729.18 ms /    12 tokens (   60.77 ms per token,    16.46 tokens per second)\n",
      "llama_print_timings:        eval time =   19838.77 ms /    29 runs   (  684.10 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20658.11 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.36 ms /    27 runs   (    0.42 ms per token,  2376.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     616.56 ms /    11 tokens (   56.05 ms per token,    17.84 tokens per second)\n",
      "llama_print_timings:        eval time =   17236.77 ms /    26 runs   (  662.95 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   17935.45 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.11 ms /    27 runs   (    0.41 ms per token,  2431.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     606.01 ms /    11 tokens (   55.09 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:        eval time =   17397.61 ms /    26 runs   (  669.14 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   18085.19 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.60 ms /    67 runs   (    0.41 ms per token,  2427.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.13 ms /    12 tokens (   54.51 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   45075.80 ms /    66 runs   (  682.97 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   45933.94 ms /    78 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.00 ms /    37 runs   (    0.41 ms per token,  2467.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.80 ms /    12 tokens (   55.32 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =   24421.92 ms /    36 runs   (  678.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   25195.61 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.46 ms /    30 runs   (    0.42 ms per token,  2408.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.36 ms /    12 tokens (   54.53 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   19361.22 ms /    29 runs   (  667.63 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20106.06 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.87 ms /    50 runs   (    0.42 ms per token,  2395.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     615.41 ms /    11 tokens (   55.95 ms per token,    17.87 tokens per second)\n",
      "llama_print_timings:        eval time =   33456.14 ms /    49 runs   (  682.78 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   34221.80 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.42 ms /    32 runs   (    0.42 ms per token,  2384.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     738.44 ms /    14 tokens (   52.75 ms per token,    18.96 tokens per second)\n",
      "llama_print_timings:        eval time =   21091.52 ms /    31 runs   (  680.37 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   21927.67 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3700 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.41 ms /    30 runs   (    0.41 ms per token,  2417.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.32 ms /    12 tokens (   54.61 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   19646.25 ms /    29 runs   (  677.46 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20392.84 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.62 ms /    23 runs   (    0.42 ms per token,  2391.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.12 ms /    12 tokens (   56.84 ms per token,    17.59 tokens per second)\n",
      "llama_print_timings:        eval time =   14916.60 ms /    22 runs   (  678.03 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   15668.78 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.12 ms /    29 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     668.95 ms /    12 tokens (   55.75 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =   19048.41 ms /    28 runs   (  680.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19805.48 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.94 ms /    61 runs   (    0.43 ms per token,  2351.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     672.97 ms /    12 tokens (   56.08 ms per token,    17.83 tokens per second)\n",
      "llama_print_timings:        eval time =   40955.65 ms /    60 runs   (  682.59 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   41816.97 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.50 ms /    37 runs   (    0.42 ms per token,  2387.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     612.73 ms /    11 tokens (   55.70 ms per token,    17.95 tokens per second)\n",
      "llama_print_timings:        eval time =   24896.36 ms /    36 runs   (  691.57 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   25623.00 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.77 ms /    30 runs   (    0.43 ms per token,  2348.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.40 ms /    11 tokens (   59.40 ms per token,    16.83 tokens per second)\n",
      "llama_print_timings:        eval time =   19953.57 ms /    29 runs   (  688.05 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   20699.98 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      28.78 ms /    68 runs   (    0.42 ms per token,  2363.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     674.09 ms /    12 tokens (   56.17 ms per token,    17.80 tokens per second)\n",
      "llama_print_timings:        eval time =   46148.93 ms /    67 runs   (  688.79 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   47035.44 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.18 ms /    36 runs   (    0.42 ms per token,  2372.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     707.93 ms /    13 tokens (   54.46 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =   24753.39 ms /    35 runs   (  707.24 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   25573.90 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      39.65 ms /    94 runs   (    0.42 ms per token,  2370.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.67 ms /    12 tokens (   55.31 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =   63845.69 ms /    93 runs   (  686.51 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   64802.25 ms /   105 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.34 ms /    61 runs   (    0.42 ms per token,  2407.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     712.54 ms /    13 tokens (   54.81 ms per token,    18.24 tokens per second)\n",
      "llama_print_timings:        eval time =   40859.33 ms /    60 runs   (  680.99 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   41758.56 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.48 ms /    30 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.73 ms /    12 tokens (   57.73 ms per token,    17.32 tokens per second)\n",
      "llama_print_timings:        eval time =   19970.06 ms /    29 runs   (  688.62 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   20755.27 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.75 ms /    59 runs   (    0.44 ms per token,  2291.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     614.29 ms /    11 tokens (   55.84 ms per token,    17.91 tokens per second)\n",
      "llama_print_timings:        eval time =   39856.38 ms /    58 runs   (  687.18 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   40656.97 ms /    69 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.65 ms /    30 runs   (    0.42 ms per token,  2370.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     854.48 ms /    12 tokens (   71.21 ms per token,    14.04 tokens per second)\n",
      "llama_print_timings:        eval time =   19583.44 ms /    29 runs   (  675.29 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20531.56 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.66 ms /    30 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     620.44 ms /    11 tokens (   56.40 ms per token,    17.73 tokens per second)\n",
      "llama_print_timings:        eval time =   20218.48 ms /    29 runs   (  697.19 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =   20931.03 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.42 ms /    30 runs   (    0.41 ms per token,  2416.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     699.41 ms /    13 tokens (   53.80 ms per token,    18.59 tokens per second)\n",
      "llama_print_timings:        eval time =   19797.46 ms /    29 runs   (  682.67 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20586.96 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.51 ms /    30 runs   (    0.42 ms per token,  2399.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     755.25 ms /    12 tokens (   62.94 ms per token,    15.89 tokens per second)\n",
      "llama_print_timings:        eval time =   20409.15 ms /    29 runs   (  703.76 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   21257.12 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.32 ms /    30 runs   (    0.41 ms per token,  2435.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.67 ms /    12 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   19913.37 ms /    29 runs   (  686.67 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20652.27 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.64 ms /    59 runs   (    0.42 ms per token,  2394.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.06 ms /    12 tokens (   57.67 ms per token,    17.34 tokens per second)\n",
      "llama_print_timings:        eval time =   40301.98 ms /    58 runs   (  694.86 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   41174.75 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.04 ms /    33 runs   (    0.43 ms per token,  2350.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     689.56 ms /    12 tokens (   57.46 ms per token,    17.40 tokens per second)\n",
      "llama_print_timings:        eval time =   21888.61 ms /    32 runs   (  684.02 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   22678.02 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.43 ms /    30 runs   (    0.41 ms per token,  2412.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     676.21 ms /    12 tokens (   56.35 ms per token,    17.75 tokens per second)\n",
      "llama_print_timings:        eval time =   19917.77 ms /    29 runs   (  686.82 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20684.31 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.16 ms /    59 runs   (    0.43 ms per token,  2344.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     673.57 ms /    12 tokens (   56.13 ms per token,    17.82 tokens per second)\n",
      "llama_print_timings:        eval time =   39401.69 ms /    58 runs   (  679.34 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   40257.27 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.41 ms /    25 runs   (    0.42 ms per token,  2402.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.30 ms /    11 tokens (   62.12 ms per token,    16.10 tokens per second)\n",
      "llama_print_timings:        eval time =   16223.65 ms /    24 runs   (  675.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   16983.12 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.67 ms /    30 runs   (    0.42 ms per token,  2367.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     694.23 ms /    13 tokens (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:        eval time =   19637.02 ms /    29 runs   (  677.14 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20424.36 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.70 ms /    30 runs   (    0.42 ms per token,  2362.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     738.67 ms /    13 tokens (   56.82 ms per token,    17.60 tokens per second)\n",
      "llama_print_timings:        eval time =   19408.47 ms /    29 runs   (  669.26 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20240.40 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.61 ms /    30 runs   (    0.45 ms per token,  2204.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.44 ms /    12 tokens (   54.62 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   19759.33 ms /    29 runs   (  681.36 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20511.83 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.39 ms /    30 runs   (    0.41 ms per token,  2421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     759.68 ms /    12 tokens (   63.31 ms per token,    15.80 tokens per second)\n",
      "llama_print_timings:        eval time =   19805.11 ms /    29 runs   (  682.93 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20656.24 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.47 ms /    29 runs   (    0.43 ms per token,  2326.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.66 ms /    11 tokens (   54.61 ms per token,    18.31 tokens per second)\n",
      "llama_print_timings:        eval time =   19801.56 ms /    28 runs   (  707.20 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   20492.76 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.57 ms /    30 runs   (    0.42 ms per token,  2386.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     667.33 ms /    12 tokens (   55.61 ms per token,    17.98 tokens per second)\n",
      "llama_print_timings:        eval time =   21042.10 ms /    29 runs   (  725.59 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =   21802.56 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.33 ms /    61 runs   (    0.45 ms per token,  2231.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     780.57 ms /    13 tokens (   60.04 ms per token,    16.65 tokens per second)\n",
      "llama_print_timings:        eval time =   42678.45 ms /    60 runs   (  711.31 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =   43653.21 ms /    73 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       8.28 ms /    19 runs   (    0.44 ms per token,  2294.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     666.79 ms /    12 tokens (   55.57 ms per token,    18.00 tokens per second)\n",
      "llama_print_timings:        eval time =   12467.39 ms /    18 runs   (  692.63 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   13193.82 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.58 ms /    25 runs   (    0.42 ms per token,  2363.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.36 ms /    12 tokens (   55.28 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =   16561.70 ms /    24 runs   (  690.07 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   17301.42 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      18.03 ms /    43 runs   (    0.42 ms per token,  2384.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     700.95 ms /    13 tokens (   53.92 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   28789.32 ms /    42 runs   (  685.46 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   29623.11 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.38 ms /    30 runs   (    0.41 ms per token,  2423.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.81 ms /    12 tokens (   54.65 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =   19705.74 ms /    29 runs   (  679.51 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20453.06 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.24 ms /    30 runs   (    0.41 ms per token,  2451.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     668.46 ms /    12 tokens (   55.70 ms per token,    17.95 tokens per second)\n",
      "llama_print_timings:        eval time =   19901.91 ms /    29 runs   (  686.27 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20660.81 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.32 ms /    30 runs   (    0.41 ms per token,  2435.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.78 ms /    12 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   19717.56 ms /    29 runs   (  679.92 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20454.68 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.38 ms /    30 runs   (    0.41 ms per token,  2423.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     724.00 ms /    12 tokens (   60.33 ms per token,    16.57 tokens per second)\n",
      "llama_print_timings:        eval time =   19761.12 ms /    29 runs   (  681.42 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20576.80 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.63 ms /    30 runs   (    0.42 ms per token,  2375.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.51 ms /    12 tokens (   54.46 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:        eval time =   19914.03 ms /    29 runs   (  686.69 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20659.80 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      25.43 ms /    61 runs   (    0.42 ms per token,  2398.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     601.74 ms /    11 tokens (   54.70 ms per token,    18.28 tokens per second)\n",
      "llama_print_timings:        eval time =   41601.86 ms /    60 runs   (  693.36 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   42388.52 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.73 ms /    36 runs   (    0.41 ms per token,  2444.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     688.45 ms /    13 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   23900.99 ms /    35 runs   (  682.89 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   24698.56 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.93 ms /    30 runs   (    0.43 ms per token,  2319.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     813.93 ms /    12 tokens (   67.83 ms per token,    14.74 tokens per second)\n",
      "llama_print_timings:        eval time =   19729.30 ms /    29 runs   (  680.32 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20636.32 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      30.88 ms /    73 runs   (    0.42 ms per token,  2363.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.96 ms /    11 tokens (   59.00 ms per token,    16.95 tokens per second)\n",
      "llama_print_timings:        eval time =   49680.01 ms /    72 runs   (  690.00 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   50553.23 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.51 ms /    30 runs   (    0.42 ms per token,  2397.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.62 ms /    12 tokens (   55.30 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =   20105.06 ms /    29 runs   (  693.28 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   20860.16 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.43 ms /    30 runs   (    0.41 ms per token,  2413.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     603.21 ms /    11 tokens (   54.84 ms per token,    18.24 tokens per second)\n",
      "llama_print_timings:        eval time =   20078.39 ms /    29 runs   (  692.36 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   20772.16 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.79 ms /    24 runs   (    0.41 ms per token,  2451.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     660.30 ms /    12 tokens (   55.03 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:        eval time =   15623.58 ms /    23 runs   (  679.29 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   16356.61 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.83 ms /    28 runs   (    0.42 ms per token,  2367.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     708.14 ms /    12 tokens (   59.01 ms per token,    16.95 tokens per second)\n",
      "llama_print_timings:        eval time =   18606.13 ms /    27 runs   (  689.12 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   19399.45 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.70 ms /    30 runs   (    0.42 ms per token,  2362.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.34 ms /    11 tokens (   54.12 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   19826.19 ms /    29 runs   (  683.66 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20513.18 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.76 ms /    31 runs   (    0.41 ms per token,  2428.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     791.50 ms /    13 tokens (   60.88 ms per token,    16.42 tokens per second)\n",
      "llama_print_timings:        eval time =   20513.48 ms /    30 runs   (  683.78 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   21398.88 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.22 ms /    30 runs   (    0.41 ms per token,  2455.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.75 ms /    12 tokens (   53.73 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   19606.92 ms /    29 runs   (  676.10 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20341.72 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.43 ms /    25 runs   (    0.42 ms per token,  2396.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     703.04 ms /    12 tokens (   58.59 ms per token,    17.07 tokens per second)\n",
      "llama_print_timings:        eval time =   16532.64 ms /    24 runs   (  688.86 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   17315.14 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.06 ms /    27 runs   (    0.41 ms per token,  2440.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     604.64 ms /    11 tokens (   54.97 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:        eval time =   17578.58 ms /    26 runs   (  676.10 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   18264.47 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      42.67 ms /   102 runs   (    0.42 ms per token,  2390.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.30 ms /    12 tokens (   53.61 ms per token,    18.65 tokens per second)\n",
      "llama_print_timings:        eval time =   69205.83 ms /   101 runs   (  685.21 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   70165.31 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      82.37 ms /   197 runs   (    0.42 ms per token,  2391.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.79 ms /    12 tokens (   54.40 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =  132502.91 ms /   196 runs   (  676.04 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =  133776.86 ms /   208 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.12 ms /    30 runs   (    0.40 ms per token,  2475.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     874.60 ms /    12 tokens (   72.88 ms per token,    13.72 tokens per second)\n",
      "llama_print_timings:        eval time =   19621.39 ms /    29 runs   (  676.60 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20587.65 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.51 ms /    33 runs   (    0.41 ms per token,  2443.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     733.21 ms /    14 tokens (   52.37 ms per token,    19.09 tokens per second)\n",
      "llama_print_timings:        eval time =   21719.13 ms /    32 runs   (  678.72 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22550.93 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.06 ms /    48 runs   (    0.42 ms per token,  2392.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     653.09 ms /    12 tokens (   54.42 ms per token,    18.37 tokens per second)\n",
      "llama_print_timings:        eval time =   31822.81 ms /    47 runs   (  677.08 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   32622.81 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.29 ms /    30 runs   (    0.41 ms per token,  2440.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     597.60 ms /    11 tokens (   54.33 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:        eval time =   19738.49 ms /    29 runs   (  680.64 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20426.46 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      42.43 ms /   100 runs   (    0.42 ms per token,  2356.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.18 ms /    12 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:        eval time =   67295.52 ms /    99 runs   (  679.75 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   68252.18 ms /   111 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.48 ms /    33 runs   (    0.41 ms per token,  2447.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     613.16 ms /    11 tokens (   55.74 ms per token,    17.94 tokens per second)\n",
      "llama_print_timings:        eval time =   21286.74 ms /    32 runs   (  665.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   21999.80 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.32 ms /    42 runs   (    0.41 ms per token,  2424.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.33 ms /    12 tokens (   53.69 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   27822.12 ms /    41 runs   (  678.59 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   28594.59 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      33.91 ms /    81 runs   (    0.42 ms per token,  2388.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     678.83 ms /    12 tokens (   56.57 ms per token,    17.68 tokens per second)\n",
      "llama_print_timings:        eval time =   54188.49 ms /    80 runs   (  677.36 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   55117.26 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.23 ms /    30 runs   (    0.41 ms per token,  2453.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.12 ms /    13 tokens (   52.78 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   19413.05 ms /    29 runs   (  669.42 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20188.73 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      37.45 ms /    89 runs   (    0.42 ms per token,  2376.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     657.20 ms /    12 tokens (   54.77 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =   58817.05 ms /    88 runs   (  668.38 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   59747.66 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.77 ms /    60 runs   (    0.41 ms per token,  2422.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.71 ms /    12 tokens (   53.64 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   39792.30 ms /    59 runs   (  674.45 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   40621.13 ms /    71 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.23 ms /    30 runs   (    0.41 ms per token,  2452.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     618.54 ms /    11 tokens (   56.23 ms per token,    17.78 tokens per second)\n",
      "llama_print_timings:        eval time =   19246.89 ms /    29 runs   (  663.69 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   19954.63 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.42 ms /    38 runs   (    0.41 ms per token,  2463.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     600.07 ms /    11 tokens (   54.55 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   24565.13 ms /    37 runs   (  663.92 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =   25279.18 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.51 ms /    30 runs   (    0.42 ms per token,  2398.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.14 ms /    12 tokens (   54.51 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:        eval time =   19722.42 ms /    29 runs   (  680.08 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20468.91 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.60 ms /    30 runs   (    0.42 ms per token,  2380.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     711.42 ms /    13 tokens (   54.72 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =   19472.08 ms /    29 runs   (  671.45 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20277.37 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.51 ms /    60 runs   (    0.41 ms per token,  2447.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     606.57 ms /    11 tokens (   55.14 ms per token,    18.13 tokens per second)\n",
      "llama_print_timings:        eval time =   40041.32 ms /    59 runs   (  678.67 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   40829.37 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.22 ms /    30 runs   (    0.41 ms per token,  2454.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     625.54 ms /    11 tokens (   56.87 ms per token,    17.58 tokens per second)\n",
      "llama_print_timings:        eval time =   19331.46 ms /    29 runs   (  666.60 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20046.80 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.76 ms /    30 runs   (    0.43 ms per token,  2351.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.09 ms /    12 tokens (   54.34 ms per token,    18.40 tokens per second)\n",
      "llama_print_timings:        eval time =   19360.49 ms /    29 runs   (  667.60 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20101.94 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.63 ms /    30 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     673.77 ms /    12 tokens (   56.15 ms per token,    17.81 tokens per second)\n",
      "llama_print_timings:        eval time =   19708.96 ms /    29 runs   (  679.62 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20476.80 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.18 ms /    30 runs   (    0.41 ms per token,  2462.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     629.69 ms /    11 tokens (   57.24 ms per token,    17.47 tokens per second)\n",
      "llama_print_timings:        eval time =   19552.85 ms /    29 runs   (  674.24 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20272.56 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.45 ms /    30 runs   (    0.41 ms per token,  2410.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.50 ms /    12 tokens (   53.96 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:        eval time =   19291.20 ms /    29 runs   (  665.21 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20028.51 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.34 ms /    30 runs   (    0.41 ms per token,  2430.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.42 ms /    13 tokens (   53.72 ms per token,    18.61 tokens per second)\n",
      "llama_print_timings:        eval time =   19613.98 ms /    29 runs   (  676.34 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20402.67 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.92 ms /    27 runs   (    0.40 ms per token,  2473.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     616.61 ms /    11 tokens (   56.06 ms per token,    17.84 tokens per second)\n",
      "llama_print_timings:        eval time =   17729.96 ms /    26 runs   (  681.92 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18427.00 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.17 ms /    30 runs   (    0.41 ms per token,  2465.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.01 ms /    12 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:        eval time =   19810.51 ms /    29 runs   (  683.12 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20535.23 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.69 ms /    33 runs   (    0.41 ms per token,  2410.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.57 ms /    12 tokens (   53.88 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   21469.23 ms /    32 runs   (  670.91 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   22214.65 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.66 ms /    36 runs   (    0.41 ms per token,  2454.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.60 ms /    12 tokens (   53.47 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   23923.90 ms /    35 runs   (  683.54 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   24676.52 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.04 ms /    41 runs   (    0.42 ms per token,  2405.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     839.72 ms /    13 tokens (   64.59 ms per token,    15.48 tokens per second)\n",
      "llama_print_timings:        eval time =   27509.18 ms /    40 runs   (  687.73 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   28475.94 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.37 ms /    30 runs   (    0.41 ms per token,  2425.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     648.74 ms /    12 tokens (   54.06 ms per token,    18.50 tokens per second)\n",
      "llama_print_timings:        eval time =   19935.41 ms /    29 runs   (  687.43 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   20677.13 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.53 ms /    30 runs   (    0.42 ms per token,  2393.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     620.84 ms /    11 tokens (   56.44 ms per token,    17.72 tokens per second)\n",
      "llama_print_timings:        eval time =   19671.21 ms /    29 runs   (  678.32 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20382.17 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.39 ms /    30 runs   (    0.41 ms per token,  2420.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.77 ms /    12 tokens (   53.48 ms per token,    18.70 tokens per second)\n",
      "llama_print_timings:        eval time =   19645.14 ms /    29 runs   (  677.42 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20377.25 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.62 ms /    30 runs   (    0.42 ms per token,  2376.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     658.10 ms /    12 tokens (   54.84 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =   19757.82 ms /    29 runs   (  681.30 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20508.01 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.60 ms /    30 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     611.98 ms /    11 tokens (   55.63 ms per token,    17.97 tokens per second)\n",
      "llama_print_timings:        eval time =   20165.93 ms /    29 runs   (  695.38 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   20870.82 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.52 ms /    30 runs   (    0.42 ms per token,  2396.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     930.26 ms /    12 tokens (   77.52 ms per token,    12.90 tokens per second)\n",
      "llama_print_timings:        eval time =   20482.86 ms /    29 runs   (  706.31 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =   21505.28 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.59 ms /    30 runs   (    0.42 ms per token,  2383.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.79 ms /    11 tokens (   59.62 ms per token,    16.77 tokens per second)\n",
      "llama_print_timings:        eval time =   19743.32 ms /    29 runs   (  680.80 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20489.93 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.04 ms /    30 runs   (    0.43 ms per token,  2300.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     897.64 ms /    13 tokens (   69.05 ms per token,    14.48 tokens per second)\n",
      "llama_print_timings:        eval time =   19707.85 ms /    29 runs   (  679.58 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20699.45 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.16 ms /    53 runs   (    0.42 ms per token,  2391.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     739.35 ms /    12 tokens (   61.61 ms per token,    16.23 tokens per second)\n",
      "llama_print_timings:        eval time =   35827.94 ms /    52 runs   (  689.00 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   36728.57 ms /    64 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.63 ms /    30 runs   (    0.42 ms per token,  2375.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     666.20 ms /    12 tokens (   55.52 ms per token,    18.01 tokens per second)\n",
      "llama_print_timings:        eval time =   19275.02 ms /    29 runs   (  664.66 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20032.68 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.97 ms /    37 runs   (    0.40 ms per token,  2471.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.75 ms /    12 tokens (   56.98 ms per token,    17.55 tokens per second)\n",
      "llama_print_timings:        eval time =   24765.35 ms /    36 runs   (  687.93 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   25561.34 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.56 ms /    33 runs   (    0.41 ms per token,  2433.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     668.07 ms /    12 tokens (   55.67 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:        eval time =   21737.88 ms /    32 runs   (  679.31 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   22505.74 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.19 ms /    55 runs   (    0.42 ms per token,  2371.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     725.75 ms /    13 tokens (   55.83 ms per token,    17.91 tokens per second)\n",
      "llama_print_timings:        eval time =   36531.73 ms /    54 runs   (  676.51 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   37426.69 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.09 ms /    55 runs   (    0.44 ms per token,  2283.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     832.25 ms /    11 tokens (   75.66 ms per token,    13.22 tokens per second)\n",
      "llama_print_timings:        eval time =   37592.33 ms /    54 runs   (  696.15 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   38597.02 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.66 ms /    42 runs   (    0.42 ms per token,  2378.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.77 ms /    11 tokens (   57.98 ms per token,    17.25 tokens per second)\n",
      "llama_print_timings:        eval time =   28076.28 ms /    41 runs   (  684.79 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   28843.38 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.86 ms /    36 runs   (    0.41 ms per token,  2423.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     702.45 ms /    12 tokens (   58.54 ms per token,    17.08 tokens per second)\n",
      "llama_print_timings:        eval time =   23949.00 ms /    35 runs   (  684.26 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   24760.20 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.33 ms /    49 runs   (    0.41 ms per token,  2409.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     594.87 ms /    11 tokens (   54.08 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:        eval time =   32683.35 ms /    48 runs   (  680.90 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   33426.43 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.27 ms /    41 runs   (    0.42 ms per token,  2373.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     665.19 ms /    12 tokens (   55.43 ms per token,    18.04 tokens per second)\n",
      "llama_print_timings:        eval time =   27863.05 ms /    40 runs   (  696.58 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   28653.29 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.67 ms /    36 runs   (    0.41 ms per token,  2454.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     748.98 ms /    13 tokens (   57.61 ms per token,    17.36 tokens per second)\n",
      "llama_print_timings:        eval time =   23754.30 ms /    35 runs   (  678.69 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   24614.05 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.38 ms /    55 runs   (    0.43 ms per token,  2352.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     607.41 ms /    11 tokens (   55.22 ms per token,    18.11 tokens per second)\n",
      "llama_print_timings:        eval time =   37436.90 ms /    54 runs   (  693.28 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   38213.85 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.48 ms /    30 runs   (    0.42 ms per token,  2404.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.96 ms /    12 tokens (   55.00 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =   19658.39 ms /    29 runs   (  677.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20408.66 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 3800 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.27 ms /    31 runs   (    0.43 ms per token,  2336.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     786.09 ms /    12 tokens (   65.51 ms per token,    15.27 tokens per second)\n",
      "llama_print_timings:        eval time =   20897.93 ms /    30 runs   (  696.60 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   21779.32 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.93 ms /    36 runs   (    0.41 ms per token,  2411.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     669.40 ms /    12 tokens (   55.78 ms per token,    17.93 tokens per second)\n",
      "llama_print_timings:        eval time =   23784.93 ms /    35 runs   (  679.57 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   24563.88 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      27.85 ms /    67 runs   (    0.42 ms per token,  2406.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     742.41 ms /    13 tokens (   57.11 ms per token,    17.51 tokens per second)\n",
      "llama_print_timings:        eval time =   47035.23 ms /    66 runs   (  712.65 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   47982.68 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.22 ms /    30 runs   (    0.41 ms per token,  2453.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.81 ms /    12 tokens (   57.15 ms per token,    17.50 tokens per second)\n",
      "llama_print_timings:        eval time =   20203.90 ms /    29 runs   (  696.69 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   20981.09 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      28.91 ms /    68 runs   (    0.43 ms per token,  2352.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.59 ms /    12 tokens (   57.80 ms per token,    17.30 tokens per second)\n",
      "llama_print_timings:        eval time =   45683.59 ms /    67 runs   (  681.84 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   46592.21 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.18 ms /    37 runs   (    0.41 ms per token,  2437.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     612.12 ms /    11 tokens (   55.65 ms per token,    17.97 tokens per second)\n",
      "llama_print_timings:        eval time =   24380.77 ms /    36 runs   (  677.24 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   25106.41 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.17 ms /    36 runs   (    0.42 ms per token,  2372.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     698.88 ms /    12 tokens (   58.24 ms per token,    17.17 tokens per second)\n",
      "llama_print_timings:        eval time =   23855.96 ms /    35 runs   (  681.60 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   24666.72 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.87 ms /    59 runs   (    0.42 ms per token,  2372.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     681.44 ms /    12 tokens (   56.79 ms per token,    17.61 tokens per second)\n",
      "llama_print_timings:        eval time =   39851.36 ms /    58 runs   (  687.09 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   40716.68 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      49.53 ms /   116 runs   (    0.43 ms per token,  2342.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     654.70 ms /    12 tokens (   54.56 ms per token,    18.33 tokens per second)\n",
      "llama_print_timings:        eval time =   78129.30 ms /   115 runs   (  679.39 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   79150.63 ms /   127 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.13 ms /    27 runs   (    0.41 ms per token,  2425.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     700.18 ms /    13 tokens (   53.86 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   17307.55 ms /    26 runs   (  665.68 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   18090.48 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.03 ms /    27 runs   (    0.41 ms per token,  2447.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     595.82 ms /    11 tokens (   54.17 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   16874.49 ms /    26 runs   (  649.02 ms per token,     1.54 tokens per second)\n",
      "llama_print_timings:       total time =   17552.59 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      36.92 ms /    88 runs   (    0.42 ms per token,  2383.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.84 ms /    12 tokens (   54.74 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =   60272.37 ms /    87 runs   (  692.79 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   61198.54 ms /    99 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.58 ms /    30 runs   (    0.42 ms per token,  2385.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     658.89 ms /    12 tokens (   54.91 ms per token,    18.21 tokens per second)\n",
      "llama_print_timings:        eval time =   19938.06 ms /    29 runs   (  687.52 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   20688.02 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.75 ms /    30 runs   (    0.42 ms per token,  2353.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     705.82 ms /    11 tokens (   64.17 ms per token,    15.58 tokens per second)\n",
      "llama_print_timings:        eval time =   19996.61 ms /    29 runs   (  689.54 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   20794.69 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.12 ms /    29 runs   (    0.42 ms per token,  2392.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     713.39 ms /    12 tokens (   59.45 ms per token,    16.82 tokens per second)\n",
      "llama_print_timings:        eval time =   19023.33 ms /    28 runs   (  679.40 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   19826.46 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.73 ms /    30 runs   (    0.42 ms per token,  2355.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     778.77 ms /    14 tokens (   55.63 ms per token,    17.98 tokens per second)\n",
      "llama_print_timings:        eval time =   19534.90 ms /    29 runs   (  673.62 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20405.04 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.14 ms /    21 runs   (    0.44 ms per token,  2298.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     825.16 ms /    12 tokens (   68.76 ms per token,    14.54 tokens per second)\n",
      "llama_print_timings:        eval time =   14245.36 ms /    20 runs   (  712.27 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =   15135.93 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =       9.73 ms /    23 runs   (    0.42 ms per token,  2362.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     750.40 ms /    12 tokens (   62.53 ms per token,    15.99 tokens per second)\n",
      "llama_print_timings:        eval time =   14859.07 ms /    22 runs   (  675.41 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   15679.81 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      20.96 ms /    49 runs   (    0.43 ms per token,  2337.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.83 ms /    12 tokens (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:        eval time =   33172.40 ms /    48 runs   (  691.09 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   33970.79 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.67 ms /    30 runs   (    0.42 ms per token,  2367.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     617.79 ms /    11 tokens (   56.16 ms per token,    17.81 tokens per second)\n",
      "llama_print_timings:        eval time =   19903.96 ms /    29 runs   (  686.34 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20612.53 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      22.95 ms /    55 runs   (    0.42 ms per token,  2396.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     669.99 ms /    12 tokens (   55.83 ms per token,    17.91 tokens per second)\n",
      "llama_print_timings:        eval time =   37056.15 ms /    54 runs   (  686.23 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   37894.58 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.42 ms /    37 runs   (    0.42 ms per token,  2399.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.59 ms /    12 tokens (   53.55 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   24560.21 ms /    36 runs   (  682.23 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   25313.80 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.44 ms /    34 runs   (    0.42 ms per token,  2355.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     655.76 ms /    12 tokens (   54.65 ms per token,    18.30 tokens per second)\n",
      "llama_print_timings:        eval time =   22602.88 ms /    33 runs   (  684.94 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   23362.75 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.51 ms /    30 runs   (    0.45 ms per token,  2220.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     685.90 ms /    13 tokens (   52.76 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:        eval time =   19769.05 ms /    29 runs   (  681.69 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20552.68 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.49 ms /    30 runs   (    0.42 ms per token,  2401.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     659.95 ms /    12 tokens (   55.00 ms per token,    18.18 tokens per second)\n",
      "llama_print_timings:        eval time =   19376.53 ms /    29 runs   (  668.16 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20130.22 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.44 ms /    30 runs   (    0.41 ms per token,  2410.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     682.43 ms /    12 tokens (   56.87 ms per token,    17.58 tokens per second)\n",
      "llama_print_timings:        eval time =   19830.51 ms /    29 runs   (  683.81 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20604.70 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.29 ms /    46 runs   (    0.42 ms per token,  2385.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     644.38 ms /    12 tokens (   53.70 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:        eval time =   30311.20 ms /    45 runs   (  673.58 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   31095.78 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.69 ms /    59 runs   (    0.42 ms per token,  2390.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.97 ms /    12 tokens (   54.16 ms per token,    18.46 tokens per second)\n",
      "llama_print_timings:        eval time =   39193.92 ms /    58 runs   (  675.76 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   40024.64 ms /    70 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      37.74 ms /    88 runs   (    0.43 ms per token,  2331.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     690.75 ms /    13 tokens (   53.13 ms per token,    18.82 tokens per second)\n",
      "llama_print_timings:        eval time =   59964.80 ms /    87 runs   (  689.25 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   60933.88 ms /   100 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.09 ms /    30 runs   (    0.40 ms per token,  2481.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.04 ms /    12 tokens (   53.75 ms per token,    18.60 tokens per second)\n",
      "llama_print_timings:        eval time =   19744.77 ms /    29 runs   (  680.85 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20479.81 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.43 ms /    30 runs   (    0.41 ms per token,  2413.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     602.26 ms /    11 tokens (   54.75 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:        eval time =   19799.72 ms /    29 runs   (  682.75 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20493.17 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.58 ms /    30 runs   (    0.45 ms per token,  2209.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.43 ms /    12 tokens (   53.37 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:        eval time =   19430.56 ms /    29 runs   (  670.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20168.34 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.23 ms /    30 runs   (    0.41 ms per token,  2452.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     643.93 ms /    12 tokens (   53.66 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:        eval time =   19396.99 ms /    29 runs   (  668.86 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20132.71 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      42.84 ms /   101 runs   (    0.42 ms per token,  2357.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.67 ms /    13 tokens (   52.90 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   68259.72 ms /   100 runs   (  682.60 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   69259.62 ms /   113 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.43 ms /    30 runs   (    0.41 ms per token,  2412.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.87 ms /    12 tokens (   53.24 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   19300.22 ms /    29 runs   (  665.52 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20029.69 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.32 ms /    30 runs   (    0.41 ms per token,  2435.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.23 ms /    12 tokens (   55.27 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =   19598.60 ms /    29 runs   (  675.81 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20352.29 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.24 ms /    30 runs   (    0.41 ms per token,  2450.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.30 ms /    12 tokens (   54.19 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:        eval time =   19876.49 ms /    29 runs   (  685.40 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20617.69 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.09 ms /    29 runs   (    0.42 ms per token,  2398.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.89 ms /    12 tokens (   53.57 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   18906.22 ms /    28 runs   (  675.22 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   19637.94 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.21 ms /    30 runs   (    0.41 ms per token,  2456.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     700.47 ms /    13 tokens (   53.88 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   19849.07 ms /    29 runs   (  684.45 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20640.05 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      17.27 ms /    41 runs   (    0.42 ms per token,  2373.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.79 ms /    12 tokens (   53.90 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   27557.17 ms /    40 runs   (  688.93 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   28327.68 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.31 ms /    30 runs   (    0.41 ms per token,  2437.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.68 ms /    12 tokens (   53.56 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   19603.72 ms /    29 runs   (  675.99 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20337.11 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.87 ms /    36 runs   (    0.41 ms per token,  2421.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.36 ms /    12 tokens (   53.86 ms per token,    18.57 tokens per second)\n",
      "llama_print_timings:        eval time =   24065.13 ms /    35 runs   (  687.58 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   24820.15 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.48 ms /    30 runs   (    0.42 ms per token,  2403.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.20 ms /    11 tokens (   59.02 ms per token,    16.94 tokens per second)\n",
      "llama_print_timings:        eval time =   19277.04 ms /    29 runs   (  664.73 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20016.88 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      32.48 ms /    78 runs   (    0.42 ms per token,  2401.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.12 ms /    12 tokens (   53.26 ms per token,    18.78 tokens per second)\n",
      "llama_print_timings:        eval time =   53263.82 ms /    77 runs   (  691.74 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =   54140.97 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      28.39 ms /    66 runs   (    0.43 ms per token,  2324.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     593.16 ms /    11 tokens (   53.92 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:        eval time =   43360.44 ms /    65 runs   (  667.08 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   44162.17 ms /    76 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.95 ms /    56 runs   (    0.43 ms per token,  2338.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.24 ms /    12 tokens (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_print_timings:        eval time =   37473.12 ms /    55 runs   (  681.33 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   38280.31 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.20 ms /    30 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.33 ms /    13 tokens (   52.79 ms per token,    18.94 tokens per second)\n",
      "llama_print_timings:        eval time =   19642.18 ms /    29 runs   (  677.32 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20424.75 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.62 ms /    30 runs   (    0.42 ms per token,  2376.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     692.39 ms /    12 tokens (   57.70 ms per token,    17.33 tokens per second)\n",
      "llama_print_timings:        eval time =   19670.30 ms /    29 runs   (  678.29 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20453.23 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.40 ms /    30 runs   (    0.41 ms per token,  2420.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.55 ms /    12 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_print_timings:        eval time =   19808.71 ms /    29 runs   (  683.06 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20534.17 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      15.92 ms /    38 runs   (    0.42 ms per token,  2386.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     663.73 ms /    12 tokens (   55.31 ms per token,    18.08 tokens per second)\n",
      "llama_print_timings:        eval time =   24864.74 ms /    37 runs   (  672.02 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   25645.14 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      33.34 ms /    81 runs   (    0.41 ms per token,  2429.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     716.90 ms /    13 tokens (   55.15 ms per token,    18.13 tokens per second)\n",
      "llama_print_timings:        eval time =   53990.74 ms /    80 runs   (  674.88 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   54956.02 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      23.91 ms /    57 runs   (    0.42 ms per token,  2383.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     603.43 ms /    11 tokens (   54.86 ms per token,    18.23 tokens per second)\n",
      "llama_print_timings:        eval time =   38433.64 ms /    56 runs   (  686.31 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   39211.47 ms /    67 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.19 ms /    32 runs   (    0.41 ms per token,  2426.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.27 ms /    12 tokens (   53.44 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:        eval time =   21303.53 ms /    31 runs   (  687.21 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   22042.24 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.76 ms /    30 runs   (    0.43 ms per token,  2350.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     608.09 ms /    11 tokens (   55.28 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:        eval time =   19893.53 ms /    29 runs   (  685.98 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20594.95 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.88 ms /    36 runs   (    0.41 ms per token,  2419.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.44 ms /    12 tokens (   53.12 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:        eval time =   23444.98 ms /    35 runs   (  669.86 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   24191.65 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      84.78 ms /   195 runs   (    0.43 ms per token,  2299.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.54 ms /    12 tokens (   53.54 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:        eval time =  132413.46 ms /   194 runs   (  682.54 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =  133675.32 ms /   206 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      19.25 ms /    46 runs   (    0.42 ms per token,  2390.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.40 ms /    12 tokens (   53.87 ms per token,    18.56 tokens per second)\n",
      "llama_print_timings:        eval time =   30164.68 ms /    45 runs   (  670.33 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   30953.21 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.54 ms /    25 runs   (    0.42 ms per token,  2373.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     627.76 ms /    11 tokens (   57.07 ms per token,    17.52 tokens per second)\n",
      "llama_print_timings:        eval time =   16106.64 ms /    24 runs   (  671.11 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   16810.00 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.93 ms /    36 runs   (    0.41 ms per token,  2410.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.45 ms /    12 tokens (   54.12 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:        eval time =   23748.16 ms /    35 runs   (  678.52 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   24505.86 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.68 ms /    30 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     592.93 ms /    11 tokens (   53.90 ms per token,    18.55 tokens per second)\n",
      "llama_print_timings:        eval time =   19852.73 ms /    29 runs   (  684.58 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   20537.40 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.94 ms /    31 runs   (    0.42 ms per token,  2395.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.65 ms /    13 tokens (   52.90 ms per token,    18.90 tokens per second)\n",
      "llama_print_timings:        eval time =   20140.46 ms /    30 runs   (  671.35 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20923.84 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.41 ms /    30 runs   (    0.41 ms per token,  2417.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.70 ms /    12 tokens (   53.56 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:        eval time =   19757.16 ms /    29 runs   (  681.28 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   20491.21 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.27 ms /    55 runs   (    0.44 ms per token,  2266.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     693.86 ms /    12 tokens (   57.82 ms per token,    17.29 tokens per second)\n",
      "llama_print_timings:        eval time =   39000.69 ms /    54 runs   (  722.23 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =   39869.77 ms /    66 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.48 ms /    30 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.27 ms /    13 tokens (   52.56 ms per token,    19.03 tokens per second)\n",
      "llama_print_timings:        eval time =   19614.94 ms /    29 runs   (  676.38 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =   20388.63 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      14.75 ms /    34 runs   (    0.43 ms per token,  2305.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     641.96 ms /    12 tokens (   53.50 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:        eval time =   22891.14 ms /    33 runs   (  693.67 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =   23641.69 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      24.93 ms /    60 runs   (    0.42 ms per token,  2406.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     687.61 ms /    13 tokens (   52.89 ms per token,    18.91 tokens per second)\n",
      "llama_print_timings:        eval time =   40365.30 ms /    59 runs   (  684.16 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =   41239.84 ms /    72 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.21 ms /    27 runs   (    0.42 ms per token,  2408.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     611.55 ms /    11 tokens (   55.60 ms per token,    17.99 tokens per second)\n",
      "llama_print_timings:        eval time =   17690.79 ms /    26 runs   (  680.41 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =   18383.52 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      13.20 ms /    30 runs   (    0.44 ms per token,  2273.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     656.91 ms /    12 tokens (   54.74 ms per token,    18.27 tokens per second)\n",
      "llama_print_timings:        eval time =   19528.35 ms /    29 runs   (  673.39 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   20284.67 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.96 ms /    29 runs   (    0.41 ms per token,  2424.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     602.89 ms /    11 tokens (   54.81 ms per token,    18.25 tokens per second)\n",
      "llama_print_timings:        eval time =   18321.08 ms /    28 runs   (  654.32 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   19011.61 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      10.69 ms /    26 runs   (    0.41 ms per token,  2432.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     669.70 ms /    12 tokens (   55.81 ms per token,    17.92 tokens per second)\n",
      "llama_print_timings:        eval time =   16335.70 ms /    25 runs   (  653.43 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =   17084.70 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      12.69 ms /    31 runs   (    0.41 ms per token,  2442.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     732.40 ms /    14 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:        eval time =   20045.69 ms /    30 runs   (  668.19 ms per token,     1.50 tokens per second)\n",
      "llama_print_timings:       total time =   20874.05 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4636.77 ms\n",
      "llama_print_timings:      sample time =      11.88 ms /    29 runs   (    0.41 ms per token,  2440.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     652.75 ms /    12 tokens (   54.40 ms per token,    18.38 tokens per second)\n",
      "llama_print_timings:        eval time =   18804.63 ms /    28 runs   (  671.59 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =   19545.05 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    \n",
    "    if i%100==0:\n",
    "        print(f\"Completed {i} rows\")\n",
    "        \n",
    "    try:\n",
    "        \n",
    "        prompt= f\"List the factors of {sorted_df.iloc[i, 1]}?\"\n",
    "        \n",
    "        prompt_template=f'''You are a math assistant. I will ask you to find factors of given number. Please answer in the correct format. For example, if I ask 'List the factors of 15?' , you should answer 'factors=[1, 3, 5, 15]'. Do not include any other information in your answer.\n",
    "\n",
    "        USER: {prompt}\n",
    "        \n",
    "        ASSISTANT:'''\n",
    "        \n",
    "        response=lcpp_llm(prompt=prompt_template, max_tokens=500, temperature=0.00001, top_p=0.95,\n",
    "                    repeat_penalty=1.2, top_k=150,\n",
    "                    echo=False)\n",
    "        \n",
    "        with open('composite_factors.txt', 'a') as f:\n",
    "            answer=response[\"choices\"][0][\"text\"]\n",
    "            f.write(f\"{sorted_df.iloc[i, 1]} = {answer} \\n\")\n",
    "            \n",
    "            \n",
    "    except:\n",
    "        \n",
    "        with open('composite_factors.txt', 'a') as f:\n",
    "            f.write(f\"{sorted_df.iloc[i, 1]} = Error \\n\")\n",
    "            \n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viveksdmlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
